# 1.3.1. LLaMA-Reviewer. Advancing Code Review.2308.11148v2.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: D:\llm\notebooks\AI-Papers\1.3.1. LLaMA-Reviewer. Advancing Code Review.2308.11148v2.pdf
# KÃ­ch thÆ°á»›c file: 733550 bytes

===============================================
Ná»˜I DUNG FILE PDF
===============================================


--- TRANG 1 ---
LLaMA-Reviewer: ThÃºc Ä‘áº©y Tá»± Ä‘á»™ng hÃ³a Code Review
vá»›i Large Language Models thÃ´ng qua
Parameter-Efficient Fine-Tuning
Junyi Luâ€ â€¡, Lei Yuâ€ â€¡, Xiaojia LiÂ§, Li Yangâˆ—â€ , Chun ZuoÂ¶
â€ Institute of Software, Chinese Academy of Sciences, Beijing, China
â€¡University of Chinese Academy of Sciences, Beijing, China
Â§School of Software, Tsinghua University, Beijing, ChinaÂ¶Sinosoft Company Limited, Beijing, China
{lujunyi21, yulei21 }@mails.ucas.ac.cn, lixj21@mails.tsinghua.edu.cn,
yangli2017@iscas.ac.cn, zuochun@sinosoft.com.cn

TÃ³m táº¯t â€”Viá»‡c tá»± Ä‘á»™ng hÃ³a cÃ¡c hoáº¡t Ä‘á»™ng code review, má»™t
má»¥c tiÃªu lÃ¢u dÃ i trong ká»¹ thuáº­t pháº§n má»m, Ä‘Ã£ Ä‘Æ°á»£c giáº£i quyáº¿t chá»§ yáº¿u
bá»Ÿi nhiá»u mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ lÄ©nh vá»±c. Máº·c dÃ¹
thÃ nh cÃ´ng, nhá»¯ng mÃ´ hÃ¬nh nÃ y thÆ°á»ng Ä‘Ã²i há»i tÃ i nguyÃªn má»Ÿ rá»™ng
Ä‘á»ƒ pre-training tá»« Ä‘áº§u. NgÆ°á»£c láº¡i, Large Language
Models (LLMs) cung cáº¥p má»™t lá»±a chá»n thay tháº¿ háº¥p dáº«n, vá»›i kháº£ nÄƒng
Ä‘Ã¡ng chÃº Ã½ cá»§a chÃºng khi Ä‘Æ°á»£c bá»• sung vá»›i kiáº¿n thá»©c cá»¥ thá»ƒ lÄ©nh vá»±c.
Tuy nhiÃªn, tiá»m nÄƒng cá»§a chÃºng Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ code review
váº«n pháº§n lá»›n chÆ°a Ä‘Æ°á»£c khÃ¡m phÃ¡.

Äá»ƒ Ä‘Ã¡p á»©ng khoáº£ng trá»‘ng nghiÃªn cá»©u nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y LLaMA-Reviewer,
má»™t framework sÃ¡ng táº¡o táº­n dá»¥ng kháº£ nÄƒng cá»§a
LLaMA, má»™t LLM phá»• biáº¿n, trong lÄ©nh vá»±c code review. ChÃº Ã½ Ä‘áº¿n
cÃ¡c rÃ ng buá»™c tÃ i nguyÃªn, framework nÃ y sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-efficient
fine-tuning (PEFT), mang láº¡i hiá»‡u nÄƒng cao trong khi
sá»­ dá»¥ng Ã­t hÆ¡n 1% tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n.

Má»™t Ä‘Ã¡nh giÃ¡ má»Ÿ rá»™ng cá»§a LLaMA-Reviewer Ä‘Æ°á»£c tiáº¿n hÃ nh trÃªn
hai dataset Ä‘a dáº¡ng, cÃ³ sáºµn cÃ´ng khai. ÄÃ¡ng chÃº Ã½, ngay cáº£ vá»›i
mÃ´ hÃ¬nh cÆ¡ sá»Ÿ LLaMA nhá» nháº¥t gá»“m 6.7B tham sá»‘ vÃ 
sá»‘ lÆ°á»£ng epoch tuning háº¡n cháº¿, LLaMA-Reviewer báº±ng vá»›i
hiá»‡u nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh táº­p trung vÃ o code-review hiá»‡n cÃ³.

CÃ¡c thÃ­ nghiá»‡m ablation cung cáº¥p insight vá» áº£nh hÆ°á»Ÿng
cá»§a cÃ¡c thÃ nh pháº§n quÃ¡ trÃ¬nh fine-tuning khÃ¡c nhau, bao gá»“m biá»ƒu diá»…n Ä‘áº§u vÃ o,
instruction tuning, vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT khÃ¡c nhau. Äá»ƒ
thÃºc Ä‘áº©y tiáº¿n bá»™ liÃªn tá»¥c trong lÄ©nh vá»±c nÃ y, code vÃ  táº¥t cáº£ PEFT-
weight plugins Ä‘Ã£ Ä‘Æ°á»£c open-source.

Index Terms â€”Code Review Automation, Large Language
Models (LLMs), Parameter-Efficient Fine-Tuning (PEFT), Deep
Learning, LLaMA, Software Quality Assurance

I. GIá»šI THIá»†U
Ká»ƒ tá»« khi Ä‘Æ°á»£c chÃ­nh thá»©c hÃ³a bá»Ÿi Fagan vÃ o nÄƒm 1976 [1], code review
Ä‘Ã£ lÃ  ná»n táº£ng cá»§a ká»¹ thuáº­t pháº§n má»m, cÃ³ vai trÃ² quan trá»ng
trong viá»‡c xÃ¡c Ä‘á»‹nh lá»—i, cáº£i thiá»‡n cháº¥t lÆ°á»£ng, vÃ  chia sáº» kiáº¿n thá»©c
[2]. Tuy nhiÃªn, quÃ¡ trÃ¬nh chá»§ yáº¿u thá»§ cÃ´ng nÃ y Ã¡p Ä‘áº·t
khá»‘i lÆ°á»£ng cÃ´ng viá»‡c Ä‘Ã¡ng ká»ƒ cho cÃ¡c nhÃ  phÃ¡t triá»ƒn. Ngay cáº£ vá»›i cÃ¡c thá»±c tiá»…n code
review hiá»‡n Ä‘áº¡i (MCR), Ä‘Æ°á»£c sáº¯p xáº¿p há»£p lÃ½ hÆ¡n so vá»›i
cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng, ná»— lá»±c cáº§n thiáº¿t váº«n Ä‘Ã¡ng ká»ƒ [3]â€“[5].

Äá»ƒ giáº£m bá»›t gÃ¡nh náº·ng nÃ y, má»™t lÃ n sÃ³ng nghiÃªn cá»©u Ä‘Ã£ táº­p trung vÃ o
viá»‡c tá»± Ä‘á»™ng hÃ³a quÃ¡ trÃ¬nh code review. Äiá»u nÃ y bao gá»“m cÃ¡c nhiá»‡m vá»¥ nhÆ°
Ä‘á» xuáº¥t reviewer [6]â€“[15], Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng code
[12], [16]â€“[21], tinh chá»‰nh code cÃ³ váº¥n Ä‘á» [20], [22]â€“[25], vÃ 
táº¡o ra cÃ¡c comment review tiá»m nÄƒng [20], [23], [26]â€“[31].

âˆ—TÃ¡c giáº£ liÃªn há»‡. Nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP)
Ä‘Ã£ tiáº¿p tá»¥c cho phÃ©p viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ pre-trained
(PLMs) cho nhá»¯ng nhiá»‡m vá»¥ nÃ y [20], [23]. Tuy nhiÃªn, nhá»¯ng mÃ´ hÃ¬nh cá»¥ thá»ƒ lÄ©nh vá»±c
nhÆ° váº­y thÆ°á»ng yÃªu cáº§u tÃ i nguyÃªn Ä‘Ã¡ng ká»ƒ Ä‘á»ƒ pre-
training tá»« Ä‘áº§u.

NgÆ°á»£c láº¡i, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n thá»‘ng nháº¥t (LLMs) chá»©ng minh
hiá»‡u nÄƒng Ä‘Ã¡ng chÃº Ã½ khi Ä‘Æ°á»£c má»Ÿ rá»™ng Ä‘áº¿n má»™t kÃ­ch thÆ°á»›c tham sá»‘
nháº¥t Ä‘á»‹nh [12], [13]. ChÃºng cÃ³ thá»ƒ xá»­ lÃ½ hiá»‡u quáº£ cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ
mÃ  khÃ´ng cáº§n pre-training cá»¥ thá»ƒ lÄ©nh vá»±c, trÃ¬nh bÃ y
má»™t hÆ°á»›ng Ä‘i há»©a háº¹n cho tá»± Ä‘á»™ng hÃ³a code review.

Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y LLaMA-Reviewer, má»™t frame-
work má»›i táº­n dá»¥ng LLaMA, má»™t LLM chÃ­nh thá»‘ng, Ä‘á»ƒ tá»±
Ä‘á»™ng hÃ³a code review. ChÃºng tÃ´i káº¿t há»£p cÃ¡c phÆ°Æ¡ng phÃ¡p Parameter-Efficient
Fine-Tuning (PEFT) Ä‘á»ƒ giáº£i quyáº¿t thÃ¡ch thá»©c tÃ­nh toÃ¡n
cá»§a viá»‡c fine-tuning LLM. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i xÃ¢y dá»±ng dá»±a trÃªn
pipeline Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Li et al. [20], bao gá»“m 1) dá»± Ä‘oÃ¡n
tÃ­nh cáº§n thiáº¿t review, 2) táº¡o comment review, vÃ  3)
cÃ¡c nhiá»‡m vá»¥ tinh chá»‰nh code.

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ má»Ÿ rá»™ng LLaMA-Reviewer trÃªn hai dataset cÃ´ng khai
cho má»—i sub-task vÃ  Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a
biá»ƒu diá»…n Ä‘áº§u vÃ o, instruction tuning, vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT
khÃ¡c nhau. Nhá»¯ng Ä‘Ã³ng gÃ³p chÃ­nh cá»§a cÃ´ng trÃ¬nh nÃ y bao gá»“m:

â€¢ Giá»›i thiá»‡u á»©ng dá»¥ng cá»§a LLMs vÃ o cÃ¡c nhiá»‡m vá»¥ tá»± Ä‘á»™ng hÃ³a code review,
cung cáº¥p má»™t lá»±a chá»n thay tháº¿ offline vÃ  cÃ³ Ã½ thá»©c báº£o máº­t
cho cÃ¡c giáº£i phÃ¡p closed-source nhÆ° OpenAI APIs.

â€¢ Äá» xuáº¥t paradigm "unified model + PEFT" Ä‘á»ƒ giáº£m
nhu cáº§u tÃ­nh toÃ¡n trong cÃ¡c nhiá»‡m vá»¥ code review, vá»›i
mÃ´ hÃ¬nh plug-in lÃ  má»™t pháº§n cá»§a nÃ³ Ä‘á»ƒ tá»‘i Æ°u hÃ³a
yÃªu cáº§u khÃ´ng gian lÆ°u trá»¯, Ä‘áº§u tiÃªn trong lÄ©nh vá»±c ká»¹ thuáº­t pháº§n má»m.

â€¢ Tiáº¿n hÃ nh Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n cá»§a hai phÆ°Æ¡ng phÃ¡p PEFT
vÃ  cÃ¡c nghiÃªn cá»©u ablation vá» cÃ¡c thÃ nh pháº§n fine-tuning.

â€¢ Open-sourcing code, mÃ´ hÃ¬nh, vÃ  káº¿t quáº£ cá»§a chÃºng tÃ´i [32].

ÄÃ¢y lÃ  cáº¥u trÃºc cá»§a paper: Má»¥c II cung cáº¥p background
cáº§n thiáº¿t; Má»¥c III chi tiáº¿t phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i; Má»¥c
IV mÃ´ táº£ thiáº¿t káº¿ thÃ­ nghiá»‡m; Má»¥c V tháº£o luáº­n
káº¿t quáº£ Ä‘Ã¡nh giÃ¡; Má»¥c VI xem xÃ©t cÃ´ng trÃ¬nh liÃªn quan; Má»¥c
VII xÃ¡c Ä‘á»‹nh cÃ¡c má»‘i Ä‘e dá»a validity tiá»m nÄƒng; Má»¥c VIII káº¿t luáº­n
cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i vÃ  Ä‘á» xuáº¥t hÆ°á»›ng nghiÃªn cá»©u tÆ°Æ¡ng lai.arXiv:2308.11148v2  [cs.SE]  5 Sep 2023

--- TRANG 2 ---
Kiá»ƒm tra TÃ­nh cáº§n thiáº¿t Review (Pr) Tinh chá»‰nh Code (Pc) Comment trÃªn Code (Pr)
Chu ká»³ nÃ y láº·p láº¡i cho Ä‘áº¿n khi reviewer(s) vÃ  
committer(s) Ä‘áº¡t Ä‘Æ°á»£c thá»a thuáº­n.HÃ¬nh 1. Chu ká»³ cá»§a quy trÃ¬nh code review.

II. BACKGROUND
Má»¥c nÃ y cung cáº¥p giá»›i thiá»‡u ngáº¯n gá»n vá» ba khÃ¡i niá»‡m chÃ­nh
lÃ m ná»n táº£ng cho nghiÃªn cá»©u cá»§a chÃºng tÃ´i: pipeline code re-
view tá»± Ä‘á»™ng, large language models (LLMs), vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-
efficient fine-tuning (PEFT).

A. Tá»± Ä‘á»™ng hÃ³a trong Code Review
Modern Code Review (MCR), má»™t ká»¹ thuáº­t Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i
bá»Ÿi cáº£ cÃ¡c doanh nghiá»‡p lá»›n vÃ  cÃ¡c dá»± Ã¡n open-source, cÃ³
má»™t chu ká»³ cá»‘t lÃµi tÆ°Æ¡ng Ä‘á»‘i nháº¥t quÃ¡n máº·c dÃ¹ cÃ³ cÃ¡c triá»ƒn khai
khÃ¡c nhau. Chu ká»³ nÃ y, tá»« viá»‡c táº¡o pull request Ä‘áº¿n viá»‡c merge
cuá»‘i cÃ¹ng vÃ o nhÃ¡nh chÃ­nh hoáº·c tá»« chá»‘i, liÃªn quan Ä‘áº¿n hai ngÆ°á»i tham gia
chÃ­nh: cÃ¡c committers (Pc) vÃ  reviewers (Pr). Chu ká»³
bao gá»“m ba bÆ°á»›c chÃ­nh (nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1): dá»± Ä‘oÃ¡n
tÃ­nh cáº§n thiáº¿t review (Pr), commenting trÃªn code (Pr), vÃ 
tinh chá»‰nh code (Pc). Má»¥c tiÃªu cá»§a viá»‡c tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh code review
lÃ  giáº£m bá»›t khá»‘i lÆ°á»£ng cÃ´ng viá»‡c cho cáº£ hai bÃªn.

Ba bÆ°á»›c nÃ y dá»‹ch thÃ nh ba nhiá»‡m vá»¥ tá»± Ä‘á»™ng hÃ³a: 1)
Review Necessity Prediction, dá»± Ä‘oÃ¡n liá»‡u má»™t code diff
cÃ³ yÃªu cáº§u comment review hay khÃ´ng; 2) Review Comment Generation,
tá»± Ä‘á»™ng táº¡o comment review cho má»™t code diff
Ä‘Æ°á»£c cho; vÃ  3) Code Refinement, tinh chá»‰nh code dá»±a trÃªn
cÃ¡c Ä‘oáº¡n trÆ°á»›c Ä‘Ã³ vÃ  comment review. NghiÃªn cá»©u cá»§a chÃºng tÃ´i táº­p trung vÃ o
nhá»¯ng nhiá»‡m vá»¥ nÃ y, nháº±m tá»± Ä‘á»™ng hÃ³a hoÃ n toÃ n quy trÃ¬nh code review.

B. Large Language Models
Sá»± tiáº¿n hÃ³a cá»§a language modeling (LM) Ä‘Ã£ tráº£i qua bá»‘n
giai Ä‘oáº¡n quan trá»ng: statistical language models (SLMs), neu-
ral language models (NLMs), pre-trained language models
(PLMs), vÃ  phÃ¡t triá»ƒn má»›i nháº¥t, large language models
(LLMs) [33]. PLMs, Ä‘Æ°á»£c pre-trained rÃµ rÃ ng cho cÃ¡c nhiá»‡m vá»¥ nháº¥t Ä‘á»‹nh,
Ä‘Ã£ ráº¥t thÃ nh cÃ´ng trong nhiá»u nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m
downstream. Äiá»u nÃ y Ä‘Æ°á»£c chá»©ng minh bá»Ÿi cÃ¡c mÃ´ hÃ¬nh nhÆ°
CodeT5 [34] vÃ  PLBART [35]. Tuy nhiÃªn, tiá»m nÄƒng cá»§a
LLMs trong nhá»¯ng bá»‘i cáº£nh nÃ y váº«n chÆ°a Ä‘Æ°á»£c khÃ¡m phÃ¡ Ä‘áº§y Ä‘á»§.

Sá»± khÃ¡c biá»‡t chÃ­nh giá»¯a PLMs vÃ  LLMs lÃ 
quy mÃ´ tham sá»‘ vÃ  kÃ­ch thÆ°á»›c dá»¯ liá»‡u cá»§a chÃºng. LLMs lÃ  cÃ¡c mÃ´ hÃ¬nh vá»›i
âˆ¼10B tham sá»‘ hoáº·c hÆ¡n, Ä‘Æ°á»£c pre-trained vá»›i dá»¯ liá»‡u má»Ÿ rá»™ng
[33]. NghiÃªn cá»©u hiá»‡n táº¡i cho tháº¥y viá»‡c má»Ÿ rá»™ng cÃ¡c kÃ­ch thÆ°á»›c nÃ y
cáº£i thiá»‡n hiá»‡u nÄƒng mÃ´ hÃ¬nh vÃ  táº¡o ra cÃ¡c kháº£ nÄƒng emergent
[36]. ÄÃ¡ng chÃº Ã½, LLMs cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng ngang báº±ng
vá»›i PLMs mÃ  khÃ´ng cáº§n pre-training cá»¥ thá»ƒ nhiá»‡m vá»¥,
do Ä‘Ã³ giáº£m bá»›t nhu cáº§u náº·ng vá» tÃ i nguyÃªn cá»§a pre-training.

Cá»¥ thá»ƒ hÆ¡n, cÃ¡c LLMs Ä‘ang thá»‹nh hÃ nh hiá»‡n táº¡i cÃ³ thá»ƒ Ä‘Æ°á»£c
phÃ¢n loáº¡i thÃ nh unified LLMs vÃ  code LLMs. Nhá»¯ng mÃ´ hÃ¬nh trÆ°á»›c
chá»§ yáº¿u Ä‘Æ°á»£c pre-trained trÃªn corpus ngÃ´n ngá»¯ tá»± nhiÃªn,
Ä‘Æ°á»£c lÃ m giÃ u vá»›i má»™t pháº§n nhá» hÆ¡n cá»§a code, vÃ  Ä‘Ã£ Ä‘Æ°á»£c
xÃ¡c thá»±c lÃ  hiá»‡u quáº£ trong nhiá»u nhiá»‡m vá»¥ khÃ¡c nhau [37], [38]. Nhá»¯ng mÃ´ hÃ¬nh sau
chá»§ yáº¿u Ä‘Æ°á»£c pre-trained trÃªn corpus dá»±a trÃªn code vÃ  chÃºng Ä‘Ã£
Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ áº¥n tÆ°á»£ng trong sinh code [39]â€“[42].

Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng LLaMA, má»™t unified
LLM open-source Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Meta. Lá»±a chá»n nÃ y xuáº¥t phÃ¡t tá»« bá»‘n gÃ³c
Ä‘á»™: 1) CÃ¡c mÃ´ hÃ¬nh hiá»‡u nÄƒng cao nháº¥t (GPT-3.5/GPT-4) cho cÃ¡c nhiá»‡m vá»¥ code
lÃ  cÃ¡c mÃ´ hÃ¬nh unified, khÃ´ng pháº£i code LLMs; 2) Xu hÆ°á»›ng tÄƒng
vá» cÃ¡c mÃ´ hÃ¬nh unified, Ä‘Æ°á»£c minh há»a báº±ng quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i cá»§a OpenAI
tá»« Codex sang GPT-3.5 Ä‘á»ƒ sá»­ dá»¥ng API; 3) Xu hÆ°á»›ng tÄƒng
vá» cÃ¡c mÃ´ hÃ¬nh unified, Ä‘Æ°á»£c minh há»a báº±ng quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i cá»§a OpenAI
tá»« Codex sang GPT-3.5 Ä‘á»ƒ sá»­ dá»¥ng API; 4) Code LLMs
chá»§ yáº¿u xuáº¥t sáº¯c trong cÃ¡c nhiá»‡m vá»¥ sinh code, trong khi cÃ¡c nhiá»‡m vá»¥ code review
Ä‘áº·t ra nhá»¯ng thÃ¡ch thá»©c khÃ¡c nhau.

C. Parameter-Efficient Fine-Tuning
Máº·c dÃ¹ hiá»‡u quáº£, tÃ i nguyÃªn tÃ­nh toÃ¡n cao
cáº§n thiáº¿t Ä‘á»ƒ fine-tuning cÃ¡c large language models (LLMs) trÃ¬nh bÃ y
má»™t thÃ¡ch thá»©c Ä‘Ã¡ng ká»ƒ. Nhiá»u chiáº¿n lÆ°á»£c Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t
triá»ƒn Ä‘á»ƒ tÄƒng hiá»‡u quáº£ cá»§a quy trÃ¬nh fine-tuning
vÃ  giáº£m chi phÃ­ huáº¥n luyá»‡n. Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y bao gá»“m adapter tuning [43],
[44], prefix tuning [45], prompt tuning [46], [47], vÃ  low-
rank adaptation (LoRA) [48]. Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y Ä‘Ã³ng bÄƒng cÃ¡c
tham sá»‘ cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ trong khi huáº¥n luyá»‡n má»™t sá»‘ tham sá»‘ bá»• sung,
Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i full-parameter tuning.

Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng hai phÆ°Æ¡ng phÃ¡p PEFTâ€”zero-init atten-
tion prefix-tuning [49] vÃ  LoRA tuning [48]â€”Ä‘á»ƒ fine-tune
LLaMA. Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng giá»›i thiá»‡u latency bá»• sung cho
mÃ´ hÃ¬nh vÃ  Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ trong cÃ¡c nhiá»‡m vá»¥ ngÃ´n ngá»¯ tá»± nhiÃªn.
CÃ¡c chi tiáº¿t cá»¥ thá»ƒ cá»§a phÆ°Æ¡ng phÃ¡p PEFT Ä‘Æ°á»£c trÃ¬nh bÃ y thÃªm trong
má»¥c tiáº¿p theo vá» cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i.

III. LLAMA-REVIEWER: PHÆ¯Æ NG PHÃP Äá»€ XUáº¤T
A. Tá»•ng quan
Framework cá»§a chÃºng tÃ´i, Ä‘Æ°á»£c minh há»a trong HÃ¬nh 2, sá»­ dá»¥ng quy trÃ¬nh
fine-tuning hai giai Ä‘oáº¡n. ChÃºng tÃ´i báº¯t Ä‘áº§u vá»›i instruction-following tun-
ing trÃªn LLaMA sá»­ dá»¥ng dá»¯ liá»‡u lÄ©nh vá»±c táº­p trung vÃ o code, nÃ¢ng cao
trÃ¬nh Ä‘á»™ cá»§a mÃ´ hÃ¬nh trong viá»‡c hiá»ƒu cÃ¡c nhiá»‡m vá»¥ code review vÃ 
tuÃ¢n thá»§ hÆ°á»›ng dáº«n nhiá»‡m vá»¥. Sau Ä‘Ã³ chÃºng tÃ´i tiáº¿n hÃ nh supervised fine-
tuning cho má»—i sub-task trong quy trÃ¬nh code review sá»­ dá»¥ng
LLaMA Ä‘Æ°á»£c nÃ¢ng cao. Äá»ƒ cÃ¢n báº±ng hiá»‡u quáº£ tham sá»‘ vÃ 
hiá»‡u nÄƒng mÃ´ hÃ¬nh, chÃºng tÃ´i káº¿t há»£p hai ká»¹ thuáº­t chÃ­nhâ€”zero-
init attention prefix-tuning vÃ  low-rank adaptation (LoRA)
tuningâ€”vÃ¬ chÃºng Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c sá»± cháº¥p nháº­n rá»™ng rÃ£i vÃ  káº¿t quáº£
há»©a háº¹n, Ä‘áº·c biá»‡t vá»›i LLaMA [49], [50]. Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y,
Ä‘Æ°á»£c thÃ nh láº­p trÃªn chiáº¿n lÆ°á»£c plugin encapsulation cá»§a PEFT, trang
bá»‹ cho chÃºng tÃ´i cÃ¡c plugin cá»¥ thá»ƒ nhiá»‡m vá»¥ nháº¹. Nhá»¯ng plugin nÃ y,
Ä‘á»™c láº­p vá»›i cÃ¡c weight cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­ch há»£p
liá»n máº¡ch trong quÃ¡ trÃ¬nh inference.

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i sá»­ dá»¥ng hai
dataset riÃªng biá»‡t. Äá»ƒ rÃµ rÃ ng, chÃºng tÃ´i sáº½ gá»i dataset trong
CodeReviewer [20] lÃ  "CRer dataset", vÃ  dataset tá»«
Tufano et al. [23] lÃ  "Tuf. dataset". Chi tiáº¿t thÃªm vá»
quy trÃ¬nh Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong cÃ¡c má»¥c tiáº¿p theo.

--- TRANG 3 ---
Review Necessity Prediction (RNP)
Code Refinement (CR) Review Comment Generation (RCG) Instruction Tuning Base Model
Low-Rank Adaptation Prefix-tuning Freeze Fine-tune PEFT Plugins HÃ¬nh 2. Tá»•ng quan vá» LLaMA-Reviewer.

B. Instruction Tuning trÃªn LLaMA
NghiÃªn cá»©u cho tháº¥y khi LLMs Ä‘Æ°á»£c fine-tuned trÃªn má»™t
pháº¡m vi Ä‘a dáº¡ng cá»§a cÃ¡c dataset Ä‘a nhiá»‡m vá»¥ sá»­ dá»¥ng mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn,
chÃºng chá»©ng minh hiá»‡u nÄƒng tÄƒng cÆ°á»ng trÃªn cÃ¡c nhiá»‡m vá»¥
chÆ°a tháº¥y [51], [52]. Instruction-following tuning há»— trá»£ mÃ´ hÃ¬nh
hiá»ƒu Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n vÃ  tuÃ¢n theo hÆ°á»›ng dáº«n.
Äá»ƒ ban Ä‘áº§u thÃ­ch á»©ng mÃ´ hÃ¬nh pre-trained cho cÃ¡c nhiá»‡m vá»¥ code review,
chÃºng tÃ´i sá»­ dá»¥ng instruction tuning trÃªn lÄ©nh vá»±c táº­p trung vÃ o code.

ChÃºng tÃ´i táº­n dá»¥ng quy trÃ¬nh vÃ  template chÃ­nh tá»« Stanford
Alpaca [53], sá»­a Ä‘á»•i full-parameter fine-tuning Ä‘á»ƒ sá»­ dá»¥ng
cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT nhÆ° Ä‘Æ°á»£c giáº£i thÃ­ch trong Má»¥c III-C vÃ  Má»¥c III-
D. Cho nhiá»‡m vá»¥ code review cá»§a chÃºng tÃ´i cÃ³ sá»± liÃªn quan sÃ¢u sáº¯c Ä‘áº¿n coding, chÃºng tÃ´i
thay tháº¿ dá»¯ liá»‡u gá»‘c báº±ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng lÄ©nh vá»±c code cá»§a nÃ³,
Code Alpaca [54]. Káº¿t há»£p dá»¯ liá»‡u tá»« Alpaca vÃ  Code
Alpaca Ä‘Ã£ Ä‘Æ°á»£c xem xÃ©t nhÆ°ng khÃ´ng dáº«n Ä‘áº¿n cáº£i thiá»‡n hiá»‡u nÄƒng,
nhÆ° Ä‘Æ°á»£c tháº£o luáº­n thÃªm trong má»¥c thÃ­ nghiá»‡m ablation. Cáº¥u trÃºc dá»¯ liá»‡u tuÃ¢n thá»§ Ä‘á»‹nh dáº¡ng {instruction, input
(tÃ¹y chá»n), output}, theo framework tá»« [55].
Template prompt tÆ°Æ¡ng tá»± Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c sub-task tiáº¿p theo Ä‘á»ƒ
tá»‘i Ä‘a hÃ³a viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh fine-tuned giai Ä‘oáº¡n Ä‘áº§u. HÃ¬nh 3
minh há»a template prompt vÃ  Ä‘á»‹nh dáº¡ng instruction, input,
vÃ  output cá»§a sub-task.

C. Zero-init Attention Prefix-tuning
Zero-init attention prefix-tuning, má»™t nhÃ¡nh cá»§a prefix-
tuning, giá»¯ nguyÃªn cÃ¡c weight cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ trong khi tÃ­ch há»£p
Kprefix tokens bá»• sung vÃ o L layers trÃªn cÃ¹ng cá»§a transformer LLaMA. Nhá»¯ng prompt linh hoáº¡t nÃ y Ä‘Æ°á»£c ná»‘i vá»›i
cÃ¡c token gá»‘c, cho phÃ©p tÃ­nh toÃ¡n multi-head
attention sá»­ dá»¥ng cÃ¡c keys vÃ  values má»›i Ä‘Æ°á»£c giá»›i thiá»‡u. Trong quÃ¡ trÃ¬nh
fine-tuning, chá»‰ nhá»¯ng prompt cÃ³ thá»ƒ thÃ­ch á»©ng nÃ y Ä‘Æ°á»£c huáº¥n luyá»‡n.

PhÆ°Æ¡ng phÃ¡p nÃ y khÃ¡c vá»›i prefix-tuning thÃ´ng thÆ°á»ng báº±ng cÃ¡ch
giá»›i thiá»‡u má»™t learnable gating factor trong quÃ¡ trÃ¬nh tÃ­nh toÃ¡n attention. Factor nÃ y Ä‘iá»u chá»‰nh sá»± liÃªn quan cá»§a cÃ¡c prompt tokens
Ä‘Æ°á»£c chÃ¨n. Äá»ƒ táº¡o Ä‘iá»u kiá»‡n cho quy trÃ¬nh tuning, gating factor nÃ y
ban Ä‘áº§u Ä‘Æ°á»£c zeroed, dáº«n Ä‘áº¿n 'zero-init' trong tÃªn cá»§a
phÆ°Æ¡ng phÃ¡p. Factor nÃ y cá»¥ thá»ƒ kiá»ƒm soÃ¡t attention Ä‘Æ°á»£c chia sáº»
giá»¯a cÃ¡c prompt tokens vÃ  cÃ¡c token gá»‘c.

HÃ¬nh 4 minh há»a cÃ¡c chi tiáº¿t. ChÃºng tÃ´i láº¥y l layer, má»™t
trong sá»‘ L layers trÃªn cÃ¹ng lÃ m vÃ­ dá»¥. á» Ä‘Ã¢y, PlâˆˆRKÃ—C
Ä‘áº¡i diá»‡n cho K prompt tokens vÃ  TlâˆˆRMÃ—C biá»ƒu thá»‹
M token gá»‘c trong l layer. KÃ­ch thÆ°á»›c feature
Ä‘Æ°á»£c kÃ½ hiá»‡u bá»Ÿi C. Khi token thá»© (M+1) tM+1 Ä‘Æ°á»£c
tÃ­nh toÃ¡n thÃ´ng qua cÆ¡ cháº¿ attention, cÃ¡c queries, keys, vÃ 
values Ä‘Æ°á»£c thu Ä‘Æ°á»£c thÃ´ng qua má»™t sá»‘ linear layers nhÆ° sau:

Instructions, Inputs & Output Prompt Template
DÆ°á»›i Ä‘Ã¢y lÃ  má»™t instruction mÃ´ táº£ má»™t nhiá»‡m vá»¥, Ä‘Æ°á»£c ghÃ©p vá»›i má»™t input cung cáº¥p
ngá»¯ cáº£nh thÃªm. Viáº¿t má»™t response hoÃ n thÃ nh yÃªu cáº§u má»™t cÃ¡ch thÃ­ch há»£p.
### Instruction:
{instruction}
### Input:
{input}
### Response:
{output}

Review Necessity Prediction (RNP):
(Instruction) XÃ¡c Ä‘á»‹nh liá»‡u diff hunk Ä‘Æ°á»£c cung cáº¥p cÃ³ yÃªu cáº§u code review hay khÃ´ng. Tráº£ lá»i báº±ng
'yes' hoáº·c 'no'.
(Input) Diff hunk lÃ : '{diff hunk}'
(Output) yes/no

Review Comment Generation (RCG):
(Instruction) Review code Ä‘Æ°á»£c cho vÃ  cung cáº¥p má»™t comment code review mang tÃ­nh xÃ¢y dá»±ng.
(Input) Code/(diff hunk) lÃ : '{code/(diff hunk)}'
(Output) {comment}

Code Refinement (CR) (Tufano Dataset):
(Instruction) Tinh chá»‰nh toÃ n bá»™ code dá»±a trÃªn pháº£n há»“i Ä‘Æ°á»£c cung cáº¥p trong comment code review,
vá»›i focus vÃ o Ä‘oáº¡n giá»¯a <START> vÃ  <END>.
(Input) Comment lÃ : '{comment}' \n Code lÃ : '{source code}'
(Output) {target code}

Code Refinement (CR) (Crer Dataset):
(Instruction) Tinh chá»‰nh code Ä‘Æ°á»£c cho dá»±a trÃªn comment code review Ä‘Æ°á»£c cung cáº¥p.
(Input) Comment lÃ : '{comment}' \n Code lÃ : '{source code}'
(Output) {target code}

Code Refinement (CR) (Crer Dataset) (+ Lang. Label trong Instruction):
(Instruction) Tinh chá»‰nh {lang. label} code Ä‘Æ°á»£c cho dá»±a trÃªn comment code review Ä‘Æ°á»£c cung cáº¥p.
(Input) Comment lÃ : '{comment}' \n Code lÃ : '{source code}'
(Output) {target code}

Code Refinement (CR) (Crer Dataset) (+ Lang. Label trong Input):
(Instruction) Tinh chá»‰nh code Ä‘Æ°á»£c cho dá»±a trÃªn comment code review Ä‘Æ°á»£c cung cáº¥p.
(Input) Comment lÃ : '{comment}' \n {lang. label} code lÃ : '{source code}'
(Output) {target code}

HÃ¬nh 3. Template prompt vÃ  Ä‘á»‹nh dáº¡ng instruction, input vÃ  output.

Vanilla Attention Zero-init Attention Prefix
(Zero-Gating) Ã—L
Ã—(Nâ€“L) Forward Backward
Adaptation Prefix
Freeze
Fine-tune
Concatenate
Base Model (LLaMA) Transformer Layer

HÃ¬nh 4. Chi tiáº¿t cá»§a prefix-tuning trÃªn LLaMA.

Ql= Linearq(tM+1)
Kl= Lineark([Pl;Tl;tM+1])
Vl= Linearv([Pl;Tl;tM+1]) (1)

Tiáº¿p theo, cÃ¡c attention scores Ä‘Æ°á»£c dáº«n xuáº¥t:

--- TRANG 4 ---
ğ‘¥ğ‘¥ğ‘‘ğ‘‘Pre-trained Weights
ğ‘Šğ‘Š0âˆˆğ‘…ğ‘…ğ‘‘ğ‘‘Ã—ğ‘˜ğ‘˜
ğ‘Šğ‘Šdownâˆˆğ‘…ğ‘…ğ‘‘ğ‘‘Ã—ğ‘Ÿğ‘Ÿğ‘Šğ‘Šupâˆˆğ‘…ğ‘…rÃ—ğ‘˜ğ‘˜
ğ‘Ÿğ‘Ÿğ‘˜ğ‘˜â„
Freeze
Fine-tune
Concatenate
Base Model (LLaMA) Transformer Layer

HÃ¬nh 5. ThÃ nh pháº§n cá»‘t lÃµi cá»§a Low-Rank Adaptation (LoRA).

Sl= SKl;SM+1lT
SKl=Ql KKlT/âˆšCâˆˆR1Ã—K
SM+1l=Ql KM+1lT/âˆšCâˆˆR1Ã—(M+1) (2)

Gating factor Ä‘Æ°á»£c tÃ­ch há»£p sau khi Ã¡p dá»¥ng softmax:
Sgl= Softmax(SKl)Â·gl; Softmax(SM+1lT) (3)

Cuá»‘i cÃ¹ng, output cá»§a token tM+1 Ä‘Æ°á»£c táº¡o ra thÃ´ng qua má»™t
linear projection layer, vÃ  nÃ³ Ä‘Æ°á»£c kiá»ƒm soÃ¡t bá»Ÿi cÃ¡c prefixes:
toM+1= Linearo(SglVl)âˆˆR1Ã—C. (4)

D. Low-Rank Adaptation
Low-Rank Adaptation (LoRA) cung cáº¥p má»™t gÃ³c nhÃ¬n khÃ¡c
vá» Parameter-Efficient Fine-Tuning (PEFT). KhÃ´ng nhÆ°
cÃ¡c phÆ°Æ¡ng phÃ¡p full-parameter tuning yÃªu cáº§u táº¥t cáº£ weights Ä‘Æ°á»£c
cáº­p nháº­t trong giai Ä‘oáº¡n fine-tuning, LoRA giá»¯ láº¡i
cÃ¡c weights cá»§a mÃ´ hÃ¬nh gá»‘c vÃ  tÃ­ch há»£p cÃ¡c low-
rank matrices cÃ³ thá»ƒ huáº¥n luyá»‡n vÃ o cÃ¡c transformer layers Ä‘á»ƒ mÃ´ phá»ng cÃ¡c Ä‘iá»u chá»‰nh
weight. PhÃ©p xáº¥p xá»‰ nÃ y dá»±a trÃªn nguyÃªn táº¯c ráº±ng
quÃ¡ trÃ¬nh thÃ­ch á»©ng vá»‘n cÃ³ "intrinsic rank" tháº¥p.

HÃ¬nh 5 minh há»a thÃ nh pháº§n cá»‘t lÃµi cá»§a LoRA. Giáº£ sá»­
W0âˆˆRdÃ—k Ä‘áº¡i diá»‡n cho ma tráº­n pre-trained. PhÃ©p xáº¥p xá»‰
cá»§a viá»‡c Ä‘iá»u chá»‰nh weight tá»« W0 Ä‘áº¿n W0+âˆ†W sá»­ dá»¥ng
LoRA cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ°:
W0+ âˆ†W=W0+WdownWup (5)

á» Ä‘Ã¢y, Wdown âˆˆRdÃ—r vÃ  WupâˆˆRrÃ—k, vá»›i râ‰ª
min(d, k) lÃ  rank. Trong quÃ¡ trÃ¬nh fine-tuning,
W0 khÃ´ng thay Ä‘á»•i, trong khi Wdown vÃ  Wup trá»Ÿ thÃ nh
cÃ¡c tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n. Cho má»™t input x vÃ  output gá»‘c
liÃªn quan h, output Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Â¯h Ä‘Æ°á»£c tÃ­nh nhÆ°:
Â¯h=W0x+ âˆ†Wx=h+WdownWupx (6)

Báº¢NG I
TÃ“M Táº®T CÃC NHIá»†M Vá»¤ Tá»° Äá»˜NG HÃ“A CODE REVIEW

Nhiá»‡m vá»¥         Input    Output    Datasets
Review Necessity Prediction    PL    L (yes/no)    Crer.
Code Review Comment Generation    PL    NL    CRer., Tuf.
Code Refinement    PL, NL    PL    CRer., Tuf.

E. CÃ¡c Nhiá»‡m vá»¥ Tá»± Ä‘á»™ng hÃ³a Code Review
LLaMA-Reviewer Ä‘Æ°á»£c thiáº¿t káº¿ cá»¥ thá»ƒ Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a ba
nhiá»‡m vá»¥ cá»‘t lÃµi khÃ´ng thá»ƒ tÃ¡ch rá»i khá»i quy trÃ¬nh code review, cá»¥ thá»ƒ lÃ  review
necessity prediction, code review comment generation, vÃ 
code refinement. Nhá»¯ng nhiá»‡m vá»¥ nÃ y tuáº§n tá»± tÆ°Æ¡ng á»©ng vá»›i cÃ¡c giai Ä‘oáº¡n
trong má»™t quy trÃ¬nh code review Ä‘iá»ƒn hÃ¬nh. Inputs vÃ  outputs cho nhá»¯ng
nhiá»‡m vá»¥ nÃ y Ä‘Æ°á»£c phÃ¢n loáº¡i thÃ nh ba Ä‘á»‹nh dáº¡ng:

â€¢ Programming Language (PL) cho cÃ¡c Ä‘oáº¡n code,
â€¢ Natural Language (NL) cho cÃ¡c comment code, vÃ 
â€¢ Binary Labels (L) cho cÃ¡c quyáº¿t Ä‘á»‹nh vá» yÃªu cáº§u cho
review thÃªm. Äiá»u nÃ y Ä‘Æ¡n giáº£n hÃ³a quy trÃ¬nh quyáº¿t Ä‘á»‹nh thÃ nh
"yes" (cáº§n review) hoáº·c "no" (khÃ´ng cáº§n review).

Báº£ng I minh há»a má»—i nhiá»‡m vá»¥ cÃ¹ng vá»›i Ä‘á»‹nh dáº¡ng input vÃ  output
cá»§a nÃ³, vÃ  cÃ¡c tham chiáº¿u dataset tÆ°Æ¡ng á»©ng (Crer. cho
CRer dataset, vÃ  Tuf. cho Tufano dataset). PhÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng
prompt Ä‘Æ°á»£c hÃ¬nh dung trong HÃ¬nh 3.

1) Review Necessity Prediction: Nhiá»‡m vá»¥ nÃ y liÃªn quan Ä‘áº¿n viá»‡c kiá»ƒm
tra liá»‡u cÃ¡c diff hunks cÃ³ cáº§n reviews hay khÃ´ng. ÄÆ°á»£c Ä‘á» xuáº¥t bá»Ÿi Li et al. [20],
má»™t diff hunk Ä‘áº¡i diá»‡n cho má»™t Ä‘oáº¡n code ngáº¯n gá»n cho tháº¥y
sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c Ä‘oáº¡n code cÅ© vÃ  má»›i. Máº·c dÃ¹
viá»‡c bao gá»“m ngá»¯ cáº£nh method bá»• sung cÃ³ thá»ƒ cÃ³ lá»£i,
cÃ¡c dÃ²ng trong diff hunk gá»‘c thÆ°á»ng Ä‘á»§ dÃ i Ä‘á»ƒ
trÃ¬nh bÃ y má»™t thÃ¡ch thá»©c khi Ä‘Æ°á»£c quáº£n lÃ½ nhÆ° input.

2) Code Review Comment Generation: Nhiá»‡m vá»¥ nÃ y táº¡o ra
cÃ¡c comment phÃ¹ há»£p cho má»™t Ä‘oáº¡n code Ä‘Æ°á»£c cho. Hai gÃ³c nhÃ¬n
Ä‘Æ°á»£c xem xÃ©t: gÃ³c nhÃ¬n cáº¥p dÃ²ng táº­p trung vÃ o
ná»™i dung cá»§a cÃ¡c dÃ²ng code riÃªng láº» (sá»­ dá»¥ng CRer dataset),
vÃ  gÃ³c nhÃ¬n cáº¥p method cung cáº¥p má»™t cÃ¡i nhÃ¬n toÃ n diá»‡n hÆ¡n
vá» ngá»¯ cáº£nh cá»§a code (sá»­ dá»¥ng Tufano dataset).

3) Code Refinement: Code refinement Ä‘Ã²i há»i viá»‡c thá»±c hiá»‡n cÃ¡c Ä‘iá»u chá»‰nh nhá»
hoáº·c sáº¯p xáº¿p láº¡i code hiá»‡n cÃ³ Ä‘á»ƒ nÃ¢ng cao cháº¥t lÆ°á»£ng
cá»§a nÃ³. Cho tÃ­nh cháº¥t cá»§a nhá»¯ng sá»­a Ä‘á»•i nhá» nÃ y,
code input vÃ  output thÆ°á»ng cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng máº¡nh máº½. Inputs
Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng theo Tufano vÃ  CRer datasets.
ThÃ´ng thÆ°á»ng, chÃºng tÃ´i bá» qua thÃ´ng tin loáº¡i ngÃ´n ngá»¯ vÃ¬ cÃ¡c mÃ´ hÃ¬nh base-
line Ä‘Ã£ lÃ m nhÆ° váº­y vÃ  nÃ³ chá»‰ cÃ³ sáºµn trong má»™t nhiá»‡m vá»¥
cá»§a má»™t dataset Ä‘Æ°á»£c cÃ´ng bá»‘, Ä‘á»ƒ Ä‘áº£m báº£o so sÃ¡nh cÃ´ng báº±ng.
TÃ¡c Ä‘á»™ng cá»§a thÃ´ng tin nhÆ° váº­y Ä‘Æ°á»£c khÃ¡m phÃ¡ thÃªm trong
má»¥c Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i.

IV. THIáº¾T Káº¾ THÃ NGHIá»†M
Má»¥c nÃ y chi tiáº¿t thiáº¿t káº¿ thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, phÃ¡c tháº£o
cÃ¡c cÃ¢u há»i nghiÃªn cá»©u cÆ¡ báº£n thÃºc Ä‘áº©y Ä‘iá»u tra cá»§a chÃºng tÃ´i,
cÃ¡c dataset Ä‘Æ°á»£c sá»­ dá»¥ng, cÃ¡c metric Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c sá»­ dá»¥ng, vÃ  má»™t tÃ³m táº¯t
ká»¹ lÆ°á»¡ng cá»§a cÃ¡c mÃ´ hÃ¬nh baseline vÃ  chi tiáº¿t triá»ƒn khai
cá»§a chÃºng tÃ´i.

--- TRANG 5 ---
A. CÃ¢u há»i NghiÃªn cá»©u
Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a framework Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i,
chÃºng tÃ´i Ä‘áº·t ra cÃ¡c truy váº¥n nghiÃªn cá»©u sau:

(RQ1) MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n hiá»‡u quáº£ nhÆ° tháº¿ nÃ o trong viá»‡c tá»±
Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ code review, so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p
state-of-the-art?

Äá»™ng lá»±c. Nhá»¯ng tiáº¿n bá»™ nhanh chÃ³ng trong AI-Generated Content
(AIGC) vÃ  má»‘i tÆ°Æ¡ng quan Ä‘Ã£ biáº¿t giá»¯a kháº£ nÄƒng mÃ´ hÃ¬nh
vÃ  kÃ­ch thÆ°á»›c cá»§a chÃºng Ä‘Ã£ dáº«n Ä‘áº¿n viá»‡c sá»­ dá»¥ng rá»™ng rÃ£i cÃ¡c large language models (LLMs) pre-trained Ä‘Ã£ Ä‘Æ°á»£c fine-tuned. Máº·c dÃ¹ dá»¯ liá»‡u ngÃ´n ngá»¯ láº­p trÃ¬nh
Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c tÄƒng cÆ°á»ng
kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh, viá»‡c Ã¡p dá»¥ng dá»¯ liá»‡u nhÆ° váº­y cho cÃ¡c nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n codeâ€”
Ä‘áº·c biá»‡t lÃ  nhá»¯ng nhiá»‡m vá»¥ Ä‘Ã²i há»i thÃ nh tháº¡o cáº£
natural language (NL) vÃ  programming language (PL),
nhÆ° automated code reviewâ€”váº«n pháº§n lá»›n chÆ°a Ä‘Æ°á»£c khÃ¡m phÃ¡.

Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng biáº¿n thá»ƒ nhá» nháº¥t cá»§a LLaMA
lÃ m large language model cÆ¡ sá»Ÿ cá»§a chÃºng tÃ´i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£
cá»§a nÃ³ trong viá»‡c tá»± Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ code review so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p state-of-the-
art, Ä‘áº·c biá»‡t lÃ  cÃ¡c mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ nhiá»‡m vá»¥ nhÆ°
CodeReviewer [20]. Hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c xem xÃ©t ká»¹ lÆ°á»¡ng
qua má»—i nhiá»‡m vá»¥ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘iá»ƒm máº¡nh vÃ  cÃ¡c khu vá»±c cáº§n
nÃ¢ng cao. Cá»¥ thá»ƒ, chÃºng tÃ´i Ä‘áº·t ra cÃ¡c cÃ¢u há»i sau:

â€¢ (RQ1.1) MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n hiá»‡u quáº£ nhÆ° tháº¿ nÃ o trong viá»‡c
kiá»ƒm tra tÃ­nh cáº§n thiáº¿t review (classification)?
â€¢ (RQ1.2) MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n thÃ nh tháº¡o nhÆ° tháº¿ nÃ o trong viá»‡c
táº¡o ra comment code review (NL generation)?
â€¢ (RQ1.3) MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cÃ³ kháº£ nÄƒng nhÆ° tháº¿ nÃ o trong viá»‡c
tinh chá»‰nh code dá»±a trÃªn comment (PL generation)?

(RQ2) Biá»ƒu diá»…n cá»§a dá»¯ liá»‡u input tÃ¡c Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘áº¿n
hiá»‡u nÄƒng cá»§a large language models?

Äá»™ng lá»±c. Cho Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u pre-training cá»‘ Ä‘á»‹nh, cÃ³ thá»ƒ
cÃ³ sá»± khÃ¡c biá»‡t giá»¯a Ä‘á»‹nh dáº¡ng nÃ y vÃ  Ä‘á»‹nh dáº¡ng yÃªu cáº§u cho
cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ. Äá»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a large language
model, chÃºng tÃ´i Ä‘i sÃ¢u vÃ o hai yáº¿u tá»‘ quan trá»ng:

1) Code Formatting. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh
trÃªn raw code input vÃ  input vá»›i Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c sá»­a Ä‘á»•i
(bao gá»“m loáº¡i bá» consecutive spaces) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh
cÃ¡i nÃ o cÃ³ thá»ƒ Ä‘Æ°á»£c xá»­ lÃ½ hiá»‡u quáº£ hÆ¡n.

2) Programming Language Labels. Vá»›i cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh
khÃ¡c nhau, chÃºng tÃ´i kiá»ƒm tra tÃ¡c Ä‘á»™ng cá»§a viá»‡c chá»‰ Ä‘á»‹nh
loáº¡i ngÃ´n ngá»¯ trong input vÃ  táº§m quan trá»ng cá»§a
vá»‹ trÃ­ label trong prompt template.

Trong Ã¡nh sÃ¡ng cá»§a nhá»¯ng cÃ¢n nháº¯c nÃ y, chÃºng tÃ´i Ä‘áº·t ra hai cÃ¢u há»i phá»¥:
â€¢ (RQ2.1) Code formatting áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n hiá»‡u nÄƒng
cá»§a mÃ´ hÃ¬nh?
â€¢ (RQ2.2) Viá»‡c bao gá»“m vÃ  vá»‹ trÃ­ cá»§a cÃ¡c programming
language labels áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh?

(RQ3) Instruction tuning áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n hiá»‡u
nÄƒng cá»§a cÃ¡c sub-tasks tiáº¿p theo?

Äá»™ng lá»±c. Instruction tuning, viá»‡c bao gá»“m cÃ¡c hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n code
trong giai Ä‘oáº¡n ban Ä‘áº§u, nháº±m truyá»n Ä‘áº¡t kiáº¿n thá»©c lÄ©nh vá»±c
vÃ  giÃºp mÃ´ hÃ¬nh hiá»ƒu cÃ¡c sub-tasks tá»‘t hÆ¡n. Hiá»‡u quáº£
cá»§a phÆ°Æ¡ng phÃ¡p nÃ y vÃ  kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch cá»§a nÃ³ vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-efficient fine-tuning (PEFT) khÃ¡c nhau váº«n lÃ 
má»™t khu vá»±c khÃ¡m phÃ¡ phong phÃº. NgoÃ i ra, cho tÃ­nh cháº¥t kÃ©p
cá»§a cÃ¡c nhiá»‡m vá»¥ code review liÃªn quan Ä‘áº¿n natural language (NL) vÃ 
programming language (PL), má»™t so sÃ¡nh giá»¯a viá»‡c sá»­ dá»¥ng
Ä‘á»™c quyá»n cÃ¡c hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n PL vÃ  má»™t há»—n há»£p cÃ¡c hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n NL vÃ  PL
lÃ  cáº§n thiáº¿t. Do Ä‘Ã³, chÃºng tÃ´i há»i:

â€¢ (RQ3.1) TÃ¡c Ä‘á»™ng cá»§a giai Ä‘oáº¡n instruction
tuning ban Ä‘áº§u Ä‘á»‘i vá»›i zero-init attention prefix-tuning lÃ  gÃ¬?
â€¢ (RQ3.2) Giai Ä‘oáº¡n instruction tuning ban Ä‘áº§u
áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n low-rank adaptation (LoRA)?
â€¢ (RQ3.3) PhÆ°Æ¡ng phÃ¡p nÃ o mang láº¡i káº¿t quáº£ vÆ°á»£t trá»™i trong cÃ¡c nhiá»‡m vá»¥
code review: sá»­ dá»¥ng há»—n há»£p cÃ¡c hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n NL vÃ  PL-
hay dá»±a duy nháº¥t vÃ o cÃ¡c hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n PL?

(RQ4) Nhá»¯ng tÃ¡c Ä‘á»™ng nÃ o phÃ¡t sinh tá»« cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-
efficient fine-tuning (PEFT) khÃ¡c nhau?

Äá»™ng lá»±c. Hai phÆ°Æ¡ng phÃ¡p PEFT Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£m
nhu cáº§u tÃ i nguyÃªn tÃ­nh toÃ¡n trong quÃ¡ trÃ¬nh fine-tuning. Tuy nhiÃªn,
viá»‡c Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng tá»‘i Æ°u giá»¯a hiá»‡u quáº£ vÃ  hiá»‡u quáº£
lÃ  thÃ¡ch thá»©c. Theo Ä‘Ã³, chÃºng tÃ´i cÃ³ Ã½ Ä‘á»‹nh phÃ¢n tÃ­ch
káº¿t quáº£ thu Ä‘Æ°á»£c tá»« hai phÆ°Æ¡ng phÃ¡p nÃ y. HÆ¡n ná»¯a, trong
bá»‘i cáº£nh cá»§a low-rank adaptation (LoRA), rank r xÃ¡c Ä‘á»‹nh
sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n; do Ä‘Ã³, chÃºng tÃ´i thá»±c hiá»‡n má»™t
nghiÃªn cá»©u ablation Ä‘á»ƒ Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a rank r. Cuá»‘i cÃ¹ng, chÃºng tÃ´i
so sÃ¡nh hai phÆ°Æ¡ng phÃ¡p liÃªn quan Ä‘áº¿n sá»‘ lÆ°á»£ng tham sá»‘ vÃ 
yÃªu cáº§u khÃ´ng gian lÆ°u trá»¯ vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã³. Vá»›i má»¥c Ä‘Ã­ch nÃ y,
chÃºng tÃ´i khÃ¡m phÃ¡ cÃ¡c cÃ¢u há»i phá»¥ sau:

â€¢ (RQ4.1) PhÆ°Æ¡ng phÃ¡p PEFT nÃ o hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n, vÃ  táº¡i sao?
â€¢ (RQ4.2) Trong LoRA, rank r áº£nh hÆ°á»Ÿng nhÆ° tháº¿ nÃ o Ä‘áº¿n
cÃ¡c tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n vÃ  hiá»‡u nÄƒng tá»•ng thá»ƒ?
â€¢ (RQ4.3) Hai phÆ°Æ¡ng phÃ¡p PEFT so sÃ¡nh nhÆ° tháº¿ nÃ o vá»›i
cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã³ vá» hiá»‡u quáº£ tham sá»‘ vÃ 
yÃªu cáº§u khÃ´ng gian lÆ°u trá»¯?

B. Datasets
ChÃºng tÃ´i sá»­ dá»¥ng hai dataset code review ná»•i báº­t: dataset
tá»« CodeReviewer cá»§a Li et al. [20] (sau Ä‘Ã¢y lÃ  CRer
dataset), vÃ  dataset tá»« Tufano et al. [23] (sau Ä‘Ã¢y lÃ 
Tufano dataset). LÃ½ do cho lá»±a chá»n cá»§a chÃºng tÃ´i bao gá»“m:

â€¢ KhÃ´ng nhÆ° cÃ¡c dataset khÃ¡c trong literature [30], [56] bao phá»§
cÃ¡c sub-tasks cá»¥ thá»ƒ, cÃ¡c dataset Ä‘Æ°á»£c chá»n bao gá»“m
toÃ n bá»™ quy trÃ¬nh code review.
â€¢ Cáº£ CRer vÃ  Tufano datasets Ä‘á»u Ä‘Æ°á»£c dáº«n xuáº¥t tá»« má»™t
pháº¡m vi Ä‘a dáº¡ng cá»§a cÃ¡c repository, cung cáº¥p pháº¡m vi bao phá»§ rá»™ng.
Äiá»u nÃ y tÆ°Æ¡ng pháº£n vá»›i cÃ¡c dataset khÃ¡c [30], [56] láº¥y
tá»« má»™t pool repository háº¡n cháº¿, cÃ³ thá»ƒ dáº«n Ä‘áº¿n bias
do pháº¡m vi háº¡n cháº¿ cá»§a chÃºng.
â€¢ Tufano dataset lÃ  má»™t phiÃªn báº£n nÃ¢ng cao so vá»›i
nhá»¯ng dataset Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ [22], [25], [57], lÃ m cho nÃ³
Ä‘Æ°á»£c Æ°a thÃ­ch hÆ¡n vá» Ä‘á»™ má»›i vÃ  tÃ­nh toÃ n diá»‡n.
â€¢ Cáº£ hai datasets Ä‘á»u cÃ³ tÃ­nh seminal trong lÄ©nh vá»±c, má»—i dataset cung cáº¥p
cÃ¡c tÃ­nh nÄƒng Ä‘á»™c Ä‘Ã¡o gÃ³p pháº§n vÃ o nghiÃªn cá»©u cá»§a chÃºng tÃ´i.

CRer dataset, má»™t corpus Ä‘a ngÃ´n ngá»¯, Ä‘Æ°á»£c láº¥y tá»«
cÃ¡c repository GitHub vÃ  tuÃ¢n thá»§ Ä‘á»‹nh dáº¡ng diff-aware, line-grained. NÃ³ báº£o tá»“n inline comments vÃ  docstrings trong
cÃ¡c Ä‘oáº¡n code vÃ  giá»¯ láº¡i consecutive spaces. Dataset nÃ y Ä‘Æ°á»£c
chia thÃ nh ba sub-datasets, má»—i dataset Ä‘Æ°á»£c dÃ nh riÃªng cho má»™t khÃ­a cáº¡nh cá»¥ thá»ƒ
cá»§a code review: review necessity prediction, code review
comment generation, vÃ  code refinement.

--- TRANG 6 ---
Tufano dataset, ngÆ°á»£c láº¡i, lÃ  language-specific (Java)
vÃ  tá»•ng há»£p dá»¯ liá»‡u tá»« cáº£ GitHub vÃ  Gerrit. NÃ³ sá»­ dá»¥ng
Ä‘á»‹nh dáº¡ng function-grained, loáº¡i bá» comments vÃ  consecutive
spaces, vÃ  khÃ´ng pháº£n Ã¡nh sá»± khÃ¡c biá»‡t giá»¯a commit liÃªn quan
vÃ  base branch. Äá»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ code refinement, nÃ³
biá»ƒu thá»‹ cÃ¡c khu vá»±c focus trong comments sá»­ dá»¥ng marker "âŸ¨STARTâŸ©"
vÃ  "âŸ¨ENDâŸ©". ChÃºng tÃ´i sá»­ dá»¥ng hai subset cá»§a dataset nÃ y
cho code review comment generation vÃ  code refinement.

Báº£ng II cung cáº¥p tÃ³m táº¯t thá»‘ng kÃª chi tiáº¿t cá»§a cÃ¡c datasets.

C. TiÃªu chÃ­ ÄÃ¡nh giÃ¡
ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c metric cá»¥ thá»ƒ nhiá»‡m vá»¥ Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»‡u nÄƒng
cá»§a mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i qua cÃ¡c nhiá»‡m vá»¥ code review.

Äá»‘i vá»›i review necessity prediction, chÃºng tÃ´i tiáº¿p cáº­n nÃ³ nhÆ° má»™t váº¥n Ä‘á»
classification nhá»‹ phÃ¢n trong Ä‘Ã³ 'requiring a review' lÃ 
class positive. Do Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng precision, recall, vÃ  F1-score
lÃ m cÃ¡c metric Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ lÆ°á»£ng hÃ³a Ä‘á»™ chÃ­nh xÃ¡c phÃ¢n loáº¡i
cá»§a mÃ´ hÃ¬nh.

Äá»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ code review comment generation vÃ  code refine-
ment, liÃªn quan Ä‘áº¿n response generation, chÃºng tÃ´i sá»­ dá»¥ng
BLEU-4 score, Ä‘o lÆ°á»ng sá»± chá»“ng láº¥p cá»§a n-grams cho
n dao Ä‘á»™ng tá»« 1 Ä‘áº¿n 4. Äiá»u nÃ y tuÃ¢n theo phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡
Ä‘Æ°á»£c sá»­ dá»¥ng trong CodeReviewer [20].

ChÃºng tÃ´i khÃ´ng sá»­ dá»¥ng metric codeBLEU Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Tufano
et al. [23], do sá»± khÃ´ng tÆ°Æ¡ng thÃ­ch cá»§a nÃ³ vá»›i CRer dataset.
Cáº¥u trÃºc vÃ  sá»± Ä‘a dáº¡ng ngÃ´n ngá»¯ cá»§a CRer dataset lÃ m cho nÃ³
khÃ´ng phÃ¹ há»£p cho metric nÃ y.

Äá»‘i vá»›i táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥, chÃºng tÃ´i xem xÃ©t káº¿t quáº£ top-1, phÃ¹ há»£p vá»›i
má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh code review Ä‘á»ƒ giáº£m nháº¹
khá»‘i lÆ°á»£ng cÃ´ng viá»‡c cá»§a nhÃ  phÃ¡t triá»ƒn báº±ng cÃ¡ch táº­p trung vÃ o pháº£n há»“i cÃ³ liÃªn quan nháº¥t.

D. Baselines
ChÃºng tÃ´i chá»n baselines cá»§a mÃ¬nh dá»±a trÃªn nhu cáº§u Ä‘á»™c Ä‘Ã¡o
cá»§a cÃ¡c nhiá»‡m vá»¥ vÃ  datasets. Báº£ng III hiá»ƒn thá»‹ cÃ¡c baselines Ä‘Æ°á»£c chá»n.

ChÃºng tÃ´i bá» qua cÃ¡c nghiÃªn cá»©u cá»§a [25], [56], [57] khá»i lá»±a chá»n baseline
cá»§a chÃºng tÃ´i, vÃ¬ chÃºng Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ¡c datasets nhá» hÆ¡n hoáº·c yÃªu cáº§u
thÃ´ng tin input bá»• sung.

E. Chi tiáº¿t Triá»ƒn khai
ChÃºng tÃ´i triá»ƒn khai phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh sá»­ dá»¥ng cÃ¡c framework xturingÂ¹ vÃ  Lit
LLaMAÂ², tÆ°Æ¡ng á»©ng. Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c tiáº¿n
hÃ nh trÃªn cÃ¡c platform NVIDIA A100-SXM4-80GB GPU, vá»›i
giá»›i háº¡n Ä‘á»™ dÃ i token Ä‘Æ°á»£c Ä‘áº·t thÃ nh 2048 vÃ  batch size lÃ  64.
ChÃºng tÃ´i sá»­ dá»¥ng optimizer AdamW vÃ  huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh trong 5
epochs cho review necessity prediction vÃ  10 epochs cho cáº£
code review comment generation vÃ  code refinement tasks.

Äá»‘i vá»›i zero-init attention prefix-tuning, chÃºng tÃ´i sá»­ dá»¥ng learning rate
0.009, weight decay 0.02, prefix prompt length 10,
vÃ  prefix layer 30. Trong Low-rank Adaptation (LoRA),
chÃºng tÃ´i Ä‘áº·t learning rate thÃ nh 0.0003, weight decay thÃ nh 0.01,
LoRA rank thÃ nh 16, vÃ  LoRA scaling factor thÃ nh 16. CÃ i Ä‘áº·t thÃ­ nghiá»‡m ablation
cÃ³ thá»ƒ thay Ä‘á»•i dá»±a trÃªn yÃªu cáº§u cá»§a má»—i thÃ­ nghiá»‡m. LoRA rank vÃ  cÃ i Ä‘áº·t prefix-tuning Ä‘Æ°á»£c
Â¹https://github.com/stochasticai/xturing
Â²https://github.com/Lightning-AI/lit-llama dá»±a trÃªn kinh nghiá»‡m thá»±c nghiá»‡m [49], [50]. Chi tiáº¿t thÃªm vá»
cÃ¡c siÃªu tham sá»‘ cá»¥ thá»ƒ cÃ³ sáºµn trong tÃ i liá»‡u cá»§a chÃºng tÃ´i.

Triá»ƒn khai baseline Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho tá»«ng tÃ¬nh huá»‘ng. Äá»‘i vá»›i
káº¿t quáº£ CRer dataset, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c phÃ¡t hiá»‡n Ä‘Æ°á»£c bÃ¡o cÃ¡o trong
paper CodeReviewer [20], vÃ¬ chÃºng tÃ´i khÃ´ng thá»±c hiá»‡n sá»­a Ä‘á»•i nÃ o Ä‘á»‘i vá»›i
dataset. ChÃºng tÃ´i tÃ¡i táº¡o káº¿t quáº£ CommentFinder [31]
trÃªn cáº£ hai datasets sá»­ dá»¥ng code cÃ³ sáºµn cÃ´ng khai cá»§a há». Táº¥t cáº£
káº¿t quáº£ baseline khÃ¡c Ä‘Æ°á»£c dáº«n xuáº¥t tá»« cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p cá»§a há».

V. ÄÃNH GIÃ
Trong má»¥c nÃ y, chÃºng tÃ´i tuáº§n tá»± giáº£i quyáº¿t tá»«ng cÃ¢u há»i nghiÃªn
cá»©u, trÃ¬nh bÃ y káº¿t quáº£ thu Ä‘Æ°á»£c tá»« cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i vÃ 
rÃºt ra káº¿t luáº­n cho má»—i RQ. Tháº£o luáº­n cá»§a chÃºng tÃ´i báº¯t Ä‘áº§u vá»›i
má»™t Ä‘Ã¡nh giÃ¡ vá» hiá»‡u nÄƒng cá»§a LLaMA-Reviewer, tiáº¿p theo
bá»Ÿi má»™t khÃ¡m phÃ¡ vá» áº£nh hÆ°á»Ÿng cá»§a biá»ƒu diá»…n input vÃ 
giai Ä‘oáº¡n ban Ä‘áº§u cá»§a instruction tuning. ChÃºng tÃ´i káº¿t thÃºc vá»›i má»™t
phÃ¢n tÃ­ch vá» cÃ¡c tÃ¡c Ä‘á»™ng phÃ¡t sinh tá»« cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-
efficient fine-tuning (PEFT) khÃ¡c nhau.

A. RQ1: ÄÃ¡nh giÃ¡ Hiá»‡u nÄƒng cá»§a LLaMA-Reviewer
Má»¥c phá»¥ nÃ y Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a LLaMA-Reviewer
qua tá»«ng nhiá»‡m vá»¥, giáº£i thÃ­ch cÃ¡c káº¿t quáº£ quan sÃ¡t Ä‘Æ°á»£c, vÃ  tÃ³m táº¯t
cÃ¡c káº¿t luáº­n lÃ m nhá»¯ng phÃ¡t hiá»‡n chÃ­nh.

1) (RQ1.1) Hiá»‡u nÄƒng Review Necessity Prediction:
Trong cÃ¡c thÃ­ nghiá»‡m review necessity prediction cá»§a chÃºng tÃ´i, chÃºng tÃ´i táº­p trung
Ä‘á»™c quyá»n vÃ o CRer dataset, vÃ¬ Ä‘Ã¢y lÃ  dataset duy nháº¥t
cung cáº¥p dá»¯ liá»‡u cáº§n thiáº¿t cho nhiá»‡m vá»¥ nÃ y. Káº¿t quáº£
Ä‘Æ°á»£c trÃ¬nh bÃ y trong Báº£ng IV, vá»›i hÃ ng cuá»‘i hiá»ƒn thá»‹
káº¿t quáº£ cho LLaMA-Reviewer. CÃ¡c hÃ ng trÆ°á»›c Ä‘Ã³ hiá»ƒn thá»‹
káº¿t quáº£ dáº«n xuáº¥t tá»« [20]. ChÃºng tÃ´i xem xÃ©t class yÃªu cáº§u
má»™t review nhÆ° positive. Quan trá»ng, káº¿t quáº£ cho LLaMA-
Reviewer vá»›i prefix-tuning khÃ´ng Ä‘Æ°á»£c bao gá»“m trong nhiá»‡m vá»¥ nÃ y
do cáº¥u trÃºc huáº¥n luyá»‡n cá»©ng nháº¯c cá»§a nÃ³, khÃ´ng thuáº­n lá»£i cho
viá»‡c thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ classification.

LLaMA-Reviewer Ä‘áº¡t Ä‘Æ°á»£c recall vÆ°á»£t trá»™i vá»›i F1 score
tÆ°Æ¡ng Ä‘Æ°Æ¡ng, nhÆ° káº¿t quáº£ cho tháº¥y, cho tháº¥y ráº±ng nÃ³ cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh
má»™t sá»‘ lÆ°á»£ng lá»›n hÆ¡n cÃ¡c Ä‘oáº¡n code cÃ³ váº¥n Ä‘á» cÃ³ thá»ƒ
khuyáº¿n khÃ­ch tháº£o luáº­n trong quy trÃ¬nh code review tiáº¿p theo.
Kháº£ nÄƒng nÃ y lÃ  quan trá»ng Ä‘á»‘i vá»›i reviewers vÃ¬ má»¥c tiÃªu chÃ­nh
cá»§a code review lÃ  khÃ¡m phÃ¡ ra cÃ ng nhiá»u váº¥n Ä‘á» tiá»m nÄƒng cÃ ng
tá»‘t. Trong ká»‹ch báº£n nÃ y, LLaMA-Reviewer cÃ³ thá»ƒ giáº£m
sá»‘ lÆ°á»£ng Ä‘oáº¡n code cáº§n review sau khi lá»c, mÃ 
khÃ´ng bá» sÃ³t má»™t sá»‘ lÆ°á»£ng Ä‘Ã¡ng ká»ƒ cÃ¡c Ä‘oáº¡n cÃ³ váº¥n Ä‘á».
ChÃºng tÃ´i thu Ä‘Æ°á»£c nhá»¯ng káº¿t quáº£ nÃ y thÃ´ng qua Ä‘iá»u chá»‰nh threshold.

HÆ¡n ná»¯a, vá»›i threshold 0.5, giá»‘ng há»‡t vá»›i cÃ i Ä‘áº·t
generation gá»‘c, LLaMA-Reviewer Ä‘áº¡t Ä‘Æ°á»£c precision
88.61%, vÆ°á»£t qua táº¥t cáº£ baselines. Hiá»‡u nÄƒng nÃ y cÅ©ng
cÃ³ Ã½ nghÄ©a trong cÃ¡c ká»‹ch báº£n thá»±c táº¿, nÆ¡i cÃ¡c Ä‘oáº¡n code cÃ³ váº¥n Ä‘á»
Ã­t phá»• biáº¿n hÆ¡n nhá»¯ng Ä‘oáº¡n bÃ¬nh thÆ°á»ng, cho tháº¥y ráº±ng
false positives cÃ³ thá»ƒ Ä‘áº·t gÃ¡nh náº·ng bá»• sung lÃªn reviewers.

2) (RQ1.2) Hiá»‡u nÄƒng Review Comment Generation: ChÃºng tÃ´i
Ä‘Ã¡nh giÃ¡ nhiá»‡m vá»¥ code review comment generation sá»­ dá»¥ng cáº£
Tufano vÃ  CRer datasets. Báº£ng V minh há»a káº¿t quáº£,
vá»›i kÃ½ hiá»‡u "âˆ’" biá»ƒu thá»‹ giÃ¡ trá»‹ thiáº¿u. ÄÃ¡ng chÃº Ã½
ráº±ng CommentFinder [31] khÃ´ng bao gá»“m sá»‘ lÆ°á»£ng tham sá»‘
vÃ¬ nÃ³ khÃ´ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p deep learning. ChÃºng tÃ´i Ä‘Ã£

--- TRANG 7 ---
Báº¢NG II
Tá»”NG QUAN THá»NG KÃŠ Vá»€ TUFANO DATASET VÃ€ CRER DATASET.

Dataset Review Necessity Prediction Review Comment Generation Code Refinement Lang # Gran. Indent. & Consec. Spaces Diff. & Comm. Train # Valid # Test # Train # Valid # Test # Train # Valid # Test #
Tufano â€“ â€“ â€“ âˆ¼134k âˆ¼17k âˆ¼17k âˆ¼134k âˆ¼17k âˆ¼17k 1 Func. âœ˜ âœ˜
Crer âˆ¼226k âˆ¼31k âˆ¼31k âˆ¼118k âˆ¼10k âˆ¼10k âˆ¼150k âˆ¼13k âˆ¼13k 9 Line. âœ” âœ”

Báº¢NG III
TÃ“M Táº®T CÃC BASELINES.

Baseline (MÃ´ táº£) Nhiá»‡m vá»¥ Datasets Tham kháº£o
Transformer-s (6-layer encoder/decoder, huáº¥n luyá»‡n tá»« Ä‘áº§u) RCG, CR Tuf. [23], [58]
Transformer-b (12-layer encoder/decoder, huáº¥n luyá»‡n tá»« Ä‘áº§u) RNP, RCG, CR CRer [20], [58]
Tufano et al. (Pre-trained Transformer-s trÃªn datasets cá»§a há») RCG, CR CRer, Tuf. [23]
CodeT5 (Pre-trained Transformer-b model cho code understanding vÃ  generation) RNP, RCG, CR CRer [20], [34]
CodeReviewer (Pre-trained vá»›i Transformer-b vÃ  cÃ¡c pre-training tasks cá»¥ thá»ƒ code-review) RNP, RCG, CR CRer [20]
CommentFinder (Retrieval-based review comment recommendation) RCG CRer, Tuf. [31]
AUGER (Re-pre-trained T5 vá»›i extra review tags input) RCG Tuf. [30]

Viáº¿t táº¯t nhiá»‡m vá»¥: RNP (Review Necessity Prediction), RCG (Review Comment Generation), CR (Code Refinement).
Viáº¿t táº¯t dataset: CRer (CRer dataset), Tuf. (Tufano dataset).

Báº¢NG IV
Káº¾T QUáº¢ REVIEW NECESSITY PREDICTION TRÃŠN CRER DATASET.

Model Layers Model Params Trainable Params Storage Space Prec. Recall F1
Transformer-b 24 âˆ¼220M âˆ¼220M 850M 74.50 46.07 56.93
Tufano et al. 12 âˆ¼60M âˆ¼60M 231M 70.82 57.20 63.29
CodeT5 24 âˆ¼220M âˆ¼220M 850M 70.36 58.96 64.16
CodeReviewer 24 âˆ¼220M âˆ¼220M 850M 78.60 65.63 71.53
LLaMA-Reviewer (LoRA) 32 âˆ¼6.7B âˆ¼8.4M 16M 60.99 83.50 70.49

Báº¢NG V
Káº¾T QUáº¢ REVIEW COMMENT GENERATION.

Model L. Model Params Trainable Params Storage Space BLEU-4 Crer. Tuf.
Transformer-s 12 âˆ¼60M âˆ¼60M 231M â€“ 6.94*
Transformer-b 24 âˆ¼220M âˆ¼220M 850M 4.76 â€“
Tufano et al. 12 âˆ¼60M âˆ¼60M 231M 4.39 7.39*
CodeT5 24 âˆ¼220M âˆ¼220M 850M 4.83 â€“
CodeReviewer 24 âˆ¼220M âˆ¼220M 850M 5.32 â€“
CommentFinder â€“ â€“ â€“ âˆ¼100M 3.82* 4.19*
AUGER 24 âˆ¼220M âˆ¼220M 850M â€“ 3.03*
Ours (Prefix) 32 âˆ¼6.7B âˆ¼1.2M 2.4M 5.16 4.66
Ours (LoRA) 32 âˆ¼6.7B âˆ¼8.4M 16M 5.70 5.04

*Biá»ƒu thá»‹ káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c bá»Ÿi code hoáº·c mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p cá»§a há».

chá»n khÃ´ng bÃ¡o cÃ¡o má»™t sá»‘ káº¿t quáº£ baseline do sá»± khÃ´ng phÃ¹ há»£p
vá» granularity giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t vÃ  dataset,
Ä‘iá»u nÃ y lÃ m cho káº¿t quáº£ trá»Ÿ nÃªn vÃ´ nghÄ©a.

Káº¿t quáº£ cho tháº¥y LLaMA-Reviewer vÆ°á»£t qua táº¥t cáº£
baselines trÃªn CRer dataset, Ä‘áº·c biá»‡t khi sá»­ dá»¥ng
Low-Rank Adaptation (LoRA) Ä‘á»ƒ fine-tuning. Hiá»‡u nÄƒng vÆ°á»£t trá»™i
nÃ y lÃ m ná»•i báº­t tiá»m nÄƒng cá»§a large language models
(LLMs). Máº·c dÃ¹ LLaMA khÃ´ng Ä‘Æ°á»£c pre-trained cá»¥ thá»ƒ
cho cÃ¡c nhiá»‡m vá»¥ code review nhÆ° CodeReviewer [20], hiá»‡u nÄƒng vÆ°á»£t trá»™i
cá»§a nÃ³ vá»›i lÆ°á»£ng tuning háº¡n cháº¿ vÆ°á»£t qua hiá»‡u nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n. Káº¿t quáº£ trÃªn Tufano dataset tÆ°Æ¡ng Ä‘á»‘i
Ã­t lÃ½ tÆ°á»Ÿng hÆ¡n, mÃ  chÃºng tÃ´i sáº½ tháº£o luáº­n thÃªm trong RQ2.1.

Má»™t giáº£i thÃ­ch há»£p lÃ½ cho hiá»‡u nÄƒng nÃ¢ng cao nÃ y lÃ 
sá»± phÃ¹ há»£p giá»¯a nhiá»‡m vá»¥ natural language generation
vÃ  corpus pre-training cá»§a LLaMA. HÆ¡n ná»¯a, hiá»‡u nÄƒng áº¥n tÆ°á»£ng
trÃªn CRer dataset cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho viá»‡c sá»­ dá»¥ng
code differences vÃ  Ä‘á»‹nh dáº¡ng code thÃ´, pháº£n Ã¡nh
cÃ¡c Ä‘iá»u kiá»‡n cá»§a giai Ä‘oáº¡n pre-training. Cho Ä‘á»™ phá»©c táº¡p
cá»§a nhiá»‡m vá»¥ code review comment generation so vá»›i
cÃ¡c nhiá»‡m vá»¥ khÃ¡c [20], kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lá»›n hÆ¡n cá»§a LLaMA cung cáº¥p
má»™t lá»£i tháº¿ riÃªng biá»‡t.

3) (RQ1.3) Hiá»‡u nÄƒng Code Refinement: ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡
nhiá»‡m vá»¥ code refinement trÃªn cáº£ Tufano vÃ  CRer datasets.
Káº¿t quáº£ Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng VI, nÆ¡i kÃ½ hiá»‡u "âˆ’"
biá»ƒu thá»‹ giÃ¡ trá»‹ thiáº¿u.

TrÃªn cáº£ hai datasets, máº·c dÃ¹ khÃ´ng vÆ°á»£t qua táº¥t cáº£ mÃ´ hÃ¬nh,
LLaMA-Reviewer cáº¡nh tranh sÃ¡t sao vá»›i CodeReviewer [20]
hoáº·c Tufano et al. [23], cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c pre-trained cá»¥ thá»ƒ cho
code review vÃ  Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u tÆ°Æ¡ng á»©ng vÃ  vÆ°á»£t qua
hiá»‡u nÄƒng cá»§a cÃ¡c baselines khÃ¡c. Xem xÃ©t ráº±ng chÃºng tÃ´i sá»­ dá»¥ng
phiÃªn báº£n nhá» nháº¥t cá»§a LLaMA vÃ  epochs tuning háº¡n cháº¿,
káº¿t quáº£ nÃ y gá»£i Ã½ cÃ¡c cáº£i thiá»‡n tiá»m nÄƒng.

Lá»£i tháº¿ cá»§a LLaMA-Reviewer so vá»›i háº§u háº¿t baselines
chá»§ yáº¿u phÃ¡t sinh tá»« kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lá»›n vÃ  tÃ­nh cháº¥t cá»§a
dá»¯ liá»‡u pre-training. Khoáº£ng cÃ¡ch giá»¯a LLaMA-Reviewer vÃ 

--- TRANG 8 ---
Báº¢NG VI
Káº¾T QUáº¢ CODE REFINEMENT.

Model L. Model Params Trainable Params Storage Space BLEU-4 Crer. Tuf.
Transformer-s 12 âˆ¼60M âˆ¼60M 231M â€“ 77.54*
Tufano et al. 12 âˆ¼60M âˆ¼60M 231M 77.03 78.33*
CodeT5 24 âˆ¼220M âˆ¼220M 850M 80.82 â€“
CodeReviewer 24 âˆ¼220M âˆ¼220M 850M 82.61 â€“
Ours (Prefix) 32 âˆ¼6.7B âˆ¼1.2M 2.4M 76.71 77.04
Ours (LoRA) 32 âˆ¼6.7B âˆ¼8.4M 16M 82.27 78.23

*Biá»ƒu thá»‹ káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c bá»Ÿi code hoáº·c mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p cá»§a há».

CodeReviewer [20] hoáº·c Tufano et al. [23] lÃ  do sá»± khÃ¡c
biá»‡t giá»¯a cÃ¡c nhiá»‡m vá»¥ má»¥c tiÃªu cá»§a há» vÃ  cÃ¡c nhiá»‡m vá»¥ pre-training
cá»§a LLaMA, cÅ©ng nhÆ° cÃ¡c Ä‘á»‹nh dáº¡ng input. Tuy nhiÃªn, pre-
training cá»¥ thá»ƒ nhiá»‡m vá»¥ tá»« Ä‘áº§u, nhÆ° vá»›i CodeReviewer [20], tá»‘n
tÃ i nguyÃªn, táº¡o ra rÃ o cáº£n cho viá»‡c nÃ¢ng cao thÃ´ng qua má»Ÿ rá»™ng
kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. Thay vÃ o Ä‘Ã³, viá»‡c tÃ­ch há»£p kiáº¿n thá»©c lÄ©nh vá»±c vÃ o má»™t
mÃ´ hÃ¬nh pre-trained duy nháº¥t vÃ  Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p parameter-efficient fine-
tuning cÃ³ thá»ƒ tiáº¿t kiá»‡m chi phÃ­ hÆ¡n.

ThÃº vá»‹, tÃ­nh Ä‘Æ¡n giáº£n tÆ°Æ¡ng Ä‘á»‘i cá»§a nhiá»‡m vá»¥ code refinement
so vá»›i nhiá»‡m vá»¥ review comment generation cÃ³ thá»ƒ
Ä‘Ã£ nghá»‹ch lÃ½ lÃ m giáº£m BLEU score cá»§a LLaMA-Reviewer.
Äiá»u nÃ y lÃ  do mÃ´ hÃ¬nh, Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ táº¡o ra cÃ¡c
dá»± Ä‘oÃ¡n Ä‘a dáº¡ng báº¯t chÆ°á»›c hÃ nh vi con ngÆ°á»i, cÃ³ thá»ƒ táº¡o ra nhiá»u
refinements Ä‘a dáº¡ng hÆ¡n, nhÆ°ng há»£p lá»‡, mÃ  khÃ¡c vá»›i
ground truth duy nháº¥t, do Ä‘Ã³ giáº£m Ä‘á»™ tÆ°Æ¡ng tá»± textual.

Tráº£ lá»i cho RQ1: LLaMA-Reviewer tÆ°Æ¡ng Ä‘á»‘i xuáº¥t sáº¯c hÆ¡n
trong viá»‡c táº¡o ra review comments (NL) vÃ  xÃ¡c Ä‘á»‹nh
nhiá»u váº¥n Ä‘á» hÆ¡n trong necessity prediction trong khi duy
trÃ¬ hiá»‡u nÄƒng cáº¡nh tranh trong code refinement.

B. RQ2: áº¢nh hÆ°á»Ÿng cá»§a Biá»ƒu diá»…n Input
Trong má»¥c phá»¥ nÃ y, chÃºng tÃ´i Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a biá»ƒu diá»…n input
sá»­ dá»¥ng káº¿t quáº£ tá»« RQ1 vÃ  cÃ¡c thÃ­ nghiá»‡m ablation bá»• sung. ChÃºng tÃ´i giáº£i quyáº¿t tá»«ng cÃ¢u há»i phá»¥ láº§n lÆ°á»£t trÆ°á»›c khi
rÃºt ra káº¿t luáº­n tá»•ng thá»ƒ.

1) (RQ2.1) Háº­u quáº£ cá»§a Code Formatting: Äá»ƒ Ä‘Ã¡nh giÃ¡
hiá»‡u á»©ng cá»§a code formatting, chÃºng tÃ´i kiá»ƒm tra káº¿t quáº£ cá»§a cÃ¡c nhiá»‡m vá»¥
comment generation vÃ  code refinement code sá»­ dá»¥ng cáº£
CRer vÃ  Tufano datasets.

Káº¿t quáº£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong Má»¥c V-A cho tháº¥y hiá»‡u nÄƒng tÆ°Æ¡ng Ä‘á»‘i vÆ°á»£t trá»™i
trÃªn CRer dataset so vá»›i
Tufano dataset. Máº·c dÃ¹ cÃ³ sá»± khÃ¡c biá»‡t trong phÃ¢n phá»‘i dá»¯ liá»‡u,
sá»± khÃ¡c biá»‡t chÃ­nh giá»¯a hai datasets nÃ y náº±m á»Ÿ
code formatting cá»§a chÃºng. Code trong CRer dataset thÃ´ sÆ¡ hÆ¡n
vÃ  giá»‘ng vá»›i Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh pre-training cá»§a LLaMA,
trong khi code trong Tufano dataset Ä‘Ã£ tráº£i qua
xá»­ lÃ½ tinh vi. Nhá»¯ng káº¿t quáº£ nÃ y gá»£i Ã½ ráº±ng má»™t biá»ƒu diá»…n code
tÆ°Æ¡ng tá»± vá»›i biá»ƒu diá»…n Ä‘Æ°á»£c sá»­ dá»¥ng trong pre-training
cho phÃ©p mÃ´ hÃ¬nh táº­n dá»¥ng tá»‘t hÆ¡n hiá»ƒu biáº¿t cá»§a nÃ³ vá» cáº¥u trÃºc code
vÃ  semantics.

2) (RQ2.2) Vai trÃ² cá»§a Language Label: ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­
nghiá»‡m Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a language labels chá»‰

Báº¢NG VII
VAI TRÃ’ Cá»¦A LANGUAGE LABEL (LoRA r= 8).

Model Lang. Label Placement BLEU-4
LLaMA-Reviewer (LoRA) w/o Instruction Tuning âœ˜ â€“ 81.87
âœ” Instruction 81.07
âœ” Input 81.33
LLaMA-Reviewer (LoRA) w/ Instruction Tuning âœ˜ â€“ 81.59
âœ” Instruction 82.00

trÃªn CRer dataset, vÃ¬ nÃ³ bao gá»“m nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh.
Language labels, Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh dá»±a trÃªn ngÃ´n ngá»¯ láº­p trÃ¬nh
cá»§a code, Ä‘Æ°á»£c tÃ­ch há»£p vÃ o instruction hoáº·c input,
nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3. CÃ¡c cÃ i Ä‘áº·t cÃ²n láº¡i, mÆ°á»£n tá»« nhiá»‡m vá»¥ code refinement vá»›i low-
rank adaptation lÃ m phÆ°Æ¡ng phÃ¡p fine-tuning, Ä‘Æ°á»£c giá»¯ khÃ´ng Ä‘á»•i.

TrÃ¡i vá»›i ká»³ vá»ng, káº¿t quáº£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong Báº£ng
VII tiáº¿t lá»™ ráº±ng viá»‡c thÃªm language label khÃ´ng nÃ¢ng cao
hiá»‡u nÄƒng mÃ  khÃ´ng cÃ³ giai Ä‘oáº¡n ban Ä‘áº§u cá»§a instruction tuning.
Äiá»u nÃ y cÃ³ thá»ƒ do khÃ³ khÄƒn cá»§a mÃ´ hÃ¬nh trong viá»‡c liÃªn káº¿t thÃ´ng tin label
vá»›i nhiá»‡m vá»¥ mÃ  khÃ´ng cÃ³ kiáº¿n thá»©c lÄ©nh vá»±c cÃ³ sáºµn trÆ°á»›c.
Tuy nhiÃªn, má»™t khi instruction tuning Ä‘Æ°á»£c triá»ƒn khai,
cÃ¡c labels thá»±c sá»± Ä‘Ã³ng gÃ³p tÃ­ch cá»±c vÃ o hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.
ThÃ´ng qua paired bootstrap resampling test, chÃºng tÃ´i xÃ¡c Ä‘á»‹nh
ráº±ng viá»‡c sá»­ dá»¥ng language label cáº£i thiá»‡n hiá»‡u nÄƒng so vá»›i
viá»‡c khÃ´ng cÃ³ nÃ³, Ä‘Æ°á»£c chá»©ng minh bá»Ÿi p-value 0.0032.

Máº·c dÃ¹ language labels Ä‘Ã£ chá»©ng minh giÃ¡ trá»‹ cá»§a chÃºng, chÃºng tÃ´i
chá»n khÃ´ng bao gá»“m chÃºng trong cÃ¡c thÃ­ nghiá»‡m khÃ¡c Ä‘á»ƒ
duy trÃ¬ tÃ­nh nháº¥t quÃ¡n vá»›i nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ [20] vÃ  Ä‘áº£m báº£o
so sÃ¡nh cÃ´ng báº±ng.

Tráº£ lá»i cho RQ2: LLaMA-Reviewer hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n
khi biá»ƒu diá»…n input giá»‘ng vá»›i biá»ƒu diá»…n Ä‘Æ°á»£c sá»­ dá»¥ng trong
pre-training. ThÃ´ng tin natural language bá»• sung,
nhÆ° language labels, cÃ³ thá»ƒ Ä‘Æ°á»£c táº­n dá»¥ng tá»‘t hÆ¡n
bá»Ÿi mÃ´ hÃ¬nh thÃ´ng qua instruction tuning.

C. RQ3: TÃ¡c Ä‘á»™ng cá»§a Instruction Tuning
Äá»ƒ tráº£ lá»i RQ3, chÃºng tÃ´i thá»±c hiá»‡n thÃ­ nghiá»‡m vá»›i cÃ¡c mÃ´ hÃ¬nh
Ä‘Æ°á»£c huáº¥n luyá»‡n cÃ³ vÃ  khÃ´ng cÃ³ giai Ä‘oáº¡n sÆ¡ bá»™ cá»§a instruction
tuning, sá»­ dá»¥ng cáº£ zero-init attention prefix-tuning vÃ 
Low-Rank Adaptation (LoRA). ChÃºng tÃ´i cÅ©ng giá»›i thiá»‡u cÃ¡c thÃ­ nghiá»‡m bá»•
sung vá»›i cÃ¡c hÆ°á»›ng dáº«n natural language bá»• sung
[53] trong quÃ¡ trÃ¬nh LoRA instruction tuning Ä‘á»ƒ xÃ¡c Ä‘á»‹nh dá»¯ liá»‡u
instruction tuning tá»‘i Æ°u (nhÆ° Ä‘Æ°á»£c Ä‘áº·t ra bá»Ÿi RQ3.3). CÃ¡c thÃ­ nghiá»‡m
Ä‘Æ°á»£c tiáº¿n hÃ nh trÃªn CRer dataset sá»­ dá»¥ng LoRA, vÃ  káº¿t quáº£
tá»« cÃ¡c nhiá»‡m vá»¥ code review Ä‘Æ°á»£c ghi chÃ©p trong Báº£ng VIII.

1) (RQ3.1) Háº­u quáº£ cho Zero-init Attention Prefix-
tuning: Káº¿t quáº£ cá»§a chÃºng tÃ´i gá»£i Ã½ ráº±ng instruction tuning khÃ´ng
thuáº­n lá»£i cho prefix tuning. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho
cáº¥u trÃºc cá»§a prefix tuning, sá»­ dá»¥ng prefix chá»‰ Ä‘á»ƒ
kiá»ƒm soÃ¡t attention vÃ  giá»¯ attention qua postfix cá»‘ Ä‘á»‹nh.
Do Ä‘Ã³, kháº£ nÄƒng náº¯m báº¯t kiáº¿n thá»©c lÄ©nh vá»±c tá»•ng quÃ¡t
cá»§a nÃ³ bá»‹ háº¡n cháº¿. HÆ¡n ná»¯a, zero-init prefix attention, Ä‘Ã³ng gÃ³p
Ä‘Ã¡ng ká»ƒ vÃ o hiá»‡u quáº£ cá»§a prefix tuning, bá»‹
lÃ m suy yáº¿u khi instruction tuning Ä‘Æ°á»£c thÃªm vÃ o.

--- TRANG 9 ---
Báº¢NG VIII
TÃC Äá»˜NG Cá»¦A INSTRUCTION TUNING (LoRA r= 8).

Method I. Tuning Dataset RNP (F1) RCG CR
LoRA âœ˜ â€“ 70.20 5.58 81.87
âœ” PL 69.34 5.64 81.59
âœ” PL + NL 69.82 5.23 81.17
Prefix-tuning âœ˜ â€“ â€“ 5.16 76.71
âœ” PL â€“ 5.02 76.04

2) (RQ3.2) Háº­u quáº£ cho Low-Rank Adaptation: KhÃ´ng
nhÆ° prefix tuning, instruction tuning káº¿t há»£p vá»›i LoRA
cáº£i thiá»‡n hiá»‡u nÄƒng qua háº§u háº¿t cÃ¡c nhiá»‡m vá»¥. Äá»‘i vá»›i review necessity
prediction, nÃ³ nÃ¢ng cao precision cá»§a dá»± Ä‘oÃ¡n tá»« 81.56%
lÃªn 83.99% khi sá»­ dá»¥ng PL dataset lÃ m bá»™ tuning
duy nháº¥t, máº·c dÃ¹ nÃ³ khÃ´ng nÃ¢ng cao f1-score. Äá»‘i vá»›i review
comment generation, nÃ³ tÄƒng BLEU score.Â³ Äá»‘i vá»›i code
refinement, máº·c dÃ¹ khÃ´ng phÃ¡t hiá»‡n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ,
chÃºng tÃ´i suy luáº­n tá»« Má»¥c V-B ráº±ng nÃ³ tÄƒng cÆ°á»ng kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh
Ä‘á»ƒ káº¿t há»£p thÃ´ng tin label. Instruction tuning vá»›i LoRA
giÃºp mÃ´ hÃ¬nh cÆ¡ sá»Ÿ hiá»ƒu Ã½ Ä‘á»‹nh hÆ°á»›ng dáº«n, mÃ 
láº§n lÆ°á»£t cÃ³ lá»£i cho task tuning tiáº¿p theo, Ä‘áº·c biá»‡t review
comment generation, cho Ä‘á»™ phá»©c táº¡p vÃ  tÃ­nh cháº¥t Ä‘a Ã½ Ä‘á»‹nh
cá»§a nÃ³.

3) (RQ3.3) áº¢nh hÆ°á»Ÿng cá»§a CÃ¡c loáº¡i Instruction: ChÃºng tÃ´i táº­p trung vÃ o
cÃ¡c hÃ ng "PL+NL" vÃ  "PL" sá»­ dá»¥ng LoRA, biá»ƒu thá»‹ viá»‡c sá»­ dá»¥ng
cáº£ dá»¯ liá»‡u Alpaca vÃ  Code Alpaca vÃ  chá»‰ dá»¯ liá»‡u Code Alpaca,
tÆ°Æ¡ng á»©ng. ThÃº vá»‹, máº·c dÃ¹ cÃ¡c nhiá»‡m vá»¥ code review
cÃ³ liÃªn quan máº­t thiáº¿t Ä‘áº¿n natural language, viá»‡c káº¿t há»£p dá»¯ liá»‡u Alpaca
cho instruction tuning lÃ m giáº£m hiá»‡u nÄƒng qua táº¥t cáº£
cÃ¡c nhiá»‡m vá»¥. Xu hÆ°á»›ng nÃ y cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n sá»± Ä‘a dáº¡ng má»Ÿ rá»™ng cá»§a
cÃ¡c hÆ°á»›ng dáº«n natural language trong Alpaca. CÃ¡c hÆ°á»›ng dáº«n rá»™ng trong
Alpaca dataset cÃ³ cÃ¡c Ä‘á»™ng tá»« nhÆ° rewrite vÃ  classify,
vÃ  chÃºng dÆ°á»ng nhÆ° quÃ¡ táº£i cho cÃ¡c nhiá»‡m vá»¥ code review do
pháº¡m vi rá»™ng cá»§a cÃ¡c nhiá»‡m vá»¥.

Tráº£ lá»i cho RQ3: Instruction tuning cÃ³ thá»ƒ tiá»m nÄƒng
nÃ¢ng cao hiá»‡u nÄƒng nhiá»‡m vá»¥ hoáº·c kháº£ nÄƒng xá»­ lÃ½
thÃ´ng tin natural language bá»• sung. Tuy nhiÃªn,
hiá»‡u quáº£ lÃ  nhá» do sá»± khÃ´ng nháº¥t quÃ¡n vá» thÃ³i quen tá»«
giá»¯a instruction vÃ  downstream datasets.

D. RQ4: áº¢nh hÆ°á»Ÿng cá»§a Parameter-Efficient Fine-Tuning
Äá»ƒ khÃ¡m phÃ¡ tÃ¡c Ä‘á»™ng cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Parameter-Efficient Fine-Tuning
(PEFT), chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m bá»• sung Ä‘iá»u chá»‰nh
rank r cá»§a LoRA, cá»¥ thá»ƒ Ä‘áº·t rank thÃ nh 8 vÃ 
16. Äiá»u tra vá» cÃ¡c siÃªu tham sá»‘ cho prefix-tuning Ä‘Æ°á»£c
bá» qua vÃ¬ nÃ³ Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ­ch Ä‘áº§y Ä‘á»§ trong cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã³ [49]. Káº¿t
quáº£ Ä‘Æ°á»£c chi tiáº¿t trong Báº£ng IX. Äá»ƒ phÃ¢n tÃ­ch so sÃ¡nh,
chÃºng tÃ´i cÅ©ng bao gá»“m káº¿t quáº£ cá»§a prefix-tuning.

1) (RQ4.1) So sÃ¡nh giá»¯a cÃ¡c PhÆ°Æ¡ng phÃ¡p PEFT: Káº¿t
quáº£ quyáº¿t Ä‘á»‹nh cho tháº¥y LoRA vÆ°á»£t qua prefix-tuning
qua táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥. ChÃºng tÃ´i quy hiá»‡u nÄƒng nÃ¢ng cao nÃ y cho hai

Â³Hiá»‡u á»©ng nÃ y rÃµ rÃ ng hÆ¡n vá»›i learning rate 5e-5. Sau 10 epochs,
káº¿t quáº£ cÃ³ vÃ  khÃ´ng cÃ³ instruction tuning láº§n lÆ°á»£t lÃ  5.43 vÃ  5.27.

Báº¢NG IX
áº¢NH HÆ¯á»NG Cá»¦A CÃC PHÆ¯Æ NG PHÃP PARAMETER-EFFICIENT FINE-TUNING.

Tuning Method r Trainable Params Storage Space RNP (F1) RCG (BLEU) CR (BLEU)
Prefix â€“ âˆ¼1.2M 2.4M â€“ 5.16 76.71
LoRA 8 âˆ¼4.2M 8M 69.34 5.64 81.59
LoRA 16 âˆ¼8.4M 16M 70.49 5.7 82.27

khÃ­a cáº¡nh chÃ­nh. Äáº§u tiÃªn, phÆ°Æ¡ng phÃ¡p prefix-tuning Ä‘Æ°á»£c triá»ƒn khai
trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i cÃ³ Ã­t tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n hÆ¡n so vá»›i LoRA,
cáº£n trá»Ÿ kháº£ nÄƒng thÃ­ch á»©ng cá»§a nÃ³ tá»« mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Thá»© hai,
trÃ¡i vá»›i prefix-tuning dá»±a vÃ o prefixes Ä‘á»ƒ kiá»ƒm soÃ¡t
mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, LoRA xáº¥p xá»‰ full-parameter tuning, má»™t
thuá»™c tÃ­nh quan trá»ng khi output má»¥c tiÃªu khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ
tá»« Ä‘á»‹nh dáº¡ng pre-training.

2) (RQ4.2) TÃ¡c Ä‘á»™ng cá»§a LoRA Rank r: TÄƒng LoRA
rank r tá»« 8 lÃªn 16 cáº£i thiá»‡n hiá»‡u nÄƒng cá»§a LLaMA-
Reviewer. Cáº£i thiá»‡n nÃ y lÃ  trá»±c quan, vÃ¬ rank cao hÆ¡n
tÄƒng cÆ°á»ng sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n, Ä‘Æ°a
mÃ´ hÃ¬nh gáº§n hÆ¡n vá»›i full-parameter tuning. Tuy nhiÃªn, má»¥c tiÃªu chÃ­nh
cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT lÃ  háº¡n cháº¿ tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n
vÃ  báº£o tá»“n tÃ i nguyÃªn tÃ­nh toÃ¡n. Do Ä‘Ã³, viá»‡c Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng
giá»¯a hiá»‡u nÄƒng vÃ  hiá»‡u quáº£ lÃ  má»™t cÃ¢n nháº¯c quan trá»ng.

3) (RQ4.3) Hiá»‡u quáº£ cá»§a cÃ¡c PhÆ°Æ¡ng phÃ¡p PEFT: NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong
báº£ng, cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n
xuá»‘ng dÆ°á»›i 1% trong khi váº«n Ä‘áº£m báº£o hiá»‡u nÄƒng cháº¥p nháº­n Ä‘Æ°á»£c.
Cho ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT giá»¯ cÃ¡c weights cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ
khÃ´ng Ä‘á»•i, khÃ´ng gian lÆ°u trá»¯ giáº£m máº¡nh tá»« 13GB xuá»‘ng
dÆ°á»›i 20MB. Nhá»¯ng independent plug-in weights nÃ y lÃ m cho cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT
phÃ¹ há»£p lÃ½ tÆ°á»Ÿng cho cÃ¡c quy trÃ¬nh Ä‘a nhiá»‡m vá»¥, nhÆ°
tá»± Ä‘á»™ng hÃ³a cÃ¡c hoáº¡t Ä‘á»™ng code review.

Tráº£ lá»i cho RQ4: Trong sá»‘ cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT, LoRA
phÃ¹ há»£p hÆ¡n cho viá»‡c tá»± Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ code review.
Báº±ng cÃ¡ch chá»n LoRA rank thÃ­ch há»£p, LLaMA-
Reviewer cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng cáº¡nh tranh vá»›i
Ã­t hÆ¡n 1% tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n vÃ  yÃªu cáº§u
khÃ´ng gian lÆ°u trá»¯ giáº£m Ä‘Ã¡ng ká»ƒ.

VI. CÃ”NG TRÃŒNH LIÃŠN QUAN
A. Tuning trÃªn LLaMA
Trong khi ChatGPT vÃ  series GPT proprietary cá»§a OpenAI Ä‘Ã£
thÃºc Ä‘áº©y tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong lÄ©nh vá»±c AI, báº£n cháº¥t closed-source
cá»§a chÃºng Ä‘Ã£ táº¡o ra sá»± dÃ¨ dáº·t trong sá»‘ cÃ¡c nhÃ  nghiÃªn cá»©u. Giáº£i
quyáº¿t má»‘i quan tÃ¢m nÃ y, Meta Ä‘Ã£ giá»›i thiá»‡u Large
Language Model (LLaMA) open-source cá»§a há» [37], nhanh chÃ³ng ná»•i lÃªn
nhÆ° má»™t tÃ i sáº£n then chá»‘t trong bá»‘i cáº£nh AI do kháº£ nÄƒng hiá»‡u nÄƒng
Ä‘Ã¡ng chÃº Ã½ cá»§a nÃ³.

Má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh tuned dá»±a trÃªn LLaMA Ä‘Ã£ cho tháº¥y
hiá»‡u nÄƒng Ä‘áº·c biá»‡t, cáº¡nh tranh vá»›i ChatGPT vÃ  GPT se-
ries. Alpaca cá»§a Stanford [53] Ä‘áº¡i diá»‡n cho má»™t phÃ¡t triá»ƒn quan trá»ng sá»›m
trong khu vá»±c nÃ y, tuning LLaMA sá»­ dá»¥ng má»™t dataset
Ä‘Æ°á»£c táº¡o ra tá»« ChatGPT. CÃ¡c cÃ´ng trÃ¬nh Ä‘Ã¡ng chÃº Ã½ tiáº¿p theo Ä‘Ã£
theo Ä‘uá»•i má»™t pháº¡m vi má»¥c tiÃªu, bao gá»“m cÃ¡c thÃ­ch á»©ng cá»¥ thá»ƒ ngÃ´n ngá»¯
[59], [60], nÃ¢ng cao cháº¥t lÆ°á»£ng vÄƒn báº£n [61], [62],

--- TRANG 10 ---
multi-modal input accommodation [49], [63], [64], vÃ  cáº£i thiá»‡n kháº£ nÄƒng liÃªn quan Ä‘áº¿n code
[54].

Do nhu cáº§u tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ cá»§a full pa-
rameter tuning, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ hÆ°á»›ng tá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p Parameter-
Efficient Fine-Tuning (PEFT) Ä‘á»ƒ tuning LLaMA.
Má»™t vÃ­ dá»¥ nhÆ° váº­y lÃ  Alpaca LoRA, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u
nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i Alpaca chá»‰ vá»›i 0.13%
tham sá»‘ huáº¥n luyá»‡n, dáº«n Ä‘áº¿n khoáº£ng 60 láº§n tÄƒng tá»‘c
[50]. LLaMA-adapter, Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Zhang et al.
[49], Ä‘áº¡i diá»‡n cho má»™t Ä‘Ã³ng gÃ³p thÃªm, sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p zero-init
attention prefix-tuning.

NghiÃªn cá»©u cá»§a chÃºng tÃ´i táº­p trung vÃ o Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a LLaMA trÃªn
cÃ¡c nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n code review vÃ  sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT
state-of-the-art Ä‘á»ƒ nÃ¢ng cao hiá»‡u quáº£ huáº¥n luyá»‡n.

B. Tá»± Ä‘á»™ng hÃ³a cÃ¡c Hoáº¡t Ä‘á»™ng Code Review
Code review lÃ  má»™t khÃ­a cáº¡nh cáº§n thiáº¿t, máº·c dÃ¹ tá»‘n thá»i gian, cá»§a
phÃ¡t triá»ƒn pháº§n má»m, khÆ¡i dáº­y sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ Ä‘áº¿n
cÃ¡c chiáº¿n lÆ°á»£c tá»± Ä‘á»™ng hÃ³a cho cÃ¡c hoáº¡t Ä‘á»™ng nhÆ° Ä‘á» xuáº¥t reviewer
[6]â€“[15], Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng code [12], [16]â€“[21],
tinh chá»‰nh code cÃ³ váº¥n Ä‘á» [20], [22]â€“[25], vÃ  gá»£i Ã½ comment review
[20], [23], [26]â€“[31]. Paper nÃ y táº­p trung vÃ o
pipeline Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Li et al. [20], bao gá»“m review
necessity prediction, code review comment generation, vÃ 
code refinement.

CÃ¡c nghiÃªn cá»©u sá»›m vá» review necessity prediction chá»§ yáº¿u kiá»ƒm
tra sá»± cháº¥p nháº­n diff hunk, vá»›i Shi et al. [16] tiÃªn phong má»™t
framework dá»±a trÃªn CNN vÃ  LSTM, DACE, vÃ  Hellendoorn
et al. [17] sá»­ dá»¥ng Transformer Ä‘á»ƒ tÃ­nh Ä‘áº¿n quan há»‡ inter-diff hunk
trong má»™t pull request (PR) duy nháº¥t. Tuy nhiÃªn, lÄ©nh vá»±c
Ä‘Ã£ tiáº¿n hÃ³a ká»ƒ tá»« Ä‘Ã³, vá»›i Li et al. [20] chuyá»ƒn focus vá»
viá»‡c xÃ¡c Ä‘á»‹nh cÃ¡c diff hunks yÃªu cáº§u review vÃ  tÃ­ch há»£p Ä‘iá»u nÃ y vÃ o
má»™t pipeline vá»›i mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ code review.

CÃ¡c ná»— lá»±c ban Ä‘áº§u trong comment code review táº­n dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn retrieval
cho viá»‡c trÃ­ch xuáº¥t comment lá»‹ch sá»­. Gupta et
al. [27] giá»›i thiá»‡u mÃ´ hÃ¬nh dá»±a trÃªn LSTM, DeepMem, Ä‘á»ƒ
Ä‘á» xuáº¥t comment cho cÃ¡c Ä‘oáº¡n code má»›i dá»±a trÃªn má»‘i quan há»‡
cá»§a chÃºng vá»›i cÃ¡c thay Ä‘á»•i code, trong khi Siow et al. [28] nÃ¢ng cao
retrieval thÃ´ng qua viá»‡c náº¯m báº¯t thÃ´ng tin semantic LSTM dá»±a trÃªn attention.
LÄ©nh vá»±c Ä‘Ã£ chuyá»ƒn vá» viá»‡c táº¡o ra review
comments vá»›i sá»± gia tÄƒng cá»§a deep learning. Tufano et al. [23]
tiÃªn phong phÆ°Æ¡ng phÃ¡p nÃ y, pre-training má»™t mÃ´ hÃ¬nh trÃªn cáº£ code vÃ 
ngÃ´n ngá»¯ ká»¹ thuáº­t, vá»›i cÃ¡c ná»— lá»±c tiáº¿p theo bá»Ÿi CodeReviewer
[20] vÃ  AUGER [30] sá»­ dá»¥ng mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ code review
vÃ  review tags, tÆ°Æ¡ng á»©ng, Ä‘á»ƒ cáº£i thiá»‡n káº¿t quáº£.
Äá»“ng thá»i, CommentFinder [31] trÃ¬nh bÃ y má»™t
lá»±a chá»n thay tháº¿ dá»±a trÃªn retrieval hiá»‡u quáº£.

Äá»‘i vá»›i code refinement, cÃ¡c ná»— lá»±c sá»›m thÆ°á»ng Ä‘Æ°á»£c cÄƒn chá»‰nh vá»›i
cÃ¡c ká»¹ thuáº­t automatic bug-fixing [65]â€“[67]. TiÃªn phong viá»‡c
thÃ­ch á»©ng nhiá»‡m vá»¥ nÃ y vá»›i code review, Tufano et al. [68]
táº­p trung vÃ o viá»‡c há»c tá»« cÃ¡c thay Ä‘á»•i code Ä‘Æ°á»£c triá»ƒn khai trong PRs.
CÃ¡c nhÃ  nghiÃªn cá»©u sau Ä‘Ã³ káº¿t há»£p comment code review vÃ o input nhiá»‡m vá»¥
Ä‘á»ƒ mÃ´ phá»ng tá»‘t hÆ¡n code refinement [22], [23]. Giáº£i quyáº¿t
thÃ¡ch thá»©c cá»§a cÃ¡c token má»›i, AutoTransforms [25] sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p
byte-pair encoding (BPE), bá»• sung sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nháº­n biáº¿t diff,
D-ACT [56], Ä‘á»ƒ tÄƒng hiá»‡u nÄƒng trong cÃ¡c trÆ°á»ng há»£p liÃªn quan máº­t thiáº¿t Ä‘áº¿n sá»± khÃ¡c biá»‡t Ä‘Æ¡n láº» giá»¯a code base vÃ 
commit ban Ä‘áº§u. Tuy nhiÃªn, há» khÃ´ng tÃ­nh Ä‘áº¿n áº£nh hÆ°á»Ÿng
cá»§a comment code review vÃ  loáº¡i trá»« dá»¯ liá»‡u vá»›i input
tÆ°Æ¡ng tá»±. CoditT5 [57], má»™t mÃ´ hÃ¬nh pre-trained Ä‘Æ°á»£c thiáº¿t káº¿ rÃµ rÃ ng
cho editing, sá»­ dá»¥ng má»™t pháº§n dataset cá»§a Tufano Ä‘á»ƒ validation nhÆ° má»™t
downstream task. TÆ°Æ¡ng tá»±, CodeReviewer [20] phÃ¡t triá»ƒn má»™t
mÃ´ hÃ¬nh dá»±a trÃªn mÃ´ hÃ¬nh pre-trained cá»§a há», Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cá»¥ thá»ƒ
cho quy trÃ¬nh code review.

Máº·c dÃ¹ cÃ³ tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong viá»‡c tá»± Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ code review
, nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ thÆ°á»ng bá» qua tiá»m nÄƒng cá»§a cÃ¡c
large language models (LLMs) thá»‘ng nháº¥t. Khi kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u huáº¥n luyá»‡n
tiáº¿p tá»¥c tÄƒng trÆ°á»Ÿng, cÃ¡c LLMs thá»‘ng nháº¥t Ä‘ang cáº£i thiá»‡n
hiá»‡u nÄƒng cá»§a chÃºng vá»›i tá»‘c Ä‘á»™ nhanh vÃ  cho tháº¥y hiá»‡u nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng
vá»›i nhá»¯ng mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ nhiá»‡m vá»¥. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh pre-trained cá»¥ thá»ƒ nhiá»‡m vá»¥
, xÃ¢y dá»±ng tá»« Ä‘áº§u tá»‘n tÃ i nguyÃªn vÃ 
thá»i gian. Do Ä‘Ã³, trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i táº­n dá»¥ng LLaMA, má»™t
large language model thá»‘ng nháº¥t chÃ­nh thá»‘ng, Ä‘á»ƒ Ä‘iá»u tra
tiá»m nÄƒng phÃ¡t triá»ƒn cá»§a LLMs vÃ  Ä‘Ã¡nh giÃ¡ sá»± phÃ¹ há»£p cá»§a chÃºng cho
cÃ¡c nhiá»‡m vá»¥ bao gá»“m cáº£ láº­p trÃ¬nh vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn,
nhÆ° cÃ¡c nhiá»‡m vá»¥ code review.

VII. ÄE Dá»ŒA Äá»I Vá»šI VALIDITY
A. Construct Validity
ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i dá»±a chá»§ yáº¿u vÃ o má»™t biáº¿n thá»ƒ cá»§a
metric BLEU-4. Máº·c dÃ¹ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ [20], [22],
[23], [25], [31], [57], nÃ³ khÃ´ng Ä‘Æ°á»£c cÃ´ng nháº­n rá»™ng rÃ£i nhÆ°
metric chÃ­nh thá»©c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ comment code review vÃ 
cÃ¡c Ä‘oáº¡n code Ä‘Æ°á»£c tinh chá»‰nh. CÃ¡c metric khÃ¡c nhÆ° rouge khÃ´ng Ä‘Æ°á»£c
xem xÃ©t vÃ¬ má»™t sá»‘ mÃ´ hÃ¬nh baseline khÃ´ng cung
cáº¥p káº¿t quáº£ trá»±c tiáº¿p hoáº·c mÃ´ hÃ¬nh fine-tuned vÃ  cÃ¡c dá»± Ä‘oÃ¡n Ä‘Æ°á»£c táº¡o ra
. CÃ¡c test cá»§a chÃºng tÃ´i trÃªn baselines, bao gá»“m AUGER [30]
vÃ  CommentFinder [31], dá»±a vÃ o code hoáº·c mÃ´ hÃ¬nh
Ä‘Æ°á»£c cung cáº¥p bá»Ÿi paper gá»‘c, cÃ³ thá»ƒ Ä‘Ã£ lá»‡ch khá»i
káº¿t quáº£ tá»‘i Æ°u do cÃ¡c Ä‘á»‹nh dáº¡ng vÃ  phÃ¢n phá»‘i dá»¯ liá»‡u khÃ¡c nhau.

B. Internal Validity
ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i vá» parameter-efficient fine-tuning (PEFT)
bá»‹ háº¡n cháº¿ Ä‘á»‘i vá»›i hai phÆ°Æ¡ng phÃ¡p PEFT ná»•i báº­t vÃ  khÃ´ng
bao gá»“m so sÃ¡nh full-parameter fine-tuning. Äiá»u nÃ y lÃ  do
tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ cáº§n thiáº¿t cho full-
parameter fine-tuning, Ä‘Ã²i há»i 8 A100-SXM4-80G
trong hÆ¡n ná»­a thÃ¡ng. TÆ°Æ¡ng tá»±, cÃ¡c thÃ­ nghiá»‡m ablation cá»§a chÃºng tÃ´i bao phá»§
má»™t táº­p há»£p cÃ i Ä‘áº·t háº¡n cháº¿ do rÃ ng buá»™c tÃ i nguyÃªn. Máº·c dÃ¹
nhá»¯ng háº¡n cháº¿ nÃ y cÃ³ thá»ƒ Ä‘Ã£ dáº«n Ä‘áº¿n cÃ¡c phÃ¡t hiá»‡n thay tháº¿,
chÃºng khÃ´ng lÃ m suy yáº¿u cÆ¡ báº£n má»¥c tiÃªu chÃ­nh cá»§a chÃºng tÃ´i:
Ä‘Ã¡nh giÃ¡ tiá»m nÄƒng cá»§a cÃ¡c large language models thá»‘ng nháº¥t.

Má»™t má»‘i Ä‘e dá»a internal validity tiá»m nÄƒng khÃ¡c lÃ  chÃºng tÃ´i háº¡n
cháº¿ huáº¥n luyá»‡n cá»§a mÃ¬nh Ä‘á»‘i vá»›i kÃ­ch thÆ°á»›c nhá» nháº¥t cá»§a LLaMA vÃ  má»™t
sá»‘ lÆ°á»£ng epochs há»¯u háº¡n. Cho ráº±ng kháº£ nÄƒng vÃ 
káº¿t quáº£ dá»¯ liá»‡u cá»§a LLaMA tiáº¿p tá»¥c cáº£i thiá»‡n vá»›i viá»‡c tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh
vÃ  thá»i lÆ°á»£ng tuning, nghiÃªn cá»©u cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ tháº¥p
kháº£ nÄƒng latent thá»±c táº¿ cá»§a large language models.

C. External Validity
CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cÃ³ thá»ƒ khÃ´ng tá»•ng quÃ¡t hÃ³a ngoÃ i bá»‘i cáº£nh cá»§a
hai datasets [20], [23] Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u nÃ y, Ä‘Æ°á»£c

--- TRANG 11 ---
dáº«n xuáº¥t Ä‘á»™c quyá»n tá»« cÃ¡c dá»± Ã¡n open-source. Do Ä‘Ã³, nhá»¯ng
phÃ¡t hiá»‡n nÃ y cÃ³ thá»ƒ khÃ´ng Ã¡p dá»¥ng Ä‘áº§y Ä‘á»§ cho cÃ¡c bá»‘i cáº£nh cÃ´ng nghiá»‡p vÃ  khÃ¡c.
NgoÃ i ra, má»—i dataset chá»‰ giá»¯ láº¡i má»™t comment duy nháº¥t cho má»—i
thay Ä‘á»•i code, cÃ³ thá»ƒ giá»›i thiá»‡u bias trong quÃ¡ trÃ¬nh lá»c.

VIII. Káº¾T LUáº¬N VÃ€ CÃ”NG VIá»†C TÆ¯Æ NG LAI
Trong paper nÃ y, chÃºng tÃ´i giá»›i thiá»‡u LLaMA-Reviewer, má»™t framework
Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh code review sá»­ dá»¥ng large language
models (LLMs) vÃ  cÃ¡c ká»¹ thuáº­t parameter-efficient fine-tuning (PEFT)
. ChÃºng tÃ´i chá»©ng minh ráº±ng, máº·c dÃ¹ sá»­ dá»¥ng
phiÃªn báº£n nhá» nháº¥t cá»§a LLaMA chá»‰ vá»›i 6.7B tham sá»‘ vÃ  Ã­t hÆ¡n
1% tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n trong má»™t sá»‘ lÆ°á»£ng epochs tuning
háº¡n cháº¿, LLaMA-Reviewer cÃ³ thá»ƒ phÃ¹ há»£p vá»›i hiá»‡u nÄƒng cá»§a
cÃ¡c mÃ´ hÃ¬nh state-of-the-art táº­p trung vÃ o code-review. NgoÃ i ra, báº±ng cÃ¡ch
Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh kiá»ƒu plug-in, chÃºng tÃ´i giáº£m Ä‘Ã¡ng ká»ƒ yÃªu cáº§u
khÃ´ng gian lÆ°u trá»¯.

CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cÅ©ng gá»£i Ã½ ráº±ng viá»‡c cÄƒn chá»‰nh biá»ƒu diá»…n input
vá»›i Ä‘á»‹nh dáº¡ng Ä‘Æ°á»£c sá»­ dá»¥ng trong pre-training cÃ³ thá»ƒ táº­n dá»¥ng tá»‘t hÆ¡n
kháº£ nÄƒng cá»§a LLMs. NgoÃ i ra, má»™t giai Ä‘oáº¡n ban Ä‘áº§u
cá»§a instruction tuning cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u nÄƒng nhiá»‡m vá»¥
vÃ  tÄƒng kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ xá»­ lÃ½ thÃ´ng tin natural
language bá»• sung. Káº¿t quáº£ cá»§a chÃºng tÃ´i cÅ©ng cho tháº¥y low-rank
adaptation vá»›i rank thÃ­ch há»£p Ä‘Æ°á»£c Æ°a thÃ­ch cho cÃ¡c nhiá»‡m vá»¥ vá»›i
Ä‘á»‹nh dáº¡ng input vÃ  output cá»¥ thá»ƒ.

NhÃ¬n vá» phÃ­a trÆ°á»›c, chÃºng tÃ´i nháº±m má»Ÿ rá»™ng khÃ¡m phÃ¡ cá»§a chÃºng tÃ´i vá» large
language models, xem xÃ©t cÃ¡c mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c vÃ 
loáº¡i khÃ¡c nhau, vÃ  Ä‘iá»u tra thÃªm cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT. ChÃºng tÃ´i cÅ©ng
quan tÃ¢m Ä‘áº¿n viá»‡c kiá»ƒm tra ká»¹ hÆ¡n má»‘i quan há»‡
giá»¯a Ä‘á»™ dÃ i token cá»§a prompt templates, Ä‘oáº¡n code,
comment, vÃ  sequence block cá»§a cÃ¡c mÃ´ hÃ¬nh pre-trained.

Lá»œI Cáº¢M Æ N
CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Chinese Academy of Sciences-
Dongguan Science and Technology Service Network Plan
(No.202016002000032), vÃ  Alliance of International Science
Organizations (No. ANSO-CR-KP-2022-03).

TÃ€I LIá»†U THAM KHáº¢O
[1] M. Fagan, "Design and code inspections to reduce errors in program
development," in Software pioneers. Springer, 2002, pp. 575â€“607.
[2] D. Spadini, G. Ã‡alikli, and A. Bacchelli, "Primers or reminders? the
effects of existing review comments on code review," in 2020 IEEE/ACM
42nd International Conference on Software Engineering (ICSE). IEEE,
2020, pp. 1171â€“1182.
[3] P. C. Rigby, D. M. German, L. Cowen, and M.-A. Storey, "Peer review
on open-source software projects: Parameters, statistical models, and
theory," ACM Transactions on Software Engineering and Methodology
(TOSEM), vol. 23, no. 4, pp. 1â€“33, 2014.
[4] C. Sadowski, E. SÃ¶derberg, L. Church, M. Sipko, and A. Bacchelli,
"Modern code review: a case study at google," in Proceedings of
the 40th International Conference on Software Engineering: Software
Engineering in Practice, 2018, pp. 181â€“190.
[5] Q. Shan, D. Sukhdeo, Q. Huang, S. Rogers, L. Chen, E. Paradis, P. C.
Rigby, and N. Nagappan, "Using nudges to accelerate code reviews
at scale," in Proceedings of the 30th ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software
Engineering, 2022, pp. 472â€“482.
[6] E. SÃ¼lÃ¼n, "Suggesting reviewers of software artifacts using traceability
graphs," in Proceedings of the 2019 27th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, 2019, pp. 1250â€“1252.
[7] S. Asthana, R. Kumar, R. Bhagwan, C. Bird, C. Bansal, C. Maddila,
S. Mehta, and B. Ashok, "Whodo: Automating reviewer suggestions at
scale," in Proceedings of the 2019 27th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations
of Software Engineering, 2019, pp. 937â€“945.
[8] A. Chueshev, J. Lawall, R. Bendraou, and T. Ziadi, "Expanding the
number of reviewers in open-source projects by recommending appro-
priate developers," in 2020 IEEE International Conference on Software
Maintenance and Evolution (ICSME). IEEE, 2020, pp. 499â€“510.
[9] S. Rebai, A. Amich, S. Molaei, M. Kessentini, and R. Kazman, "Multi-
objective code reviewer recommendations: balancing expertise, avail-
ability and collaborations," Automated Software Engineering, vol. 27,
no. 3, pp. 301â€“328, 2020.
[10] E. Mirsaeedi and P. C. Rigby, "Mitigating turnover with code review
recommendation: balancing expertise, workload, and knowledge distri-
bution," in Proceedings of the ACM/IEEE 42nd International Conference
on Software Engineering, 2020, pp. 1183â€“1195.
[11] E. SÃ¼lÃ¼n, E. TÃ¼zÃ¼n, and U. DoÄŸrusÃ¶z, "Rstrace+: Reviewer suggestion
using software artifact traceability graphs," Information and Software
Technology, vol. 130, p. 106455, 2021.
[12] I. X. Gauthier, M. Lamothe, G. Mussbacher, and S. McIntosh, "Is his-
torical data an appropriate benchmark for reviewer recommendation sys-
tems?: A case study of the gerrit community," in 2021 36th IEEE/ACM
International Conference on Automated Software Engineering (ASE).
IEEE, 2021, pp. 30â€“41.
[13] D. Kong, Q. Chen, L. Bao, C. Sun, X. Xia, and S. Li, "Recommending
code reviewers for proprietary software projects: A large scale study,"
in 2022 IEEE International Conference on Software Analysis, Evolution
and Reengineering (SANER). IEEE, 2022, pp. 630â€“640.
[14] G. Rong, Y. Zhang, L. Yang, F. Zhang, H. Kuang, and H. Zhang,
"Modeling review history for reviewer recommendation: A hypergraph
approach," arXiv preprint arXiv:2204.09526, 2022.
[15] P. Pandya and S. Tiwari, "Corms: a github and gerrit based hybrid
code reviewer recommendation approach for modern code review," in
Proceedings of the 30th ACM Joint European Software Engineering
Conference and Symposium on the Foundations of Software Engineering,
2022, pp. 546â€“557.
[16] S.-T. Shi, M. Li, D. Lo, F. Thung, and X. Huo, "Automatic code review
by learning the revision of source code," in Proceedings of the AAAI
Conference on Artificial Intelligence, vol. 33, no. 01, 2019, pp. 4910â€“
4917.
[17] V. J. Hellendoorn, J. Tsay, M. Mukherjee, and M. Hirzel, "Towards
automating code review at scale," in Proceedings of the 29th ACM Joint
Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering, 2021, pp. 1479â€“1482.
[18] H. Hijazi, J. Cruz, J. Castelhano, R. Couceiro, M. Castelo-Branco,
P. de Carvalho, and H. Madeira, "ireview: an intelligent code review
evaluation tool using biofeedback," in 2021 IEEE 32nd International
Symposium on Software Reliability Engineering (ISSRE). IEEE, 2021,
pp. 476â€“485.
[19] D. Wang, Y. Ueda, R. G. Kula, T. Ishio, and K. Matsumoto, "Can
we benchmark code review studies? a systematic mapping study of
methodology, dataset, and metric," Journal of Systems and Software,
vol. 180, p. 111009, 2021.
[20] Z. Li, S. Lu, D. Guo, N. Duan, S. Jannu, G. Jenks, D. Majumder,
J. Green, A. Svyatkovskiy, S. Fu et al., "Automating code review
activities by large-scale pre-training," in Proceedings of the 30th ACM
Joint European Software Engineering Conference and Symposium on
the Foundations of Software Engineering, 2022, pp. 1035â€“1047.

[Pháº§n cÃ²n láº¡i cá»§a tÃ i liá»‡u tham kháº£o tiáº¿p tá»¥c...]

--- TRANG 12 ---
[vÃ  pháº§n cÃ²n láº¡i cá»§a cÃ¡c tÃ i liá»‡u tham kháº£o tá»« [21] Ä‘áº¿n [68]...]