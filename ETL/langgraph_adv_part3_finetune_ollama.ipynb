{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c08ea15",
   "metadata": {},
   "source": [
    "# LangGraph Advanced – Part 3️⃣: Fine‑Tuning via Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81854f",
   "metadata": {},
   "source": [
    "Claude sinh dữ liệu, Ollama fine‑tune model cục bộ bằng LoRA, rồi đánh giá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e619f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain langchain-anthropic tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bdc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, json, uuid\n",
    "from pathlib import Path\n",
    "from langgraph.graph import StateGraph, MessageState\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "WORK_DIR = Path(\"ft_work\"); WORK_DIR.mkdir(exist_ok=True)\n",
    "DATA_FILE = WORK_DIR/\"train.jsonl\"\n",
    "MODEL_BASE = \"llama2:7b\"\n",
    "MODEL_FT = \"llama2_ft\"\n",
    "\n",
    "llm_c = ChatAnthropic(model_name=\"claude-3-opus-20240229\", temperature=0.3)\n",
    "\n",
    "class FTState(MessageState):\n",
    "    step: str | None = None\n",
    "\n",
    "def gen_data(state: FTState):\n",
    "    pairs = []\n",
    "    for i in range(20):\n",
    "        q = f\"Hỏi {i}: Ngân hàng là gì?\"\n",
    "        a = llm_c([HumanMessage(content=f\"Trả lời ngắn gọn: {q}\")]).content\n",
    "        pairs.append({\"prompt\": q, \"completion\": a})\n",
    "    DATA_FILE.write_text(\"\\n\".join(json.dumps(p) for p in pairs))\n",
    "    return state\n",
    "\n",
    "def tune(state: FTState):\n",
    "    cmd = [\"ollama\", \"create\", MODEL_FT, \"--from\", MODEL_BASE,\n",
    "           \"--lora\", str(DATA_FILE)]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    return state\n",
    "\n",
    "def eval(state: FTState):\n",
    "    test_q = \"Ngân hàng số là gì?\"\n",
    "    out = subprocess.check_output([\"ollama\", \"run\", MODEL_FT, test_q])\n",
    "    print(\"Model says:\", out.decode()[:200])\n",
    "    return state\n",
    "\n",
    "g = StateGraph(FTState)\n",
    "g.add_node(\"data\", gen_data)\n",
    "g.add_node(\"tune\", tune)\n",
    "g.add_node(\"eval\", eval)\n",
    "g.set_entry_point(\"data\")\n",
    "g.add_edge(\"data\", \"tune\")\n",
    "g.add_edge(\"tune\", \"eval\")\n",
    "g.compile().invoke(FTState())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
