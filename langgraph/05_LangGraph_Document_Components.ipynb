{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Document Components và API Reference\n",
    "\n",
    "## Mục tiêu học tập\n",
    "- Hiểu về cấu trúc tài liệu của LangGraph và cách sử dụng API Reference\n",
    "- Nắm vững các thành phần chính: Nodes, Edges, State, Graph\n",
    "- Thực hành với các API quan trọng của LangGraph\n",
    "- Xây dựng các ví dụ thực tế sử dụng ChatAnthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu\n",
    "\n",
    "LangGraph là một framework mạnh mẽ để xây dựng các ứng dụng AI phức tạp dựa trên đồ thị (graph). Các thành phần chính của LangGraph bao gồm:\n",
    "\n",
    "### 🎯 Thành phần cơ bản\n",
    "1. **Graph**: Container chính chứa toàn bộ workflow\n",
    "2. **StateGraph**: Graph có khả năng quản lý state\n",
    "3. **Node**: Các điểm xử lý logic (functions/agents)\n",
    "4. **Edge**: Kết nối giữa các nodes\n",
    "5. **State**: Dữ liệu được chia sẻ giữa các nodes\n",
    "\n",
    "### 🔗 API Methods quan trọng\n",
    "- `add_node()`: Thêm node vào graph\n",
    "- `add_edge()`: Tạo kết nối giữa các nodes\n",
    "- `set_entry_point()`: Xác định điểm bắt đầu\n",
    "- `compile()`: Biên dịch graph thành runnable\n",
    "- `invoke()`: Thực thi đồng bộ\n",
    "- `stream()`: Thực thi bất đồng bộ với streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cài đặt và Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các package cần thiết\n",
    "!pip install langgraph langchain-anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Dict, Any\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Kiểm tra API key\n",
    "if not os.getenv(\"ANTHROPIC_API_KEY\"):\n",
    "    print(\"⚠️ ANTHROPIC_API_KEY chưa được thiết lập!\")\n",
    "else:\n",
    "    print(\"✅ ANTHROPIC_API_KEY đã được thiết lập\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference và Cấu trúc Tài liệu\n",
    "\n",
    "### 📚 Tài liệu chính thức LangGraph\n",
    "- **API Reference**: https://langchain-ai.github.io/langgraph/reference/\n",
    "- **Hướng dẫn**: https://langchain-ai.github.io/langgraph/\n",
    "- **Examples**: https://github.com/langchain-ai/langgraph/tree/main/examples\n",
    "\n",
    "### 🔍 Cách sử dụng API Reference\n",
    "1. Truy cập trang API Reference chính thức\n",
    "2. Tìm kiếm class/method cần sử dụng\n",
    "3. Đọc docstring và parameters\n",
    "4. Xem examples và return types\n",
    "5. Kiểm tra version compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ 1: Graph Đơn giản với StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa State schema\n",
    "class SimpleState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    step_count: int\n",
    "    current_action: str\n",
    "\n",
    "# Khởi tạo LLM\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "def greeting_node(state: SimpleState) -> Dict[str, Any]:\n",
    "    \"\"\"Node chào hỏi đầu tiên\"\"\"\n",
    "    print(f\"🔸 Executing greeting_node - Step: {state.get('step_count', 0)}\")\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=\"Chào bạn! Hãy giới thiệu bản thân một cách ngắn gọn.\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"step_count\": state.get('step_count', 0) + 1,\n",
    "        \"current_action\": \"greeting_completed\"\n",
    "    }\n",
    "\n",
    "def analysis_node(state: SimpleState) -> Dict[str, Any]:\n",
    "    \"\"\"Node phân tích thông tin\"\"\"\n",
    "    print(f\"🔸 Executing analysis_node - Step: {state.get('step_count', 0)}\")\n",
    "    \n",
    "    # Lấy tin nhắn cuối cùng từ state\n",
    "    last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=f\"Phân tích ngắn gọn về nội dung này: {last_message}\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"step_count\": state.get('step_count', 0) + 1,\n",
    "        \"current_action\": \"analysis_completed\"\n",
    "    }\n",
    "\n",
    "def summary_node(state: SimpleState) -> Dict[str, Any]:\n",
    "    \"\"\"Node tóm tắt cuối cùng\"\"\"\n",
    "    print(f\"🔸 Executing summary_node - Step: {state.get('step_count', 0)}\")\n",
    "    \n",
    "    total_messages = len(state[\"messages\"])\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=f\"Tóm tắt cuộc trò chuyện với {total_messages} tin nhắn đã xử lý.\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"step_count\": state.get('step_count', 0) + 1,\n",
    "        \"current_action\": \"summary_completed\"\n",
    "    }\n",
    "\n",
    "# Tạo StateGraph\n",
    "workflow = StateGraph(SimpleState)\n",
    "\n",
    "# Thêm các nodes\n",
    "workflow.add_node(\"greeting\", greeting_node)\n",
    "workflow.add_node(\"analysis\", analysis_node)\n",
    "workflow.add_node(\"summary\", summary_node)\n",
    "\n",
    "# Thiết lập entry point\n",
    "workflow.set_entry_point(\"greeting\")\n",
    "\n",
    "# Thêm các edges\n",
    "workflow.add_edge(\"greeting\", \"analysis\")\n",
    "workflow.add_edge(\"analysis\", \"summary\")\n",
    "workflow.add_edge(\"summary\", END)\n",
    "\n",
    "# Compile graph\n",
    "simple_app = workflow.compile()\n",
    "\n",
    "print(\"✅ Graph đơn giản đã được tạo thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực thi graph đơn giản\n",
    "print(\"🚀 Bắt đầu thực thi Graph đơn giản...\\n\")\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"step_count\": 0,\n",
    "    \"current_action\": \"starting\"\n",
    "}\n",
    "\n",
    "result = simple_app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n📊 Kết quả cuối cùng:\")\n",
    "print(f\"- Tổng số bước: {result['step_count']}\")\n",
    "print(f\"- Hành động cuối: {result['current_action']}\")\n",
    "print(f\"- Số tin nhắn: {len(result['messages'])}\")\n",
    "\n",
    "print(\"\\n💬 Tin nhắn cuối cùng:\")\n",
    "if result['messages']:\n",
    "    print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ 2: Agent với Tool Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa tools\n",
    "@tool\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"Tính toán biểu thức toán học đơn giản.\n",
    "    \n",
    "    Args:\n",
    "        expression: Biểu thức toán học (ví dụ: '2+3*4')\n",
    "    \n",
    "    Returns:\n",
    "        Kết quả tính toán\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Chỉ cho phép các ký tự an toàn\n",
    "        allowed_chars = set('0123456789+-*/(). ')\n",
    "        if not all(char in allowed_chars for char in expression):\n",
    "            return \"Lỗi: Biểu thức chứa ký tự không hợp lệ\"\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return f\"Kết quả của {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Lỗi tính toán: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_weather_info(city: str) -> str:\n",
    "    \"\"\"Lấy thông tin thời tiết (giả lập).\n",
    "    \n",
    "    Args:\n",
    "        city: Tên thành phố\n",
    "    \n",
    "    Returns:\n",
    "        Thông tin thời tiết\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"hà nội\": \"Hà Nội: 25°C, nắng ít mây, độ ẩm 60%\",\n",
    "        \"hồ chí minh\": \"TP.HCM: 30°C, mưa rào, độ ẩm 80%\",\n",
    "        \"đà nẵng\": \"Đà Nẵng: 28°C, nắng đẹp, độ ẩm 55%\"\n",
    "    }\n",
    "    \n",
    "    city_lower = city.lower()\n",
    "    return weather_data.get(city_lower, f\"Không có dữ liệu thời tiết cho {city}\")\n",
    "\n",
    "# Tạo LLM với tools\n",
    "tools = [calculate_math, get_weather_info]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"🛠️ Tools đã được định nghĩa:\")\n",
    "for tool in tools:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State cho Agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    tool_calls_made: int\n",
    "    current_task: str\n",
    "\n",
    "def agent_node(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node agent chính\"\"\"\n",
    "    print(f\"🤖 Agent đang xử lý...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"current_task\": \"agent_processing\"\n",
    "    }\n",
    "\n",
    "def tool_node(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"Node thực thi tools\"\"\"\n",
    "    print(f\"🔧 Thực thi tools...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_calls = getattr(last_message, 'tool_calls', [])\n",
    "    \n",
    "    if not tool_calls:\n",
    "        return {\"current_task\": \"no_tools\"}\n",
    "    \n",
    "    results = []\n",
    "    tools_dict = {tool.name: tool for tool in tools}\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        if tool_name in tools_dict:\n",
    "            try:\n",
    "                result = tools_dict[tool_name].invoke(tool_args)\n",
    "                results.append({\n",
    "                    \"tool_call_id\": tool_call['id'],\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": result\n",
    "                })\n",
    "                print(f\"✅ Tool {tool_name} thực thi thành công\")\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"tool_call_id\": tool_call['id'],\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": f\"Lỗi: {str(e)}\"\n",
    "                })\n",
    "                print(f\"❌ Tool {tool_name} gặp lỗi: {str(e)}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": results,\n",
    "        \"tool_calls_made\": state.get('tool_calls_made', 0) + len(results),\n",
    "        \"current_task\": \"tools_executed\"\n",
    "    }\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Quyết định có tiếp tục hay không\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Nếu có tool calls, thực thi tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Tạo Agent Graph\n",
    "agent_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Thêm nodes\n",
    "agent_workflow.add_node(\"agent\", agent_node)\n",
    "agent_workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Entry point\n",
    "agent_workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Conditional edges\n",
    "agent_workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tools node quay lại agent\n",
    "agent_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent_app = agent_workflow.compile()\n",
    "\n",
    "print(\"✅ Agent Graph với Tools đã được tạo thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Agent với Tools\n",
    "print(\"🚀 Test Agent với Tools...\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"Tính toán 15 * 8 + 32 cho tôi\",\n",
    "    \"Thời tiết ở Hà Nội hôm nay như thế nào?\",\n",
    "    \"Vừa tính (100 - 25) / 5 vừa cho biết thời tiết Đà Nẵng\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"📝 Test {i}: {query}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"tool_calls_made\": 0,\n",
    "        \"current_task\": \"starting\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = agent_app.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\n📊 Kết quả:\")\n",
    "        print(f\"- Tool calls made: {result.get('tool_calls_made', 0)}\")\n",
    "        print(f\"- Current task: {result.get('current_task', 'unknown')}\")\n",
    "        \n",
    "        # Lấy phản hồi cuối cùng từ AI\n",
    "        ai_messages = [msg for msg in result['messages'] if isinstance(msg, AIMessage)]\n",
    "        if ai_messages:\n",
    "            print(f\"\\n🤖 AI Response:\")\n",
    "            print(ai_messages[-1].content)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ 3: Truy cập và Xử lý State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State phức tạp với nhiều thông tin\n",
    "class ComplexState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_profile: Dict[str, Any]\n",
    "    conversation_history: list\n",
    "    current_topic: str\n",
    "    processing_steps: list\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "def profile_analyzer_node(state: ComplexState) -> Dict[str, Any]:\n",
    "    \"\"\"Phân tích thông tin user từ tin nhắn\"\"\"\n",
    "    print(\"👤 Analyzing user profile...\")\n",
    "    \n",
    "    # Lấy tin nhắn mới nhất từ user\n",
    "    human_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    if not human_messages:\n",
    "        return {\"processing_steps\": [\"No human messages found\"]}\n",
    "    \n",
    "    latest_message = human_messages[-1].content\n",
    "    \n",
    "    # Sử dụng LLM để phân tích profile\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Phân tích tin nhắn sau và trích xuất thông tin về người dùng:\n",
    "    \"{latest_message}\"\n",
    "    \n",
    "    Trả về phân tích dưới dạng JSON với các trường:\n",
    "    - name: tên người dùng (nếu có)\n",
    "    - interests: sở thích/quan tâm\n",
    "    - mood: tâm trạng\n",
    "    - intent: ý định/mục đích\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    \n",
    "    # Cập nhật user profile (đơn giản hóa)\n",
    "    current_profile = state.get(\"user_profile\", {})\n",
    "    current_profile[\"last_analysis\"] = response.content\n",
    "    current_profile[\"message_count\"] = len(human_messages)\n",
    "    \n",
    "    return {\n",
    "        \"user_profile\": current_profile,\n",
    "        \"processing_steps\": state.get(\"processing_steps\", []) + [\"profile_analyzed\"],\n",
    "        \"current_topic\": \"profile_analysis\"\n",
    "    }\n",
    "\n",
    "def context_manager_node(state: ComplexState) -> Dict[str, Any]:\n",
    "    \"\"\"Quản lý context và lịch sử hội thoại\"\"\"\n",
    "    print(\"📚 Managing conversation context...\")\n",
    "    \n",
    "    # Cập nhật lịch sử\n",
    "    current_history = state.get(\"conversation_history\", [])\n",
    "    \n",
    "    # Thêm bản tóm tắt bước hiện tại\n",
    "    summary = {\n",
    "        \"step\": len(current_history) + 1,\n",
    "        \"topic\": state.get(\"current_topic\", \"unknown\"),\n",
    "        \"message_count\": len(state.get(\"messages\", [])),\n",
    "        \"user_profile_status\": \"analyzed\" if state.get(\"user_profile\") else \"not_analyzed\"\n",
    "    }\n",
    "    \n",
    "    current_history.append(summary)\n",
    "    \n",
    "    return {\n",
    "        \"conversation_history\": current_history,\n",
    "        \"processing_steps\": state.get(\"processing_steps\", []) + [\"context_managed\"],\n",
    "        \"metadata\": {\n",
    "            \"total_steps\": len(current_history),\n",
    "            \"last_update\": \"context_manager\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "def response_generator_node(state: ComplexState) -> Dict[str, Any]:\n",
    "    \"\"\"Tạo phản hồi dựa trên toàn bộ state\"\"\"\n",
    "    print(\"💬 Generating contextual response...\")\n",
    "    \n",
    "    # Tạo context summary từ state\n",
    "    profile_info = state.get(\"user_profile\", {})\n",
    "    history_info = state.get(\"conversation_history\", [])\n",
    "    processing_info = state.get(\"processing_steps\", [])\n",
    "    \n",
    "    context_summary = f\"\"\"\n",
    "    Thông tin context hiện tại:\n",
    "    - User profile: {len(profile_info)} fields\n",
    "    - Conversation history: {len(history_info)} steps\n",
    "    - Processing steps: {', '.join(processing_info)}\n",
    "    - Current topic: {state.get('current_topic', 'unknown')}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tạo phản hồi có ngữ cảnh\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là một AI assistant thông minh. Dựa vào thông tin context sau:\n",
    "    {context_summary}\n",
    "    \n",
    "    Hãy tạo một phản hồi thân thiện và có ích cho người dùng, \n",
    "    thể hiện rằng bạn đã hiểu context và có thể hỗ trợ tốt hơn.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"processing_steps\": state.get(\"processing_steps\", []) + [\"response_generated\"],\n",
    "        \"current_topic\": \"response_complete\"\n",
    "    }\n",
    "\n",
    "# Tạo Complex State Graph\n",
    "complex_workflow = StateGraph(ComplexState)\n",
    "\n",
    "# Thêm nodes\n",
    "complex_workflow.add_node(\"profile_analyzer\", profile_analyzer_node)\n",
    "complex_workflow.add_node(\"context_manager\", context_manager_node)\n",
    "complex_workflow.add_node(\"response_generator\", response_generator_node)\n",
    "\n",
    "# Entry point\n",
    "complex_workflow.set_entry_point(\"profile_analyzer\")\n",
    "\n",
    "# Sequential edges\n",
    "complex_workflow.add_edge(\"profile_analyzer\", \"context_manager\")\n",
    "complex_workflow.add_edge(\"context_manager\", \"response_generator\")\n",
    "complex_workflow.add_edge(\"response_generator\", END)\n",
    "\n",
    "# Compile\n",
    "complex_app = complex_workflow.compile()\n",
    "\n",
    "print(\"✅ Complex State Graph đã được tạo thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Complex State Graph\n",
    "print(\"🚀 Test Complex State Management...\\n\")\n",
    "\n",
    "test_message = \"Xin chào! Tôi là Minh, đang học về AI và machine learning. Tôi muốn tìm hiểu về LangGraph.\"\n",
    "\n",
    "initial_complex_state = {\n",
    "    \"messages\": [HumanMessage(content=test_message)],\n",
    "    \"user_profile\": {},\n",
    "    \"conversation_history\": [],\n",
    "    \"current_topic\": \"introduction\",\n",
    "    \"processing_steps\": [],\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "print(f\"📝 Input: {test_message}\\n\")\n",
    "\n",
    "try:\n",
    "    result = complex_app.invoke(initial_complex_state)\n",
    "    \n",
    "    print(\"\\n📊 State Analysis:\")\n",
    "    print(f\"- Processing steps: {result.get('processing_steps', [])}\")\n",
    "    print(f\"- Current topic: {result.get('current_topic', 'unknown')}\")\n",
    "    print(f\"- Conversation history length: {len(result.get('conversation_history', []))}\")\n",
    "    print(f\"- User profile fields: {len(result.get('user_profile', {}))}\")\n",
    "    print(f\"- Total messages: {len(result.get('messages', []))}\")\n",
    "    \n",
    "    print(\"\\n👤 User Profile:\")\n",
    "    profile = result.get('user_profile', {})\n",
    "    for key, value in profile.items():\n",
    "        if key == 'last_analysis':\n",
    "            print(f\"- {key}: {value[:100]}...\" if len(str(value)) > 100 else f\"- {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"- {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n📚 Conversation History:\")\n",
    "    for step in result.get('conversation_history', []):\n",
    "        print(f\"- Step {step.get('step', '?')}: {step}\")\n",
    "    \n",
    "    print(\"\\n🤖 Final Response:\")\n",
    "    ai_messages = [msg for msg in result['messages'] if isinstance(msg, AIMessage)]\n",
    "    if ai_messages:\n",
    "        print(ai_messages[-1].content)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Lỗi: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming và Async Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo streaming execution\n",
    "print(\"🌊 Demo Streaming Execution...\\n\")\n",
    "\n",
    "stream_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Giải thích về LangGraph một cách chi tiết\")],\n",
    "    \"step_count\": 0,\n",
    "    \"current_action\": \"starting\"\n",
    "}\n",
    "\n",
    "print(\"📡 Streaming results:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    # Stream từng bước\n",
    "    for step_result in simple_app.stream(stream_state):\n",
    "        print(f\"🔸 Stream step: {list(step_result.keys())}\")\n",
    "        \n",
    "        for node_name, node_result in step_result.items():\n",
    "            print(f\"   Node '{node_name}':\")\n",
    "            print(f\"   - Current action: {node_result.get('current_action', 'unknown')}\")\n",
    "            print(f\"   - Step count: {node_result.get('step_count', 0)}\")\n",
    "            \n",
    "            # Hiển thị tin nhắn nếu có\n",
    "            if 'messages' in node_result and node_result['messages']:\n",
    "                last_msg = node_result['messages'][-1]\n",
    "                if hasattr(last_msg, 'content'):\n",
    "                    content = last_msg.content[:100] + \"...\" if len(last_msg.content) > 100 else last_msg.content\n",
    "                    print(f\"   - Message: {content}\")\n",
    "            print()\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Streaming error: {str(e)}\")\n",
    "\n",
    "print(\"✅ Streaming demo completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giải thích & Phân tích\n",
    "\n",
    "### 🎯 Các thành phần đã sử dụng\n",
    "\n",
    "#### 1. **StateGraph**\n",
    "- **Mục đích**: Container chính để quản lý workflow với state\n",
    "- **Sử dụng**: `StateGraph(StateSchema)` với TypedDict schema\n",
    "- **Ưu điểm**: Type safety, state persistence giữa các nodes\n",
    "\n",
    "#### 2. **add_node()**\n",
    "- **Syntax**: `workflow.add_node(\"name\", function)`\n",
    "- **Function signature**: `(state: StateType) -> Dict[str, Any]`\n",
    "- **Return**: Partial state update (merged với existing state)\n",
    "\n",
    "#### 3. **add_edge() & add_conditional_edges()**\n",
    "- **Simple edge**: `add_edge(\"from\", \"to\")` - luôn chuyển\n",
    "- **Conditional**: `add_conditional_edges(\"from\", condition_func, mapping)`\n",
    "- **Condition function**: Nhận state, trả về string key\n",
    "\n",
    "#### 4. **compile() & invoke()**\n",
    "- **compile()**: Tạo runnable graph từ workflow definition\n",
    "- **invoke()**: Thực thi đồng bộ, return final state\n",
    "- **stream()**: Thực thi với streaming, yield intermediate results\n",
    "\n",
    "### 🔧 Pattern phổ biến\n",
    "\n",
    "1. **State Management**\n",
    "   ```python\n",
    "   class MyState(TypedDict):\n",
    "       messages: Annotated[list, add_messages]  # Auto-merge\n",
    "       custom_field: Any  # Overwrite\n",
    "   ```\n",
    "\n",
    "2. **Tool Integration**\n",
    "   ```python\n",
    "   llm_with_tools = llm.bind_tools([tool1, tool2])\n",
    "   # Trong node: check tool_calls, execute, return results\n",
    "   ```\n",
    "\n",
    "3. **Conditional Logic**\n",
    "   ```python\n",
    "   def should_continue(state):\n",
    "       return \"continue\" if condition else \"end\"\n",
    "   ```\n",
    "\n",
    "### ⚡ Performance Notes\n",
    "- **State size**: Giữ state nhỏ gọn, tránh lưu data lớn\n",
    "- **Node functions**: Stateless, pure functions khi có thể\n",
    "- **Error handling**: Wrap trong try-catch, return error state\n",
    "- **Streaming**: Sử dụng cho long-running processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tài liệu tham khảo\n",
    "\n",
    "### 📚 Official Documentation\n",
    "- **LangGraph API Reference**: https://langchain-ai.github.io/langgraph/reference/\n",
    "- **LangGraph Tutorials**: https://langchain-ai.github.io/langgraph/tutorials/\n",
    "- **StateGraph API**: https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph\n",
    "- **Message Handling**: https://langchain-ai.github.io/langgraph/concepts/low_level/#messages\n",
    "\n",
    "### 🔗 Related Resources\n",
    "- **LangChain Tools**: https://python.langchain.com/docs/modules/tools/\n",
    "- **Anthropic Claude**: https://docs.anthropic.com/claude/docs\n",
    "- **TypedDict Documentation**: https://docs.python.org/3/library/typing.html#typing.TypedDict\n",
    "\n",
    "### 🛠️ Code Examples\n",
    "- **LangGraph Examples**: https://github.com/langchain-ai/langgraph/tree/main/examples\n",
    "- **Multi-Agent Systems**: https://langchain-ai.github.io/langgraph/tutorials/multi_agent/\n",
    "- **Tool Calling**: https://langchain-ai.github.io/langgraph/tutorials/tool-calling/\n",
    "\n",
    "### 📖 Best Practices\n",
    "- **State Design Patterns**: Keep state minimal and focused\n",
    "- **Error Handling**: Always handle exceptions in nodes\n",
    "- **Performance**: Use streaming for long-running processes\n",
    "- **Testing**: Test individual nodes before integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết luận & Bước tiếp theo\n",
    "\n",
    "### 🎓 Những gì đã học\n",
    "1. **Cấu trúc LangGraph**: StateGraph, Nodes, Edges, State management\n",
    "2. **API Reference**: Cách sử dụng tài liệu chính thức và tìm kiếm thông tin\n",
    "3. **Thực hành**: 3 ví dụ từ đơn giản đến phức tạp\n",
    "4. **Tool Integration**: Kết hợp LLM với external tools\n",
    "5. **State Management**: Quản lý state phức tạp với TypedDict\n",
    "6. **Streaming**: Thực thi bất đồng bộ và real-time updates\n",
    "\n",
    "### 🚀 Bước tiếp theo\n",
    "1. **Khám phá API Reference sâu hơn**:\n",
    "   - Đọc documentation của các class chưa sử dụng\n",
    "   - Thử nghiệm với các parameters khác nhau\n",
    "   - Tìm hiểu về error handling patterns\n",
    "\n",
    "2. **Thực hành nâng cao**:\n",
    "   - Xây dựng multi-agent systems\n",
    "   - Tích hợp với databases và external APIs\n",
    "   - Implement custom state reducers\n",
    "\n",
    "3. **Production readiness**:\n",
    "   - Error handling và logging\n",
    "   - Performance optimization\n",
    "   - Testing strategies\n",
    "\n",
    "4. **Tích hợp ecosystem**:\n",
    "   - LangSmith cho monitoring\n",
    "   - LangServe cho deployment\n",
    "   - Custom tools và integrations\n",
    "\n",
    "### 💡 Tips cho việc sử dụng API Reference\n",
    "- **Bookmark** các trang quan trọng\n",
    "- **Đọc examples** trước khi implement\n",
    "- **Check version compatibility** khi update\n",
    "- **Contribute back** với feedback và bug reports\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding với LangGraph! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}