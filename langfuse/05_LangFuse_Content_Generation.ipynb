{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 05_LangFuse_Content_Generation - Qu·∫£n l√Ω Pipeline T·∫°o N·ªôi dung ƒêa k√™nh\n",
    "\n",
    "## M·ª•c ti√™u h·ªçc t·∫≠p\n",
    "Hi·ªÉu c√°ch thi·∫øt k·∫ø, tri·ªÉn khai v√† t·ªëi ∆∞u h√≥a pipeline t·∫°o n·ªôi dung ƒëa k√™nh b·∫±ng LangFuse ƒë·ªÉ:\n",
    "- Theo d√µi hi·ªáu su·∫•t c·ªßa t·ª´ng k√™nh n·ªôi dung\n",
    "- Qu·∫£n l√Ω chi ph√≠ token m·ªôt c√°ch hi·ªáu qu·∫£\n",
    "- T·ªëi ∆∞u h√≥a ch·∫•t l∆∞·ª£ng n·ªôi dung th√¥ng qua feedback\n",
    "- X√°c ƒë·ªãnh v√† gi·∫£i quy·∫øt c√°c ƒëi·ªÉm ngh·∫Ωn trong pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Gi·ªõi thi·ªáu\n",
    "\n",
    "### Th√°ch th·ª©c c·ªßa vi·ªác s·∫£n xu·∫•t n·ªôi dung quy m√¥ l·ªõn v·ªõi LLMs\n",
    "- **ƒêa d·∫°ng k√™nh**: C·∫ßn t·∫°o n·ªôi dung ph√π h·ª£p v·ªõi t·ª´ng platform (blog, social media, email)\n",
    "- **Qu·∫£n l√Ω chi ph√≠**: Token usage c√≥ th·ªÉ tƒÉng nhanh khi scale\n",
    "- **Ch·∫•t l∆∞·ª£ng nh·∫•t qu√°n**: ƒê·∫£m b·∫£o tone v√† message ph√π h·ª£p v·ªõi brand\n",
    "- **Theo d√µi hi·ªáu su·∫•t**: Kh√≥ khƒÉn khi debug v√† t·ªëi ∆∞u pipeline ph·ª©c t·∫°p\n",
    "\n",
    "### C√°ch LangFuse h·ªó tr·ª£\n",
    "- **Tracing chi ti·∫øt**: Theo d√µi t·ª´ng b∆∞·ªõc trong pipeline t·∫°o n·ªôi dung\n",
    "- **Metrics to√†n di·ªán**: Token usage, latency, cost per content type\n",
    "- **Feedback system**: Thu th·∫≠p v√† ph√¢n t√≠ch ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng\n",
    "- **A/B testing**: So s√°nh hi·ªáu qu·∫£ c·ªßa c√°c prompt templates kh√°c nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## C√†i ƒë·∫∑t & C·∫•u h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "# LangFuse imports\n",
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Ki·ªÉm tra API keys\n",
    "required_keys = ['ANTHROPIC_API_KEY', 'LANGFUSE_PUBLIC_KEY', 'LANGFUSE_SECRET_KEY']\n",
    "missing_keys = [key for key in required_keys if not os.getenv(key)]\n",
    "\n",
    "if missing_keys:\n",
    "    print(f\"‚ö†Ô∏è Thi·∫øu c√°c API keys: {missing_keys}\")\n",
    "    print(\"Vui l√≤ng c·∫•u h√¨nh trong file .env\")\n",
    "else:\n",
    "    print(\"‚úÖ ƒê√£ c·∫•u h√¨nh ƒë·∫ßy ƒë·ªß API keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o LangFuse client v√† callback handler\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=\"http://localhost:3000\"  # Local LangFuse instance\n",
    ")\n",
    "\n",
    "# T·∫°o callback handler cho tracing\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=\"http://localhost:3000\"\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o LLM\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0.7,\n",
    "    callbacks=[langfuse_handler]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ kh·ªüi t·∫°o LangFuse v√† Anthropic LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Use Case: Multi-Channel Content Generation\n",
    "\n",
    "Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt pipeline t·∫°o n·ªôi dung t·ª´ m·ªôt √Ω t∆∞·ªüng ban ƒë·∫ßu th√†nh nhi·ªÅu format kh√°c nhau:\n",
    "- **Blog Post**: B√†i vi·∫øt chi ti·∫øt, SEO-friendly\n",
    "- **Tweet Thread**: Chu·ªói tweet ng·∫Øn g·ªçn, engaging\n",
    "- **Email Marketing**: Subject line v√† body text h·∫•p d·∫´n\n",
    "- **LinkedIn Post**: Professional tone, networking focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### ƒê·ªãnh nghƒ©a Prompt Templates cho t·ª´ng k√™nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blog Post Generator\n",
    "blog_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Vi·∫øt m·ªôt b√†i blog post SEO-friendly v√† informative v·ªÅ ch·ªß ƒë·ªÅ sau:\n",
    "    \n",
    "    Ch·ªß ƒë·ªÅ: {topic}\n",
    "    Target audience: {audience}\n",
    "    Tone: {tone}\n",
    "    \n",
    "    Y√™u c·∫ßu:\n",
    "    - ƒê·ªô d√†i: 800-1200 t·ª´\n",
    "    - Bao g·ªìm: Introduction, 3-4 main points, Conclusion\n",
    "    - S·ª≠ d·ª•ng headers (H2, H3) ƒë·ªÉ c·∫•u tr√∫c\n",
    "    - Bao g·ªìm call-to-action cu·ªëi b√†i\n",
    "    \n",
    "    Blog post:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Tweet Thread Generator  \n",
    "tweet_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    T·∫°o m·ªôt chu·ªói 5-7 tweets v·ªÅ ch·ªß ƒë·ªÅ sau:\n",
    "    \n",
    "    Ch·ªß ƒë·ªÅ: {topic}\n",
    "    Target audience: {audience}\n",
    "    Tone: {tone}\n",
    "    \n",
    "    Y√™u c·∫ßu:\n",
    "    - M·ªói tweet t·ªëi ƒëa 280 k√Ω t·ª±\n",
    "    - Tweet ƒë·∫ßu: Hook h·∫•p d·∫´n\n",
    "    - Tweets gi·ªØa: Key insights v·ªõi bullet points\n",
    "    - Tweet cu·ªëi: Call-to-action v√† hashtags\n",
    "    - ƒê√°nh s·ªë tweet (1/7, 2/7, ...)\n",
    "    \n",
    "    Tweet thread:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Email Marketing Generator\n",
    "email_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    T·∫°o email marketing v·ªÅ ch·ªß ƒë·ªÅ sau:\n",
    "    \n",
    "    Ch·ªß ƒë·ªÅ: {topic}\n",
    "    Target audience: {audience}\n",
    "    Tone: {tone}\n",
    "    \n",
    "    Bao g·ªìm:\n",
    "    1. Subject line (3 variations)\n",
    "    2. Preview text\n",
    "    3. Email body (300-500 t·ª´)\n",
    "    4. Clear call-to-action button\n",
    "    \n",
    "    Email content:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LinkedIn Post Generator\n",
    "linkedin_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Vi·∫øt LinkedIn post professional v·ªÅ ch·ªß ƒë·ªÅ sau:\n",
    "    \n",
    "    Ch·ªß ƒë·ªÅ: {topic}\n",
    "    Target audience: {audience}\n",
    "    Tone: {tone}\n",
    "    \n",
    "    Y√™u c·∫ßu:\n",
    "    - ƒê·ªô d√†i: 200-400 t·ª´\n",
    "    - B·∫Øt ƒë·∫ßu v·ªõi personal story ho·∫∑c insight\n",
    "    - Bao g·ªìm 3-5 key takeaways\n",
    "    - K·∫øt th√∫c v·ªõi question ƒë·ªÉ encourage engagement\n",
    "    - S·ª≠ d·ª•ng relevant hashtags (3-5 hashtags)\n",
    "    \n",
    "    LinkedIn post:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a prompt templates cho 4 k√™nh n·ªôi dung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### X√¢y d·ª±ng Individual Content Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o individual chains cho t·ª´ng lo·∫°i content\n",
    "blog_chain = blog_prompt | llm | StrOutputParser()\n",
    "tweet_chain = tweet_prompt | llm | StrOutputParser()\n",
    "email_chain = email_prompt | llm | StrOutputParser()\n",
    "linkedin_chain = linkedin_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Wrapper functions ƒë·ªÉ add metadata v√† tags\n",
    "def create_blog_content(inputs: Dict) -> Dict:\n",
    "    \"\"\"Generate blog content with LangFuse tagging\"\"\"\n",
    "    langfuse_handler.langfuse.trace(\n",
    "        name=\"blog_generation\",\n",
    "        tags=[\"content_type:blog\", f\"campaign:{inputs.get('campaign', 'default')}\"],\n",
    "        metadata={\"audience\": inputs[\"audience\"], \"tone\": inputs[\"tone\"]}\n",
    "    )\n",
    "    \n",
    "    content = blog_chain.invoke(inputs)\n",
    "    return {\n",
    "        \"type\": \"blog\",\n",
    "        \"content\": content,\n",
    "        \"word_count\": len(content.split()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def create_tweet_content(inputs: Dict) -> Dict:\n",
    "    \"\"\"Generate tweet thread with LangFuse tagging\"\"\"\n",
    "    langfuse_handler.langfuse.trace(\n",
    "        name=\"tweet_generation\",\n",
    "        tags=[\"content_type:tweet\", f\"campaign:{inputs.get('campaign', 'default')}\"],\n",
    "        metadata={\"audience\": inputs[\"audience\"], \"tone\": inputs[\"tone\"]}\n",
    "    )\n",
    "    \n",
    "    content = tweet_chain.invoke(inputs)\n",
    "    tweet_count = content.count(\"/\")\n",
    "    return {\n",
    "        \"type\": \"tweet\",\n",
    "        \"content\": content,\n",
    "        \"tweet_count\": tweet_count,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def create_email_content(inputs: Dict) -> Dict:\n",
    "    \"\"\"Generate email marketing content with LangFuse tagging\"\"\"\n",
    "    langfuse_handler.langfuse.trace(\n",
    "        name=\"email_generation\",\n",
    "        tags=[\"content_type:email\", f\"campaign:{inputs.get('campaign', 'default')}\"],\n",
    "        metadata={\"audience\": inputs[\"audience\"], \"tone\": inputs[\"tone\"]}\n",
    "    )\n",
    "    \n",
    "    content = email_chain.invoke(inputs)\n",
    "    return {\n",
    "        \"type\": \"email\",\n",
    "        \"content\": content,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def create_linkedin_content(inputs: Dict) -> Dict:\n",
    "    \"\"\"Generate LinkedIn post with LangFuse tagging\"\"\"\n",
    "    langfuse_handler.langfuse.trace(\n",
    "        name=\"linkedin_generation\",\n",
    "        tags=[\"content_type:linkedin\", f\"campaign:{inputs.get('campaign', 'default')}\"],\n",
    "        metadata={\"audience\": inputs[\"audience\"], \"tone\": inputs[\"tone\"]}\n",
    "    )\n",
    "    \n",
    "    content = linkedin_chain.invoke(inputs)\n",
    "    hashtag_count = content.count(\"#\")\n",
    "    return {\n",
    "        \"type\": \"linkedin\",\n",
    "        \"content\": content,\n",
    "        \"hashtag_count\": hashtag_count,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o individual content generators v·ªõi LangFuse tagging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### X√¢y d·ª±ng Parallel Content Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o parallel pipeline ƒë·ªÉ generate t·∫•t c·∫£ content types c√πng l√∫c\n",
    "multi_channel_pipeline = RunnableParallel(\n",
    "    blog=RunnableLambda(create_blog_content),\n",
    "    tweet=RunnableLambda(create_tweet_content), \n",
    "    email=RunnableLambda(create_email_content),\n",
    "    linkedin=RunnableLambda(create_linkedin_content)\n",
    ")\n",
    "\n",
    "def aggregate_results(results: Dict) -> Dict:\n",
    "    \"\"\"Aggregate v√† format k·∫øt qu·∫£ t·ª´ t·∫•t c·∫£ channels\"\"\"\n",
    "    return {\n",
    "        \"campaign_id\": results.get(\"campaign\", \"default\"),\n",
    "        \"generation_timestamp\": datetime.now().isoformat(),\n",
    "        \"contents\": {\n",
    "            \"blog\": results[\"blog\"],\n",
    "            \"tweet\": results[\"tweet\"],\n",
    "            \"email\": results[\"email\"],\n",
    "            \"linkedin\": results[\"linkedin\"]\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"total_content_pieces\": 4,\n",
    "            \"blog_word_count\": results[\"blog\"][\"word_count\"],\n",
    "            \"tweet_count\": results[\"tweet\"][\"tweet_count\"],\n",
    "            \"linkedin_hashtags\": results[\"linkedin\"][\"hashtag_count\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Complete pipeline\n",
    "content_generation_pipeline = multi_channel_pipeline | RunnableLambda(aggregate_results)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ x√¢y d·ª±ng complete multi-channel content generation pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Tri·ªÉn khai & Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input data\n",
    "test_input = {\n",
    "    \"topic\": \"C√°ch s·ª≠ d·ª•ng AI ƒë·ªÉ tƒÉng nƒÉng su·∫•t l√†m vi·ªác trong 2024\",\n",
    "    \"audience\": \"Professionals v√† entrepreneurs quan t√¢m ƒë·∫øn technology\",\n",
    "    \"tone\": \"Professional nh∆∞ng friendly, practical v√† actionable\",\n",
    "    \"campaign\": \"ai_productivity_2024\"\n",
    "}\n",
    "\n",
    "print(f\"üöÄ B·∫Øt ƒë·∫ßu generate content cho campaign: {test_input['campaign']}\")\n",
    "print(f\"üìù Topic: {test_input['topic']}\")\n",
    "print(f\"üë• Audience: {test_input['audience']}\")\n",
    "print(f\"üé≠ Tone: {test_input['tone']}\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch·∫°y pipeline v√† ƒëo th·ªùi gian\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# T·∫°o trace ch√≠nh cho to√†n b·ªô campaign\n",
    "campaign_trace = langfuse.trace(\n",
    "    name=\"multi_channel_content_generation\",\n",
    "    tags=[\"pipeline:content_generation\", f\"campaign:{test_input['campaign']}\"],\n",
    "    metadata={\n",
    "        \"topic\": test_input[\"topic\"],\n",
    "        \"audience\": test_input[\"audience\"],\n",
    "        \"tone\": test_input[\"tone\"],\n",
    "        \"channels\": [\"blog\", \"tweet\", \"email\", \"linkedin\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Ch·∫°y pipeline\n",
    "    results = content_generation_pipeline.invoke(test_input)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Update trace v·ªõi k·∫øt qu·∫£\n",
    "    campaign_trace.update(\n",
    "        output={\n",
    "            \"success\": True,\n",
    "            \"total_execution_time\": total_time,\n",
    "            \"content_summary\": results[\"summary\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ ho√†n th√†nh generation trong {total_time:.2f} gi√¢y\")\n",
    "    print(f\"üìä T·ªïng quan: {results['summary']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    campaign_trace.update(\n",
    "        output={\"success\": False, \"error\": str(e)}\n",
    "    )\n",
    "    print(f\"‚ùå L·ªói khi generate content: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Hi·ªÉn th·ªã k·∫øt qu·∫£ t·ª´ng k√™nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã Blog Post\n",
    "print(\"üìù BLOG POST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Word count: {results['contents']['blog']['word_count']}\")\n",
    "print(f\"Generated at: {results['contents']['blog']['timestamp']}\")\n",
    "print(\"\\nContent:\")\n",
    "print(results['contents']['blog']['content'][:500] + \"...\" if len(results['contents']['blog']['content']) > 500 else results['contents']['blog']['content'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã Tweet Thread\n",
    "print(\"üê¶ TWEET THREAD\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tweet count: {results['contents']['tweet']['tweet_count']}\")\n",
    "print(f\"Generated at: {results['contents']['tweet']['timestamp']}\")\n",
    "print(\"\\nContent:\")\n",
    "print(results['contents']['tweet']['content'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã Email Marketing\n",
    "print(\"üìß EMAIL MARKETING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Generated at: {results['contents']['email']['timestamp']}\")\n",
    "print(\"\\nContent:\")\n",
    "print(results['contents']['email']['content'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã LinkedIn Post\n",
    "print(\"üíº LINKEDIN POST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Hashtag count: {results['contents']['linkedin']['hashtag_count']}\")\n",
    "print(f\"Generated at: {results['contents']['linkedin']['timestamp']}\")\n",
    "print(\"\\nContent:\")\n",
    "print(results['contents']['linkedin']['content'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Feedback System & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate human feedback cho t·ª´ng content type\n",
    "def simulate_content_evaluation():\n",
    "    \"\"\"Simulate human evaluation of generated content\"\"\"\n",
    "    \n",
    "    # Blog feedback\n",
    "    blog_trace = langfuse.trace(\n",
    "        name=\"blog_evaluation\",\n",
    "        tags=[\"evaluation\", \"content_type:blog\", \"campaign:ai_productivity_2024\"]\n",
    "    )\n",
    "    \n",
    "    blog_score = langfuse.score(\n",
    "        trace_id=blog_trace.id,\n",
    "        name=\"content_quality\",\n",
    "        value=0.85,\n",
    "        comment=\"Blog post c√≥ structure t·ªët, SEO-friendly. C·∫ßn th√™m examples c·ª• th·ªÉ.\"\n",
    "    )\n",
    "    \n",
    "    blog_score_seo = langfuse.score(\n",
    "        trace_id=blog_trace.id,\n",
    "        name=\"seo_score\", \n",
    "        value=0.78,\n",
    "        comment=\"Keywords distribution t·ªët, headers clear. C·∫ßn optimize meta description.\"\n",
    "    )\n",
    "    \n",
    "    # Tweet feedback\n",
    "    tweet_trace = langfuse.trace(\n",
    "        name=\"tweet_evaluation\",\n",
    "        tags=[\"evaluation\", \"content_type:tweet\", \"campaign:ai_productivity_2024\"]\n",
    "    )\n",
    "    \n",
    "    tweet_score = langfuse.score(\n",
    "        trace_id=tweet_trace.id,\n",
    "        name=\"engagement_potential\",\n",
    "        value=0.92,\n",
    "        comment=\"Thread r·∫•t engaging, hook m·∫°nh. Format clear v√† actionable.\"\n",
    "    )\n",
    "    \n",
    "    # Email feedback\n",
    "    email_trace = langfuse.trace(\n",
    "        name=\"email_evaluation\",\n",
    "        tags=[\"evaluation\", \"content_type:email\", \"campaign:ai_productivity_2024\"]\n",
    "    )\n",
    "    \n",
    "    email_score = langfuse.score(\n",
    "        trace_id=email_trace.id,\n",
    "        name=\"conversion_potential\",\n",
    "        value=0.73,\n",
    "        comment=\"Subject line OK, CTA r√µ r√†ng. C·∫ßn c·∫£i thi·ªán personalization.\"\n",
    "    )\n",
    "    \n",
    "    # LinkedIn feedback\n",
    "    linkedin_trace = langfuse.trace(\n",
    "        name=\"linkedin_evaluation\",\n",
    "        tags=[\"evaluation\", \"content_type:linkedin\", \"campaign:ai_productivity_2024\"]\n",
    "    )\n",
    "    \n",
    "    linkedin_score = langfuse.score(\n",
    "        trace_id=linkedin_trace.id,\n",
    "        name=\"professional_tone\",\n",
    "        value=0.88,\n",
    "        comment=\"Tone professional ph√π h·ª£p, storytelling t·ªët. Hashtags relevant.\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"blog\": {\"quality\": 0.85, \"seo\": 0.78},\n",
    "        \"tweet\": {\"engagement\": 0.92},\n",
    "        \"email\": {\"conversion\": 0.73},\n",
    "        \"linkedin\": {\"professional_tone\": 0.88}\n",
    "    }\n",
    "\n",
    "# Ch·∫°y evaluation\n",
    "evaluation_scores = simulate_content_evaluation()\n",
    "print(\"üìä Content Evaluation Scores:\")\n",
    "for content_type, scores in evaluation_scores.items():\n",
    "    print(f\"{content_type.upper()}: {scores}\")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ g·ª≠i feedback scores l√™n LangFuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Automatic Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_automatic_quality_checks(results: Dict) -> Dict:\n",
    "    \"\"\"Perform automatic quality checks on generated content\"\"\"\n",
    "    \n",
    "    quality_report = {}\n",
    "    \n",
    "    # Blog quality checks\n",
    "    blog_content = results['contents']['blog']['content']\n",
    "    blog_checks = {\n",
    "        \"word_count_appropriate\": 800 <= results['contents']['blog']['word_count'] <= 1200,\n",
    "        \"has_headers\": \"##\" in blog_content or \"#\" in blog_content,\n",
    "        \"has_conclusion\": \"k·∫øt lu·∫≠n\" in blog_content.lower() or \"conclusion\" in blog_content.lower(),\n",
    "        \"has_cta\": any(word in blog_content.lower() for word in [\"li√™n h·ªá\", \"t√¨m hi·ªÉu\", \"ƒëƒÉng k√Ω\", \"contact\"])\n",
    "    }\n",
    "    quality_report[\"blog\"] = blog_checks\n",
    "    \n",
    "    # Tweet quality checks\n",
    "    tweet_content = results['contents']['tweet']['content']\n",
    "    tweet_lines = tweet_content.split('\\n')\n",
    "    tweet_checks = {\n",
    "        \"has_thread_numbers\": any(\"/\" in line for line in tweet_lines),\n",
    "        \"appropriate_length\": all(len(line) <= 280 for line in tweet_lines if line.strip()),\n",
    "        \"has_hashtags\": \"#\" in tweet_content,\n",
    "        \"thread_count_appropriate\": 5 <= results['contents']['tweet']['tweet_count'] <= 7\n",
    "    }\n",
    "    quality_report[\"tweet\"] = tweet_checks\n",
    "    \n",
    "    # Email quality checks\n",
    "    email_content = results['contents']['email']['content']\n",
    "    email_checks = {\n",
    "        \"has_subject_line\": \"subject\" in email_content.lower(),\n",
    "        \"has_preview_text\": \"preview\" in email_content.lower(),\n",
    "        \"has_cta_button\": any(word in email_content.lower() for word in [\"button\", \"click\", \"action\"]),\n",
    "        \"appropriate_length\": 300 <= len(email_content.split()) <= 500\n",
    "    }\n",
    "    quality_report[\"email\"] = email_checks\n",
    "    \n",
    "    # LinkedIn quality checks\n",
    "    linkedin_content = results['contents']['linkedin']['content']\n",
    "    linkedin_checks = {\n",
    "        \"appropriate_length\": 200 <= len(linkedin_content.split()) <= 400,\n",
    "        \"has_hashtags\": results['contents']['linkedin']['hashtag_count'] >= 3,\n",
    "        \"has_question\": \"?\" in linkedin_content,\n",
    "        \"professional_tone\": not any(word in linkedin_content.lower() for word in [\"lol\", \"omg\", \"wtf\"])\n",
    "    }\n",
    "    quality_report[\"linkedin\"] = linkedin_checks\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Ch·∫°y automatic quality checks\n",
    "quality_report = perform_automatic_quality_checks(results)\n",
    "\n",
    "print(\"üîç AUTOMATIC QUALITY CHECKS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for content_type, checks in quality_report.items():\n",
    "    print(f\"\\n{content_type.upper()}:\")\n",
    "    for check_name, passed in checks.items():\n",
    "        status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "        print(f\"  {status} {check_name}: {passed}\")\n",
    "\n",
    "# G·ª≠i quality metrics l√™n LangFuse\n",
    "quality_trace = langfuse.trace(\n",
    "    name=\"automatic_quality_checks\",\n",
    "    tags=[\"quality_assurance\", \"campaign:ai_productivity_2024\"],\n",
    "    output=quality_report\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ g·ª≠i quality report l√™n LangFuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Cost Analysis & Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate cost analysis (trong th·ª±c t·∫ø s·∫Ω l·∫•y t·ª´ LangFuse metrics)\n",
    "def analyze_generation_costs():\n",
    "    \"\"\"Analyze v√† report cost metrics cho content generation campaign\"\"\"\n",
    "    \n",
    "    # Estimate token usage (trong th·ª±c t·∫ø s·∫Ω track t·ª´ LangFuse)\n",
    "    estimated_costs = {\n",
    "        \"blog\": {\n",
    "            \"input_tokens\": 150,\n",
    "            \"output_tokens\": 1200,\n",
    "            \"estimated_cost_usd\": 0.024\n",
    "        },\n",
    "        \"tweet\": {\n",
    "            \"input_tokens\": 120,\n",
    "            \"output_tokens\": 300,\n",
    "            \"estimated_cost_usd\": 0.008\n",
    "        },\n",
    "        \"email\": {\n",
    "            \"input_tokens\": 130,\n",
    "            \"output_tokens\": 400,\n",
    "            \"estimated_cost_usd\": 0.011\n",
    "        },\n",
    "        \"linkedin\": {\n",
    "            \"input_tokens\": 140,\n",
    "            \"output_tokens\": 350,\n",
    "            \"estimated_cost_usd\": 0.010\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    total_cost = sum(channel[\"estimated_cost_usd\"] for channel in estimated_costs.values())\n",
    "    total_input_tokens = sum(channel[\"input_tokens\"] for channel in estimated_costs.values())\n",
    "    total_output_tokens = sum(channel[\"output_tokens\"] for channel in estimated_costs.values())\n",
    "    \n",
    "    cost_analysis = {\n",
    "        \"total_cost_usd\": total_cost,\n",
    "        \"total_input_tokens\": total_input_tokens,\n",
    "        \"total_output_tokens\": total_output_tokens,\n",
    "        \"cost_per_channel\": estimated_costs,\n",
    "        \"cost_efficiency\": {\n",
    "            \"cost_per_content_piece\": total_cost / 4,\n",
    "            \"tokens_per_dollar\": (total_input_tokens + total_output_tokens) / total_cost if total_cost > 0 else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return cost_analysis\n",
    "\n",
    "# Analyze costs\n",
    "cost_report = analyze_generation_costs()\n",
    "\n",
    "print(\"üí∞ COST ANALYSIS REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Cost: ${cost_report['total_cost_usd']:.4f}\")\n",
    "print(f\"Total Input Tokens: {cost_report['total_input_tokens']:,}\")\n",
    "print(f\"Total Output Tokens: {cost_report['total_output_tokens']:,}\")\n",
    "print(f\"Cost per Content Piece: ${cost_report['cost_efficiency']['cost_per_content_piece']:.4f}\")\n",
    "print(f\"Tokens per Dollar: {cost_report['cost_efficiency']['tokens_per_dollar']:.0f}\")\n",
    "\n",
    "print(\"\\nCost Breakdown by Channel:\")\n",
    "for channel, costs in cost_report['cost_per_channel'].items():\n",
    "    print(f\"  {channel.upper()}: ${costs['estimated_cost_usd']:.4f} ({costs['output_tokens']} output tokens)\")\n",
    "\n",
    "# Send cost metrics to LangFuse\n",
    "cost_trace = langfuse.trace(\n",
    "    name=\"cost_analysis\",\n",
    "    tags=[\"cost_tracking\", \"campaign:ai_productivity_2024\"],\n",
    "    output=cost_report\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ g·ª≠i cost analysis l√™n LangFuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Performance Monitoring & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate performance insights t·ª´ LangFuse data\n",
    "def generate_performance_insights():\n",
    "    \"\"\"Generate actionable insights t·ª´ content generation performance\"\"\"\n",
    "    \n",
    "    insights = {\n",
    "        \"performance_summary\": {\n",
    "            \"total_execution_time\": total_time,\n",
    "            \"avg_time_per_channel\": total_time / 4,\n",
    "            \"fastest_channel\": \"tweet\",  # Gi·∫£ ƒë·ªãnh\n",
    "            \"slowest_channel\": \"blog\"    # Gi·∫£ ƒë·ªãnh\n",
    "        },\n",
    "        \"quality_insights\": {\n",
    "            \"highest_quality_channel\": \"tweet\",  # T·ª´ evaluation scores\n",
    "            \"improvement_needed\": [\"email\"],     # Channels v·ªõi scores th·∫•p\n",
    "            \"quality_consistency\": \"good\"        # Overall assessment\n",
    "        },\n",
    "        \"cost_insights\": {\n",
    "            \"most_expensive_channel\": \"blog\",\n",
    "            \"best_value_channel\": \"tweet\",\n",
    "            \"cost_optimization_potential\": \"medium\"\n",
    "        },\n",
    "        \"recommendations\": [\n",
    "            \"Optimize blog prompt ƒë·ªÉ gi·∫£m token usage while maintaining quality\",\n",
    "            \"Improve email personalization ƒë·ªÉ tƒÉng conversion score\",\n",
    "            \"Consider caching common phrases ƒë·ªÉ gi·∫£m repeated generation costs\",\n",
    "            \"A/B test different tweet formats ƒë·ªÉ maintain high engagement\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return insights\n",
    "\n",
    "# Generate insights\n",
    "performance_insights = generate_performance_insights()\n",
    "\n",
    "print(\"üìà PERFORMANCE INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Performance Summary:\")\n",
    "perf = performance_insights[\"performance_summary\"]\n",
    "print(f\"  Total Time: {perf['total_execution_time']:.2f}s\")\n",
    "print(f\"  Avg Time/Channel: {perf['avg_time_per_channel']:.2f}s\")\n",
    "print(f\"  Fastest: {perf['fastest_channel']}\")\n",
    "print(f\"  Slowest: {perf['slowest_channel']}\")\n",
    "\n",
    "print(f\"\\nüéØ Quality Insights:\")\n",
    "qual = performance_insights[\"quality_insights\"]\n",
    "print(f\"  Best Quality: {qual['highest_quality_channel']}\")\n",
    "print(f\"  Needs Work: {', '.join(qual['improvement_needed'])}\")\n",
    "print(f\"  Consistency: {qual['quality_consistency']}\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "for i, rec in enumerate(performance_insights[\"recommendations\"], 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "# Send insights to LangFuse\n",
    "insights_trace = langfuse.trace(\n",
    "    name=\"performance_insights\",\n",
    "    tags=[\"insights\", \"campaign:ai_productivity_2024\"],\n",
    "    output=performance_insights\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ g·ª≠i performance insights l√™n LangFuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## LangFuse Dashboard Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush t·∫•t c·∫£ traces v√† observations l√™n LangFuse\n",
    "langfuse_handler.flush()\n",
    "\n",
    "print(\"üöÄ LANGFUSE DASHBOARD ACCESS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dashboard URL: http://localhost:3000\")\n",
    "print(f\"Campaign Tag: ai_productivity_2024\")\n",
    "print(f\"Traces Generated: {len(['campaign', 'blog', 'tweet', 'email', 'linkedin', 'quality', 'cost', 'insights'])}\")\n",
    "\n",
    "print(\"\\nüìä Dashboard Features to Explore:\")\n",
    "print(\"  üîç Traces: Xem chi ti·∫øt execution flow c·ªßa t·ª´ng content type\")\n",
    "print(\"  üìà Metrics: Token usage, latency, cost breakdown per channel\")\n",
    "print(\"  ‚≠ê Scores: Quality ratings v√† feedback cho t·ª´ng content piece\")\n",
    "print(\"  üè∑Ô∏è Tags: Filter theo campaign, content_type, evaluation\")\n",
    "print(\"  üí∞ Costs: Track chi ph√≠ generation theo time v√† campaign\")\n",
    "\n",
    "print(\"\\nüéØ Key Metrics to Monitor:\")\n",
    "print(\"  ‚Ä¢ Content generation latency per channel\")\n",
    "print(\"  ‚Ä¢ Token efficiency (output tokens / input tokens)\")\n",
    "print(\"  ‚Ä¢ Quality score trends over time\")\n",
    "print(\"  ‚Ä¢ Cost per content piece by campaign\")\n",
    "print(\"  ‚Ä¢ Success rate v√† error patterns\")\n",
    "\n",
    "print(\"\\n‚úÖ T·∫•t c·∫£ traces ƒë√£ ƒë∆∞·ª£c g·ª≠i l√™n LangFuse Dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Gi·∫£i th√≠ch & Ph√¢n t√≠ch\n",
    "\n",
    "### C√°ch LangFuse bi·∫øn Tracing Data th√†nh Actionable Insights\n",
    "\n",
    "#### 1. **Pipeline Visibility**\n",
    "- **Trace Hierarchy**: LangFuse t·∫°o hierarchical view c·ªßa to√†n b·ªô content generation pipeline\n",
    "- **Execution Flow**: Xem ƒë∆∞·ª£c th·ª© t·ª± v√† dependencies gi·ªØa c√°c steps\n",
    "- **Error Tracking**: Identify ch√≠nh x√°c node n√†o fail v√† t·∫°i sao\n",
    "\n",
    "#### 2. **Performance Analytics**\n",
    "- **Latency Analysis**: So s√°nh th·ªùi gian execution gi·ªØa c√°c content types\n",
    "- **Bottleneck Detection**: Identify steps n√†o l√†m ch·∫≠m to√†n b·ªô pipeline\n",
    "- **Scaling Insights**: Predict performance khi scale l√™n volume l·ªõn\n",
    "\n",
    "#### 3. **Cost Optimization**\n",
    "- **Token Efficiency**: Track input/output token ratio cho t·ª´ng channel\n",
    "- **Cost per Content**: Calculate ROI cho t·ª´ng lo·∫°i content\n",
    "- **Budget Planning**: Forecast costs cho campaigns t∆∞∆°ng lai\n",
    "\n",
    "#### 4. **Quality Management**\n",
    "- **Score Tracking**: Monitor quality trends theo th·ªùi gian\n",
    "- **A/B Testing**: So s√°nh effectiveness c·ªßa different prompts\n",
    "- **Feedback Loop**: Integrate human feedback ƒë·ªÉ improve generation quality\n",
    "\n",
    "#### 5. **Campaign Analysis**\n",
    "- **Multi-Campaign Comparison**: So s√°nh performance across campaigns\n",
    "- **Content Type Performance**: Identify lo·∫°i content n√†o perform t·ªët nh·∫•t\n",
    "- **Audience Targeting**: Analyze effectiveness cho different target audiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## T√†i li·ªáu Tham kh·∫£o\n",
    "\n",
    "### LangFuse Official Documentation\n",
    "- **[LangFuse Tracing Guide](https://langfuse.com/docs/tracing)**: Chi ti·∫øt v·ªÅ c√°ch setup v√† s·ª≠ d·ª•ng tracing\n",
    "- **[LangChain Integration](https://langfuse.com/docs/integrations/langchain)**: T√≠ch h·ª£p LangFuse v·ªõi LangChain pipelines\n",
    "- **[Scoring & Evaluation](https://langfuse.com/docs/scores)**: H·ªá th·ªëng scoring v√† feedback collection\n",
    "- **[Cost Tracking](https://langfuse.com/docs/model-usage-and-cost)**: Monitor v√† optimize model usage costs\n",
    "- **[Dashboard Features](https://langfuse.com/docs/analytics)**: S·ª≠ d·ª•ng analytics dashboard hi·ªáu qu·∫£\n",
    "\n",
    "### Content Generation Best Practices\n",
    "- **[Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)**: Techniques ƒë·ªÉ optimize prompt quality\n",
    "- **[LangChain Parallel Execution](https://python.langchain.com/docs/expression_language/how_to/parallel)**: Parallel processing strategies\n",
    "- **[Content Quality Metrics](https://langfuse.com/docs/experimentation)**: ƒê·ªãnh nghƒ©a v√† track quality metrics\n",
    "\n",
    "### Advanced Topics\n",
    "- **[LangFuse Sessions](https://langfuse.com/docs/tracing-features/sessions)**: Group related content generation tasks\n",
    "- **[Custom Metrics](https://langfuse.com/docs/scores/custom)**: T·∫°o custom evaluation metrics\n",
    "- **[API Integration](https://langfuse.com/docs/api)**: Integrate LangFuse v√†o production systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n & B∆∞·ªõc ti·∫øp theo\n",
    "\n",
    "### Nh·ªØng g√¨ ƒë√£ h·ªçc\n",
    "‚úÖ **Pipeline Design**: X√¢y d·ª±ng multi-channel content generation v·ªõi parallel processing\n",
    "\n",
    "‚úÖ **LangFuse Integration**: Comprehensive tracing, scoring, v√† cost tracking\n",
    "\n",
    "‚úÖ **Quality Assurance**: Automatic quality checks v√† human feedback integration\n",
    "\n",
    "‚úÖ **Performance Monitoring**: Real-time insights v·ªÅ latency, costs, v√† effectiveness\n",
    "\n",
    "‚úÖ **Actionable Analytics**: Transform raw tracing data th√†nh business insights\n",
    "\n",
    "### B∆∞·ªõc ti·∫øp theo ƒë·ªÉ Scale Production\n",
    "\n",
    "#### 1. **Advanced Pipeline Features**\n",
    "- Implement conditional routing d·ª±a tr√™n content type requirements\n",
    "- Add content approval workflow v·ªõi human-in-the-loop\n",
    "- Integrate v·ªõi CRM/Marketing platforms ƒë·ªÉ automated distribution\n",
    "\n",
    "#### 2. **Enhanced Monitoring**\n",
    "- Setup alerting cho quality score drops ho·∫∑c cost spikes\n",
    "- Create custom dashboards cho different stakeholders\n",
    "- Implement automated A/B testing cho prompt optimization\n",
    "\n",
    "#### 3. **Production Optimization**\n",
    "- Implement caching cho frequently used content templates\n",
    "- Add rate limiting v√† error handling cho robust production deployment\n",
    "- Scale v·ªõi async processing cho high-volume campaigns\n",
    "\n",
    "#### 4. **Advanced Analytics**\n",
    "- Content performance correlation v·ªõi business metrics\n",
    "- Predictive modeling cho content success rates\n",
    "- ROI calculation cho content marketing investments\n",
    "\n",
    "### Next Tutorial\n",
    "Notebook ti·∫øp theo s·∫Ω focus v√†o **\"LangFuse Advanced Workflows\"** - t√≠ch h·ª£p v·ªõi CI/CD pipelines, automated testing, v√† enterprise-scale monitoring strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}