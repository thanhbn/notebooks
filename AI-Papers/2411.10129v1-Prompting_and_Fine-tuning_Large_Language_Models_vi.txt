# 2411.10129v1.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: D:\llm\notebooks\AI-Papers\2411.10129v1.pdf
# Kích thước file: 1638441 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Prompting và Fine-tuning Mô hình Ngôn ngữ Lớn
cho Tự động Tạo Bình luận Review Code
Md. Asif Haider1*, Ayesha Binte Mostofa1*, Sk. Sabit Bin Mosaddek1*, Anindya Iqbal1, Toufique Ahmed2
1Đại học Kỹ thuật và Công nghệ Bangladesh, Dhaka, Bangladesh
2Đại học California, Davis, Hoa Kỳ
1805112@ugrad.cse.buet.ac.bd, 1805062@ugrad.cse.buet.ac.bd, 1805106@ugrad.cse.buet.ac.bd,
anindya@cse.buet.ac.bd, tfahmed@ucdavis.edu

Tóm tắt — Việc tạo ra các bình luận review code chính xác vẫn là một thách thức đáng kể do bản chất đa dạng và không duy nhất của đầu ra nhiệm vụ. Các mô hình ngôn ngữ lớn được huấn luyện trước trên cả dữ liệu lập trình và ngôn ngữ tự nhiên có xu hướng hoạt động tốt trong các nhiệm vụ định hướng code. Tuy nhiên, việc huấn luyện trước quy mô lớn không phải lúc nào cũng khả thi do tác động môi trường và các vấn đề về khả năng tổng quát hóa dành riêng cho dự án. Trong nghiên cứu này, trước tiên chúng tôi fine-tune các mô hình ngôn ngữ lớn mã nguồn mở (LLM) theo cách tiết kiệm tham số, quantized low-rank (QLoRA) trên phần cứng dành cho người tiêu dùng để cải thiện việc tạo bình luận review. Các nghiên cứu gần đây chứng minh hiệu quả của việc bổ sung thông tin metadata ngữ nghĩa vào prompts để tăng hiệu suất trong các nhiệm vụ liên quan đến code khác. Để khám phá điều này trong các hoạt động review code, chúng tôi cũng prompt các LLM sở hữu, mã nguồn đóng bằng cách bổ sung patch code đầu vào với đồ thị gọi hàm và tóm tắt code. Cả hai chiến lược của chúng tôi đều cải thiện hiệu suất tạo bình luận review, với few-shot prompting bổ sung đồ thị gọi hàm trên mô hình GPT-3.5 vượt qua baseline được huấn luyện trước khoảng 90% điểm BLEU-4 trên bộ dữ liệu CodeReviewer. Hơn nữa, các mô hình Gemini-1.0 Pro được prompt few-shot, Code Llama và Llama 3.1 được fine-tune QLoRA đạt được kết quả cạnh tranh (từ 25% đến 83% cải thiện hiệu suất) trong nhiệm vụ này. Một nghiên cứu đánh giá con người bổ sung tiếp tục xác thực các phát hiện thực nghiệm của chúng tôi, phản ánh nhận thức của các developer thực tế về các bình luận review code được tạo bởi LLM dựa trên các chỉ số định tính có liên quan.

Thuật ngữ chỉ mục — bình luận review code, fine-tuning quantized low-rank, few-shot prompting, đồ thị gọi hàm, mô hình ngôn ngữ lớn

I. GIỚI THIỆU
Review code, quy trình thủ công kiểm tra source code được tác giả bởi các đồng đội, là một phần quan trọng của vòng đời phát triển phần mềm giúp phát hiện lỗi và khuyến khích cải thiện code thêm [1]. Được hình thức hóa lần đầu bởi Fagan [2], đây là một hoạt động đảm bảo chất lượng phần mềm có hệ thống và hợp tác nơi các developer kiểm tra code của nhau để cải thiện. Review code không chỉ giúp xác định bugs và các vấn đề tiềm ẩn sớm trong chu kỳ phát triển mà còn tăng cường khả năng đọc, bảo trì và chất lượng phần mềm tổng thể. Tuy nhiên, bất chấp những lợi ích to lớn, quy trình review truyền thống đòi hỏi nỗ lực thủ công đáng kể, buộc các developer phải dành lượng thời gian quá mức (hơn 6 giờ mỗi tuần) để review code của đồng nghiệp, như được thể hiện trong [3], [4]. Nó cũng chịu trách nhiệm cho việc chuyển đổi ngữ cảnh thường xuyên của các developer khỏi các nhiệm vụ thực tế mà họ dự kiến tập trung vào [5]. Do đó, việc tự động hóa các hoạt động review code đang có nhu cầu đáng kể. Một nhiệm vụ riêng biệt nổi bật trong các thực hành Modern Code Review (MCR): Review Comment Generation (RCG), có thể giúp giảm gánh nặng từ một code reviewer, tự động đề xuất một thay đổi tiềm năng trong code được gửi để review. Chúng tôi tập trung vào việc cải thiện hiệu suất tự động hóa của nhiệm vụ tạo bình luận review trong nghiên cứu này.

Với những tiến bộ nhanh chóng trong deep learning và các kỹ thuật xử lý ngôn ngữ tự nhiên, các nhà nghiên cứu đã đề xuất nhiều Pretrained Language Models (PLM) trên source code tập trung vào các nhiệm vụ review, đáng chú ý bao gồm các mô hình BERT chỉ encoder [6], [7] và các mô hình T5 dựa trên encoder-decoder [8]–[10]. Các nỗ lực pretraining và fine-tuning mới trên các bộ dữ liệu quy mô lớn đã cho thấy kết quả hứa hẹn. Tuy nhiên, việc huấn luyện trên các bộ dữ liệu khổng lồ chuyên biệt về domain như vậy đòi hỏi một lượng tài nguyên máy tính tốn kém đáng kể, gây ra tác động tiêu cực đến dấu chân carbon toàn cầu [11]. Mặc dù các mô hình này thường có thể tổng quát hóa tốt, chúng có thể thiếu kiến thức sâu về codebase cụ thể của dự án, tiêu chuẩn coding của tổ chức hoặc các thư viện chuyên biệt. Điều này có thể dẫn đến các đề xuất review code chung chung hoặc ít liên quan, bỏ lỡ các sắc thái cụ thể của ngữ cảnh.

Tuy nhiên, các mô hình ngôn ngữ thống nhất chỉ decoder (ví dụ dựa trên kiến trúc GPT) đã cho thấy hiệu suất vượt trội khi được mở rộng đến kích thước tham số lớn. Còn được biết đến chung là LLMs, các mô hình này có thể giảm nhu cầu về việc huấn luyện lặp đi lặp lại trong khi cung cấp khả năng few-shot learning tuyệt vời [12]. Điều này đề cập đến prompt engineering của mô hình với một vài cặp query-response tương tự, còn được gọi là Few Shot Learning. Việc thiết kế các prompt LLM hiệu quả cho nhiệm vụ được đề cập vẫn chưa được khám phá nhiều, thúc đẩy chúng tôi hướng tới định hướng nghiên cứu này.

Ngoài các LLM sở hữu, đã có rất nhiều công việc được tiến hành trong bối cảnh mã nguồn mở. Các LLM mã nguồn mở đa mục đích (ví dụ Llama, Mistral) khi được fine-tune, cho thấy cải thiện hiệu suất so với PLMs. Các LLM được huấn luyện thêm trên dữ liệu cụ thể về code, còn được gọi là Code LLMs (ví dụ Codex, Code Llama) hiện tại là các lựa chọn vượt trội cho các nhiệm vụ phụ liên quan đến code khác nhau (bao gồm tạo code, tóm tắt code) [13]. Các phiên bản hiệu suất tốt nhất của các LLM này gần như có 30-70B tham số, điều này khá không thể phù hợp với GPU dành cho người tiêu dùng có khoảng 16GB VRAM. Do đó, fine-tuning các phiên bản nhỏ hơn của các LLM này (7-8B) là một chiến lược hiệu quả về chi phí đầy hứa hẹn để đảm bảo các trường hợp sử dụng cụ thể của dự án, nhận thức ngữ cảnh. Các phương pháp Parameter Efficient Fine-Tuning (PEFT) (Low-Rank Adaptation, 4-bit Quantization) được phát hiện là hỗ trợ trong những nỗ lực như vậy [14].

Việc bổ sung các sự kiện cấu trúc ngữ nghĩa được phân tích tĩnh vào prompt mô hình code đã được chứng minh là có lợi trong các nhiệm vụ tóm tắt code [15]. Được truyền cảm hứng từ điều này, chúng tôi đề xuất một phương pháp mới để thiết kế các prompt few-shot hiệu quả về chi phí cho các LLM sở hữu, được bổ sung với một thành phần ngôn ngữ lập trình - đồ thị gọi hàm và một thành phần ngôn ngữ tự nhiên - tóm tắt code. Chúng tôi cũng khám phá các nghiên cứu ablation thêm để hiểu những đóng góp độc lập của chúng cho nhiệm vụ tạo bình luận review code. Ngoài ra, chúng tôi fine-tune các LLM mã nguồn mở đa mục đích và code LLMs trong việc tự động hóa nhiệm vụ tạo bình luận review trong một setting hạn chế tài nguyên thấp. Cụ thể, chúng tôi tận dụng phương pháp Quantized Low-Rank Adaptation (QLoRA) để fine-tune các mô hình của chúng tôi theo cách có giám sát. Để tóm tắt, chúng tôi đặc biệt điều tra các câu hỏi nghiên cứu sau trong nghiên cứu này:

RQ1: Tạo bình luận review code sử dụng Mô hình Ngôn ngữ Lớn mã nguồn mở được fine-tune hiệu quả như thế nào?

RQ2: Các Mô hình Ngôn ngữ Lớn mã nguồn đóng hoạt động tốt như thế nào trong nhiệm vụ tạo bình luận review code khi được prompt engineering trong setting few-shot?

RQ3: Khi được kết hợp vào prompts, tác động của đồ thị gọi hàm và tóm tắt code trong việc cải thiện hiệu suất tạo bình luận review là gì?

RQ4: Các Mô hình Ngôn ngữ Lớn hiệu quả như thế nào trong việc tạo bình luận review từ góc độ của một developer thực tế?

Những đóng góp của chúng tôi có thể được tóm tắt như sau:
• Đánh giá hiệu suất tạo bình luận review code với các LLM mã nguồn mở (Llama 2, Code Llama, Llama 3 series) trong setup fine-tuning tiết kiệm tham số quantized, low-rank adapted
• Khám phá hiệu suất của các LLM sở hữu, mã nguồn đóng khác nhau (GPT 3.5-Turbo, GPT-4o, Gemini-1.0 Pro) trong setting prompt few-shot mà không có bất kỳ data augmentation thêm nào
• Điều tra tác động của việc kết hợp đồ thị gọi hàm được trích xuất thủ công và tóm tắt code được tạo bởi mô hình CodeT5 vào các prompt few-shot để quan sát tác động của chúng đến hiệu suất tạo bình luận review
• Phân tích thủ công và một nghiên cứu developer tập trung vào việc đánh giá các bình luận review được tạo bởi LLM dựa trên các chỉ số định tính có liên quan
• Một gói replication với tất cả các script cho việc xử lý dữ liệu, code và kết quả cho nghiên cứu của chúng tôi, có thể được tìm thấy tại đây.

II. KIẾN THỨC NỀN TẢNG
Chúng tôi cung cấp một tổng quan ngắn gọn về LLMs, few-shot prompting và các phương pháp fine-tuning QLoRA tiết kiệm tham số.

A. Mô hình Ngôn ngữ Lớn
Mô hình Ngôn ngữ Lớn (LLM) đại diện cho một lớp mô hình tính toán mới với hàng triệu và hàng tỷ tham số mô hình được huấn luyện được thiết kế để xử lý, hiểu và tạo ra văn bản giống con người. LLMs cho các nhiệm vụ kỹ thuật phần mềm thường được chia thành hai loại: mô hình đa mục đích và mô hình tập trung vào code. Các mô hình đa mục đích, như series GPT và Gemini [16], được thiết kế cho một loạt rộng các nhiệm vụ, bao gồm trả lời câu hỏi, tóm tắt và tạo đối화. Các LLM cụ thể về code, như Code Llama [17], chuyên biệt trong các ngôn ngữ lập trình và xuất sắc trong việc tạo, hoàn thành và debug code. Được xây dựng trên nền tảng của kiến trúc Transformer với multi-headed attention cho việc xử lý sequence hiệu quả, các mô hình này đã phát triển đáng kể kể từ năm 2017. Transformers đã thay thế RNNs, cho phép xử lý phụ thuộc tầm xa tốt hơn và cho phép các mô hình như GPT mở rộng đến hàng nghìn tỷ tham số và khả năng đa phương thức. Gemini, dựa trên mô hình T5 [18] của Google, đã tiến xa hơn trong khả năng đa phương thức, xử lý văn bản, hình ảnh, âm thanh và video với cửa sổ ngữ cảnh mở rộng, làm cho nó có giá trị cho các nhiệm vụ như tóm tắt code và cải tiến.

B. Few-shot Prompting
Cho đến năm 2020, fine-tuning là phương pháp chủ đạo để adapting các mô hình cho một nhiệm vụ cụ thể. Tuy nhiên, với những tiến bộ trong LLMs, prompt engineering đã nổi lên như một giải pháp thay thế hiệu quả [19]–[22]. Một prompt là một đầu vào ngôn ngữ tự nhiên có cấu trúc hướng dẫn Mô hình Ngôn ngữ Lớn (LLMs) thực hiện một nhiệm vụ được chỉ định, kết hợp các hướng dẫn và thông tin ngữ cảnh để tăng cường tính liên quan của đầu ra của các truy vấn kiểm tra. Trong khi Mô hình Ngôn ngữ Lớn có thể hoạt động tốt với zero-shot, chúng đạt được hiệu suất tốt hơn với few-shot prompting [12]. Kỹ thuật này giới thiệu một số lượng hạn chế các ví dụ được gắn nhãn trong prompt như thông tin ngữ cảnh, minh họa mối quan hệ đầu vào-đầu ra để hướng dẫn phản hồi của mô hình. Ngữ cảnh few-shot hàng đầu phù hợp cho truy vấn kiểm tra có thể được truy xuất từ bộ dữ liệu huấn luyện sử dụng một thuật toán xếp hạng riêng biệt.

C. QLoRA: Fine-Tuning Tiết kiệm Tham số
Các Mô hình Ngôn ngữ Lớn hiện đại có hàng tỷ tham số, do đó fine tuning các mô hình này đòi hỏi một lượng lớn bộ nhớ và máy GPU cao cấp. Một quy trình finetuning đầy đủ cũng có thể cực kỳ tốn thời gian và năng lượng, vì nó liên quan đến việc huấn luyện tất cả các lớp và tham số với dữ liệu cụ thể của nhiệm vụ. Một số kỹ thuật fine-tuning tiết kiệm tham số, còn được gọi chung là các phương pháp PEFT [23]–[25] đã được đề xuất và áp dụng để giảm sử dụng bộ nhớ và chi phí huấn luyện trong khi duy trì độ chính xác của mô hình được fine-tune ở mức độ hợp lý [14]. Quantized LoRA, được biết đến tốt nhất là QLoRA [26] là một phiên bản quantized của LoRA giới thiệu việc quantizing mô hình transformer thành 4-bit NormalFloat (NF4) precision với xử lý quantization kép từ 16-bit FloatingPoint (FP16) thông thường. Nó cũng sử dụng một optimizer được phân trang để đối phó với các đỉnh bộ nhớ được thấy khi huấn luyện với các batch dài hơn, cuối cùng làm cho fine-tuning có thể với tài nguyên tính toán hạn chế hơn.

III. PHƯƠNG PHÁP
Hình 1 cung cấp một tổng quan đồ họa ngắn gọn về nghiên cứu của chúng tôi. Chúng tôi thu thập các bình luận review, cùng với các code snippet trước và sau khi review code từ bộ dữ liệu CodeReviewer [9]. Để trả lời RQ1, chúng tôi fine-tune các mô hình từ Meta Llama series (Llama 2, Code Llama, Llama 3, Llama 3.1, Llama 3.2). Để giải quyết RQ2 và RQ3, chúng tôi few-shot prompt các mô hình từ GPT (GPT-3.5 Turbo, GPT 4o) và Gemini (Gemini-1.0 Pro) series, và thử nghiệm với các chiến lược augmentation prompt khác nhau. Cuối cùng, chúng tôi mời một nhóm các developer phần mềm từ ngành công nghiệp tham gia vào một nghiên cứu đánh giá con người ẩn danh được thiết kế để trả lời RQ4 được đề xuất của chúng tôi. Các phần phụ sau đây giải thích chi tiết từng bước này.

A. Bộ dữ liệu
Chúng tôi sử dụng bộ dữ liệu CodeReviewer [9] cho tất cả các thí nghiệm của chúng tôi. Được giới thiệu bởi Microsoft, bộ dữ liệu này được thu thập từ các repository mã nguồn mở chất lượng cao có sẵn công khai. Nó bao gồm chín ngôn ngữ phổ biến nhất bao gồm C, C++, C#, Go, Java, JavaScript, PHP, Python và Ruby. Bộ dữ liệu này được xử lý cho ba nhiệm vụ downstream (ước lượng chất lượng thay đổi code, tạo bình luận review và cải tiến code). Vì thí nghiệm của chúng tôi tập trung vào nhiệm vụ tạo bình luận review, bộ dữ liệu này phù hợp tốt với các thí nghiệm của chúng tôi. Bộ dữ liệu đã được chia thành ba phần (Dữ liệu Training, Validation và Test). Vì dữ liệu từ cùng một dự án có thể dẫn đến dữ liệu test và validation thiên vị, bộ dữ liệu đã được chia ở cấp độ dự án. Do đó, không có mối tương quan giữa ba phần của bộ dữ liệu. Chúng tôi tách tất cả các trường cần thiết của bộ dữ liệu cho thí nghiệm của mình, bao gồm old file (file trước pull request), code diff và một review comment.

Chúng tôi dự định không sử dụng toàn bộ bộ dữ liệu test để đánh giá nhằm giữ chi phí prompting của chúng tôi trong giới hạn, vì các LLM mã nguồn đóng như GPT-3.5 và GPT-4 series áp đặt một lượng chi phí overhead đáng kể khi áp dụng cho bộ dữ liệu khổng lồ như vậy với hàng nghìn mục. Do đó, cho mục đích thí nghiệm của chúng tôi, chúng tôi chọn ngẫu nhiên 5000 và 500 mẫu từ toàn bộ tập test và chỉ đánh giá thêm prompting, fine-tuning và nghiên cứu ablation sử dụng hai tập con test này. Bảng I cho thấy tổng quan về bộ dữ liệu được sử dụng trong các thí nghiệm của chúng tôi. Wilcoxon-signed rank test được tiến hành trên các tập con này với kết quả từ phần IV-A, IV-B và IV-C cho thấy không có sự khác biệt thống kê đáng kể giữa các phiên bản khác nhau của tập test này.

B. RQ1: Fine-tuning Quantized Tiết kiệm Tham số cho RCG
Trong phần này, chúng tôi mô tả chi tiết cách chúng tôi fine-tune các LLM mã nguồn mở cho nhiệm vụ tạo bình luận review. Chúng tôi sử dụng QLoRA, một kỹ thuật fine-tuning tiết kiệm tham số (PEFT) hiệu quả kết hợp ý tưởng làm việc với các ma trận low-rank và 4-bit quantization. Động lực để đi với phương pháp PEFT là để đảm bảo fine-tuning trong một setting hạn chế, tài nguyên thấp có thể được đạt được với cấu hình GPU dành cho người tiêu dùng.

1) Tiền xử lý Dữ liệu cho Supervised Fine-tuning: LLMs, khi được huấn luyện để tuân theo một số hình thức hướng dẫn cụ thể có xu hướng cho thấy hiệu suất vượt trội trong thực tế. Fine-tuning trên một loạt đa dạng các bộ dữ liệu đa nhiệm vụ với các hướng dẫn ngôn ngữ tự nhiên phong phú đã được chứng minh là thể hiện cải thiện hiệu suất trên các nhiệm vụ hoàn toàn chưa thấy [27], [28]. Do đó trong công việc này, chúng tôi đã sửa đổi bộ dữ liệu để chứa một prompt instruction-following phù hợp cho nhiệm vụ tạo bình luận review code. Chúng tôi tạo template của mình được truyền cảm hứng từ Stanford Alpaca [29] và sử dụng bộ dữ liệu gốc từ CodeReviewer [9] để thực hiện fine-tuning theo cách có giám sát. Cấu trúc dữ liệu được sửa đổi tuân theo định dạng {instruction, input, output}, tương tự như framework được giới thiệu trong [30]. Chúng tôi cho thấy prompt template và instruction, input và output mẫu tương ứng trong Hình 2.

2) Fine-tuning Các Mô hình Mã nguồn Mở: Sử dụng bộ dữ liệu instruction-following mà chúng tôi đã chuẩn bị, chúng tôi fine-tune các thế hệ và biến thể khác nhau của Llama, series LLM hàng đầu của Meta trong kịch bản mã nguồn mở. Llama 2 [31], người kế nhiệm trực tiếp của mô hình Meta Llama đã được pretrained trên 2 nghìn tỷ token. Code Llama [17] được xây dựng trên đỉnh của Llama 2 sau khi huấn luyện với khả năng fill-in-the-middle trên các bộ dữ liệu cụ thể về code. Chúng tôi fine-tune phiên bản base 7B của cả hai mô hình cho nhiệm vụ của chúng tôi. Llama 3 thậm chí còn vượt qua các mô hình trước đó trong series Llama như các LLM có thể truy cập công khai, theo sau bởi Llama 3.1 (với cửa sổ lớn hơn của 128k token) và Llama 3.2 (phiên bản nhẹ, quantized). Chúng tôi sử dụng phiên bản 3B Instruct cho mục đích của chúng tôi.

3) Thiết lập Thí nghiệm: Chúng tôi thực hiện thí nghiệm fine-tuning của mình bằng cách sử dụng một cặp công cụ mã nguồn mở phổ biến. Chúng tôi sử dụng Axolotl để fine-tune các biến thể Llama 2 và Code Llama 7B với adapter QLoRA cho 4-bit quantization. Axolotl là một công cụ được thiết kế để streamline việc fine-tuning của các mô hình AI khác nhau, cung cấp hỗ trợ cho nhiều cấu hình và kiến trúc. Để fine-tune tất cả các mô hình Llama 3, chúng tôi sử dụng Unsloth, cung cấp tốc độ training và inference nhanh hơn cho các LLM gần đây hơn. Tất cả các thí nghiệm đều được tiến hành trên máy NVIDIA RTX 5000 GPU với 16 GB VRAM. Giới hạn độ dài token được đặt thành 2048. Tất cả các mô hình đều được huấn luyện trong 2 epoch đầy đủ (ngoại trừ 5 epoch cho Llama 3.2) sử dụng optimizer 32-bit paged AdamW cho các mô hình Llama 2 và Code Llama, trong khi series Llama 3 sử dụng optimizer 8-bit AdamW thay thế. Chúng tôi đặt LoRA rank thành 32, hệ số scaling alpha thành 16 và tỷ lệ dropout thành 0.05. Kích thước micro batch được cố định thành 2 và tốc độ học 0.0002 được sử dụng với 0.01 weight decay.

C. RQ2: Few-shot Prompting cho RCG
Trong phần này, chúng tôi thảo luận chi tiết cách chúng tôi áp dụng prompt engineering cho nhiệm vụ và bộ dữ liệu của chúng tôi.

1) Các Mô hình Mã nguồn Đóng được Prompt: Chúng tôi chọn ba LLM sở hữu phổ biến cho các thí nghiệm prompting của chúng tôi. Hai trong số chúng, các mô hình GPT-3.5 Turbo [12] và GPT-4o [32] được truy cập qua OpenAI API, mô hình Gemini-1.0 Pro [16] được cung cấp bởi Google DeepMind API. Các mô hình chỉ decoder này tạo văn bản bằng cách dự đoán token tiếp theo trong một sequence được đưa ra các token trước đó, điều này làm cho các mô hình này đặc biệt hiệu quả cho các nhiệm vụ liên quan đến tạo văn bản và hoàn thành.

Chúng tôi chọn phiên bản instruct của GPT-3.5 Turbo, mô hình hiệu quả về chi phí nhất trong series GPT-3.5. Nó cung cấp cửa sổ ngữ cảnh 4,096 token và được huấn luyện trên dữ liệu đến tháng 9 năm 2021. GPT-4 omni, còn được gọi là GPT-4o, là mô hình đa phương thức hàng đầu của OpenAI với hiệu suất reasoning tiên tiến. Nó được cập nhật với kiến thức đến tháng 10 năm 2023, cung cấp khả năng nâng cao trong việc hiểu và tạo ra các loại nội dung đa dạng. Cuối cùng chúng tôi chọn Gemini-1.0 Pro từ series Gemini của các mô hình đa phương thức tiên tiến được phát triển bởi Google. Nó được tạo ra để mở rộng trên một loạt rộng các nhiệm vụ với đến 1M token đầu vào, một giới hạn lớn hơn các mô hình tương đương khác. Gemini-1.0-pro cung cấp cửa sổ ngữ cảnh 32k token và được ghi nhận với tốc độ đầu ra ấn tượng 86.8 token mỗi giây, làm cho nó tương đối nhanh hơn.

2) Thiết kế Prompt Few-shot: Một prompt là một đầu vào ngôn ngữ tự nhiên có cấu trúc được trình bày cho một mô hình ngôn ngữ, được thiết kế để nhận một phản hồi cụ thể được điều chỉnh cho một nhiệm vụ cụ thể. Trong khi, trong nhiều trường hợp, các mô hình ngôn ngữ lớn cho thấy hiệu suất xuất sắc với zero-shot prompting (không có ví dụ nào), nó có thể cần một số ví dụ được cung cấp cho các nhiệm vụ phức tạp. Few-shot prompting là một kỹ thuật được sử dụng rộng rãi để cho phép in-context learning [33]–[35] nơi chúng tôi cung cấp các demonstrations trong prompt để hướng dẫn mô hình hoạt động tốt hơn.

Các prompt chu đáo, được tạo tốt là rất quan trọng để tận dụng hiệu suất của các mô hình generative như GPT-3.5 và 4 series. Review Comment Generation là một nhiệm vụ phức tạp đòi hỏi nhiều sự tập trung và kiến thức ngữ cảnh về code snippet. Các bình luận review được tạo cần phải chính xác, đặc biệt trên các phần nơi code cần được sửa đổi. Một bình luận cần phải thông tin, liên quan và được giải thích tốt để biểu thị nơi sửa các vấn đề trong code. Trong prompt của chúng tôi, chúng tôi bao gồm {Instruction optional + Exemplars + Query test}. Dưới đây chúng tôi thảo luận chi tiết về những điều này.

• Instruction: Hướng dẫn chỉ được thêm vào mô hình chat GPT-4o, để tránh tạo ra các code review quá dài và khuyến khích các bình luận review ngắn gọn vừa liên quan vừa thông tin đối với các thay đổi code. Chúng tôi lấy cảm hứng cho thiết kế prompt của mình từ các danh mục Specificity and Information, Content and Language Style, User Interaction and Engagement và Prompt Structure and Clarity như được thể hiện trong [36], và Emotional Stimulus như được trình bày trong [37]. Dựa trên các thí nghiệm thiết kế, chúng tôi chọn "Please provide formal code review for software developers in one sentence for following test case, implementing few-shot learning from examples. Don't start with code review/review. Just give the answer." như prompt của chúng tôi.

• Exemplars: Few-shot (k-shot nơi k có thể là 3, 5, 10 ví dụ) exemplars là các ví dụ được thu thập từ bộ dữ liệu huấn luyện để hướng dẫn mô hình hướng tới việc tạo đầu ra với độ chính xác và định dạng mong muốn. Đối với mỗi mẫu từ tập con test của chúng tôi trong nghiên cứu của chúng tôi, chúng tôi sử dụng BM-25 [38], thuật toán truy xuất thông tin và xếp hạng phổ biến để truy xuất các mẫu k có liên quan nhất từ tập huấn luyện. Theo nghiên cứu CodeReviewer gốc [9], mỗi ví dụ của prompt chúng tôi chứa các nội dung sau:
  – Code Diff: Một code snippet cho thấy các thay đổi trong code, được ký hiệu là patch trong bộ dữ liệu CodeReviewer.
  – Code Review: Bình luận review tương ứng, ban đầu là phần msg của các mẫu bộ dữ liệu CodeReviewer.

• Query test: Để đánh giá mô hình, chúng tôi sử dụng các truy vấn test có cấu trúc tương tự như các ví dụ huấn luyện. Mỗi test case của Test Subset 1 của chúng tôi chỉ chứa Code Diff. Chúng tôi thêm tag "Code Review" để chỉ ra cho mô hình hoàn thành bình luận review mong muốn trong prompt.

Chúng tôi cũng thêm các thành phần đồ thị gọi hàm và tóm tắt code vào mỗi mẫu k-shot của chúng tôi (tương tự, trong các truy vấn test) để giải quyết RQ3, mà chúng tôi thảo luận chi tiết trong phần III-D.

D. RQ3: Tác động của Prompts Bổ sung Metadata Ngữ nghĩa cho RCG
Trong phần này, chúng tôi thảo luận các bước chính của tiền xử lý bộ dữ liệu để tạo ra đồ thị gọi hàm và tóm tắt code. Sau đó chúng tôi trình bày cách chúng tôi kết hợp những điều này vào pipeline prompting của chúng tôi đã được thảo luận trong phần III-C.

1) Trích xuất Đồ thị Gọi Hàm: Vì code diff đại diện cho một phần nhỏ của toàn bộ code base, mang không nhiều thông tin về các phần khác của code, thách thức vẫn còn: làm thế nào chúng ta có thể cho phép mô hình của chúng tôi nhận ra điểm chính của code base? Để giải quyết vấn đề này, chúng tôi đặt giả thuyết rằng thông tin luồng dữ liệu ngữ nghĩa, như đồ thị gọi hàm, là một yếu tố đóng góp quan trọng cho việc hiểu sâu hơn về code base của chúng tôi. Một đồ thị gọi hàm là một đồ thị luồng điều khiển đại diện cho hàm nào được gọi từ các hàm khác. Nó tạo ra một đồ thị có hướng nơi mỗi node đại diện cho một hàm hoặc module và mỗi cạnh tượng trưng cho cuộc gọi từ một hàm này sang hàm khác.

Để đạt được điều này, chúng tôi trích xuất các chi tiết cú pháp từ mẫu code đã cho trước, tận dụng Abstract Syntax Tree (AST). AST, về bản chất, là một cấu trúc dữ liệu nắm bắt cấu trúc cú pháp của một chương trình hoặc code. Nó tạo thành một cây nơi mỗi node biểu thị một cấu trúc xảy ra trong code. Chúng tôi phân tích từng code 'oldf' file cũ từ bộ dữ liệu của mình để tạo một AST để xác định các yếu tố chính như gọi hàm và định nghĩa, sử dụng Tree-sitter, một công cụ tạo parser phổ biến và thư viện phân tích incremental với hỗ trợ cho nhiều ngôn ngữ lập trình.

Như được thể hiện trong Hình 4, chúng tôi duyệt toàn bộ cây để xác định các lời gọi hàm. Đối với mỗi trong số chín ngôn ngữ, chúng tôi xây dựng một extractor trích xuất mối quan hệ gọi hàm, từ đó chúng tôi xây dựng danh sách liền kề để biểu diễn gọn gàng các đồ thị gọi. Ban đầu, chúng tôi bao gồm tất cả các lời gọi hàm với các toán tử phân giải phạm vi để phân biệt các hàm khác nhau trong các module khác nhau, nhưng điều này dẫn đến các đồ thị gọi quá lớn, ảnh hưởng đến hiệu suất. Để giải quyết điều này, chúng tôi chọn loại bỏ các toán tử phân giải phạm vi và các lời gọi hàm trùng lặp. Cuối cùng, chúng tôi loại trừ các lời gọi hàm bên ngoài (ví dụ, thư viện) để duy trì sự tập trung vào cấu trúc code cốt lõi. Hình 5 cho thấy tổng quan về những sửa đổi này.

2) Tạo Tóm tắt Code: Chúng tôi đặt giả thuyết rằng việc bao gồm tóm tắt code sẽ nắm bắt ngữ cảnh tổng thể của các thay đổi code trong code diffs, cải thiện việc tạo bình luận review code. Ban đầu, chúng tôi cố gắng tóm tắt toàn bộ code, nhưng các giới hạn token ảnh hưởng đến hiệu suất. Sau đó chúng tôi tập trung vào việc tóm tắt chỉ hàm liên quan đến code diffs.

Sử dụng một AST, chúng tôi xác định hàm có liên quan cho mỗi code diff, xây dựng các extractor cho chín ngôn ngữ trích xuất đầu và cuối của hàm và nhận ra các định nghĩa hàm cụ thể của ngôn ngữ và xử lý các trường hợp edge như hàm lồng nhau và phương thức lớp. Nếu code diff không ở bên trong bất kỳ hàm nào, chúng tôi trích xuất code xung quanh code diff. Chúng tôi tokenize code được trích xuất bằng cách sử dụng tokenizer dựa trên RoBERTa của CodeT5, chia các hàm lớn hơn thành các chunk nhỏ hơn khi cần thiết. Các chunk được tokenize này sau đó được đưa vào mô hình CodeT5 [8], tạo ra các tóm tắt được thêm vào prompts của chúng tôi để tăng cường độ chính xác review. Hình 6 phác thảo các bước chính trong workflow tạo tóm tắt này.

3) Thiết lập Thí nghiệm: Ở đây chúng tôi thảo luận các siêu tham số mô hình mà chúng tôi đã thử nghiệm. Chúng tôi sử dụng OpenAI và Google cung cấp APIs để gọi các mô hình thí nghiệm. Chúng tôi khám phá các nhiệt độ mô hình khác nhau (temp = 0.5, 0.7) và số lượng mẫu few-shot (k = 3, 5) để tạo bình luận review. Cuối cùng chúng tôi báo cáo kết quả cho temp = 0.7, và số lượng few-shot k = 5 vì chúng cho thấy kết quả tốt hơn tương đối. Chúng tôi cũng chọn top n = 5 đầu ra bởi các mô hình, tính điểm BLEU của chúng và chỉ giữ kết quả hoạt động tốt nhất để so sánh thêm. Sau đó chúng tôi tuân theo cùng một bộ siêu tham số (ngoại trừ việc đặt số lượng few-shot k = 3) để prompt mô hình Google Gemini-1.0 Pro cũng vậy. Số lượng token tối đa được tạo bởi mô hình được đặt thành 100. Chúng tôi để lại phần còn lại của các tham số API có sẵn (frequency và present penalty, top p) theo giá trị mặc định của chúng. Cấu trúc của tất cả các prompts được hiển thị trong Hình 3.

4) Nghiên cứu Ablation: Để hiểu những đóng góp riêng lẻ của đồ thị gọi hàm và tóm tắt code, chúng tôi tạo ra tất cả các kết hợp của prompt bao gồm không có và cả hai augmentation, và augmenting chỉ với đồ thị gọi và chỉ tóm tắt. Chi tiết được thảo luận trong phần IV-C.

E. RQ4: Quan điểm của Các Developer Thực tế về Bình luận Review được Tạo bởi LLM
1) Thiết kế Web portal: Chúng tôi phát triển một web portal dành riêng để trình bày cho người tham gia các thành phần thiết yếu cho mỗi đánh giá: code snippet, tóm tắt code được tạo từ snippet, ground truth được cung cấp làm tham chiếu và code reviews được tạo bởi nhiều mô hình, với tên mô hình được ẩn danh để ngăn chặn bias. Các reviewer được yêu cầu xếp hạng các bình luận được tạo bởi mô hình dựa trên ba trong số các chỉ số định tính được tìm thấy trong tài liệu: điểm relevence, điểm information và điểm explanation clarity [9]. Để tránh bất kỳ hiểu lầm nào, các hướng dẫn được trình bày trên một trang riêng biệt, đảm bảo rằng người tham gia có thể xem xét kỹ lưỡng các hướng dẫn trước khi tiến hành đánh giá. Backend của portal được thực hiện bằng Node.js với framework Express, trong khi frontend được phát triển với React.js và TypeScript để cung cấp giao diện người dùng responsive và interactive. Dữ liệu người tham gia và phản hồi nghiên cứu được lưu trữ an toàn trong cơ sở dữ liệu PostgreSQL được host trên Render.

2) Người tham gia: Chúng tôi quảng bá web portal trong cộng đồng kỹ thuật phần mềm chuyên nghiệp xung quanh mạng lưới của các tác giả, vì nghiên cứu tập trung vào các nhiệm vụ review code. Người tham gia được tuyển dụng trên cơ sở rolling để đảm bảo một mẫu đa dạng để nắm bắt một phổ rộng các kỹ năng lập trình và kiến thức domain. Mỗi người tham gia được bồi thường cho thời gian và phản hồi của họ. Chúng tôi tuyển dụ 8 người tham gia, mỗi người liên kết với các công ty ngành công nghiệp phần mềm có uy tín trong nước. Mỗi ví dụ review code được đánh giá hai lần, với phản hồi từ hai người tham gia riêng biệt, để tăng cường độ tin cậy và tính mạnh mẽ của phân tích của chúng tôi.

F. Chỉ số Đánh giá
Chúng tôi cung cấp một mô tả ngắn gọn về các chỉ số đánh giá được sử dụng cho nhiệm vụ tạo bình luận review trong phần này.

• BLEU [39] (Bilingual Evaluation Understudy) là một trong những chỉ số được thừa nhận rộng rãi để đo hiệu suất tạo văn bản của các mô hình ngôn ngữ. BLEU-4 là trung bình hình học có trọng số của tất cả các precision 4-gram được sửa đổi, được scaled bởi brevity penalty. Precision n-gram được sửa đổi được sử dụng ở đây điều chỉnh cho các trường hợp nơi văn bản ứng viên được tạo có thể có n-grams không khớp hoàn hảo với bất kỳ n-grams nào trong các văn bản tham chiếu.

• BERTScore [40] tận dụng contextual embeddings được huấn luyện trước từ mô hình BERT [41] và tìm ra điểm F1 trung bình, là trung bình hài hòa của precision và recall, cung cấp một chỉ số duy nhất để đánh giá chất lượng của các câu được tạo so với ground truth. Nó đã được chứng minh là tương quan với judgement của con người tốt hơn về mặt tương tự cấp câu thay vì matching cấp từ. BERTScore cao hơn chỉ ra sự tương tự tốt hơn giữa các câu được dự đoán và các câu tham chiếu.

• Chỉ số Đánh giá Con người bao gồm các điểm sau:
  – Điểm Relevance đo lường mức độ bình luận review phù hợp với nội dung tổng thể.
  – Điểm Information đánh giá tính đầy đủ của thông tin được cung cấp trong bình luận review.
  – Điểm Explanation clarity đánh giá độ rõ ràng của các giải thích được đưa ra trong bình luận review.

Tất cả các chỉ số judgement định tính của con người này được đánh giá trên thang điểm từ 0 đến 5, với 5 chỉ ra điểm tốt nhất.

IV. KẾT QUẢ
Trong phần này, chúng tôi trả lời từng câu hỏi nghiên cứu lấy bằng chứng từ kết quả thí nghiệm của chúng tôi.

A. RQ1: Tạo bình luận review code sử dụng Mô hình Ngôn ngữ Lớn mã nguồn mở được fine-tune hiệu quả như thế nào?

Chúng tôi trình bày hiệu suất của các mô hình mã nguồn mở được fine-tune QLoRA của chúng tôi trên Test Subset 1 trong Bảng II. Kết quả thể hiện một cải thiện đáng chú ý trong cả chỉ số BLEU-4 và BERTScore cho tất cả các mô hình được fine-tune so với mô hình baseline CodeReviewer. Code Llama (7B) đạt được điểm BLEU-4 cao nhất là 5.58, phản ánh mức tăng 30.37% so với mô hình CodeReviewer được huấn luyện trước. Về mặt BERTScore, Llama 3.1 (8B) đạt điểm cao nhất là 0.8483, đại diện cho cải thiện 1.62%.

Phát hiện RQ1: Các mô hình fine-tuned có giám sát (QLoRA) cho thấy hiệu suất đáng chú ý trong nhiệm vụ tạo bình luận review. Tất cả các LLM mã nguồn mở được kiểm tra với phương pháp này (Llama 2, Code Llama và các biến thể Llama 3) đều vượt trội hơn baseline. Đặc biệt Code Llama, được thiết kế để xử lý code, thể hiện một cải thiện đặc biệt đáng kể.

B. RQ2: Các Mô hình Ngôn ngữ Lớn mã nguồn đóng hoạt động tốt như thế nào trong nhiệm vụ tạo bình luận review code khi được prompt engineering trong setting few-shot?

Tiếp theo, chúng tôi sử dụng few-shot prompting để tạo bình luận review sử dụng các LLM mã nguồn đóng hàng đầu. Do chi phí API phát sinh của các mô hình mã nguồn đóng, chúng tôi tiến hành thí nghiệm ban đầu trên Test Subset 2 nhỏ hơn. Chúng tôi báo cáo kết quả hứa hẹn của 5-shot prompting trong Bảng III. Như nó chỉ ra, các mô hình thí nghiệm của chúng tôi vượt trội hơn baseline ngay cả khi không có bất kỳ data augmentation thêm nào.

GPT-3.5 Turbo đạt được cải thiện hiệu suất ấn tượng 89.95% với điểm BLEU-4 là 8.13 vượt qua các mô hình thí nghiệm khác. Gemini-1.0 Pro hoạt động tốt thứ hai, với điểm BLEU-4 là 7.85 (và tăng 83.41% so với baseline). Mô hình GPT-4o hoạt động tương đối kém, đạt điểm 6.92 BLEU-4 (với cải thiện 61.68% so với baseline). Trên chỉ số BERTScore, GPT-3.5 Turbo và Gemini-1.0 Pro đạt được 0.8509, cả hai đều đạt được nâng cấp hiệu suất 1.93%.

Phát hiện RQ2: Các LLM mã nguồn đóng được chứng minh là rất hiệu quả, vì chúng đã cải thiện so với baseline, khai thác hiệu quả của few-shot prompting cho nhiệm vụ tạo bình luận review. Trong số các mô hình được kiểm tra, GPT-3.5 Turbo đạt được mức tăng hiệu suất đáng kể nhất. Gemini-1.0 Pro và GPT-4o cũng cho thấy kết quả ấn tượng.

C. RQ3: Khi được kết hợp vào prompts, tác động của đồ thị gọi hàm và tóm tắt code trong việc cải thiện hiệu suất tạo bình luận review là gì?

Trong phần này, Chúng tôi báo cáo tác động của việc thêm cả đồ thị gọi hàm và tóm tắt code vào prompts trong Bảng IV. Chúng tôi sử dụng Test Subset 2 nhỏ hơn của bộ dữ liệu để đánh giá các LLM mã nguồn đóng thí nghiệm của chúng tôi với sửa đổi được đề xuất này. Về cả hai chỉ số, augmentation đồ thị gọi và tóm tắt đã thất bại trong việc hướng dẫn các mô hình GPT-3.5 Turbo và Gemini-1.0 Pro theo đúng hướng, nơi các mô hình này có cửa sổ ngữ cảnh lần lượt là 4k và 32k token. Kiểm tra thủ công tiết lộ rằng GPT-3.5 Turbo chủ yếu bị ảnh hưởng do số lượng lớn token đầu vào trong prompt sau augmentation được đề xuất. Mặt khác, GPT-4o với cửa sổ ngữ cảnh 128k token hoạt động tốt hơn đáng kể khi được bổ sung với cùng metadata, vì nó có thể xử lý ngữ cảnh đầu vào lớn hơn nhiều. GPT-4o cải thiện 6.79% điểm BLEU-4 và 0.27% BERTScore tương đối so với phiên bản trước augmentation. Tuy nhiên, ngay cả với cải thiện tương đối như vậy, GPT-4o vẫn thua kém hiệu suất GPT-3.5 Turbo.

Trái với giả thuyết của chúng tôi, việc kết hợp cả đồ thị gọi hàm và tóm tắt code cùng nhau đã ảnh hưởng tiêu cực đến hiệu suất của một vài mô hình. Vì vậy chúng tôi thử nghiệm với tất cả các kết hợp có thể của augmentation này để xác định thông tin bổ sung nào đang gây ra sự suy giảm hiệu suất. Để giữ chi phí API trong giới hạn, chúng tôi sử dụng Test Subset 1 lớn hơn để tiến hành nghiên cứu ablation này trên mô hình hoạt động tốt nhất GPT-3.5 Turbo của chúng tôi. Bằng chứng từ Bảng V cho thấy việc thêm đồ thị gọi hàm độc lập là có lợi trong khi việc thêm tóm tắt code với prompts có tác động tiêu cực đến hiệu suất. Chỉ với đồ thị gọi hàm được thêm vào, GPT-3.5 Turbo đạt được điểm BLEU-4 cao nhất là 8.36 tức là hơn 90% hiệu suất baseline. Hình 7 trình bày một mẫu test với nhiều bình luận review được tạo bởi LLM.

Phát hiện RQ3: Mặc dù là performer kém hơn, GPT-4o với cửa sổ ngữ cảnh dài hơn cho thấy cải thiện hiệu suất tương đối khi cả đồ thị gọi và tóm tắt được thêm vào cùng lúc. Các thí nghiệm ablation thêm cho thấy rằng, trong khi đồ thị gọi hàm hướng dẫn mô hình tạo ra review code tốt hơn, tóm tắt code chủ yếu ảnh hưởng đến kết quả một cách tiêu cực. Do đó, khi cả hai được kết hợp, các mô hình đã hoạt động tốt như GPT-3.5 Turbo thể hiện sự suy giảm hiệu suất nhẹ.

D. RQ4: Các Mô hình Ngôn ngữ Lớn hiệu quả như thế nào trong việc tạo bình luận review từ góc độ của developer thực tế?

Phân tích thêm về các điểm chỉ số định tính được thu thập từ nghiên cứu developer hỗ trợ các phát hiện trước đây của chúng tôi rằng các mô hình thí nghiệm đã vượt trội đáng kể so với baseline. Hình 8 minh họa điểm của các mô hình hàng đầu trên các chỉ số relevance, informativeness và explanation clarity. Điểm chính xác được báo cáo trong Bảng VI. Trong số series GPT, GPT-3.5 Turbo với Callgraph đạt được hiệu suất đáng chú ý, vượt qua hai biến thể GPT-3.5 khác. Thú vị thay, Code Llama thể hiện kết quả định tính mạnh nhất, có thể do pretraining của nó, tập trung vào các nhiệm vụ liên quan đến code được thiết kế tỉ mỉ.

Phát hiện RQ4: Theo kinh nghiệm được báo cáo của 8 practitioner phần mềm, các bình luận review được tạo bởi LLM cho thấy hiệu suất đáng chú ý so với baseline Codereviewer. Code Llama được fine-tune đã vượt trội hơn tất cả các mô hình khác trong cả ba chỉ số định tính được theo sát chặt bởi GPT-3.5 Turbo được bổ sung với callgraph.

V. THẢO LUẬN
1) Quan sát: Mặc dù tất cả các mô hình được huấn luyện của chúng tôi đều vượt qua baseline pretrained CodeReviewer (thể hiện sự tự tin cao trong các câu trả lời không chính xác), mỗi mô hình đều có những hạn chế cụ thể. Mặc dù GPT-3.5-turbo hiệu quả về chi phí, chúng có thể bị phân tán do kích thước cửa sổ ngữ cảnh hạn chế. Ngược lại, GPT-4o cho thấy hiệu suất được cải thiện với cửa sổ ngữ cảnh dài hơn, cho phép tập trung nhiều hơn vào đồ thị gọi và tóm tắt code để tạo code reviews. Tuy nhiên, do hạn chế ngân sách, chúng tôi không thể khám phá đầy đủ hiệu suất của GPT-4o trên toàn bộ bộ dữ liệu. Mặt khác, Code Llama được fine-tune có xu hướng tổng quát hóa kém, thường thất bại trong việc giải quyết các thay đổi cụ thể chi tiết hơn.

2) Hướng tương lai: Chúng tôi đang kết hợp các code reviews được tạo bởi mô hình của chúng tôi vào các nhiệm vụ sửa chữa code, thử nghiệm với các chiến lược prompt và fine-tuning khác nhau để cải thiện khả năng của mô hình trong việc đề xuất các bản sửa lỗi code hiệu quả sau review.

VI. CÁC MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ
Các mối đe dọa đối với tính hợp lệ nội bộ liên quan đến cách các vai trò được thực hiện bởi kiến trúc mô hình và cấu hình của các siêu tham số có thể tác động đến các thí nghiệm. Do hạn chế về chi phí và tài nguyên, chúng tôi khám phá các siêu tham số ưu tiên tác động dự kiến của chúng đến hiệu suất mô hình, trong khi để lại những cái khác ít được khám phá hơn. Kết quả là, có thể việc điều chỉnh thêm có thể mang lại cải thiện bổ sung.

Các mối đe dọa đối với tính hợp lệ cấu trúc bao gồm việc sử dụng chỉ số BLEU phổ biến rộng rãi của chúng tôi, vì nó đã được sử dụng trong nghiên cứu baseline gốc và tài liệu có liên quan. Tuy nhiên, khả năng phản ánh hiệu suất thực sự của nó vẫn không chắc chắn. Kết quả đánh giá con người chỉ ra rằng Code Llama vượt trội hơn GPT-3.5 Turbo, với cả hai mô hình đều vượt qua baseline. Điều này đặt ra câu hỏi về độ tin cậy tổng thể của BLEU như một thước đo hiệu suất, cho thấy rằng điều này có thể là một mối đe dọa đối với tính hợp lệ cấu trúc.

Các mối đe dọa đối với tính hợp lệ kết luận làm nổi bật thực tế là các phản hồi hoàn toàn giống nhau có thể không được tạo ra bởi LLMs, do bản chất nondeterministic vốn có của chúng [42]. Ngoài ra, bằng cách đặt tham số nhiệt độ thành 0.7, chúng tôi khuyến khích nhiều biến đổi hơn trong đầu ra của mô hình. Sự nondeterminism này trong LLM có thể làm suy yếu tính hợp lệ kết luận được rút ra từ phản hồi của chúng.

Các mối đe dọa đối với tính hợp lệ bên ngoài chủ yếu liên quan đến bộ dữ liệu được sử dụng trong nghiên cứu này. Tất cả các thí nghiệm đều được tiến hành bằng cách sử dụng bộ dữ liệu CodeReviewer [9] của Microsoft Research. Vì bộ dữ liệu được lấy từ các repository mã nguồn mở có sẵn công khai thay vì các dự án công nghiệp, khả năng tổng quát hóa các phát hiện của chúng tôi cho các ứng dụng công nghiệp có thể bị hạn chế.

VII. CÁC CÔNG TRÌNH LIÊN QUAN
A. Tự động hóa Các Hoạt động Review Code
Đã có sự quan tâm đáng kể trong việc giảm lao động thủ công liên quan đến các hoạt động review code. Các nhà nghiên cứu đã làm việc về đánh giá chất lượng code [9], [43]–[46], đề xuất reviewer có thể [47]–[52], đề xuất bình luận review [9], [10], [53] và cải tiến các code snippet có vấn đề [9], [10], [54]–[56]. Nghiên cứu của chúng tôi tập trung vào pipeline được đề xuất bởi Li et al. [9]. Các phương pháp dựa trên retrieval ban đầu được áp dụng cho các nhiệm vụ đề xuất bình luận review. DeepMem [57], một mô hình dựa trên LSTM được giới thiệu đầu tiên để đạt được điều này. Cơ chế attention được thêm vào đỉnh kiến trúc LSTM sau đó bởi Siow et al. [58]. Tufano et al. [10] trình bày đóng góp đầu tiên của việc tận dụng deep learning cho nhiệm vụ này thông qua pretraining trên code và ngôn ngữ kỹ thuật ở quy mô lớn. Để cải thiện kết quả, CodeReviewer [9] và AUGER [59] đề xuất các mô hình pretrained cụ thể cho code review. CommentFinder [60] cũng cho thấy một giải pháp thay thế định hướng retrieval hiệu quả.

Tuy nhiên, các phương pháp cho đến nay đã không xem xét code diffs trong pipeline của chúng. D-ACT [61] là phương pháp đầu tiên giới thiệu diff-awareness trong cải tiến code để tăng hiệu suất trong sự khác biệt nhỏ giữa code base và các commit ban đầu, mặc dù họ không tận dụng các bình luận review code để đạt được điều này. CodeReviewer [9], được pretrained trên 9 ngôn ngữ lập trình phổ biến, được điều chỉnh cho các hoạt động review code và xem xét cả diff-awareness và bình luận review cùng nhau. Tiến bộ đáng kể trong các hoạt động review code đã có thể thêm cho việc sử dụng Mô hình Ngôn ngữ Lớn thống nhất, khi kích thước mô hình và dữ liệu huấn luyện tiếp tục tăng trong thời gian gần đây. Llama-Reviewer [14] được giới thiệu để fine-tune mô hình Llama mã nguồn mở được điều chỉnh cho các nhiệm vụ review code có thể đạt được cải thiện hiệu suất ấn tượng sử dụng các phương pháp fine-tuning tiết kiệm tham số. Nó sử dụng phương pháp LoRA [25] để fine-tuning, trong khi có chỗ để cải thiện sử dụng counterpart quantized [26]. Ngoài ra, các mô hình gần đây hơn và tốt hơn trong series Meta Llama đã được phát hành kể từ đó, bao gồm mô hình đa mục đích Llama 2 [31] và Code Llama [17], một mô hình được fine-tune cụ thể trên các bộ dữ liệu cụ thể về code. Cuối cùng, Llama 3 cũng được phát hành cho cộng đồng mã nguồn mở.

B. Mô hình Ngôn ngữ Pretrained và Fine-Tuned trong Kỹ thuật Phần mềm
Các kỹ thuật deep learning, được thúc đẩy bởi tác động và thành công của chúng trong các domain Xử lý Ngôn ngữ Tự nhiên, cũng đã được áp dụng rộng rãi trong các nhiệm vụ kỹ thuật phần mềm. Các mô hình chỉ encoder như BERT [41], các mô hình encoder-decoder như BART [62] và T5 [18], và các mô hình chỉ decoder như GPT [12] là một số tiến bộ đáng chú ý ở đây. Các mô hình code pretrained có thể học các biểu diễn code với các thuộc tính cụ thể về code khác nhau bao gồm thông tin lexical, semantic và syntactic. Fine-tuning có thể giúp các mô hình này phù hợp cho các nhiệm vụ cụ thể bằng cách cập nhật trọng số mô hình pretrained với dữ liệu cụ thể của nhiệm vụ. Được truyền cảm hứng từ các mô hình trên, các nhà nghiên cứu đề xuất fine-tune thêm các mô hình này trên một số nhiệm vụ downstream trong kỹ thuật phần mềm. CodeBERT [6] và GraphCodeBERT [7] là các mô hình transformer hai chiều được pretrained cụ thể trên các cặp NL-PL trong 6 ngôn ngữ lập trình, với mô hình sau giới thiệu việc kết hợp các đồ thị luồng dữ liệu source code bên trong cấp độ token mô hình. Các mô hình này cho thấy hiệu suất vượt trội trong các nhiệm vụ bao gồm tìm kiếm code ngôn ngữ tự nhiên, tóm tắt code, phát hiện clone code và tạo tài liệu từ code.

Mặt khác, các mô hình transformer chỉ decoder như CodeGPT [63], Codex [64] tập trung vào các nhiệm vụ generative như hoàn thành code và tạo code. Các mô hình như PLBART [65] và CodeT5 [8] có thể được áp dụng cho cả nhiệm vụ hiểu và tạo code. Mặc dù bao gồm một loạt rộng các nhiệm vụ liên quan đến code, các mô hình trên đã không chú ý đến các hoạt động review code khi được đề xuất. Tufano et al. [10] đầu tiên đề xuất TufanoT5 sử dụng mô hình T5 pretrained để tự động hóa các nhiệm vụ review code, với CodeReviewer [9] cải thiện điều đó bằng cách giới thiệu việc tích hợp các thay đổi code vào giai đoạn pretraining. Gần đây, đã có nhiều mô hình ngôn ngữ lớn cho code, bao gồm các LLM được phát triển bởi cộng đồng mã nguồn mở như Code Llama [17], StarCoder [66], MagiCoder [67] cùng với các mô hình sở hữu như GPT-3.5 và GPT-4 [32].

C. Prompting trong Kỹ thuật Phần mềm
Prompt engineering là một giải pháp thay thế đủ tốt cho fine-tuning nặng đòi hỏi các bộ dữ liệu có giám sát và tài nguyên tính toán. Việc cung cấp prompts cho các LLM pretrained được phát hiện là có lợi trong nhiều nhiệm vụ liên quan đến code như được thể hiện trong [20], [34], [35], [68] bao gồm tóm tắt code, sửa bug và tạo tài liệu. Các chiến lược prompting khác nhau bao gồm zero-shot learning, few-shot learning [12], [33], chain-of-thought [22], persona [21], v.v. Không phải tất cả các chiến lược prompting đều phù hợp cho các hoạt động liên quan đến review vì một số trong số này được thiết kế cụ thể cho các nhiệm vụ reasoning toán học và logic. Zero-shot, few-shot và prompting cá nhân dựa trên hướng dẫn và do đó phù hợp nhất cho các nhiệm vụ review code. Guo et al. [69] tiến hành một nghiên cứu thực nghiệm để điều tra tiềm năng của mô hình GPT-3.5 cho tự động hóa review code, trong khi few-shot prompting trên LLMs vẫn còn rất thú vị để khám phá. Ahmed et al. điều tra hiệu suất prompting trên LLMs cho các nhiệm vụ tóm tắt code [70], thường với việc bổ sung metadata ngữ nghĩa trong prompts cho các mô hình GPT [71]. Chúng tôi điều tra việc bổ sung thông tin ngữ nghĩa như vậy theo cách ngắn gọn vào prompts LLM được truyền cảm hứng từ công việc của họ.

VIII. KẾT LUẬN
Trong nghiên cứu này, chúng tôi nhằm mục đích tự động hóa việc tạo bình luận review code, sử dụng Mô hình Ngôn ngữ Lớn (LLMs) thông qua các prompts được thiết kế cẩn thận với few-shot learning và fine-tuning tiết kiệm tham số. Phương pháp prompting của chúng tôi sử dụng bộ dữ liệu CodeReviewer baseline cho nhiệm vụ của chúng tôi, kết hợp các tóm tắt code và đồ thị gọi hàm được bổ sung sau tiền xử lý kỹ lưỡng. Ngoài ra, chúng tôi áp dụng kỹ thuật QLoRA để fine-tune các Mô hình Ngôn ngữ Lớn mã nguồn mở. Kết quả thí nghiệm chứng minh rằng các chiến lược của chúng tôi vượt trội đáng kể so với baseline CodeReviewer trong việc tạo bình luận review. Hơn nữa, một thí nghiệm đánh giá con người được tiến hành trên các developer chuyên nghiệp thông qua nghiên cứu được thiết kế của chúng tôi chỉ ra rằng cả LLM cụ thể về code được finetuned và LLM đa mục đích kết hợp đồ thị gọi vào prompts few-shot đều cải thiện chất lượng của các bình luận review được tạo, từ đó xác thực thêm hiệu quả của phương pháp của chúng tôi.

TÀI LIỆU THAM KHẢO
[1] D. Spadini, G. Çalikli, và A. Bacchelli, "Primers or reminders? the effects of existing review comments on code review," trong Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, 2020, tr. 1171–1182.
[2] M. Fagan, "Design and code inspections to reduce errors in program development," trong Software pioneers: contributions to software engineering. Springer, 2011, tr. 575–607.
[3] A. Bosu và J. C. Carver, "Impact of peer code review on peer impression formation: A survey," trong 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement, 2013, tr. 133–142.
[4] X. Yang, R. G. Kula, N. Yoshida, và H. Iida, "Mining the modern code review repositories: A dataset of people, process and product," trong Proceedings of the 13th international conference on mining software repositories, 2016, tr. 460–463.
[5] J. Czerwonka, M. Greiler, và J. Tilford, "Code reviews do not find bugs. how the current code review best practice slows us down," trong 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, vol. 2. IEEE, 2015, tr. 27–28.
[6] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., "Codebert: A pre-trained model for programming and natural languages," arXiv preprint arXiv:2002.08155, 2020.
[7] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu, L. Zhou, N. Duan, A. Svyatkovskiy, S. Fu et al., "Graphcodebert: Pre-training code representations with data flow," arXiv preprint arXiv:2009.08366, 2020.
[8] Y. Wang, W. Wang, S. Joty, và S. C. Hoi, "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation," arXiv preprint arXiv:2109.00859, 2021.
[9] Z. Li, S. Lu, D. Guo, N. Duan, S. Jannu, G. Jenks, D. Majumder, J. Green, A. Svyatkovskiy, S. Fu et al., "Automating code review activities by large-scale pre-training," trong Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2022, tr. 1035–1047.
[10] R. Tufano, S. Masiero, A. Mastropaolo, L. Pascarella, D. Poshyvanyk, và G. Bavota, "Using pre-trained models to boost code review automation," trong Proceedings of the 44th international conference on software engineering, 2022, tr. 2291–2302.
[11] E. Strubell, A. Ganesh, và A. McCallum, "Energy and policy considerations for modern deep learning research," trong Proceedings of the AAAI conference on artificial intelligence, vol. 34, no. 09, 2020, tr. 13 693–13 696.
[12] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, tr. 1877–1901, 2020.
[13] Z. Zheng, K. Ning, Y. Wang, J. Zhang, D. Zheng, M. Ye, và J. Chen, "A survey of large language models for code: Evolution, benchmarking, and future trends," arXiv preprint arXiv:2311.10372, 2023.
[14] J. Lu, L. Yu, X. Li, L. Yang, và C. Zuo, "Llama-reviewer: Advancing code review automation with large language models through parameter-efficient fine-tuning," trong 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE). IEEE, 2023, tr. 647–658.
[15] T. Ahmed, K. S. Pai, P. Devanbu, và E. Barr, "Automatic semantic augmentation of language model prompts (for code summarization)," trong Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, 2024, tr. 1–13.
[16] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth et al., "Gemini: a family of highly capable multimodal models," arXiv preprint arXiv:2312.11805, 2023.
[17] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin et al., "Code llama: Open foundation models for code," arXiv preprint arXiv:2308.12950, 2023.
[18] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, và P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," Oct. 2019.
[19] C. Pornprasit và C. Tantithamthavorn, "Gpt-3.5 for code review automation: How do few-shot learning, prompt design, and model fine-tuning impact their performance?" arXiv preprint arXiv:2402.00905, 2024.
[20] S. Feng và C. Chen, "Prompting is all you need: Automated android bug replay with large language models," trong Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. New York, NY, USA: ACM, Feb. 2024.
[21] J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. Elnashar, J. Spencer-Smith, và D. C. Schmidt, "A prompt pattern catalog to enhance prompt engineering with ChatGPT," Feb. 2023.
[22] S. Kim, S. J. Joo, D. Kim, J. Jang, S. Ye, J. Shin, và M. Seo, "The CoT collection: Improving zero-shot and few-shot learning of language models via chain-of-thought fine-tuning," May 2023.
[23] X. L. Li và P. Liang, "Prefix-tuning: Optimizing continuous prompts for generation," arXiv preprint arXiv:2101.00190, 2021.
[24] B. Lester, R. Al-Rfou, và N. Constant, "The power of scale for parameter-efficient prompt tuning," arXiv preprint arXiv:2104.08691, 2021.
[25] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, và W. Chen, "Lora: Low-rank adaptation of large language models," arXiv preprint arXiv:2106.09685, 2021.
[26] T. Dettmers, A. Pagnoni, A. Holtzman, và L. Zettlemoyer, "Qlora: Efficient finetuning of quantized llms," Advances in Neural Information Processing Systems, vol. 36, 2024.
[27] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, và Q. V. Le, "Finetuned language models are zero-shot learners," arXiv preprint arXiv:2109.01652, 2021.
[28] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray et al., "Training language models to follow instructions with human feedback," Advances in neural information processing systems, vol. 35, tr. 27 730–27 744, 2022.
[29] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, và T. B. Hashimoto, "Stanford alpaca: An instruction-following llama model," https://github.com/tatsu-lab/stanford alpaca, 2023.
[30] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, và H. Hajishirzi, "Self-instruct: Aligning language models with self-generated instructions," arXiv preprint arXiv:2212.10560, 2022.
[31] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale et al., "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.
[32] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., "Gpt-4 technical report," arXiv preprint arXiv:2303.08774, 2023.
[33] J. Liu, D. Shen, Y. Zhang, B. Dolan, L. Carin, và W. Chen, "What makes good in-context examples for GPT-3?" Jan. 2021.
[34] M. Geng, S. Wang, D. Dong, H. Wang, G. Li, Z. Jin, X. Mao, và X. Liao, "Large language models are few-shot summarizers: Multi-intent comment generation via in-context learning," trong Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. New York, NY, USA: ACM, Feb. 2024.
[35] S. Gao, X.-C. Wen, C. Gao, W. Wang, H. Zhang, và M. R. Lyu, "What makes good in-context demonstrations for code intelligence tasks with LLMs?" trong 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, Sep. 2023.
[36] S. M. Bsharat, A. Myrzakhan, và Z. Shen, "Principled instructions are all you need for questioning llama-1/2, gpt-3.5/4," arXiv preprint arXiv:2312.16171, 2023.
[37] C. Li, J. Wang, Y. Zhang, K. Zhu, W. Hou, J. Lian, F. Luo, Q. Yang, và X. Xie, "Large language models understand and can be enhanced by emotional stimuli," arXiv preprint arXiv:2307.11760, 2023.
[38] S. Robertson, H. Zaragoza et al., "The probabilistic relevance framework: bm25 and beyond," Foundations and Trends® in Information Retrieval, vol. 3, no. 4, tr. 333–389, 2009.
[39] K. Papineni, S. Roukos, T. Ward, và W.-J. Zhu, "Bleu: a method for automatic evaluation of machine translation," trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics, 2002, tr. 311–318.
[40] T. Zhang*, V. Kishore*, F. Wu*, K. Q. Weinberger, và Y. Artzi, "Bertscore: Evaluating text generation with bert," trong International Conference on Learning Representations, 2020. [Trực tuyến]. Có sẵn: https://openreview.net/forum?id=SkeHuCVFDr
[41] J. Devlin, M.-W. Chang, K. Lee, và K. Toutanova, "BERT: Pre-training of deep bidirectional transformers for language understanding," Oct. 2018.
[42] S. Ouyang, J. M. Zhang, M. Harman, và M. Wang, "Llm is like a box of chocolates: the non-determinism of chatgpt in code generation," arXiv preprint arXiv:2308.02828, 2023.