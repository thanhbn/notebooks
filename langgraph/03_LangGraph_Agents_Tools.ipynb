{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Tutorial ‚Äì Part 3Ô∏è‚É£: Agents v√† Tools\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:** T√°c nh√¢n bi·∫øt s·ª≠ d·ª•ng c√¥ng c·ª•\n",
    "\n",
    "Trong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu:\n",
    "- C√°ch t√≠ch h·ª£p Agents v·ªõi Tools trong LangGraph\n",
    "- X√¢y d·ª±ng agent c√≥ kh·∫£ nƒÉng t√¨m ki·∫øm web\n",
    "- S·ª≠ d·ª•ng Conditional Edges ƒë·ªÉ agent quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông\n",
    "- Ph√¢n t√≠ch quy tr√¨nh l·ª±a ch·ªçn c√¥ng c·ª•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Gi·ªõi thi·ªáu: Agents, Tools trong LangGraph\n",
    "\n",
    "**Agent** l√† m·ªôt th·ª±c th·ªÉ AI c√≥ kh·∫£ nƒÉng:\n",
    "- Nh·∫≠n th√¥ng tin t·ª´ m√¥i tr∆∞·ªùng\n",
    "- Quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông d·ª±a tr√™n th√¥ng tin ƒë√≥\n",
    "- S·ª≠ d·ª•ng c√°c c√¥ng c·ª• (Tools) ƒë·ªÉ th·ª±c hi·ªán h√†nh ƒë·ªông\n",
    "- H·ªçc h·ªèi t·ª´ k·∫øt qu·∫£ ƒë·ªÉ c·∫£i thi·ªán quy·∫øt ƒë·ªãnh\n",
    "\n",
    "**Tools** l√† c√°c ch·ª©c nƒÉng m√† Agent c√≥ th·ªÉ s·ª≠ d·ª•ng:\n",
    "- T√¨m ki·∫øm web\n",
    "- T√≠nh to√°n\n",
    "- Truy c·∫≠p database\n",
    "- API calls\n",
    "- File operations\n",
    "\n",
    "![Agent-Tool Architecture](https://python.langgraph.org/img/agent_executor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ C√†i ƒë·∫∑t & C·∫•u h√¨nh\n",
    "\n",
    "ƒê·∫ßu ti√™n, ch√∫ng ta c·∫ßn c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "!pip install langgraph langchain-openai langchain-anthropic duckduckgo-search python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Kh·ªüi t·∫°o LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è ƒê·ªãnh nghƒ©a Tools\n",
    "\n",
    "T·∫°o c√¥ng c·ª• t√¨m ki·∫øm web s·ª≠ d·ª•ng DuckDuckGo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"T√¨m ki·∫øm th√¥ng tin tr√™n web b·∫±ng DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query: T·ª´ kh√≥a t√¨m ki·∫øm\n",
    "        \n",
    "    Returns:\n",
    "        K·∫øt qu·∫£ t√¨m ki·∫øm d∆∞·ªõi d·∫°ng text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(query, max_results=3))\n",
    "            \n",
    "        if not results:\n",
    "            return f\"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho: {query}\"\n",
    "        \n",
    "        # Format k·∫øt qu·∫£\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"{i}. **{result['title']}**\\n\"\n",
    "                f\"   {result['body']}\\n\"\n",
    "                f\"   üîó {result['href']}\\n\"\n",
    "            )\n",
    "            \n",
    "        return f\"üîç K·∫øt qu·∫£ t√¨m ki·∫øm cho '{query}':\\n\\n\" + \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"L·ªói khi t√¨m ki·∫øm: {str(e)}\"\n",
    "\n",
    "@tool \n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"T√≠nh to√°n bi·ªÉu th·ª©c to√°n h·ªçc ƒë∆°n gi·∫£n.\n",
    "    \n",
    "    Args:\n",
    "        expression: Bi·ªÉu th·ª©c to√°n h·ªçc (v√≠ d·ª•: \"2 + 3 * 4\")\n",
    "        \n",
    "    Returns:\n",
    "        K·∫øt qu·∫£ t√≠nh to√°n\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ch·ªâ cho ph√©p c√°c k√Ω t·ª± an to√†n\n",
    "        allowed_chars = set('0123456789+-*/.()')\n",
    "        if not all(c in allowed_chars or c.isspace() for c in expression):\n",
    "            return \"L·ªói: Bi·ªÉu th·ª©c ch·ª©a k√Ω t·ª± kh√¥ng h·ª£p l·ªá\"\n",
    "            \n",
    "        result = eval(expression)\n",
    "        return f\"üßÆ {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"L·ªói t√≠nh to√°n: {str(e)}\"\n",
    "\n",
    "# Danh s√°ch tools\n",
    "tools = [web_search, calculator]\n",
    "\n",
    "# Bind tools v·ªõi LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a c√°c tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"   - {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä State Definition\n",
    "\n",
    "ƒê·ªãnh nghƒ©a State ƒë·ªÉ qu·∫£n l√Ω tr·∫°ng th√°i c·ªßa Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State ch·ª©a messages v√† metadata c·ªßa Agent.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "def print_state(state: AgentState) -> None:\n",
    "    \"\"\"Utility function ƒë·ªÉ hi·ªÉn th·ªã state.\"\"\"\n",
    "    print(\"\\nüìã Current State:\")\n",
    "    for i, msg in enumerate(state[\"messages\"]):\n",
    "        print(f\"   {i+1}. {type(msg).__name__}: {msg.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Agent Nodes\n",
    "\n",
    "T·∫°o c√°c node cho Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node ch√≠nh c·ªßa Agent - quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông ti·∫øp theo.\"\"\"\n",
    "    print(\"ü§ñ Agent ƒëang suy nghƒ©...\")\n",
    "    \n",
    "    # L·∫•y response t·ª´ LLM\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    \n",
    "    # Log agent's decision\n",
    "    if response.tool_calls:\n",
    "        tool_names = [call[\"name\"] for call in response.tool_calls]\n",
    "        print(f\"üí° Agent quy·∫øt ƒë·ªãnh s·ª≠ d·ª•ng tools: {', '.join(tool_names)}\")\n",
    "    else:\n",
    "        print(\"üí¨ Agent tr·∫£ l·ªùi tr·ª±c ti·∫øp (kh√¥ng d√πng tool)\")\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Conditional edge - quy·∫øt ƒë·ªãnh c√≥ s·ª≠ d·ª•ng tools hay k·∫øt th√∫c.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if last_message.tool_calls:\n",
    "        print(\"üõ†Ô∏è Chuy·ªÉn ƒë·∫øn tool execution\")\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        print(\"üèÅ Ho√†n th√†nh - kh√¥ng c·∫ßn tools\")\n",
    "        return \"end\"\n",
    "\n",
    "# T·∫°o tool node\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üï∏Ô∏è X√¢y d·ª±ng StateGraph\n",
    "\n",
    "T·∫°o graph k·∫øt h·ª£p Agent v√† Tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o StateGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Th√™m nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Th√™m edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ x√¢y d·ª±ng Agent-Tool Graph!\")\n",
    "print(\"\\nüîÑ Workflow:\")\n",
    "print(\"   START ‚Üí agent ‚Üí [should_continue] ‚Üí tools/end\")\n",
    "print(\"              ‚Üë                         ‚Üì\")\n",
    "print(\"              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ V√≠ d·ª• th·ª±c h√†nh\n",
    "\n",
    "### V√≠ d·ª• 1: T√¨m ki·∫øm th√¥ng tin tr·ª±c tuy·∫øn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_example(query: str):\n",
    "    \"\"\"Ch·∫°y agent v·ªõi m·ªôt query c·ª• th·ªÉ.\"\"\"\n",
    "    print(f\"\\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)]\n",
    "    }\n",
    "    \n",
    "    # Ch·∫°y agent\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\nüìã K·∫øt qu·∫£ cu·ªëi c√πng:\")\n",
    "    print(result[\"messages\"][-1].content)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test v·ªõi t√¨m ki·∫øm web\n",
    "result1 = run_agent_example(\n",
    "    \"T√¨m ki·∫øm th√¥ng tin v·ªÅ LangGraph v√† cho t√¥i bi·∫øt n√≥ l√† g√¨?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√≠ d·ª• 2: T√≠nh to√°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v·ªõi calculator\n",
    "result2 = run_agent_example(\n",
    "    \"T√≠nh gi√∫p t√¥i (125 + 75) * 3 - 50\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√≠ d·ª• 3: K·∫øt h·ª£p nhi·ªÅu tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test k·∫øt h·ª£p nhi·ªÅu tools\n",
    "result3 = run_agent_example(\n",
    "    \"T√¨m ki·∫øm gi√° Bitcoin hi·ªán t·∫°i v√† t√≠nh xem n·∫øu t√¥i c√≥ 0.5 BTC th√¨ b·∫±ng bao nhi√™u USD?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√≠ d·ª• 4: C√¢u h·ªèi kh√¥ng c·∫ßn tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test c√¢u h·ªèi ƒë∆°n gi·∫£n kh√¥ng c·∫ßn tools\n",
    "result4 = run_agent_example(\n",
    "    \"Xin ch√†o! B·∫°n c√≥ th·ªÉ l√†m g√¨?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Ph√¢n t√≠ch quy tr√¨nh Agent\n",
    "\n",
    "H√£y ph√¢n t√≠ch c√°ch Agent ho·∫°t ƒë·ªông:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_agent_process(query: str, max_steps: int = 10):\n",
    "    \"\"\"Ph√¢n t√≠ch t·ª´ng b∆∞·ªõc c·ªßa Agent.\"\"\"\n",
    "    print(f\"\\nüî¨ Ph√¢n t√≠ch quy tr√¨nh cho: '{query}'\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)]\n",
    "    }\n",
    "    \n",
    "    step = 0\n",
    "    current_state = initial_state\n",
    "    \n",
    "    # Ch·∫°y t·ª´ng step\n",
    "    for event in app.stream(initial_state):\n",
    "        step += 1\n",
    "        if step > max_steps:\n",
    "            print(\"‚ö†Ô∏è ƒê√£ ƒë·∫°t gi·ªõi h·∫°n s·ªë b∆∞·ªõc!\")\n",
    "            break\n",
    "            \n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\nüìç B∆∞·ªõc {step}: Node '{node_name}'\")\n",
    "            \n",
    "            if node_name == \"agent\":\n",
    "                last_msg = node_output[\"messages\"][-1]\n",
    "                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                    print(f\"   ü§ñ Agent g·ªçi tools: {[tc['name'] for tc in last_msg.tool_calls]}\")\n",
    "                else:\n",
    "                    print(f\"   üí¨ Agent ph·∫£n h·ªìi: {last_msg.content[:100]}...\")\n",
    "                    \n",
    "            elif node_name == \"tools\":\n",
    "                tool_msgs = node_output[\"messages\"]\n",
    "                for msg in tool_msgs:\n",
    "                    if isinstance(msg, ToolMessage):\n",
    "                        print(f\"   üõ†Ô∏è Tool '{msg.name}' k·∫øt qu·∫£: {msg.content[:100]}...\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh sau {step} b∆∞·ªõc!\")\n",
    "\n",
    "# Ph√¢n t√≠ch m·ªôt v√≠ d·ª• ph·ª©c t·∫°p\n",
    "analyze_agent_process(\n",
    "    \"T√¨m th√¥ng tin v·ªÅ Python 3.12 v√† t√≠nh xem n·∫øu c√≥ 100 developer s·ª≠ d·ª•ng, \"\n",
    "    \"m·ªói ng∆∞·ªùi ti·∫øt ki·ªám 2 gi·ªù/tu·∫ßn th√¨ t·ªïng c·ªông ti·∫øt ki·ªám bao nhi√™u gi·ªù/nƒÉm?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Monitoring v√† Debugging\n",
    "\n",
    "Th√™m kh·∫£ nƒÉng theo d√µi ho·∫°t ƒë·ªông c·ªßa Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMonitor:\n",
    "    \"\"\"Class ƒë·ªÉ theo d√µi ho·∫°t ƒë·ªông c·ªßa Agent.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset_stats()\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        self.stats = {\n",
    "            \"total_steps\": 0,\n",
    "            \"agent_calls\": 0,\n",
    "            \"tool_calls\": 0,\n",
    "            \"tools_used\": set(),\n",
    "            \"execution_time\": 0\n",
    "        }\n",
    "    \n",
    "    def log_step(self, node_name: str, output: dict):\n",
    "        \"\"\"Log m·ªôt b∆∞·ªõc th·ª±c hi·ªán.\"\"\"\n",
    "        self.stats[\"total_steps\"] += 1\n",
    "        \n",
    "        if node_name == \"agent\":\n",
    "            self.stats[\"agent_calls\"] += 1\n",
    "            # Ki·ªÉm tra tool calls\n",
    "            last_msg = output[\"messages\"][-1]\n",
    "            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                for tc in last_msg.tool_calls:\n",
    "                    self.stats[\"tools_used\"].add(tc['name'])\n",
    "                    \n",
    "        elif node_name == \"tools\":\n",
    "            self.stats[\"tool_calls\"] += 1\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"Hi·ªÉn th·ªã th·ªëng k√™.\"\"\"\n",
    "        print(\"\\nüìä Th·ªëng k√™ Agent:\")\n",
    "        print(f\"   ‚Ä¢ T·ªïng s·ªë b∆∞·ªõc: {self.stats['total_steps']}\")\n",
    "        print(f\"   ‚Ä¢ Agent calls: {self.stats['agent_calls']}\")\n",
    "        print(f\"   ‚Ä¢ Tool calls: {self.stats['tool_calls']}\")\n",
    "        print(f\"   ‚Ä¢ Tools ƒë√£ d√πng: {', '.join(self.stats['tools_used']) if self.stats['tools_used'] else 'Kh√¥ng c√≥'}\")\n",
    "\n",
    "def run_with_monitoring(query: str):\n",
    "    \"\"\"Ch·∫°y Agent v·ªõi monitoring.\"\"\"\n",
    "    monitor = AgentMonitor()\n",
    "    \n",
    "    print(f\"\\nüîç Monitoring query: '{query}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)]\n",
    "    }\n",
    "    \n",
    "    # Stream v·ªõi monitoring\n",
    "    for event in app.stream(initial_state):\n",
    "        for node_name, output in event.items():\n",
    "            monitor.log_step(node_name, output)\n",
    "    \n",
    "    monitor.print_stats()\n",
    "    return monitor.stats\n",
    "\n",
    "# Test monitoring\n",
    "stats = run_with_monitoring(\n",
    "    \"T√¨m ki·∫øm th√¥ng tin v·ªÅ 'Artificial General Intelligence' v√† t√≠nh 2^10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Gi·∫£i th√≠ch & Ph√¢n t√≠ch\n",
    "\n",
    "### C√°ch Agent l·ª±a ch·ªçn Tools\n",
    "\n",
    "Agent s·ª≠ d·ª•ng LLM ƒë·ªÉ quy·∫øt ƒë·ªãnh c√¥ng c·ª• n√†o ph√π h·ª£p d·ª±a tr√™n:\n",
    "\n",
    "1. **Ph√¢n t√≠ch ng·ªØ c·∫£nh**: LLM hi·ªÉu n·ªôi dung c√¢u h·ªèi\n",
    "2. **Tool descriptions**: M√¥ t·∫£ ch·ª©c nƒÉng c·ªßa t·ª´ng tool\n",
    "3. **Pattern matching**: Nh·∫≠n di·ªán m·∫´u c√¢u h·ªèi (t√¨m ki·∫øm, t√≠nh to√°n, etc.)\n",
    "4. **Multi-step reasoning**: C√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu tools trong m·ªôt workflow\n",
    "\n",
    "### ∆Øu ƒëi·ªÉm c·ªßa LangGraph Agent-Tool Architecture:\n",
    "\n",
    "‚úÖ **Modularity**: Tools ƒë·ªôc l·∫≠p, d·ªÖ th√™m/b·ªõt  \n",
    "‚úÖ **Flexibility**: Agent t·ª± quy·∫øt ƒë·ªãnh workflow  \n",
    "‚úÖ **Transparency**: C√≥ th·ªÉ theo d√µi t·ª´ng b∆∞·ªõc  \n",
    "‚úÖ **Error handling**: X·ª≠ l√Ω l·ªói gracefully  \n",
    "‚úÖ **Extensibility**: D·ªÖ m·ªü r·ªông th√™m tools m·ªõi  \n",
    "\n",
    "### Th√°ch th·ª©c:\n",
    "\n",
    "‚ö†Ô∏è **Cost**: M·ªói agent call = 1 LLM call  \n",
    "‚ö†Ô∏è **Latency**: Multi-step c√≥ th·ªÉ ch·∫≠m  \n",
    "‚ö†Ô∏è **Reliability**: Ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng LLM  \n",
    "‚ö†Ô∏è **Tool selection**: C√≥ th·ªÉ ch·ªçn sai tool  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß N√¢ng cao: Custom Tool v·ªõi Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def file_analyzer(file_path: str) -> str:\n",
    "    \"\"\"Ph√¢n t√≠ch file text v√† ƒë∆∞a ra th·ªëng k√™ c∆° b·∫£n.\n",
    "    \n",
    "    Args:\n",
    "        file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file\n",
    "        \n",
    "    Returns:\n",
    "        Th·ªëng k√™ v·ªÅ file (s·ªë d√≤ng, t·ª´, k√Ω t·ª±)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        lines = len(content.split('\\n'))\n",
    "        words = len(content.split())\n",
    "        chars = len(content)\n",
    "        \n",
    "        return f\"\"\"üìÑ Ph√¢n t√≠ch file '{file_path}':\n",
    "   ‚Ä¢ S·ªë d√≤ng: {lines:,}\n",
    "   ‚Ä¢ S·ªë t·ª´: {words:,}\n",
    "   ‚Ä¢ S·ªë k√Ω t·ª±: {chars:,}\n",
    "   ‚Ä¢ K√≠ch th∆∞·ªõc: {chars/1024:.1f} KB\"\"\"\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return f\"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}\"\n",
    "    except PermissionError:\n",
    "        return f\"‚ùå Kh√¥ng c√≥ quy·ªÅn ƒë·ªçc file: {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}\"\n",
    "\n",
    "# Test tool m·ªõi\n",
    "print(\"üß™ Test file analyzer tool:\")\n",
    "result = file_analyzer(\"/etc/hosts\")  # File th∆∞·ªùng t·ªìn t·∫°i tr√™n Linux/Mac\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ K·∫øt lu·∫≠n & G·ª£i √Ω m·ªü r·ªông\n",
    "\n",
    "### Nh·ªØng g√¨ ch√∫ng ta ƒë√£ h·ªçc:\n",
    "\n",
    "1. **Agent Architecture**: C√°ch x√¢y d·ª±ng agent v·ªõi kh·∫£ nƒÉng s·ª≠ d·ª•ng tools\n",
    "2. **Tool Integration**: T√≠ch h·ª£p v√† qu·∫£n l√Ω nhi·ªÅu tools kh√°c nhau\n",
    "3. **Conditional Logic**: S·ª≠ d·ª•ng conditional edges ƒë·ªÉ ƒëi·ªÅu khi·ªÉn workflow\n",
    "4. **Monitoring**: Theo d√µi v√† debug ho·∫°t ƒë·ªông c·ªßa agent\n",
    "5. **Error Handling**: X·ª≠ l√Ω l·ªói trong tools m·ªôt c√°ch graceful\n",
    "\n",
    "### üöÄ G·ª£i √Ω m·ªü r·ªông:\n",
    "\n",
    "1. **Th√™m tools n√¢ng cao**:\n",
    "   - Database query tool\n",
    "   - Email sending tool  \n",
    "   - Image processing tool\n",
    "   - API integration tools\n",
    "\n",
    "2. **Memory & Context**:\n",
    "   - L∆∞u tr·ªØ conversation history\n",
    "   - Context-aware tool selection\n",
    "   - Learning from previous interactions\n",
    "\n",
    "3. **Multi-agent systems**:\n",
    "   - Specialized agents cho different domains\n",
    "   - Agent collaboration\n",
    "   - Hierarchical agent structures\n",
    "\n",
    "4. **Performance optimization**:\n",
    "   - Tool caching\n",
    "   - Parallel tool execution\n",
    "   - Smart tool selection\n",
    "\n",
    "5. **Advanced monitoring**:\n",
    "   - LangSmith integration\n",
    "   - Performance metrics\n",
    "   - Success rate tracking\n",
    "\n",
    "### üìö T√†i li·ªáu tham kh·∫£o:\n",
    "\n",
    "- [LangGraph Agent Documentation](https://python.langgraph.org/tutorials/introduction/)\n",
    "- [LangChain Tools](https://python.langchain.com/docs/modules/tools/)\n",
    "- [Agent Patterns](https://python.langgraph.org/concepts/agent_architectures/)\n",
    "\n",
    "---\n",
    "\n",
    "**Ti·∫øp theo**: Part 4 - Multi-Agent Systems v√† Advanced Workflows! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}