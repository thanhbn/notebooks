{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Prompting Deep Dive: Multi-Round Verification and Error Correction\n",
    "\n",
    "## Learning Objective\n",
    "\n",
    "Master the **Multi-Round Verification and Error Correction** mechanism in meta-prompting - understanding how the system systematically validates solutions, detects errors, and iteratively refines results through multiple expert perspectives.\n",
    "\n",
    "## Paper Context\n",
    "\n",
    "From **Section 4.2** of Suzgun & Kalai (2024):\n",
    "\n",
    "> *\"Our structured approach embodies the principle of the wisdom of the crowd, which posits that a collective opinion of a diverse set of critical thinkers often surpasses the insights of individual experts.\"*\n",
    "\n",
    "From **Section 5.1**:\n",
    "\n",
    "> *\"The Meta Model's systematic verification protocol strengthens the reliability and robustness of its solutions. Fundamental to this approach is the consistent practice of consulting an expert for validation before finalizing responses...By integrating this dual verification mechanism, the model significantly enhances solution accuracy and reliability.\"*\n",
    "\n",
    "## Core Verification Principles\n",
    "\n",
    "### 1. **Systematic Dual Verification**\n",
    "- **Primary Expert**: Generates initial solution\n",
    "- **Verification Expert**: Independent validation with fresh eyes\n",
    "- **Meta Model**: Synthesizes and makes final determination\n",
    "\n",
    "### 2. **Error Detection Mechanisms**\n",
    "- **Cross-validation**: Multiple experts review same problem\n",
    "- **Perspective diversity**: Different domain experts spot different errors\n",
    "- **Iterative refinement**: Solutions improve through multiple rounds\n",
    "\n",
    "### 3. **Wisdom of the Crowd**\n",
    "- **Collective intelligence**: Aggregate multiple expert opinions\n",
    "- **Error averaging**: Individual mistakes canceled by group consensus\n",
    "- **Confidence calibration**: Higher confidence in validated solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai python-dotenv matplotlib numpy pandas seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from typing import List, Dict, Optional, Tuple, Any, Set\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict, Counter\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import BaseMessage\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0, max_tokens=1024)\n",
    "    print(\"GPT-4 initialized successfully\")\n",
    "except:\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=1024)\n",
    "    print(\"Using GPT-3.5-turbo\")\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Framework\n",
    "\n",
    "Let's implement a comprehensive verification and error correction system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationLevel(Enum):\n",
    "    \"\"\"Verification confidence levels\"\"\"\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "    UNCERTAIN = \"uncertain\"\n",
    "\n",
    "@dataclass\n",
    "class VerificationResult:\n",
    "    \"\"\"Result of verification process\"\"\"\n",
    "    is_correct: bool\n",
    "    confidence_level: VerificationLevel\n",
    "    expert_name: str\n",
    "    verification_reasoning: str\n",
    "    identified_errors: List[str] = field(default_factory=list)\n",
    "    suggested_corrections: List[str] = field(default_factory=list)\n",
    "    verification_round: int = 1\n",
    "\n",
    "@dataclass\n",
    "class SolutionCandidate:\n",
    "    \"\"\"Solution candidate with verification history\"\"\"\n",
    "    solution: str\n",
    "    generator_expert: str\n",
    "    generation_round: int\n",
    "    verification_results: List[VerificationResult] = field(default_factory=list)\n",
    "    consensus_score: float = 0.0\n",
    "    final_confidence: VerificationLevel = VerificationLevel.UNCERTAIN\n",
    "\n",
    "class MultiRoundVerificationSystem:\n",
    "    \"\"\"Comprehensive multi-round verification and error correction system\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, max_verification_rounds: int = 4):\n",
    "        self.llm = llm\n",
    "        self.max_verification_rounds = max_verification_rounds\n",
    "        self.verification_history = []\n",
    "        self.error_patterns = defaultdict(int)  # Track common error types\n",
    "        \n",
    "        # Expert profiles for verification\n",
    "        self.verification_experts = {\n",
    "            \"Expert Mathematician\": {\n",
    "                \"specialties\": [\"calculations\", \"proofs\", \"logical reasoning\"],\n",
    "                \"verification_focus\": \"mathematical accuracy and logical consistency\"\n",
    "            },\n",
    "            \"Expert Chess Analyst\": {\n",
    "                \"specialties\": [\"move validation\", \"position analysis\", \"tactical verification\"],\n",
    "                \"verification_focus\": \"chess move accuracy and strategic validity\"\n",
    "            },\n",
    "            \"Expert Problem Solver\": {\n",
    "                \"specialties\": [\"logical analysis\", \"constraint checking\", \"solution validation\"],\n",
    "                \"verification_focus\": \"logical consistency and requirement satisfaction\"\n",
    "            },\n",
    "            \"Expert Code Reviewer\": {\n",
    "                \"specialties\": [\"code correctness\", \"algorithm validation\", \"edge case analysis\"],\n",
    "                \"verification_focus\": \"code correctness and algorithmic soundness\"\n",
    "            },\n",
    "            \"Expert Fact Checker\": {\n",
    "                \"specialties\": [\"accuracy verification\", \"source validation\", \"consistency checking\"],\n",
    "                \"verification_focus\": \"factual accuracy and information consistency\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def generate_verification_instruction(self, \n",
    "                                        expert_name: str,\n",
    "                                        original_problem: str,\n",
    "                                        candidate_solution: str,\n",
    "                                        verification_focus: str = \"\") -> str:\n",
    "        \"\"\"Generate comprehensive verification instruction for expert\"\"\"\n",
    "        \n",
    "        expert_info = self.verification_experts.get(expert_name, {})\n",
    "        verification_focus = verification_focus or expert_info.get(\"verification_focus\", \"general accuracy\")\n",
    "        \n",
    "        instruction = f\"\"\"\n",
    "You are {expert_name}, tasked with verifying the accuracy and quality of a proposed solution.\n",
    "\n",
    "Your verification focus: {verification_focus}\n",
    "\n",
    "ORIGINAL PROBLEM:\n",
    "{original_problem}\n",
    "\n",
    "PROPOSED SOLUTION TO VERIFY:\n",
    "{candidate_solution}\n",
    "\n",
    "VERIFICATION TASK:\n",
    "1. Carefully analyze the proposed solution for accuracy and completeness\n",
    "2. Check for logical consistency and adherence to requirements\n",
    "3. Identify any errors, omissions, or areas for improvement\n",
    "4. Provide specific, actionable feedback\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "VERIFICATION: [CORRECT/INCORRECT/PARTIALLY_CORRECT]\n",
    "CONFIDENCE: [HIGH/MEDIUM/LOW]\n",
    "REASONING: [Your detailed analysis]\n",
    "ERRORS_FOUND: [List specific errors, or \"None\" if no errors]\n",
    "SUGGESTIONS: [Specific improvements or corrections, or \"None\" if solution is correct]\n",
    "\n",
    "Be thorough, objective, and constructive in your verification.\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        return instruction\n",
    "    \n",
    "    def parse_verification_response(self, response: str, expert_name: str, round_num: int) -> VerificationResult:\n",
    "        \"\"\"Parse expert verification response into structured result\"\"\"\n",
    "        \n",
    "        # Extract verification components\n",
    "        verification_match = re.search(r'VERIFICATION:\\s*(\\w+)', response, re.IGNORECASE)\n",
    "        confidence_match = re.search(r'CONFIDENCE:\\s*(\\w+)', response, re.IGNORECASE)\n",
    "        reasoning_match = re.search(r'REASONING:\\s*([\\s\\S]*?)(?=ERRORS_FOUND:|$)', response, re.IGNORECASE)\n",
    "        errors_match = re.search(r'ERRORS_FOUND:\\s*([\\s\\S]*?)(?=SUGGESTIONS:|$)', response, re.IGNORECASE)\n",
    "        suggestions_match = re.search(r'SUGGESTIONS:\\s*([\\s\\S]*?)$', response, re.IGNORECASE)\n",
    "        \n",
    "        # Parse verification status\n",
    "        verification_text = verification_match.group(1).upper() if verification_match else \"UNCERTAIN\"\n",
    "        is_correct = verification_text in [\"CORRECT\", \"PARTIALLY_CORRECT\"]\n",
    "        \n",
    "        # Parse confidence level\n",
    "        confidence_text = confidence_match.group(1).upper() if confidence_match else \"UNCERTAIN\"\n",
    "        confidence_map = {\n",
    "            \"HIGH\": VerificationLevel.HIGH,\n",
    "            \"MEDIUM\": VerificationLevel.MEDIUM,\n",
    "            \"LOW\": VerificationLevel.LOW\n",
    "        }\n",
    "        confidence_level = confidence_map.get(confidence_text, VerificationLevel.UNCERTAIN)\n",
    "        \n",
    "        # Parse errors and suggestions\n",
    "        errors_text = errors_match.group(1).strip() if errors_match else \"\"\n",
    "        suggestions_text = suggestions_match.group(1).strip() if suggestions_match else \"\"\n",
    "        \n",
    "        identified_errors = [e.strip() for e in errors_text.split('\\n') if e.strip() and e.strip().lower() != \"none\"]\n",
    "        suggested_corrections = [s.strip() for s in suggestions_text.split('\\n') if s.strip() and s.strip().lower() != \"none\"]\n",
    "        \n",
    "        reasoning = reasoning_match.group(1).strip() if reasoning_match else response\n",
    "        \n",
    "        return VerificationResult(\n",
    "            is_correct=is_correct,\n",
    "            confidence_level=confidence_level,\n",
    "            expert_name=expert_name,\n",
    "            verification_reasoning=reasoning,\n",
    "            identified_errors=identified_errors,\n",
    "            suggested_corrections=suggested_corrections,\n",
    "            verification_round=round_num\n",
    "        )\n",
    "    \n",
    "    def conduct_verification_round(self, \n",
    "                                 original_problem: str,\n",
    "                                 candidate_solution: SolutionCandidate,\n",
    "                                 verifier_expert: str,\n",
    "                                 round_num: int) -> VerificationResult:\n",
    "        \"\"\"Conduct single verification round with specific expert\"\"\"\n",
    "        \n",
    "        # Generate verification instruction\n",
    "        instruction = self.generate_verification_instruction(\n",
    "            verifier_expert, original_problem, candidate_solution.solution\n",
    "        )\n",
    "        \n",
    "        # Get expert verification (Fresh Eyes - no history)\n",
    "        response = self.llm.invoke([HumanMessage(content=instruction)])\n",
    "        \n",
    "        # Parse verification result\n",
    "        verification_result = self.parse_verification_response(\n",
    "            response.content, verifier_expert, round_num\n",
    "        )\n",
    "        \n",
    "        # Track error patterns\n",
    "        for error in verification_result.identified_errors:\n",
    "            self.error_patterns[error] += 1\n",
    "        \n",
    "        return verification_result\n",
    "    \n",
    "    def calculate_consensus_score(self, verification_results: List[VerificationResult]) -> float:\n",
    "        \"\"\"Calculate consensus score from multiple verification results\"\"\"\n",
    "        \n",
    "        if not verification_results:\n",
    "            return 0.0\n",
    "        \n",
    "        # Weight votes by confidence level\n",
    "        confidence_weights = {\n",
    "            VerificationLevel.HIGH: 1.0,\n",
    "            VerificationLevel.MEDIUM: 0.7,\n",
    "            VerificationLevel.LOW: 0.4,\n",
    "            VerificationLevel.UNCERTAIN: 0.1\n",
    "        }\n",
    "        \n",
    "        total_weight = 0.0\n",
    "        correct_weight = 0.0\n",
    "        \n",
    "        for result in verification_results:\n",
    "            weight = confidence_weights[result.confidence_level]\n",
    "            total_weight += weight\n",
    "            \n",
    "            if result.is_correct:\n",
    "                correct_weight += weight\n",
    "        \n",
    "        return correct_weight / total_weight if total_weight > 0 else 0.0\n",
    "    \n",
    "    def determine_final_confidence(self, \n",
    "                                 consensus_score: float,\n",
    "                                 verification_results: List[VerificationResult]) -> VerificationLevel:\n",
    "        \"\"\"Determine final confidence level based on consensus and individual verifications\"\"\"\n",
    "        \n",
    "        num_verifications = len(verification_results)\n",
    "        high_confidence_count = sum(1 for r in verification_results if r.confidence_level == VerificationLevel.HIGH)\n",
    "        \n",
    "        if consensus_score >= 0.8 and high_confidence_count >= 2:\n",
    "            return VerificationLevel.HIGH\n",
    "        elif consensus_score >= 0.6 and num_verifications >= 2:\n",
    "            return VerificationLevel.MEDIUM\n",
    "        elif consensus_score >= 0.4:\n",
    "            return VerificationLevel.LOW\n",
    "        else:\n",
    "            return VerificationLevel.UNCERTAIN\n",
    "    \n",
    "    def run_multi_round_verification(self, \n",
    "                                   original_problem: str,\n",
    "                                   candidate_solution: SolutionCandidate,\n",
    "                                   verification_experts: List[str] = None) -> SolutionCandidate:\n",
    "        \"\"\"Run complete multi-round verification process\"\"\"\n",
    "        \n",
    "        if verification_experts is None:\n",
    "            # Default verification experts based on problem type\n",
    "            verification_experts = [\"Expert Problem Solver\", \"Expert Fact Checker\"]\n",
    "        \n",
    "        # Ensure we don't exceed max rounds\n",
    "        verification_experts = verification_experts[:self.max_verification_rounds]\n",
    "        \n",
    "        verification_results = []\n",
    "        \n",
    "        for round_num, expert in enumerate(verification_experts, 1):\n",
    "            print(f\"  Verification Round {round_num}: {expert}\")\n",
    "            \n",
    "            verification_result = self.conduct_verification_round(\n",
    "                original_problem, candidate_solution, expert, round_num\n",
    "            )\n",
    "            \n",
    "            verification_results.append(verification_result)\n",
    "            \n",
    "            # Early stopping if high confidence consensus reached\n",
    "            if (round_num >= 2 and \n",
    "                all(r.confidence_level == VerificationLevel.HIGH for r in verification_results[-2:]) and\n",
    "                all(r.is_correct == verification_results[-1].is_correct for r in verification_results[-2:])):\n",
    "                print(f\"  Early consensus reached after {round_num} rounds\")\n",
    "                break\n",
    "        \n",
    "        # Calculate final scores\n",
    "        consensus_score = self.calculate_consensus_score(verification_results)\n",
    "        final_confidence = self.determine_final_confidence(consensus_score, verification_results)\n",
    "        \n",
    "        # Update candidate solution\n",
    "        candidate_solution.verification_results = verification_results\n",
    "        candidate_solution.consensus_score = consensus_score\n",
    "        candidate_solution.final_confidence = final_confidence\n",
    "        \n",
    "        return candidate_solution\n",
    "\n",
    "# Initialize verification system\n",
    "verification_system = MultiRoundVerificationSystem(llm, max_verification_rounds=4)\n",
    "print(\"Multi-Round Verification System initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Correction and Refinement Engine\n",
    "\n",
    "This system handles iterative solution refinement based on verification feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RefinementIteration:\n",
    "    \"\"\"Single refinement iteration\"\"\"\n",
    "    iteration_number: int\n",
    "    original_solution: str\n",
    "    identified_issues: List[str]\n",
    "    correction_instructions: str\n",
    "    refined_solution: str\n",
    "    refinement_expert: str\n",
    "\n",
    "class ErrorCorrectionEngine:\n",
    "    \"\"\"Engine for iterative error correction and solution refinement\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, verification_system: MultiRoundVerificationSystem):\n",
    "        self.llm = llm\n",
    "        self.verification_system = verification_system\n",
    "        self.max_refinement_iterations = 3\n",
    "        self.refinement_history = []\n",
    "    \n",
    "    def analyze_verification_feedback(self, verification_results: List[VerificationResult]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze verification feedback to identify correction priorities\"\"\"\n",
    "        \n",
    "        all_errors = []\n",
    "        all_suggestions = []\n",
    "        error_frequency = Counter()\n",
    "        \n",
    "        for result in verification_results:\n",
    "            all_errors.extend(result.identified_errors)\n",
    "            all_suggestions.extend(result.suggested_corrections)\n",
    "            \n",
    "            # Weight errors by confidence level\n",
    "            weight = {\n",
    "                VerificationLevel.HIGH: 3,\n",
    "                VerificationLevel.MEDIUM: 2, \n",
    "                VerificationLevel.LOW: 1,\n",
    "                VerificationLevel.UNCERTAIN: 0\n",
    "            }[result.confidence_level]\n",
    "            \n",
    "            for error in result.identified_errors:\n",
    "                error_frequency[error] += weight\n",
    "        \n",
    "        # Categorize errors by type\n",
    "        error_categories = {\n",
    "            \"logical\": [],\n",
    "            \"computational\": [],\n",
    "            \"factual\": [],\n",
    "            \"procedural\": [],\n",
    "            \"other\": []\n",
    "        }\n",
    "        \n",
    "        for error in all_errors:\n",
    "            error_lower = error.lower()\n",
    "            if any(word in error_lower for word in [\"logic\", \"reasoning\", \"contradiction\", \"inconsistent\"]):\n",
    "                error_categories[\"logical\"].append(error)\n",
    "            elif any(word in error_lower for word in [\"calculation\", \"math\", \"compute\", \"number\"]):\n",
    "                error_categories[\"computational\"].append(error)\n",
    "            elif any(word in error_lower for word in [\"fact\", \"incorrect\", \"wrong\", \"inaccurate\"]):\n",
    "                error_categories[\"factual\"].append(error)\n",
    "            elif any(word in error_lower for word in [\"step\", \"procedure\", \"method\", \"approach\"]):\n",
    "                error_categories[\"procedural\"].append(error)\n",
    "            else:\n",
    "                error_categories[\"other\"].append(error)\n",
    "        \n",
    "        return {\n",
    "            \"all_errors\": all_errors,\n",
    "            \"all_suggestions\": all_suggestions,\n",
    "            \"error_frequency\": error_frequency,\n",
    "            \"error_categories\": error_categories,\n",
    "            \"priority_errors\": error_frequency.most_common(5)\n",
    "        }\n",
    "    \n",
    "    def generate_correction_instruction(self, \n",
    "                                      original_problem: str,\n",
    "                                      current_solution: str,\n",
    "                                      feedback_analysis: Dict[str, Any],\n",
    "                                      refinement_expert: str) -> str:\n",
    "        \"\"\"Generate instruction for solution refinement\"\"\"\n",
    "        \n",
    "        priority_errors = [error for error, _ in feedback_analysis[\"priority_errors\"]]\n",
    "        key_suggestions = feedback_analysis[\"all_suggestions\"][:5]  # Top 5 suggestions\n",
    "        \n",
    "        instruction = f\"\"\"\n",
    "You are {refinement_expert}, tasked with refining a solution based on expert feedback.\n",
    "\n",
    "ORIGINAL PROBLEM:\n",
    "{original_problem}\n",
    "\n",
    "CURRENT SOLUTION (needs refinement):\n",
    "{current_solution}\n",
    "\n",
    "IDENTIFIED ISSUES TO ADDRESS:\n",
    "        \"\"\"\n",
    "        \n",
    "        if priority_errors:\n",
    "            instruction += \"\\n\".join([f\"- {error}\" for error in priority_errors])\n",
    "        else:\n",
    "            instruction += \"- No specific errors identified, but solution needs improvement\"\n",
    "        \n",
    "        instruction += \"\\n\\nSUGGESTED IMPROVEMENTS:\\n\"\n",
    "        \n",
    "        if key_suggestions:\n",
    "            instruction += \"\\n\".join([f\"- {suggestion}\" for suggestion in key_suggestions])\n",
    "        else:\n",
    "            instruction += \"- General improvement and optimization needed\"\n",
    "        \n",
    "        instruction += \"\"\"\n",
    "\n",
    "REFINEMENT TASK:\n",
    "1. Address each identified issue systematically\n",
    "2. Incorporate suggested improvements where applicable\n",
    "3. Ensure the refined solution is accurate, complete, and clear\n",
    "4. Maintain all positive aspects of the original solution\n",
    "5. Verify your refinements are correct\n",
    "\n",
    "Provide the COMPLETE refined solution, not just the changes.\n",
    "        \"\"\"\n",
    "        \n",
    "        return instruction.strip()\n",
    "    \n",
    "    def refine_solution(self, \n",
    "                       original_problem: str,\n",
    "                       candidate_solution: SolutionCandidate,\n",
    "                       refinement_expert: str = \"Expert Problem Solver\") -> SolutionCandidate:\n",
    "        \"\"\"Refine solution based on verification feedback\"\"\"\n",
    "        \n",
    "        # Analyze verification feedback\n",
    "        feedback_analysis = self.analyze_verification_feedback(candidate_solution.verification_results)\n",
    "        \n",
    "        # Generate correction instruction\n",
    "        correction_instruction = self.generate_correction_instruction(\n",
    "            original_problem, candidate_solution.solution, feedback_analysis, refinement_expert\n",
    "        )\n",
    "        \n",
    "        # Get refined solution (Fresh Eyes - no conversation history)\n",
    "        response = self.llm.invoke([HumanMessage(content=correction_instruction)])\n",
    "        refined_solution = response.content\n",
    "        \n",
    "        # Record refinement iteration\n",
    "        refinement_iteration = RefinementIteration(\n",
    "            iteration_number=len(self.refinement_history) + 1,\n",
    "            original_solution=candidate_solution.solution,\n",
    "            identified_issues=feedback_analysis[\"all_errors\"],\n",
    "            correction_instructions=correction_instruction,\n",
    "            refined_solution=refined_solution,\n",
    "            refinement_expert=refinement_expert\n",
    "        )\n",
    "        \n",
    "        self.refinement_history.append(refinement_iteration)\n",
    "        \n",
    "        # Create new solution candidate\n",
    "        refined_candidate = SolutionCandidate(\n",
    "            solution=refined_solution,\n",
    "            generator_expert=refinement_expert,\n",
    "            generation_round=candidate_solution.generation_round + 1\n",
    "        )\n",
    "        \n",
    "        return refined_candidate\n",
    "    \n",
    "    def run_iterative_refinement(self, \n",
    "                                original_problem: str,\n",
    "                                initial_solution: SolutionCandidate,\n",
    "                                quality_threshold: float = 0.8) -> Tuple[SolutionCandidate, List[RefinementIteration]]:\n",
    "        \"\"\"Run complete iterative refinement process\"\"\"\n",
    "        \n",
    "        current_solution = initial_solution\n",
    "        refinement_iterations = []\n",
    "        \n",
    "        for iteration in range(self.max_refinement_iterations):\n",
    "            print(f\"\\n=== REFINEMENT ITERATION {iteration + 1} ===\")\n",
    "            \n",
    "            # Run verification on current solution\n",
    "            print(\"Running verification...\")\n",
    "            verified_solution = self.verification_system.run_multi_round_verification(\n",
    "                original_problem, current_solution\n",
    "            )\n",
    "            \n",
    "            print(f\"Consensus Score: {verified_solution.consensus_score:.2f}\")\n",
    "            print(f\"Confidence Level: {verified_solution.final_confidence.value}\")\n",
    "            \n",
    "            # Check if quality threshold met\n",
    "            if (verified_solution.consensus_score >= quality_threshold and \n",
    "                verified_solution.final_confidence in [VerificationLevel.HIGH, VerificationLevel.MEDIUM]):\n",
    "                print(f\"Quality threshold met! Stopping refinement.\")\n",
    "                return verified_solution, refinement_iterations\n",
    "            \n",
    "            # Check if no errors found (perfect solution)\n",
    "            total_errors = sum(len(vr.identified_errors) for vr in verified_solution.verification_results)\n",
    "            if total_errors == 0 and verified_solution.consensus_score > 0.5:\n",
    "                print(f\"No errors found! Solution verified.\")\n",
    "                return verified_solution, refinement_iterations\n",
    "            \n",
    "            # Refine solution based on feedback\n",
    "            print(\"Refining solution based on feedback...\")\n",
    "            current_solution = self.refine_solution(original_problem, verified_solution)\n",
    "            refinement_iterations.append(self.refinement_history[-1])\n",
    "            \n",
    "            print(f\"Solution refined by {current_solution.generator_expert}\")\n",
    "        \n",
    "        # Final verification\n",
    "        print(\"\\n=== FINAL VERIFICATION ===\")\n",
    "        final_solution = self.verification_system.run_multi_round_verification(\n",
    "            original_problem, current_solution\n",
    "        )\n",
    "        \n",
    "        return final_solution, refinement_iterations\n",
    "\n",
    "# Initialize error correction engine\n",
    "error_correction = ErrorCorrectionEngine(llm, verification_system)\n",
    "print(\"Error Correction Engine initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Verification and Correction System\n",
    "\n",
    "This integrates all components into a complete system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveVerificationSystem:\n",
    "    \"\"\"Complete verification and error correction system\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.verification_system = MultiRoundVerificationSystem(llm)\n",
    "        self.error_correction = ErrorCorrectionEngine(llm, self.verification_system)\n",
    "        self.session_history = []\n",
    "    \n",
    "    def generate_initial_solution(self, problem: str, generator_expert: str = \"Expert Problem Solver\") -> SolutionCandidate:\n",
    "        \"\"\"Generate initial solution for the problem\"\"\"\n",
    "        \n",
    "        instruction = f\"\"\"\n",
    "You are {generator_expert}, tasked with solving the following problem.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Provide a comprehensive, accurate solution that addresses all aspects of the problem.\n",
    "Show your work and reasoning clearly.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.llm.invoke([HumanMessage(content=instruction)])\n",
    "        \n",
    "        return SolutionCandidate(\n",
    "            solution=response.content,\n",
    "            generator_expert=generator_expert,\n",
    "            generation_round=1\n",
    "        )\n",
    "    \n",
    "    def run_complete_verification_cycle(self, \n",
    "                                      problem: str,\n",
    "                                      generator_expert: str = \"Expert Problem Solver\",\n",
    "                                      verification_experts: List[str] = None,\n",
    "                                      quality_threshold: float = 0.8) -> Dict[str, Any]:\n",
    "        \"\"\"Run complete verification and correction cycle\"\"\"\n",
    "        \n",
    "        print(f\"=== COMPREHENSIVE VERIFICATION CYCLE ===\")\n",
    "        print(f\"Problem: {problem[:100]}...\")\n",
    "        \n",
    "        # Step 1: Generate initial solution\n",
    "        print(f\"\\n1. GENERATING INITIAL SOLUTION\")\n",
    "        print(f\"   Generator: {generator_expert}\")\n",
    "        initial_solution = self.generate_initial_solution(problem, generator_expert)\n",
    "        print(f\"   Solution generated: {len(initial_solution.solution)} characters\")\n",
    "        \n",
    "        # Step 2: Run iterative verification and refinement\n",
    "        print(f\"\\n2. ITERATIVE VERIFICATION AND REFINEMENT\")\n",
    "        final_solution, refinement_iterations = self.error_correction.run_iterative_refinement(\n",
    "            problem, initial_solution, quality_threshold\n",
    "        )\n",
    "        \n",
    "        # Step 3: Compile results\n",
    "        print(f\"\\n3. COMPILATION AND ANALYSIS\")\n",
    "        \n",
    "        session_result = {\n",
    "            'problem': problem,\n",
    "            'initial_solution': initial_solution,\n",
    "            'final_solution': final_solution,\n",
    "            'refinement_iterations': refinement_iterations,\n",
    "            'total_verification_rounds': len(final_solution.verification_results),\n",
    "            'total_refinement_iterations': len(refinement_iterations),\n",
    "            'final_consensus_score': final_solution.consensus_score,\n",
    "            'final_confidence': final_solution.final_confidence,\n",
    "            'quality_threshold_met': (final_solution.consensus_score >= quality_threshold and \n",
    "                                    final_solution.final_confidence in [VerificationLevel.HIGH, VerificationLevel.MEDIUM]),\n",
    "            'experts_involved': self._get_all_involved_experts(initial_solution, final_solution, refinement_iterations)\n",
    "        }\n",
    "        \n",
    "        self.session_history.append(session_result)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n=== VERIFICATION CYCLE COMPLETE ===\")\n",
    "        print(f\"Final Consensus Score: {final_solution.consensus_score:.2f}\")\n",
    "        print(f\"Final Confidence: {final_solution.final_confidence.value}\")\n",
    "        print(f\"Quality Threshold Met: {session_result['quality_threshold_met']}\")\n",
    "        print(f\"Total Refinement Iterations: {len(refinement_iterations)}\")\n",
    "        print(f\"Experts Involved: {len(session_result['experts_involved'])}\")\n",
    "        \n",
    "        return session_result\n",
    "    \n",
    "    def _get_all_involved_experts(self, \n",
    "                                initial_solution: SolutionCandidate,\n",
    "                                final_solution: SolutionCandidate,\n",
    "                                refinement_iterations: List[RefinementIteration]) -> List[str]:\n",
    "        \"\"\"Get list of all experts involved in the process\"\"\"\n",
    "        \n",
    "        experts = set()\n",
    "        \n",
    "        # Generator expert\n",
    "        experts.add(initial_solution.generator_expert)\n",
    "        \n",
    "        # Verification experts\n",
    "        for vr in final_solution.verification_results:\n",
    "            experts.add(vr.expert_name)\n",
    "        \n",
    "        # Refinement experts\n",
    "        for ri in refinement_iterations:\n",
    "            experts.add(ri.refinement_expert)\n",
    "        \n",
    "        return list(experts)\n",
    "\n",
    "# Initialize comprehensive system\n",
    "comprehensive_system = ComprehensiveVerificationSystem(llm)\n",
    "print(\"Comprehensive Verification System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Multi-Round Verification in Action\n",
    "\n",
    "Let's test the system with problems that have subtle errors requiring multiple verification rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Mathematical problem with common error trap\n",
    "math_problem = \"\"\"\n",
    "A train travels 120 miles in 2 hours. If it maintains the same speed, \n",
    "how long will it take to travel 300 miles? Also, what is the train's speed in kilometers per hour?\n",
    "(Note: 1 mile = 1.60934 kilometers)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== TEST CASE 1: MATHEMATICAL PROBLEM ===\")\n",
    "math_result = comprehensive_system.run_complete_verification_cycle(\n",
    "    problem=math_problem.strip(),\n",
    "    generator_expert=\"Expert Mathematician\",\n",
    "    quality_threshold=0.85\n",
    ")\n",
    "\n",
    "print(f\"\\n=== RESULTS SUMMARY ===\")\n",
    "print(f\"Initial Solution Preview: {math_result['initial_solution'].solution[:200]}...\")\n",
    "print(f\"Final Solution Preview: {math_result['final_solution'].solution[:200]}...\")\n",
    "print(f\"Improvement Achieved: {math_result['final_consensus_score'] > 0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case 2: Complex Programming Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Programming problem requiring multiple verification rounds\n",
    "programming_problem = \"\"\"\n",
    "Write a Python function that finds the longest common subsequence (LCS) between two strings.\n",
    "The function should return both the length of the LCS and the actual LCS string.\n",
    "Include proper error handling for edge cases and optimize for both time and space complexity.\n",
    "\n",
    "Example:\n",
    "lcs(\"ABCDGH\", \"AEDFHR\") should return (3, \"ADH\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\\n=== TEST CASE 2: PROGRAMMING PROBLEM ===\")\n",
    "programming_result = comprehensive_system.run_complete_verification_cycle(\n",
    "    problem=programming_problem.strip(),\n",
    "    generator_expert=\"Expert Python\",\n",
    "    quality_threshold=0.80\n",
    ")\n",
    "\n",
    "print(f\"\\n=== RESULTS SUMMARY ===\")\n",
    "print(f\"Programming solution verification complete\")\n",
    "print(f\"Quality threshold met: {programming_result['quality_threshold_met']}\")\n",
    "print(f\"Experts involved: {programming_result['experts_involved']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization\n",
    "\n",
    "Let's analyze the verification patterns and effectiveness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_verification_effectiveness(session_results: List[Dict[str, Any]]):\n",
    "    \"\"\"Analyze effectiveness of verification system across multiple sessions\"\"\"\n",
    "    \n",
    "    if not session_results:\n",
    "        print(\"No session results to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Collect metrics\n",
    "    metrics = {\n",
    "        'initial_scores': [],\n",
    "        'final_scores': [],\n",
    "        'improvement_deltas': [],\n",
    "        'refinement_iterations': [],\n",
    "        'verification_rounds': [],\n",
    "        'experts_involved': [],\n",
    "        'quality_threshold_met': [],\n",
    "        'confidence_levels': []\n",
    "    }\n",
    "    \n",
    "    for result in session_results:\n",
    "        # Calculate initial score (assume 0.3 as baseline for unverified solutions)\n",
    "        initial_score = 0.3  # Placeholder for initial solutions\n",
    "        final_score = result['final_consensus_score']\n",
    "        \n",
    "        metrics['initial_scores'].append(initial_score)\n",
    "        metrics['final_scores'].append(final_score)\n",
    "        metrics['improvement_deltas'].append(final_score - initial_score)\n",
    "        metrics['refinement_iterations'].append(result['total_refinement_iterations'])\n",
    "        metrics['verification_rounds'].append(result['total_verification_rounds'])\n",
    "        metrics['experts_involved'].append(len(result['experts_involved']))\n",
    "        metrics['quality_threshold_met'].append(result['quality_threshold_met'])\n",
    "        \n",
    "        # Convert confidence to numeric\n",
    "        confidence_numeric = {\n",
    "            VerificationLevel.HIGH: 4,\n",
    "            VerificationLevel.MEDIUM: 3,\n",
    "            VerificationLevel.LOW: 2,\n",
    "            VerificationLevel.UNCERTAIN: 1\n",
    "        }[result['final_confidence']]\n",
    "        metrics['confidence_levels'].append(confidence_numeric)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Score improvement\n",
    "    x_pos = range(len(session_results))\n",
    "    ax1.bar([x - 0.2 for x in x_pos], metrics['initial_scores'], 0.4, label='Initial Score', alpha=0.7, color='lightcoral')\n",
    "    ax1.bar([x + 0.2 for x in x_pos], metrics['final_scores'], 0.4, label='Final Score', alpha=0.7, color='lightgreen')\n",
    "    ax1.set_xlabel('Test Case')\n",
    "    ax1.set_ylabel('Consensus Score')\n",
    "    ax1.set_title('Score Improvement Through Verification')\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0, 1.0)\n",
    "    \n",
    "    # 2. Verification rounds vs final score\n",
    "    ax2.scatter(metrics['verification_rounds'], metrics['final_scores'], \n",
    "               c=metrics['refinement_iterations'], cmap='viridis', s=100, alpha=0.7)\n",
    "    ax2.set_xlabel('Verification Rounds')\n",
    "    ax2.set_ylabel('Final Consensus Score')\n",
    "    ax2.set_title('Verification Rounds vs Quality')\n",
    "    cbar = plt.colorbar(ax2.collections[0], ax=ax2)\n",
    "    cbar.set_label('Refinement Iterations')\n",
    "    \n",
    "    # 3. Expert involvement\n",
    "    ax3.bar(x_pos, metrics['experts_involved'], color='orange', alpha=0.7)\n",
    "    ax3.set_xlabel('Test Case')\n",
    "    ax3.set_ylabel('Number of Experts')\n",
    "    ax3.set_title('Expert Involvement per Case')\n",
    "    \n",
    "    # 4. Success rate and confidence\n",
    "    success_rate = sum(metrics['quality_threshold_met']) / len(metrics['quality_threshold_met']) * 100\n",
    "    avg_confidence = np.mean(metrics['confidence_levels'])\n",
    "    \n",
    "    categories = ['Success Rate (%)', 'Avg Confidence (1-4)', 'Avg Improvement']\n",
    "    values = [success_rate, avg_confidence * 25, np.mean(metrics['improvement_deltas']) * 100]\n",
    "    \n",
    "    ax4.bar(categories, values, color=['green', 'blue', 'purple'], alpha=0.7)\n",
    "    ax4.set_ylabel('Percentage / Score')\n",
    "    ax4.set_title('Overall System Performance')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\n=== VERIFICATION SYSTEM ANALYSIS ===\")\n",
    "    print(f\"Total Test Cases: {len(session_results)}\")\n",
    "    print(f\"Success Rate: {success_rate:.1f}%\")\n",
    "    print(f\"Average Score Improvement: {np.mean(metrics['improvement_deltas']):.2f}\")\n",
    "    print(f\"Average Verification Rounds: {np.mean(metrics['verification_rounds']):.1f}\")\n",
    "    print(f\"Average Refinement Iterations: {np.mean(metrics['refinement_iterations']):.1f}\")\n",
    "    print(f\"Average Experts Involved: {np.mean(metrics['experts_involved']):.1f}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(f\"\\n=== CORRELATION ANALYSIS ===\")\n",
    "    correlations = {\n",
    "        'Verification Rounds vs Final Score': stats.pearsonr(metrics['verification_rounds'], metrics['final_scores'])[0],\n",
    "        'Expert Count vs Final Score': stats.pearsonr(metrics['experts_involved'], metrics['final_scores'])[0],\n",
    "        'Refinement Iterations vs Improvement': stats.pearsonr(metrics['refinement_iterations'], metrics['improvement_deltas'])[0]\n",
    "    }\n",
    "    \n",
    "    for correlation_name, correlation_value in correlations.items():\n",
    "        print(f\"{correlation_name}: {correlation_value:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Analyze results from our test cases\n",
    "test_results = comprehensive_system.session_history\n",
    "if test_results:\n",
    "    analysis_metrics = analyze_verification_effectiveness(test_results)\nelse:\n",
    "    print(\"No test results available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Pattern Analysis\n",
    "\n",
    "Let's analyze common error patterns detected by the verification system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_patterns(verification_system: MultiRoundVerificationSystem):\n",
    "    \"\"\"Analyze common error patterns detected across all verifications\"\"\"\n",
    "    \n",
    "    error_patterns = verification_system.error_patterns\n",
    "    \n",
    "    if not error_patterns:\n",
    "        print(\"No error patterns detected yet\")\n",
    "        return\n",
    "    \n",
    "    # Get top error patterns\n",
    "    top_errors = error_patterns.most_common(10)\n",
    "    \n",
    "    # Categorize errors\n",
    "    error_categories = defaultdict(list)\n",
    "    \n",
    "    for error, count in top_errors:\n",
    "        error_lower = error.lower()\n",
    "        \n",
    "        if any(word in error_lower for word in ['calculation', 'math', 'arithmetic', 'compute']):\n",
    "            error_categories['Computational'].append((error, count))\n",
    "        elif any(word in error_lower for word in ['logic', 'reasoning', 'contradiction']):\n",
    "            error_categories['Logical'].append((error, count))\n",
    "        elif any(word in error_lower for word in ['fact', 'incorrect', 'wrong']):\n",
    "            error_categories['Factual'].append((error, count))\n",
    "        elif any(word in error_lower for word in ['format', 'structure', 'syntax']):\n",
    "            error_categories['Structural'].append((error, count))\n",
    "        else:\n",
    "            error_categories['Other'].append((error, count))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Top errors\n",
    "    if top_errors:\n",
    "        errors, counts = zip(*top_errors[:8])  # Top 8\n",
    "        y_pos = range(len(errors))\n",
    "        \n",
    "        ax1.barh(y_pos, counts, color='lightcoral', alpha=0.7)\n",
    "        ax1.set_yticks(y_pos)\n",
    "        ax1.set_yticklabels([error[:40] + '...' if len(error) > 40 else error for error in errors])\n",
    "        ax1.set_xlabel('Frequency')\n",
    "        ax1.set_title('Most Common Errors Detected')\n",
    "        ax1.invert_yaxis()\n",
    "    \n",
    "    # 2. Error categories\n",
    "    category_totals = {cat: sum(count for _, count in errors) for cat, errors in error_categories.items()}\n",
    "    \n",
    "    if category_totals:\n",
    "        categories = list(category_totals.keys())\n",
    "        totals = list(category_totals.values())\n",
    "        \n",
    "        colors = plt.cm.Set3(range(len(categories)))\n",
    "        ax2.pie(totals, labels=categories, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax2.set_title('Error Distribution by Category')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\n=== ERROR PATTERN ANALYSIS ===\")\n",
    "    print(f\"Total Unique Errors Detected: {len(error_patterns)}\")\n",
    "    print(f\"Total Error Instances: {sum(error_patterns.values())}\")\n",
    "    \n",
    "    print(\"\\n=== TOP ERROR PATTERNS ===\")\n",
    "    for i, (error, count) in enumerate(top_errors[:5], 1):\n",
    "        print(f\"{i}. {error} (detected {count} times)\")\n",
    "    \n",
    "    print(\"\\n=== ERROR CATEGORIES ===\")\n",
    "    for category, errors in error_categories.items():\n",
    "        if errors:\n",
    "            total_in_category = sum(count for _, count in errors)\n",
    "            print(f\"{category}: {total_in_category} instances ({len(errors)} unique errors)\")\n",
    "    \n",
    "    return error_patterns, error_categories\n",
    "\n",
    "# Analyze error patterns\n",
    "if verification_system.error_patterns:\n",
    "    error_analysis = analyze_error_patterns(verification_system)\nelse:\n",
    "    print(\"No error patterns detected yet - run more verification cycles to collect data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Quality Metrics\n",
    "\n",
    "Let's implement metrics to evaluate the quality of the verification process itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationQualityMetrics:\n",
    "    \"\"\"Metrics for evaluating verification system quality\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics_history = []\n",
    "    \n",
    "    def calculate_consensus_stability(self, verification_results: List[VerificationResult]) -> float:\n",
    "        \"\"\"Calculate how stable the consensus is across experts\"\"\"\n",
    "        \n",
    "        if len(verification_results) < 2:\n",
    "            return 1.0  # Perfect stability with single expert\n",
    "        \n",
    "        # Check agreement in correctness assessment\n",
    "        correctness_votes = [vr.is_correct for vr in verification_results]\n",
    "        agreement_rate = max(correctness_votes.count(True), correctness_votes.count(False)) / len(correctness_votes)\n",
    "        \n",
    "        # Weight by confidence levels\n",
    "        confidence_weights = []\n",
    "        for vr in verification_results:\n",
    "            weight = {\n",
    "                VerificationLevel.HIGH: 1.0,\n",
    "                VerificationLevel.MEDIUM: 0.8,\n",
    "                VerificationLevel.LOW: 0.6,\n",
    "                VerificationLevel.UNCERTAIN: 0.2\n",
    "            }[vr.confidence_level]\n",
    "            confidence_weights.append(weight)\n",
    "        \n",
    "        avg_confidence = np.mean(confidence_weights)\n",
    "        \n",
    "        # Combine agreement rate with confidence\n",
    "        stability_score = agreement_rate * avg_confidence\n",
    "        \n",
    "        return stability_score\n",
    "    \n",
    "    def calculate_error_detection_rate(self, verification_results: List[VerificationResult]) -> float:\n",
    "        \"\"\"Calculate rate of error detection across experts\"\"\"\n",
    "        \n",
    "        if not verification_results:\n",
    "            return 0.0\n",
    "        \n",
    "        # Count how many experts detected errors\n",
    "        experts_detecting_errors = sum(1 for vr in verification_results if vr.identified_errors)\n",
    "        total_experts = len(verification_results)\n",
    "        \n",
    "        return experts_detecting_errors / total_experts\n",
    "    \n",
    "    def calculate_improvement_efficiency(self, \n",
    "                                       initial_score: float, \n",
    "                                       final_score: float, \n",
    "                                       total_rounds: int) -> float:\n",
    "        \"\"\"Calculate improvement per verification round\"\"\"\n",
    "        \n",
    "        if total_rounds == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        improvement = final_score - initial_score\n",
    "        efficiency = improvement / total_rounds\n",
    "        \n",
    "        return max(0.0, efficiency)  # Ensure non-negative\n",
    "    \n",
    "    def calculate_expert_agreement_score(self, verification_results: List[VerificationResult]) -> float:\n",
    "        \"\"\"Calculate how much experts agree with each other\"\"\"\n",
    "        \n",
    "        if len(verification_results) < 2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Compare all pairs of experts\n",
    "        agreements = []\n",
    "        \n",
    "        for i in range(len(verification_results)):\n",
    "            for j in range(i + 1, len(verification_results)):\n",
    "                vr1, vr2 = verification_results[i], verification_results[j]\n",
    "                \n",
    "                # Agreement on correctness\n",
    "                correctness_agreement = 1.0 if vr1.is_correct == vr2.is_correct else 0.0\n",
    "                \n",
    "                # Confidence similarity\n",
    "                conf_values = {\n",
    "                    VerificationLevel.HIGH: 4,\n",
    "                    VerificationLevel.MEDIUM: 3,\n",
    "                    VerificationLevel.LOW: 2,\n",
    "                    VerificationLevel.UNCERTAIN: 1\n",
    "                }\n",
    "                \n",
    "                conf1 = conf_values[vr1.confidence_level]\n",
    "                conf2 = conf_values[vr2.confidence_level]\n",
    "                confidence_similarity = 1.0 - abs(conf1 - conf2) / 3.0\n",
    "                \n",
    "                # Combined agreement\n",
    "                pair_agreement = (correctness_agreement + confidence_similarity) / 2.0\n",
    "                agreements.append(pair_agreement)\n",
    "        \n",
    "        return np.mean(agreements) if agreements else 1.0\n",
    "    \n",
    "    def evaluate_verification_session(self, session_result: Dict[str, Any]) -> Dict[str, float]:\n",
    "        \"\"\"Evaluate complete verification session\"\"\"\n",
    "        \n",
    "        final_solution = session_result['final_solution']\n",
    "        verification_results = final_solution.verification_results\n",
    "        \n",
    "        metrics = {\n",
    "            'consensus_stability': self.calculate_consensus_stability(verification_results),\n",
    "            'error_detection_rate': self.calculate_error_detection_rate(verification_results),\n",
    "            'improvement_efficiency': self.calculate_improvement_efficiency(\n",
    "                0.3,  # Assumed initial score\n",
    "                final_solution.consensus_score,\n",
    "                session_result['total_verification_rounds'] + session_result['total_refinement_iterations']\n",
    "            ),\n",
    "            'expert_agreement': self.calculate_expert_agreement_score(verification_results),\n",
    "            'final_consensus_score': final_solution.consensus_score,\n",
    "            'confidence_level_numeric': {\n",
    "                VerificationLevel.HIGH: 1.0,\n",
    "                VerificationLevel.MEDIUM: 0.75,\n",
    "                VerificationLevel.LOW: 0.5,\n",
    "                VerificationLevel.UNCERTAIN: 0.25\n",
    "            }[final_solution.final_confidence]\n",
    "        }\n",
    "        \n",
    "        # Overall quality score (weighted combination)\n",
    "        weights = {\n",
    "            'consensus_stability': 0.25,\n",
    "            'error_detection_rate': 0.20,\n",
    "            'improvement_efficiency': 0.15,\n",
    "            'expert_agreement': 0.20,\n",
    "            'final_consensus_score': 0.20\n",
    "        }\n",
    "        \n",
    "        overall_quality = sum(metrics[key] * weights[key] for key in weights.keys())\n",
    "        metrics['overall_quality'] = overall_quality\n",
    "        \n",
    "        self.metrics_history.append(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def visualize_quality_metrics(self, session_metrics: List[Dict[str, float]]):\n",
    "        \"\"\"Visualize verification quality metrics\"\"\"\n",
    "        \n",
    "        if not session_metrics:\n",
    "            print(\"No metrics to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Extract metrics for visualization\n",
    "        metric_names = ['consensus_stability', 'error_detection_rate', 'improvement_efficiency', \n",
    "                       'expert_agreement', 'final_consensus_score', 'overall_quality']\n",
    "        \n",
    "        metric_values = {name: [session[name] for session in session_metrics] for name in metric_names}\n",
    "        \n",
    "        # Create radar chart\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # 1. Quality metrics comparison\n",
    "        x_pos = range(len(session_metrics))\n",
    "        width = 0.15\n",
    "        \n",
    "        for i, metric in enumerate(metric_names[:-1]):  # Exclude overall_quality\n",
    "            ax1.bar([x + i * width for x in x_pos], metric_values[metric], \n",
    "                   width, label=metric.replace('_', ' ').title(), alpha=0.8)\n",
    "        \n",
    "        ax1.set_xlabel('Session')\n",
    "        ax1.set_ylabel('Score')\n",
    "        ax1.set_title('Verification Quality Metrics by Session')\n",
    "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax1.set_ylim(0, 1.1)\n",
    "        \n",
    "        # 2. Overall quality trend\n",
    "        ax2.plot(x_pos, metric_values['overall_quality'], 'o-', linewidth=2, markersize=8, color='purple')\n",
    "        ax2.fill_between(x_pos, metric_values['overall_quality'], alpha=0.3, color='purple')\n",
    "        ax2.set_xlabel('Session')\n",
    "        ax2.set_ylabel('Overall Quality Score')\n",
    "        ax2.set_title('Overall Verification Quality Trend')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_ylim(0, 1.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\n=== VERIFICATION QUALITY SUMMARY ===\")\n",
    "        for metric in metric_names:\n",
    "            values = metric_values[metric]\n",
    "            print(f\"{metric.replace('_', ' ').title():.<25} Avg: {np.mean(values):.3f} ± {np.std(values):.3f}\")\n",
    "\n",
    "# Initialize quality metrics\n",
    "quality_metrics = VerificationQualityMetrics()\n",
    "\n",
    "# Evaluate our test sessions\n",
    "if test_results:\n",
    "    session_quality_metrics = []\n",
    "    \n",
    "    for session in test_results:\n",
    "        metrics = quality_metrics.evaluate_verification_session(session)\n",
    "        session_quality_metrics.append(metrics)\n",
    "        \n",
    "        print(f\"\\nSession Quality Metrics:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"  {metric_name}: {value:.3f}\")\n",
    "    \n",
    "    # Visualize quality metrics\n",
    "    quality_metrics.visualize_quality_metrics(session_quality_metrics)\nelse:\n",
    "    print(\"No test results available for quality evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Implementation Template\n",
    "\n",
    "Here's a streamlined template for production use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionVerificationSystem:\n",
    "    \"\"\"Production-ready verification and error correction system\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, config: Dict[str, Any] = None):\n",
    "        self.llm = llm\n",
    "        \n",
    "        # Default configuration\n",
    "        default_config = {\n",
    "            'max_verification_rounds': 3,\n",
    "            'max_refinement_iterations': 2,\n",
    "            'quality_threshold': 0.75,\n",
    "            'consensus_threshold': 0.7,\n",
    "            'enable_early_stopping': True,\n",
    "            'require_high_confidence': False\n",
    "        }\n",
    "        \n",
    "        self.config = {**default_config, **(config or {})}\n",
    "        self.verification_cache = {}  # Cache for similar problems\n",
    "    \n",
    "    def verify_solution(self, \n",
    "                       problem: str, \n",
    "                       solution: str,\n",
    "                       domain: str = \"general\") -> Dict[str, Any]:\n",
    "        \"\"\"Main verification entry point\"\"\"\n",
    "        \n",
    "        # Select appropriate verification experts based on domain\n",
    "        domain_experts = {\n",
    "            'mathematical': ['Expert Mathematician', 'Expert Problem Solver'],\n",
    "            'programming': ['Expert Code Reviewer', 'Expert Problem Solver'],\n",
    "            'chess': ['Expert Chess Analyst', 'Expert Chess Player'],\n",
    "            'creative': ['Expert Fact Checker', 'Expert Problem Solver'],\n",
    "            'general': ['Expert Problem Solver', 'Expert Fact Checker']\n",
    "        }\n",
    "        \n",
    "        verification_experts = domain_experts.get(domain, domain_experts['general'])\n",
    "        \n",
    "        # Run verification process\n",
    "        candidate = SolutionCandidate(\n",
    "            solution=solution,\n",
    "            generator_expert=\"Initial\",\n",
    "            generation_round=1\n",
    "        )\n",
    "        \n",
    "        verification_results = []\n",
    "        \n",
    "        for i, expert in enumerate(verification_experts[:self.config['max_verification_rounds']]):\n",
    "            # Generate verification instruction\n",
    "            instruction = self._create_verification_instruction(problem, solution, expert)\n",
    "            \n",
    "            # Get expert verification\n",
    "            response = self.llm.invoke([HumanMessage(content=instruction)])\n",
    "            \n",
    "            # Parse result\n",
    "            verification_result = self._parse_verification_response(response.content, expert, i + 1)\n",
    "            verification_results.append(verification_result)\n",
    "            \n",
    "            # Early stopping if high confidence consensus\n",
    "            if (self.config['enable_early_stopping'] and i >= 1 and\n",
    "                self._check_early_stopping_condition(verification_results)):\n",
    "                break\n",
    "        \n",
    "        # Calculate final assessment\n",
    "        consensus_score = self._calculate_consensus_score(verification_results)\n",
    "        final_confidence = self._determine_confidence_level(consensus_score, verification_results)\n",
    "        \n",
    "        # Determine if refinement needed\n",
    "        needs_refinement = (consensus_score < self.config['quality_threshold'] or\n",
    "                          any(vr.identified_errors for vr in verification_results))\n",
    "        \n",
    "        return {\n",
    "            'verified': consensus_score >= self.config['consensus_threshold'],\n",
    "            'consensus_score': consensus_score,\n",
    "            'confidence_level': final_confidence,\n",
    "            'needs_refinement': needs_refinement,\n",
    "            'verification_results': verification_results,\n",
    "            'recommendations': self._generate_recommendations(verification_results)\n",
    "        }\n",
    "    \n",
    "    def refine_solution(self, \n",
    "                       problem: str, \n",
    "                       solution: str, \n",
    "                       verification_feedback: Dict[str, Any]) -> str:\n",
    "        \"\"\"Refine solution based on verification feedback\"\"\"\n",
    "        \n",
    "        # Extract key issues and suggestions\n",
    "        all_errors = []\n",
    "        all_suggestions = []\n",
    "        \n",
    "        for vr in verification_feedback['verification_results']:\n",
    "            all_errors.extend(vr.identified_errors)\n",
    "            all_suggestions.extend(vr.suggested_corrections)\n",
    "        \n",
    "        # Create refinement instruction\n",
    "        refinement_instruction = f\"\"\"\n",
    "You are an Expert Problem Solver tasked with refining a solution based on expert feedback.\n",
    "\n",
    "ORIGINAL PROBLEM:\n",
    "{problem}\n",
    "\n",
    "CURRENT SOLUTION:\n",
    "{solution}\n",
    "\n",
    "ISSUES TO ADDRESS:\n",
    "\"\"\" + \"\\n\".join([f\"- {error}\" for error in all_errors[:5]]) + \"\"\"\n",
    "\n",
    "IMPROVEMENT SUGGESTIONS:\n",
    "\"\"\" + \"\\n\".join([f\"- {suggestion}\" for suggestion in all_suggestions[:5]]) + \"\"\"\n",
    "\n",
    "Provide a refined solution that addresses these issues while maintaining the strengths of the original solution.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.llm.invoke([HumanMessage(content=refinement_instruction)])\n",
    "        return response.content\n",
    "    \n",
    "    def verify_and_refine(self, \n",
    "                         problem: str, \n",
    "                         initial_solution: str,\n",
    "                         domain: str = \"general\") -> Dict[str, Any]:\n",
    "        \"\"\"Complete verification and refinement pipeline\"\"\"\n",
    "        \n",
    "        current_solution = initial_solution\n",
    "        iteration_history = []\n",
    "        \n",
    "        for iteration in range(self.config['max_refinement_iterations'] + 1):\n",
    "            # Verify current solution\n",
    "            verification_result = self.verify_solution(problem, current_solution, domain)\n",
    "            \n",
    "            iteration_data = {\n",
    "                'iteration': iteration,\n",
    "                'solution': current_solution,\n",
    "                'verification': verification_result\n",
    "            }\n",
    "            iteration_history.append(iteration_data)\n",
    "            \n",
    "            # Check if solution meets quality standards\n",
    "            if (verification_result['verified'] and \n",
    "                not verification_result['needs_refinement']):\n",
    "                break\n",
    "            \n",
    "            # Refine if not at max iterations\n",
    "            if iteration < self.config['max_refinement_iterations']:\n",
    "                current_solution = self.refine_solution(problem, current_solution, verification_result)\n",
    "        \n",
    "        return {\n",
    "            'final_solution': current_solution,\n",
    "            'final_verification': iteration_history[-1]['verification'],\n",
    "            'iteration_history': iteration_history,\n",
    "            'total_iterations': len(iteration_history),\n",
    "            'quality_achieved': iteration_history[-1]['verification']['verified']\n",
    "        }\n",
    "    \n",
    "    def _create_verification_instruction(self, problem: str, solution: str, expert: str) -> str:\n",
    "        \"\"\"Create verification instruction for expert\"\"\"\n",
    "        return f\"\"\"\n",
    "You are {expert}, verifying the accuracy of a solution.\n",
    "\n",
    "PROBLEM: {problem}\n",
    "\n",
    "SOLUTION TO VERIFY: {solution}\n",
    "\n",
    "Respond with:\n",
    "VERIFICATION: [CORRECT/INCORRECT/PARTIALLY_CORRECT]\n",
    "CONFIDENCE: [HIGH/MEDIUM/LOW]\n",
    "REASONING: [Your analysis]\n",
    "ERRORS_FOUND: [List errors or \"None\"]\n",
    "SUGGESTIONS: [Improvements or \"None\"]\n",
    "        \"\"\"\n",
    "    \n",
    "    def _parse_verification_response(self, response: str, expert: str, round_num: int) -> VerificationResult:\n",
    "        \"\"\"Parse verification response (simplified)\"\"\"\n",
    "        # This is a simplified version - use the full parser from above for production\n",
    "        is_correct = \"CORRECT\" in response.upper() and \"INCORRECT\" not in response.upper()\n",
    "        confidence = VerificationLevel.MEDIUM  # Default\n",
    "        \n",
    "        if \"HIGH\" in response.upper():\n",
    "            confidence = VerificationLevel.HIGH\n",
    "        elif \"LOW\" in response.upper():\n",
    "            confidence = VerificationLevel.LOW\n",
    "        \n",
    "        return VerificationResult(\n",
    "            is_correct=is_correct,\n",
    "            confidence_level=confidence,\n",
    "            expert_name=expert,\n",
    "            verification_reasoning=response,\n",
    "            verification_round=round_num\n",
    "        )\n",
    "    \n",
    "    def _calculate_consensus_score(self, verification_results: List[VerificationResult]) -> float:\n",
    "        \"\"\"Calculate consensus score (simplified)\"\"\"\n",
    "        if not verification_results:\n",
    "            return 0.0\n",
    "        \n",
    "        correct_count = sum(1 for vr in verification_results if vr.is_correct)\n",
    "        return correct_count / len(verification_results)\n",
    "    \n",
    "    def _determine_confidence_level(self, consensus_score: float, verification_results: List[VerificationResult]) -> VerificationLevel:\n",
    "        \"\"\"Determine overall confidence level\"\"\"\n",
    "        if consensus_score >= 0.8:\n",
    "            return VerificationLevel.HIGH\n",
    "        elif consensus_score >= 0.6:\n",
    "            return VerificationLevel.MEDIUM\n",
    "        else:\n",
    "            return VerificationLevel.LOW\n",
    "    \n",
    "    def _check_early_stopping_condition(self, verification_results: List[VerificationResult]) -> bool:\n",
    "        \"\"\"Check if early stopping conditions are met\"\"\"\n",
    "        if len(verification_results) < 2:\n",
    "            return False\n",
    "        \n",
    "        # Check if last two experts agree with high confidence\n",
    "        last_two = verification_results[-2:]\n",
    "        return (all(vr.confidence_level == VerificationLevel.HIGH for vr in last_two) and\n",
    "                all(vr.is_correct == last_two[0].is_correct for vr in last_two))\n",
    "    \n",
    "    def _generate_recommendations(self, verification_results: List[VerificationResult]) -> List[str]:\n",
    "        \"\"\"Generate actionable recommendations\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Collect all suggestions\n",
    "        all_suggestions = []\n",
    "        for vr in verification_results:\n",
    "            all_suggestions.extend(vr.suggested_corrections)\n",
    "        \n",
    "        # Return top unique suggestions\n",
    "        unique_suggestions = list(set(all_suggestions))\n",
    "        return unique_suggestions[:5]\n",
    "\n",
    "# Initialize production system\n",
    "production_config = {\n",
    "    'max_verification_rounds': 2,\n",
    "    'max_refinement_iterations': 1,\n",
    "    'quality_threshold': 0.8,\n",
    "    'consensus_threshold': 0.7,\n",
    "    'enable_early_stopping': True\n",
    "}\n",
    "\n",
    "production_verification = ProductionVerificationSystem(llm, production_config)\n",
    "\n",
    "print(\"\\n🚀 PRODUCTION VERIFICATION SYSTEM READY\")\n",
    "print(\"\\n✅ Key Features:\")\n",
    "print(\"  • Streamlined verification with domain-specific experts\")\n",
    "print(\"  • Automated refinement based on feedback\")\n",
    "print(\"  • Early stopping for efficiency\")\n",
    "print(\"  • Configurable quality thresholds\")\n",
    "print(\"  • Complete pipeline from initial solution to verified result\")\n",
    "print(\"\\n📊 Configuration:\")\n",
    "for key, value in production_config.items():\n",
    "    print(f\"  • {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Production System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the production verification system\n",
    "test_problem = \"\"\"\n",
    "A company has 120 employees. 40% work in sales, 25% in engineering, 20% in marketing, \n",
    "and the rest in administration. If the company plans to hire 30 more employees with \n",
    "the same proportional distribution, how many employees will work in each department \n",
    "after the expansion?\n",
    "\"\"\"\n",
    "\n",
    "test_solution = \"\"\"\n",
    "Current distribution:\n",
    "- Sales: 40% of 120 = 48 employees\n",
    "- Engineering: 25% of 120 = 30 employees  \n",
    "- Marketing: 20% of 120 = 24 employees\n",
    "- Administration: 15% of 120 = 18 employees\n",
    "\n",
    "New hires (30 employees):\n",
    "- Sales: 40% of 30 = 12 employees\n",
    "- Engineering: 25% of 30 = 7.5 ≈ 8 employees\n",
    "- Marketing: 20% of 30 = 6 employees\n",
    "- Administration: 15% of 30 = 4.5 ≈ 4 employees\n",
    "\n",
    "Final distribution:\n",
    "- Sales: 48 + 12 = 60 employees\n",
    "- Engineering: 30 + 8 = 38 employees\n",
    "- Marketing: 24 + 6 = 30 employees\n",
    "- Administration: 18 + 4 = 22 employees\n",
    "Total: 150 employees\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing Production Verification System...\")\n",
    "production_result = production_verification.verify_and_refine(\n",
    "    problem=test_problem.strip(),\n",
    "    initial_solution=test_solution.strip(),\n",
    "    domain=\"mathematical\"\n",
    ")\n",
    "\n",
    "print(f\"\\n=== PRODUCTION SYSTEM RESULTS ===\")\n",
    "print(f\"Quality Achieved: {production_result['quality_achieved']}\")\n",
    "print(f\"Total Iterations: {production_result['total_iterations']}\")\n",
    "print(f\"Final Consensus Score: {production_result['final_verification']['consensus_score']:.2f}\")\n",
    "print(f\"Final Confidence: {production_result['final_verification']['confidence_level'].value}\")\n",
    "\n",
    "if production_result['final_verification']['recommendations']:\n",
    "    print(f\"\\nRecommendations:\")\n",
    "    for i, rec in enumerate(production_result['final_verification']['recommendations'][:3], 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(f\"\\nFinal Solution Preview: {production_result['final_solution'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 🎯 **Multi-Round Verification Principles**\n",
    "1. **Systematic Dual Verification**: Always use multiple experts for independent validation\n",
    "2. **Fresh Eyes for Each Round**: Each verification expert sees only the problem and solution\n",
    "3. **Iterative Refinement**: Solutions improve through feedback-driven refinement cycles\n",
    "4. **Consensus-Based Assessment**: Aggregate multiple expert opinions for robust evaluation\n",
    "\n",
    "### 📊 **Paper Insights Validated**\n",
    "- **Wisdom of the Crowd**: Multiple expert perspectives consistently outperform single expert assessment\n",
    "- **Error Detection**: Fresh eyes approach significantly improves error detection rates\n",
    "- **Systematic Verification**: Structured verification protocols enhance solution reliability\n",
    "- **Quality Improvement**: Multi-round refinement achieves measurable quality gains\n",
    "\n",
    "### 🔧 **Implementation Best Practices**\n",
    "1. **Expert Selection**: Use domain-appropriate experts for verification\n",
    "2. **Confidence Weighting**: Weight expert opinions by their confidence levels\n",
    "3. **Early Stopping**: Implement efficient stopping criteria for high-confidence consensus\n",
    "4. **Error Categorization**: Track and categorize common error patterns\n",
    "5. **Quality Metrics**: Monitor verification system effectiveness over time\n",
    "\n",
    "### ⚖️ **Trade-offs**\n",
    "- **Quality vs. Speed**: More verification rounds improve quality but increase latency\n",
    "- **Consensus vs. Individual Excellence**: Group consensus may overlook brilliant individual insights\n",
    "- **Coverage vs. Depth**: Broader expert coverage vs. deeper domain-specific verification\n",
    "\n",
    "### 🚀 **Production Recommendations**\n",
    "1. **Start with 2-3 verification experts** for most problems\n",
    "2. **Implement early stopping** when high confidence consensus is reached\n",
    "3. **Use domain-specific expert selection** for better verification quality\n",
    "4. **Track quality metrics** to optimize verification parameters\n",
    "5. **Cache verification patterns** for similar problems to improve efficiency\n",
    "\n",
    "### 📈 **Quality Indicators**\n",
    "- **Consensus Score**: >0.8 indicates high agreement among experts\n",
    "- **Confidence Level**: HIGH confidence with consensus suggests reliable solution\n",
    "- **Error Detection Rate**: Higher rates indicate more thorough verification\n",
    "- **Expert Agreement**: High agreement suggests stable, reliable assessment\n",
    "\n",
    "Multi-Round Verification and Error Correction is the quality assurance engine of meta-prompting, ensuring solutions are accurate, reliable, and continuously improved through systematic expert validation and iterative refinement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}