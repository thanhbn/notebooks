{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Chains trong LangChain\n",
    "\n",
    "## Kh√°i ni·ªám v·ªÅ Chains\n",
    "\n",
    "### Chains l√† g√¨?\n",
    "**Chain** trong LangChain l√† c√°ch ƒë·ªÉ k·∫øt n·ªëi nhi·ªÅu components l·∫°i v·ªõi nhau th√†nh m·ªôt workflow c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng. Chains cho ph√©p:\n",
    "\n",
    "- **K·∫øt n·ªëi** c√°c components nh∆∞ Prompts, LLMs, Output Parsers\n",
    "- **T·ª± ƒë·ªông h√≥a** data flow gi·ªØa c√°c b∆∞·ªõc\n",
    "- **T√°i s·ª≠ d·ª•ng** logic x·ª≠ l√Ω ph·ª©c t·∫°p\n",
    "- **Compose** c√°c chains nh·ªè th√†nh chains l·ªõn h∆°n\n",
    "\n",
    "### T·∫°i sao c·∫ßn Chains?\n",
    "1. **Modularity**: Chia nh·ªè complex tasks th√†nh manageable pieces\n",
    "2. **Reusability**: S·ª≠ d·ª•ng l·∫°i chains cho different inputs\n",
    "3. **Maintainability**: D·ªÖ debug v√† modify t·ª´ng component\n",
    "4. **Composability**: K·∫øt h·ª£p chains ƒë·ªÉ t·∫°o workflows ph·ª©c t·∫°p\n",
    "\n",
    "### Chain Operators trong LangChain\n",
    "LangChain s·ª≠ d·ª•ng **pipe operator** (`|`) ƒë·ªÉ chain components:\n",
    "```python\n",
    "chain = prompt | llm | output_parser\n",
    "```\n",
    "\n",
    "ƒêi·ªÅu n√†y t∆∞∆°ng ƒë∆∞∆°ng v·ªõi:\n",
    "```python\n",
    "def chain(input_data):\n",
    "    prompt_output = prompt.format(**input_data)\n",
    "    llm_output = llm.invoke(prompt_output)\n",
    "    final_output = output_parser.parse(llm_output)\n",
    "    return final_output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup v√† Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# LangChain Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Output Parsers\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úì ƒê√£ import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o ChatAnthropic\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    temperature=0.7,\n",
    "    anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"‚úì LLM ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chain ƒë∆°n gi·∫£n nh·∫•t: Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o prompt template ƒë∆°n gi·∫£n\n",
    "simple_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Vi·∫øt m·ªôt c√¢u th∆° ng·∫Øn v·ªÅ {topic}. H√£y s√°ng t·∫°o v√† c√≥ c·∫£m x√∫c.\"\n",
    ")\n",
    "\n",
    "# T·∫°o chain ƒë∆°n gi·∫£n: prompt + llm\n",
    "simple_chain = simple_prompt | llm\n",
    "\n",
    "print(\"‚úì Simple chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: prompt | llm\")\n",
    "\n",
    "# Test chain\n",
    "result = simple_chain.invoke({\"topic\": \"m√πa xu√¢n\"})\n",
    "\n",
    "print(f\"\\n=== Test Simple Chain ===\")\n",
    "print(f\"Input: topic='m√πa xu√¢n'\")\n",
    "print(f\"Output type: {type(result)}\")\n",
    "print(f\"Output: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v·ªõi nhi·ªÅu topics kh√°c nhau\n",
    "topics = [\"bi·ªÉn c·∫£\", \"n√∫i r·ª´ng\", \"th√†nh ph·ªë\", \"t√¨nh y√™u\"]\n",
    "\n",
    "print(\"=== Testing v·ªõi nhi·ªÅu topics ===\")\n",
    "for topic in topics:\n",
    "    result = simple_chain.invoke({\"topic\": topic})\n",
    "    print(f\"\\nüé® Topic: {topic}\")\n",
    "    print(f\"üìù Th∆°: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chain v·ªõi Output Parser: Prompt + LLM + Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain v·ªõi String Output Parser\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "# Chain ho√†n ch·ªânh: prompt + llm + parser\n",
    "string_chain = simple_prompt | llm | str_parser\n",
    "\n",
    "print(\"‚úì String chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: prompt | llm | str_parser\")\n",
    "\n",
    "# Test v√† so s√°nh\n",
    "test_topic = \"m√πa thu\"\n",
    "\n",
    "# Without parser\n",
    "without_parser = simple_chain.invoke({\"topic\": test_topic})\n",
    "print(f\"\\n=== So s√°nh Output ===\")\n",
    "print(f\"Without parser - Type: {type(without_parser)}\")\n",
    "print(f\"Without parser - Content: {without_parser.content}\")\n",
    "\n",
    "# With parser\n",
    "with_parser = string_chain.invoke({\"topic\": test_topic})\n",
    "print(f\"\\nWith parser - Type: {type(with_parser)}\")\n",
    "print(f\"With parser - Content: {with_parser}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain v·ªõi List Output Parser\n",
    "list_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Li·ªát k√™ 5 ƒëi·ªÅu th√∫ v·ªã v·ªÅ {subject}.\n",
    "    \n",
    "    {format_instructions}\"\"\"\n",
    ")\n",
    "\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Chain v·ªõi list parser\n",
    "list_chain = list_prompt | llm | list_parser\n",
    "\n",
    "print(\"‚úì List chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(f\"Format instructions: {list_parser.get_format_instructions()}\")\n",
    "\n",
    "# Test list chain\n",
    "subjects = [\"v≈© tr·ª•\", \"ƒë·∫°i d∆∞∆°ng\", \"tr√≠ tu·ªá nh√¢n t·∫°o\"]\n",
    "\n",
    "print(f\"\\n=== Testing List Chain ===\")\n",
    "for subject in subjects:\n",
    "    result = list_chain.invoke({\n",
    "        \"subject\": subject,\n",
    "        \"format_instructions\": list_parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìö Subject: {subject}\")\n",
    "    print(f\"üìã Type: {type(result)}\")\n",
    "    print(f\"üìù List items:\")\n",
    "    for i, item in enumerate(result, 1):\n",
    "        print(f\"   {i}. {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chain v·ªõi Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a Pydantic model cho structured output\n",
    "class ProductReview(BaseModel):\n",
    "    product_name: str = Field(description=\"T√™n s·∫£n ph·∫©m\")\n",
    "    rating: int = Field(description=\"ƒê√°nh gi√° t·ª´ 1-5 sao\", ge=1, le=5)\n",
    "    pros: List[str] = Field(description=\"C√°c ∆∞u ƒëi·ªÉm\")\n",
    "    cons: List[str] = Field(description=\"C√°c nh∆∞·ª£c ƒëi·ªÉm\")\n",
    "    summary: str = Field(description=\"T√≥m t·∫Øt ƒë√°nh gi√°\")\n",
    "    would_recommend: bool = Field(description=\"C√≥ recommend hay kh√¥ng\")\n",
    "\n",
    "# T·∫°o parser t·ª´ Pydantic model\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=ProductReview)\n",
    "\n",
    "# Prompt cho product review\n",
    "review_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Ph√¢n t√≠ch ƒë√°nh gi√° s·∫£n ph·∫©m sau v√† tr√≠ch xu·∫•t th√¥ng tin c√≥ c·∫•u tr√∫c:\n",
    "    \n",
    "    ƒê√°nh gi√°: {review_text}\n",
    "    \n",
    "    {format_instructions}\"\"\"\n",
    ")\n",
    "\n",
    "# T·∫°o structured chain\n",
    "structured_chain = review_prompt | llm | pydantic_parser\n",
    "\n",
    "print(\"‚úì Structured chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: prompt | llm | pydantic_parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test structured chain\n",
    "sample_review = \"\"\"\n",
    "iPhone 15 Pro Max th·ª±c s·ª± ·∫•n t∆∞·ª£ng! M√†n h√¨nh 6.7 inch si√™u s·∫Øc n√©t, \n",
    "camera 48MP ch·ª•p ·∫£nh c·ª±c ƒë·∫πp, ƒë·∫∑c bi·ªát l√† ch·∫ø ƒë·ªô ch·ª•p ƒë√™m. \n",
    "Pin s·ª≠ d·ª•ng ƒë∆∞·ª£c c·∫£ ng√†y m√† kh√¥ng c·∫ßn s·∫°c. \n",
    "Tuy nhi√™n gi√° h∆°i cao, kho·∫£ng 35 tri·ªáu, v√† h∆°i n·∫∑ng so v·ªõi c√°c d√≤ng tr∆∞·ªõc. \n",
    "Nh√¨n chung m√¨nh r·∫•t h√†i l√≤ng v√† s·∫Ω recommend cho b·∫°n b√®.\n",
    "\"\"\"\n",
    "\n",
    "result = structured_chain.invoke({\n",
    "    \"review_text\": sample_review,\n",
    "    \"format_instructions\": pydantic_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"=== Structured Output ===\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"\\nüì± Product: {result.product_name}\")\n",
    "print(f\"‚≠ê Rating: {result.rating}/5\")\n",
    "print(f\"‚úÖ Would recommend: {result.would_recommend}\")\n",
    "print(f\"\\nüü¢ Pros:\")\n",
    "for pro in result.pros:\n",
    "    print(f\"   ‚Ä¢ {pro}\")\n",
    "print(f\"\\nüî¥ Cons:\")\n",
    "for con in result.cons:\n",
    "    print(f\"   ‚Ä¢ {con}\")\n",
    "print(f\"\\nüìù Summary: {result.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain v·ªõi Conditional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o conditional logic v·ªõi RunnableLambda\n",
    "def determine_response_style(input_dict):\n",
    "    \"\"\"X√°c ƒë·ªãnh style ph·∫£n h·ªìi d·ª±a tr√™n audience\"\"\"\n",
    "    audience = input_dict.get(\"audience\", \"general\")\n",
    "    topic = input_dict.get(\"topic\", \"\")\n",
    "    \n",
    "    if audience == \"kids\":\n",
    "        style = \"ƒë∆°n gi·∫£n, vui nh·ªôn, d·ªÖ hi·ªÉu\"\n",
    "    elif audience == \"experts\":\n",
    "        style = \"chuy√™n s√¢u, k·ªπ thu·∫≠t, chi ti·∫øt\"\n",
    "    elif audience == \"business\":\n",
    "        style = \"chuy√™n nghi·ªáp, s√∫c t√≠ch, t·∫≠p trung v√†o gi√° tr·ªã\"\n",
    "    else:\n",
    "        style = \"c√¢n b·∫±ng, d·ªÖ hi·ªÉu, th√¥ng tin ƒë·∫ßy ƒë·ªß\"\n",
    "    \n",
    "    return {\n",
    "        \"topic\": topic,\n",
    "        \"audience\": audience,\n",
    "        \"style\": style\n",
    "    }\n",
    "\n",
    "# Prompt ƒë·ªông d·ª±a tr√™n style\n",
    "adaptive_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Gi·∫£i th√≠ch v·ªÅ {topic} cho ƒë·ªëi t∆∞·ª£ng {audience}.\n",
    "    \n",
    "    Style y√™u c·∫ßu: {style}\n",
    "    \n",
    "    H√£y ƒëi·ªÅu ch·ªânh ng√¥n ng·ªØ v√† ƒë·ªô ph·ª©c t·∫°p cho ph√π h·ª£p.\"\"\"\n",
    ")\n",
    "\n",
    "# T·∫°o conditional chain\n",
    "conditional_chain = (\n",
    "    RunnableLambda(determine_response_style) \n",
    "    | adaptive_prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úì Conditional chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: style_determiner | prompt | llm | parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conditional chain v·ªõi different audiences\n",
    "test_cases = [\n",
    "    {\"topic\": \"tr√≠ tu·ªá nh√¢n t·∫°o\", \"audience\": \"kids\"},\n",
    "    {\"topic\": \"tr√≠ tu·ªá nh√¢n t·∫°o\", \"audience\": \"experts\"},\n",
    "    {\"topic\": \"tr√≠ tu·ªá nh√¢n t·∫°o\", \"audience\": \"business\"},\n",
    "    {\"topic\": \"tr√≠ tu·ªá nh√¢n t·∫°o\", \"audience\": \"general\"}\n",
    "]\n",
    "\n",
    "print(\"=== Testing Conditional Chain ===\")\n",
    "for test_case in test_cases:\n",
    "    result = conditional_chain.invoke(test_case)\n",
    "    \n",
    "    print(f\"\\nüéØ Audience: {test_case['audience']}\")\n",
    "    print(f\"üìñ Topic: {test_case['topic']}\")\n",
    "    print(f\"üí¨ Response: {result[:200]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain v·ªõi Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing functions\n",
    "def extract_keywords(input_dict):\n",
    "    \"\"\"Extract keywords t·ª´ text\"\"\"\n",
    "    text = input_dict[\"text\"]\n",
    "    # Simplified keyword extraction\n",
    "    words = text.lower().split()\n",
    "    # Filter out common words (simplified)\n",
    "    stop_words = {\"v√†\", \"c·ªßa\", \"trong\", \"v·ªõi\", \"t·ª´\", \"ƒë·ªÉ\", \"c√≥\", \"l√†\", \"m·ªôt\", \"c√°c\", \"n√†y\", \"ƒë√≥\"}\n",
    "    keywords = [word for word in words if len(word) > 3 and word not in stop_words]\n",
    "    # Take top 5 unique keywords\n",
    "    unique_keywords = list(dict.fromkeys(keywords))[:5]\n",
    "    \n",
    "    return {\n",
    "        \"original_text\": text,\n",
    "        \"keywords\": unique_keywords\n",
    "    }\n",
    "\n",
    "def format_summary_prompt(input_dict):\n",
    "    \"\"\"Format prompt v·ªõi keywords\"\"\"\n",
    "    return {\n",
    "        \"text\": input_dict[\"original_text\"],\n",
    "        \"keywords\": \", \".join(input_dict[\"keywords\"])\n",
    "    }\n",
    "\n",
    "# Prompt cho summarization\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"T√≥m t·∫Øt vƒÉn b·∫£n sau th√†nh 2-3 c√¢u, t·∫≠p trung v√†o c√°c t·ª´ kh√≥a ch√≠nh: {keywords}\n",
    "    \n",
    "    VƒÉn b·∫£n: {text}\n",
    "    \n",
    "    T√≥m t·∫Øt:\"\"\"\n",
    ")\n",
    "\n",
    "# T·∫°o processing chain\n",
    "processing_chain = (\n",
    "    RunnableLambda(extract_keywords)\n",
    "    | RunnableLambda(format_summary_prompt)\n",
    "    | summary_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úì Processing chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: keyword_extract | format | prompt | llm | parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test processing chain\n",
    "sample_text = \"\"\"\n",
    "LangChain l√† m·ªôt framework m·∫°nh m·∫Ω ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph√°t tri·ªÉn c√°c ·ª©ng d·ª•ng \n",
    "s·ª≠ d·ª•ng Large Language Models (LLMs). Framework n√†y cung c·∫•p nhi·ªÅu c√¥ng c·ª• \n",
    "v√† abstractions gi√∫p developers d·ªÖ d√†ng t√≠ch h·ª£p LLMs v√†o c√°c ·ª©ng d·ª•ng th·ª±c t·∫ø. \n",
    "LangChain h·ªó tr·ª£ nhi·ªÅu LLM providers kh√°c nhau nh∆∞ OpenAI, Anthropic, Cohere, \n",
    "v√† Hugging Face. C√°c th√†nh ph·∫ßn ch√≠nh c·ªßa LangChain bao g·ªìm Chains, Agents, \n",
    "Memory, v√† Callbacks. Chains cho ph√©p k·∫øt n·ªëi nhi·ªÅu components l·∫°i v·ªõi nhau \n",
    "ƒë·ªÉ t·∫°o ra workflows ph·ª©c t·∫°p. Agents c√≥ kh·∫£ nƒÉng reasoning v√† t·ª± quy·∫øt ƒë·ªãnh \n",
    "actions c·∫ßn th·ª±c hi·ªán. Memory gi√∫p l∆∞u tr·ªØ conversation history ƒë·ªÉ maintain \n",
    "context gi·ªØa c√°c l·∫ßn t∆∞∆°ng t√°c.\n",
    "\"\"\"\n",
    "\n",
    "# Test keyword extraction step\n",
    "keywords_result = extract_keywords({\"text\": sample_text})\n",
    "print(\"=== Keyword Extraction ===\")\n",
    "print(f\"Keywords: {keywords_result['keywords']}\")\n",
    "\n",
    "# Test full chain\n",
    "summary_result = processing_chain.invoke({\"text\": sample_text})\n",
    "print(f\"\\n=== Summary Result ===\")\n",
    "print(f\"Original length: {len(sample_text)} characters\")\n",
    "print(f\"Summary: {summary_result}\")\n",
    "print(f\"Summary length: {len(summary_result)} characters\")\n",
    "print(f\"Compression ratio: {len(summary_result)/len(sample_text):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chain v·ªõi Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o chain tr·∫£ v·ªÅ multiple outputs\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Different prompts cho different tasks\n",
    "sentiment_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa text sau (T√≠ch c·ª±c/Ti√™u c·ª±c/Trung l·∫≠p): {text}\"\n",
    ")\n",
    "\n",
    "category_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Ph√¢n lo·∫°i ch·ªß ƒë·ªÅ c·ªßa text sau (C√¥ng ngh·ªá/Kinh doanh/Gi·∫£i tr√≠/Kh√°c): {text}\"\n",
    ")\n",
    "\n",
    "language_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ƒê√°nh gi√° ƒë·ªô ph·ª©c t·∫°p ng√¥n ng·ªØ c·ªßa text sau (ƒê∆°n gi·∫£n/Trung b√¨nh/Ph·ª©c t·∫°p): {text}\"\n",
    ")\n",
    "\n",
    "# T·∫°o parallel chains\n",
    "parallel_chain = RunnableParallel(\n",
    "    sentiment=sentiment_prompt | llm | StrOutputParser(),\n",
    "    category=category_prompt | llm | StrOutputParser(),\n",
    "    complexity=language_prompt | llm | StrOutputParser(),\n",
    "    original_text=RunnablePassthrough()\n",
    ")\n",
    "\n",
    "print(\"‚úì Parallel chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain structure: parallel(sentiment, category, complexity, original)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parallel chain\n",
    "test_texts = [\n",
    "    \"T√¥i r·∫•t h√†o h·ª©ng v·ªõi c√¥ng ngh·ªá AI m·ªõi n√†y! N√≥ s·∫Ω thay ƒë·ªïi c√°ch ch√∫ng ta l√†m vi·ªác.\",\n",
    "    \"Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n h√¥m nay gi·∫£m m·∫°nh, nhi·ªÅu nh√† ƒë·∫ßu t∆∞ lo l·∫Øng v·ªÅ tri·ªÉn v·ªçng kinh t·∫ø.\",\n",
    "    \"B·ªô phim h√¥m qua kh√° hay, di·ªÖn vi√™n di·ªÖn xu·∫•t t·ª± nhi√™n v√† k·ªãch b·∫£n h·∫•p d·∫´n.\"\n",
    "]\n",
    "\n",
    "print(\"=== Testing Parallel Chain ===\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    result = parallel_chain.invoke({\"text\": text})\n",
    "    \n",
    "    print(f\"\\nüìÑ Text {i}: {text[:80]}...\")\n",
    "    print(f\"üòä Sentiment: {result['sentiment']}\")\n",
    "    print(f\"üìÇ Category: {result['category']}\")\n",
    "    print(f\"üéØ Complexity: {result['complexity']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chain Composition - K·∫øt h·ª£p chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o analysis chain t·ª´ parallel chain\n",
    "def combine_analysis(parallel_result):\n",
    "    \"\"\"Combine results t·ª´ parallel analysis\"\"\"\n",
    "    return {\n",
    "        \"text\": parallel_result[\"original_text\"][\"text\"],\n",
    "        \"sentiment\": parallel_result[\"sentiment\"],\n",
    "        \"category\": parallel_result[\"category\"],\n",
    "        \"complexity\": parallel_result[\"complexity\"]\n",
    "    }\n",
    "\n",
    "# Final summary prompt\n",
    "final_summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"D·ª±a tr√™n ph√¢n t√≠ch sau, t·∫°o m·ªôt b√°o c√°o t√≥m t·∫Øt v·ªÅ vƒÉn b·∫£n:\n",
    "    \n",
    "    Text: {text}\n",
    "    C·∫£m x√∫c: {sentiment}\n",
    "    Ch·ªß ƒë·ªÅ: {category}\n",
    "    ƒê·ªô ph·ª©c t·∫°p: {complexity}\n",
    "    \n",
    "    B√°o c√°o t√≥m t·∫Øt (2-3 c√¢u):\"\"\"\n",
    ")\n",
    "\n",
    "# Composed chain: parallel analysis ‚Üí combine ‚Üí final summary\n",
    "composed_chain = (\n",
    "    parallel_chain\n",
    "    | RunnableLambda(combine_analysis)\n",
    "    | final_summary_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úì Composed chain ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "print(\"Chain: parallel_analysis | combine | summary_prompt | llm | parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test composed chain\n",
    "complex_text = \"\"\"\n",
    "Vi·ªác ·ª©ng d·ª•ng tr√≠ tu·ªá nh√¢n t·∫°o trong chƒÉm s√≥c s·ª©c kh·ªèe ƒëang m·ªü ra nh·ªØng \n",
    "c∆° h·ªôi to l·ªõn nh∆∞ng c≈©ng ƒë·∫∑t ra nhi·ªÅu th√°ch th·ª©c v·ªÅ ƒë·∫°o ƒë·ª©c v√† quy·ªÅn ri√™ng t∆∞. \n",
    "C√°c thu·∫≠t to√°n machine learning c√≥ th·ªÉ gi√∫p ch·∫©n ƒëo√°n b·ªánh ch√≠nh x√°c h∆°n, \n",
    "nh∆∞ng vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu y t·∫ø nh·∫°y c·∫£m c·∫ßn ƒë∆∞·ª£c th·ª±c hi·ªán c·∫©n tr·ªçng. \n",
    "S·ª± h·ª£p t√°c gi·ªØa c√°c chuy√™n gia y t·∫ø, k·ªπ s∆∞ ph·∫ßn m·ªÅm v√† c√°c nh√† ho·∫°ch ƒë·ªãnh \n",
    "ch√≠nh s√°ch l√† c·∫ßn thi·∫øt ƒë·ªÉ ƒë·∫£m b·∫£o AI ƒë∆∞·ª£c s·ª≠ d·ª•ng m·ªôt c√°ch c√≥ tr√°ch nhi·ªám \n",
    "v√† mang l·∫°i l·ª£i √≠ch t·ªëi ƒëa cho b·ªánh nh√¢n.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Testing Composed Chain ===\")\n",
    "print(f\"Input text: {complex_text[:100]}...\")\n",
    "print(f\"\\nüìä Running parallel analysis...\")\n",
    "\n",
    "# Test parallel analysis first\n",
    "parallel_result = parallel_chain.invoke({\"text\": complex_text})\n",
    "print(f\"Sentiment: {parallel_result['sentiment']}\")\n",
    "print(f\"Category: {parallel_result['category']}\")\n",
    "print(f\"Complexity: {parallel_result['complexity']}\")\n",
    "\n",
    "# Test full composed chain\n",
    "print(f\"\\nüìù Generating final summary...\")\n",
    "final_result = composed_chain.invoke({\"text\": complex_text})\n",
    "print(f\"\\nüìã Final Summary:\\n{final_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Handling trong Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain v·ªõi error handling\n",
    "def safe_text_processor(input_dict):\n",
    "    \"\"\"Process text v·ªõi error handling\"\"\"\n",
    "    try:\n",
    "        text = input_dict.get(\"text\", \"\")\n",
    "        if not text or len(text.strip()) == 0:\n",
    "            return {\"error\": \"Empty text provided\", \"processed_text\": \"\"}\n",
    "        \n",
    "        if len(text) > 5000:\n",
    "            return {\n",
    "                \"warning\": \"Text too long, truncating\",\n",
    "                \"processed_text\": text[:5000] + \"...\"\n",
    "            }\n",
    "        \n",
    "        return {\"processed_text\": text, \"status\": \"success\"}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"processed_text\": \"\"}\n",
    "\n",
    "def handle_processing_result(result):\n",
    "    \"\"\"Handle result t·ª´ text processor\"\"\"\n",
    "    if \"error\" in result:\n",
    "        return {\"text\": f\"Error: {result['error']}\"}\n",
    "    \n",
    "    if \"warning\" in result:\n",
    "        print(f\"‚ö†Ô∏è Warning: {result['warning']}\")\n",
    "    \n",
    "    return {\"text\": result[\"processed_text\"]}\n",
    "\n",
    "# Safe chain v·ªõi error handling\n",
    "safe_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Ph√¢n t√≠ch v√† t√≥m t·∫Øt vƒÉn b·∫£n sau: {text}\"\n",
    ")\n",
    "\n",
    "safe_chain = (\n",
    "    RunnableLambda(safe_text_processor)\n",
    "    | RunnableLambda(handle_processing_result)\n",
    "    | safe_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úì Safe chain v·ªõi error handling ƒë√£ ƒë∆∞·ª£c t·∫°o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling\n",
    "test_cases_error = [\n",
    "    {\"text\": \"\"},  # Empty text\n",
    "    {\"text\": \"   \"},  # Whitespace only\n",
    "    {\"text\": \"Normal text ƒë·ªÉ test.\"},  # Normal case\n",
    "    {\"text\": \"A\" * 6000},  # Very long text\n",
    "]\n",
    "\n",
    "print(\"=== Testing Error Handling ===\")\n",
    "for i, test_case in enumerate(test_cases_error, 1):\n",
    "    try:\n",
    "        result = safe_chain.invoke(test_case)\n",
    "        print(f\"\\n‚úÖ Test {i}: Success\")\n",
    "        if len(str(result)) > 200:\n",
    "            print(f\"Result: {str(result)[:200]}...\")\n",
    "        else:\n",
    "            print(f\"Result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Test {i}: Error - {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Chain Performance v√† Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "# Performance monitoring wrapper\n",
    "def monitor_performance(chain_name):\n",
    "    \"\"\"Decorator ƒë·ªÉ monitor chain performance\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                end_time = time.time()\n",
    "                duration = end_time - start_time\n",
    "                print(f\"‚è±Ô∏è {chain_name}: {duration:.2f}s\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                end_time = time.time()\n",
    "                duration = end_time - start_time\n",
    "                print(f\"‚ùå {chain_name}: Failed after {duration:.2f}s - {str(e)}\")\n",
    "                raise\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Benchmark different chains\n",
    "@monitor_performance(\"Simple Chain\")\n",
    "def run_simple_chain(input_data):\n",
    "    return string_chain.invoke(input_data)\n",
    "\n",
    "@monitor_performance(\"Structured Chain\")\n",
    "def run_structured_chain(input_data):\n",
    "    return structured_chain.invoke(input_data)\n",
    "\n",
    "@monitor_performance(\"Parallel Chain\")\n",
    "def run_parallel_chain(input_data):\n",
    "    return parallel_chain.invoke(input_data)\n",
    "\n",
    "# Test performance\n",
    "test_input = {\"topic\": \"blockchain technology\"}\n",
    "test_review = {\n",
    "    \"review_text\": \"S·∫£n ph·∫©m t·ªët, giao h√†ng nhanh, gi√° h·ª£p l√Ω. Recommend!\",\n",
    "    \"format_instructions\": pydantic_parser.get_format_instructions()\n",
    "}\n",
    "test_text = {\"text\": \"AI ƒëang thay ƒë·ªïi th·∫ø gi·ªõi m·ªôt c√°ch t√≠ch c·ª±c.\"}\n",
    "\n",
    "print(\"=== Performance Benchmark ===\")\n",
    "print(\"Testing chain performance...\")\n",
    "\n",
    "# Run benchmarks\n",
    "simple_result = run_simple_chain(test_input)\n",
    "structured_result = run_structured_chain(test_review)\n",
    "parallel_result = run_parallel_chain(test_text)\n",
    "\n",
    "print(\"\\n‚úÖ All benchmarks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices cho Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices demonstration\n",
    "def demonstrate_best_practices():\n",
    "    print(\"=== SIMPLE CHAINS BEST PRACTICES ===\")\n",
    "    \n",
    "    practices = [\n",
    "        {\n",
    "            \"title\": \"1. START SIMPLE\",\n",
    "            \"description\": \"Begin v·ªõi basic prompt | llm chain\",\n",
    "            \"example\": \"prompt | llm | parser\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2. ADD PARSERS\",\n",
    "            \"description\": \"Always use output parsers for consistent results\",\n",
    "            \"example\": \"StrOutputParser, JsonOutputParser, PydanticOutputParser\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"3. ERROR HANDLING\",\n",
    "            \"description\": \"Implement graceful error handling\",\n",
    "            \"example\": \"RunnableLambda v·ªõi try-catch blocks\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"4. COMPOSABILITY\",\n",
    "            \"description\": \"Design chains to be composable\",\n",
    "            \"example\": \"Small chains ‚Üí Combined chains\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"5. MONITORING\",\n",
    "            \"description\": \"Monitor performance v√† errors\",\n",
    "            \"example\": \"Timing, logging, error tracking\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for practice in practices:\n",
    "        print(f\"\\n{practice['title']}\")\n",
    "        print(f\"   {practice['description']}\")\n",
    "        print(f\"   Example: {practice['example']}\")\n",
    "\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common pitfalls v√† solutions\n",
    "def common_pitfalls():\n",
    "    print(\"\\n=== COMMON PITFALLS & SOLUTIONS ===\")\n",
    "    \n",
    "    pitfalls = [\n",
    "        {\n",
    "            \"problem\": \"‚ùå No Output Parsing\",\n",
    "            \"issue\": \"Raw LLM output kh√¥ng consistent\",\n",
    "            \"solution\": \"‚úÖ Always use appropriate parsers\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"‚ùå Complex Single Chain\",\n",
    "            \"issue\": \"Monolithic chain kh√≥ debug\",\n",
    "            \"solution\": \"‚úÖ Break into smaller, testable chains\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"‚ùå No Error Handling\",\n",
    "            \"issue\": \"Chain fails v·ªõi invalid input\",\n",
    "            \"solution\": \"‚úÖ Implement input validation v√† error handling\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"‚ùå Hardcoded Values\",\n",
    "            \"issue\": \"Chain kh√¥ng flexible\",\n",
    "            \"solution\": \"‚úÖ Use parameters v√† conditional logic\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"‚ùå No Testing\",\n",
    "            \"issue\": \"Bugs in production\",\n",
    "            \"solution\": \"‚úÖ Test each component v√† full chain\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for pitfall in pitfalls:\n",
    "        print(f\"\\n{pitfall['problem']}\")\n",
    "        print(f\"   Issue: {pitfall['issue']}\")\n",
    "        print(f\"   {pitfall['solution']}\")\n",
    "\n",
    "common_pitfalls()\n",
    "\n",
    "print(\"\\n‚úÖ Simple Chains tutorial completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T·ªïng k·∫øt\n",
    "\n",
    "### **Simple Chains: Key Concepts**\n",
    "\n",
    "#### **Chain Basics**\n",
    "- **Purpose**: K·∫øt n·ªëi components th√†nh reusable workflows\n",
    "- **Operator**: Pipe (`|`) ƒë·ªÉ chain components\n",
    "- **Flow**: Data t·ª± ƒë·ªông flow t·ª´ component n√†y sang component kh√°c\n",
    "\n",
    "#### **Chain Patterns h·ªçc ƒë∆∞·ª£c**\n",
    "1. **Basic Chain**: `prompt | llm`\n",
    "2. **With Parser**: `prompt | llm | parser`\n",
    "3. **Conditional**: `logic | prompt | llm | parser`\n",
    "4. **Parallel**: `RunnableParallel` cho multiple outputs\n",
    "5. **Composed**: K·∫øt h·ª£p multiple chains\n",
    "\n",
    "#### **Components ƒë√£ s·ª≠ d·ª•ng**\n",
    "- **ChatPromptTemplate**: Structured prompts\n",
    "- **ChatAnthropic**: LLM for generation\n",
    "- **Output Parsers**: String, List, Pydantic\n",
    "- **RunnableLambda**: Custom logic\n",
    "- **RunnableParallel**: Parallel execution\n",
    "\n",
    "### **Best Practices**\n",
    "1. **Start Simple**: Begin v·ªõi basic chain, add complexity gradually\n",
    "2. **Always Parse**: Use output parsers cho consistent results\n",
    "3. **Error Handling**: Implement graceful error handling\n",
    "4. **Composability**: Design for reusability v√† composition\n",
    "5. **Testing**: Test individual components v√† full chains\n",
    "6. **Monitoring**: Track performance v√† errors\n",
    "\n",
    "### **Next Steps**\n",
    "- **Sequential Chains**: Multi-step workflows\n",
    "- **Retrieval Chains**: Combine v·ªõi vectorstores\n",
    "- **Agent Chains**: Decision-making workflows\n",
    "- **Production**: Deployment, scaling, monitoring\n",
    "\n",
    "Simple Chains l√† foundation cho complex LangChain applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}