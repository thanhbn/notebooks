{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af4e9d5",
   "metadata": {},
   "source": [
    "# LangGraph Advanced – Part 5️⃣: Multi‑Step Support Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4534d",
   "metadata": {},
   "source": [
    "Workflow đa bước (user → retrieve → answer → moderation → approve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain langchain-anthropic chromadb tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessageState\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import HumanMessage\n",
    "import random\n",
    "\n",
    "llm = ChatAnthropic(model_name=\"claude-3-haiku-20240307\", temperature=0.3)\n",
    "\n",
    "class S(MessageState):\n",
    "    question:str|None=None\n",
    "    answer:str|None=None\n",
    "\n",
    "def ask(_:S):\n",
    "    return S(question=input(\"Ask: \"))\n",
    "\n",
    "def retrieve(state:S):\n",
    "    state.context=\"fake-doc\"\n",
    "    return state\n",
    "\n",
    "def answer(state:S):\n",
    "    state.answer = llm([HumanMessage(content=f\"{state.question}\\nCONTEXT:{state.context}\")]).content\n",
    "    return state\n",
    "\n",
    "def moderate(state:S):\n",
    "    if \"bad\" in state.answer.lower():\n",
    "        state.answer=\"[moderated]\"\n",
    "    return state\n",
    "\n",
    "g = StateGraph(S)\n",
    "g.add_node(\"ask\", ask)\n",
    "g.add_node(\"ret\", retrieve)\n",
    "g.add_node(\"ans\", answer)\n",
    "g.add_node(\"mod\", moderate)\n",
    "g.set_entry_point(\"ask\")\n",
    "g.add_edge(\"ask\",\"ret\").add_edge(\"ret\",\"ans\").add_edge(\"ans\",\"mod\")\n",
    "g.compile().invoke(S())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
