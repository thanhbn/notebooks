{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AutoKaggle: Machine Learning Tools Library\n",
        "\n",
        "## Mục Tiêu\n",
        "\n",
        "Notebook này tập trung vào phân tích chuyên sâu về thư viện công cụ học máy (Machine Learning Tools Library) được giới thiệu trong bài báo \"AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions\". Chúng ta sẽ khám phá cách thiết kế, tổ chức và triển khai một bộ công cụ toàn diện hỗ trợ toàn bộ quy trình khoa học dữ liệu.\n",
        "\n",
        "Sau khi hoàn thành notebook này, bạn sẽ:\n",
        "1. Hiểu được cách tổ chức thư viện công cụ ML theo các danh mục chức năng\n",
        "2. Nắm được thiết kế API nhất quán cho các công cụ\n",
        "3. Hiểu được cách tích hợp và sử dụng các công cụ trong quy trình tự động\n",
        "4. Có thể mở rộng thư viện với các công cụ mới"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trích Xuất Từ Bài Báo\n",
        "\n",
        "> \"The foundation of our solution is a curated library of data science tools, encompassing functions for data cleaning, feature engineering, and modeling. This library not only provides the necessary tools for data processing and analysis but also ensures that the generated code is reliable and follows best practices.\" (Section 3.3 Machine Learning Tools Library, Page 6)\n",
        "\n",
        "> \"The ML tools library is organized into three main categories: data cleaning tools, feature engineering tools, and model building, validation, and prediction tools. Each category contains a set of functions that are commonly used in data science competitions and have been validated through extensive testing.\" (Section 3.3 Machine Learning Tools Library, Page 6)\n",
        "\n",
        "> \"Data Cleaning Tools: This category includes functions for handling missing values, removing duplicates, detecting and handling outliers, and converting data types. These tools are essential for preparing clean, high-quality data for analysis and modeling.\" (Section 3.3 Machine Learning Tools Library, Page 6)\n",
        "\n",
        "> \"Feature Engineering Tools: This category encompasses functions for creating new features, transforming existing features, encoding categorical variables, and feature selection. These tools help improve model performance by creating informative and relevant features.\" (Section 3.3 Machine Learning Tools Library, Page 6)\n",
        "\n",
        "> \"Model Building, Validation, and Prediction Tools: This category includes functions for training various machine learning models, evaluating model performance, performing cross-validation, and making predictions. These tools support the entire modeling workflow from training to final prediction.\" (Section 3.3 Machine Learning Tools Library, Page 6)\n",
        "\n",
        "![ML Tools Library Structure](https://m-a-p.ai/AutoKaggle.github.io/assets/images/fig3.png)\n",
        "*(Note: Diagram representation - actual image not included)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cài Đặt Môi Trường"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn\n",
        "!pip install -q xgboost lightgbm catboost\n",
        "!pip install -q category_encoders feature-engine\n",
        "!pip install -q optuna bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Optional, Tuple, Any, Union, Callable\n",
        "from abc import ABC, abstractmethod\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import machine learning libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
        "\n",
        "# Import advanced ML libraries\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 1: Thiết Kế Kiến Trúc Thư Viện Công Cụ\n",
        "\n",
        "Theo bài báo, thư viện công cụ ML được tổ chức thành 3 danh mục chính. Chúng ta sẽ thiết kế một kiến trúc có thể mở rộng và dễ bảo trì:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base class cho tất cả các công cụ ML\n",
        "class MLTool(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class cho tất cả các công cụ ML trong thư viện\n",
        "    \n",
        "    Mỗi công cụ phải implement các phương thức cơ bản:\n",
        "    - execute: Thực thi chức năng chính của công cụ\n",
        "    - validate_input: Kiểm tra tính hợp lệ của đầu vào\n",
        "    - get_description: Trả về mô tả chi tiết về công cụ\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, category: str, description: str):\n",
        "        self.name = name\n",
        "        self.category = category\n",
        "        self.description = description\n",
        "        self.execution_log = []\n",
        "    \n",
        "    @abstractmethod\n",
        "    def execute(self, *args, **kwargs) -> Any:\n",
        "        \"\"\"Thực thi chức năng chính của công cụ\"\"\"\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def validate_input(self, *args, **kwargs) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_description(self) -> str:\n",
        "        \"\"\"Trả về mô tả chi tiết về công cụ\"\"\"\n",
        "        return f\"{self.name} ({self.category}): {self.description}\"\n",
        "    \n",
        "    def log_execution(self, inputs: Dict, outputs: Dict, execution_time: float):\n",
        "        \"\"\"Ghi log quá trình thực thi\"\"\"\n",
        "        log_entry = {\n",
        "            'timestamp': pd.Timestamp.now(),\n",
        "            'inputs': inputs,\n",
        "            'outputs': outputs,\n",
        "            'execution_time': execution_time\n",
        "        }\n",
        "        self.execution_log.append(log_entry)\n",
        "\n",
        "# Enum cho các danh mục công cụ\n",
        "class ToolCategory:\n",
        "    DATA_CLEANING = \"Data Cleaning\"\n",
        "    FEATURE_ENGINEERING = \"Feature Engineering\"\n",
        "    MODEL_BUILDING = \"Model Building, Validation & Prediction\"\n",
        "\n",
        "# Registry để quản lý tất cả các công cụ\n",
        "class MLToolRegistry:\n",
        "    \"\"\"\n",
        "    Registry pattern để quản lý và truy cập các công cụ ML\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self._tools = {}\n",
        "        self._categories = {}\n",
        "    \n",
        "    def register_tool(self, tool: MLTool):\n",
        "        \"\"\"Đăng ký một công cụ mới\"\"\"\n",
        "        self._tools[tool.name] = tool\n",
        "        \n",
        "        if tool.category not in self._categories:\n",
        "            self._categories[tool.category] = []\n",
        "        self._categories[tool.category].append(tool.name)\n",
        "    \n",
        "    def get_tool(self, name: str) -> Optional[MLTool]:\n",
        "        \"\"\"Lấy công cụ theo tên\"\"\"\n",
        "        return self._tools.get(name)\n",
        "    \n",
        "    def get_tools_by_category(self, category: str) -> List[MLTool]:\n",
        "        \"\"\"Lấy tất cả công cụ trong một danh mục\"\"\"\n",
        "        tool_names = self._categories.get(category, [])\n",
        "        return [self._tools[name] for name in tool_names]\n",
        "    \n",
        "    def list_all_tools(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Liệt kê tất cả công cụ theo danh mục\"\"\"\n",
        "        return self._categories.copy()\n",
        "    \n",
        "    def search_tools(self, keyword: str) -> List[MLTool]:\n",
        "        \"\"\"Tìm kiếm công cụ theo từ khóa\"\"\"\n",
        "        results = []\n",
        "        for tool in self._tools.values():\n",
        "            if (keyword.lower() in tool.name.lower() or \n",
        "                keyword.lower() in tool.description.lower()):\n",
        "                results.append(tool)\n",
        "        return results\n",
        "\n",
        "# Khởi tạo registry toàn cục\n",
        "ml_registry = MLToolRegistry()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 2: Danh Mục 1 - Công Cụ Làm Sạch Dữ Liệu (Data Cleaning Tools)\n",
        "\n",
        "Danh mục này bao gồm các công cụ để xử lý dữ liệu thiếu, loại bỏ bản sao, phát hiện và xử lý dữ liệu ngoại lai, và chuyển đổi kiểu dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from scipy import stats\n",
        "\n",
        "class MissingValueHandler(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ xử lý giá trị thiếu với nhiều chiến lược khác nhau\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"missing_value_handler\",\n",
        "            category=ToolCategory.DATA_CLEANING,\n",
        "            description=\"Handle missing values using various strategies (mean, median, mode, forward fill, etc.)\"\n",
        "        )\n",
        "        self.supported_strategies = {\n",
        "            'mean': self._fill_mean,\n",
        "            'median': self._fill_median,\n",
        "            'mode': self._fill_mode,\n",
        "            'forward_fill': self._forward_fill,\n",
        "            'backward_fill': self._backward_fill,\n",
        "            'interpolate': self._interpolate,\n",
        "            'drop': self._drop_missing,\n",
        "            'constant': self._fill_constant\n",
        "        }\n",
        "    \n",
        "    def validate_input(self, df: pd.DataFrame, strategy: Dict[str, str]) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            return False\n",
        "        if not isinstance(strategy, dict):\n",
        "            return False\n",
        "        \n",
        "        # Kiểm tra xem các cột có tồn tại không\n",
        "        for col in strategy.keys():\n",
        "            if col not in df.columns:\n",
        "                return False\n",
        "        \n",
        "        # Kiểm tra xem các chiến lược có được hỗ trợ không\n",
        "        for strat in strategy.values():\n",
        "            if isinstance(strat, str) and strat not in self.supported_strategies:\n",
        "                return False\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def execute(self, df: pd.DataFrame, strategy: Dict[str, Union[str, Any]]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Xử lý giá trị thiếu theo chiến lược được chỉ định\n",
        "        \n",
        "        Parameters:\n",
        "        - df: DataFrame cần xử lý\n",
        "        - strategy: Dictionary với key là tên cột, value là chiến lược xử lý\n",
        "        \n",
        "        Returns:\n",
        "        - DataFrame đã xử lý giá trị thiếu\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(df, strategy):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        df_processed = df.copy()\n",
        "        missing_info = {}\n",
        "        \n",
        "        for column, method in strategy.items():\n",
        "            if column not in df_processed.columns:\n",
        "                continue\n",
        "            \n",
        "            # Ghi nhận thông tin về giá trị thiếu trước khi xử lý\n",
        "            missing_count = df_processed[column].isnull().sum()\n",
        "            missing_info[column] = {\n",
        "                'missing_count_before': missing_count,\n",
        "                'missing_percentage_before': (missing_count / len(df_processed)) * 100,\n",
        "                'strategy_used': method\n",
        "            }\n",
        "            \n",
        "            if missing_count == 0:\n",
        "                continue\n",
        "            \n",
        "            # Áp dụng chiến lược xử lý\n",
        "            if isinstance(method, str) and method in self.supported_strategies:\n",
        "                df_processed = self.supported_strategies[method](df_processed, column)\n",
        "            else:\n",
        "                # Sử dụng giá trị constant\n",
        "                df_processed[column].fillna(method, inplace=True)\n",
        "            \n",
        "            # Ghi nhận thông tin sau khi xử lý\n",
        "            missing_count_after = df_processed[column].isnull().sum()\n",
        "            missing_info[column]['missing_count_after'] = missing_count_after\n",
        "            missing_info[column]['missing_percentage_after'] = (missing_count_after / len(df_processed)) * 100\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'dataframe_shape': df.shape, 'strategy': strategy},\n",
        "            outputs={'processed_shape': df_processed.shape, 'missing_info': missing_info},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return df_processed\n",
        "    \n",
        "    def _fill_mean(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị trung bình\"\"\"\n",
        "        if pd.api.types.is_numeric_dtype(df[column]):\n",
        "            df[column].fillna(df[column].mean(), inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _fill_median(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị trung vị\"\"\"\n",
        "        if pd.api.types.is_numeric_dtype(df[column]):\n",
        "            df[column].fillna(df[column].median(), inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _fill_mode(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị mode (phổ biến nhất)\"\"\"\n",
        "        mode_value = df[column].mode()\n",
        "        if not mode_value.empty:\n",
        "            df[column].fillna(mode_value[0], inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _forward_fill(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị phía trước\"\"\"\n",
        "        df[column].fillna(method='ffill', inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _backward_fill(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị phía sau\"\"\"\n",
        "        df[column].fillna(method='bfill', inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _interpolate(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Nội suy giá trị\"\"\"\n",
        "        if pd.api.types.is_numeric_dtype(df[column]):\n",
        "            df[column].interpolate(inplace=True)\n",
        "        return df\n",
        "    \n",
        "    def _drop_missing(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Loại bỏ hàng có giá trị thiếu\"\"\"\n",
        "        return df.dropna(subset=[column])\n",
        "    \n",
        "    def _fill_constant(self, df: pd.DataFrame, column: str, value: Any = 0) -> pd.DataFrame:\n",
        "        \"\"\"Điền giá trị constant\"\"\"\n",
        "        df[column].fillna(value, inplace=True)\n",
        "        return df\n",
        "\n",
        "class OutlierDetector(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ phát hiện và xử lý dữ liệu ngoại lai\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"outlier_detector\",\n",
        "            category=ToolCategory.DATA_CLEANING,\n",
        "            description=\"Detect and handle outliers using IQR, Z-score, and Isolation Forest methods\"\n",
        "        )\n",
        "        self.supported_methods = ['iqr', 'zscore', 'isolation_forest']\n",
        "        self.supported_actions = ['remove', 'cap', 'transform']\n",
        "    \n",
        "    def validate_input(self, df: pd.DataFrame, columns: List[str], method: str, action: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            return False\n",
        "        if not all(col in df.columns for col in columns):\n",
        "            return False\n",
        "        if method not in self.supported_methods:\n",
        "            return False\n",
        "        if action not in self.supported_actions:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, df: pd.DataFrame, columns: List[str], \n",
        "                method: str = 'iqr', action: str = 'cap', \n",
        "                threshold: float = 1.5) -> Tuple[pd.DataFrame, Dict]:\n",
        "        \"\"\"\n",
        "        Phát hiện và xử lý dữ liệu ngoại lai\n",
        "        \n",
        "        Parameters:\n",
        "        - df: DataFrame cần xử lý\n",
        "        - columns: Danh sách cột cần kiểm tra\n",
        "        - method: Phương pháp phát hiện ('iqr', 'zscore', 'isolation_forest')\n",
        "        - action: Hành động xử lý ('remove', 'cap', 'transform')\n",
        "        - threshold: Ngưỡng phát hiện\n",
        "        \n",
        "        Returns:\n",
        "        - Tuple của (DataFrame đã xử lý, thông tin outlier)\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(df, columns, method, action):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        df_processed = df.copy()\n",
        "        outlier_info = {}\n",
        "        \n",
        "        for column in columns:\n",
        "            if not pd.api.types.is_numeric_dtype(df_processed[column]):\n",
        "                continue\n",
        "            \n",
        "            # Phát hiện outlier\n",
        "            if method == 'iqr':\n",
        "                outlier_mask = self._detect_outliers_iqr(df_processed[column], threshold)\n",
        "            elif method == 'zscore':\n",
        "                outlier_mask = self._detect_outliers_zscore(df_processed[column], threshold)\n",
        "            elif method == 'isolation_forest':\n",
        "                outlier_mask = self._detect_outliers_isolation_forest(df_processed[column])\n",
        "            \n",
        "            outlier_count = outlier_mask.sum()\n",
        "            outlier_info[column] = {\n",
        "                'outlier_count': outlier_count,\n",
        "                'outlier_percentage': (outlier_count / len(df_processed)) * 100,\n",
        "                'method_used': method,\n",
        "                'action_taken': action\n",
        "            }\n",
        "            \n",
        "            # Xử lý outlier\n",
        "            if action == 'remove':\n",
        "                df_processed = df_processed[~outlier_mask]\n",
        "            elif action == 'cap':\n",
        "                df_processed = self._cap_outliers(df_processed, column, method, threshold)\n",
        "            elif action == 'transform':\n",
        "                df_processed[column] = self._transform_outliers(df_processed[column])\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'dataframe_shape': df.shape, 'columns': columns, 'method': method, 'action': action},\n",
        "            outputs={'processed_shape': df_processed.shape, 'outlier_info': outlier_info},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return df_processed, outlier_info\n",
        "    \n",
        "    def _detect_outliers_iqr(self, series: pd.Series, threshold: float = 1.5) -> pd.Series:\n",
        "        \"\"\"Phát hiện outlier bằng phương pháp IQR\"\"\"\n",
        "        Q1 = series.quantile(0.25)\n",
        "        Q3 = series.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - threshold * IQR\n",
        "        upper_bound = Q3 + threshold * IQR\n",
        "        return (series < lower_bound) | (series > upper_bound)\n",
        "    \n",
        "    def _detect_outliers_zscore(self, series: pd.Series, threshold: float = 3.0) -> pd.Series:\n",
        "        \"\"\"Phát hiện outlier bằng phương pháp Z-score\"\"\"\n",
        "        z_scores = np.abs(stats.zscore(series.dropna()))\n",
        "        outlier_mask = pd.Series(False, index=series.index)\n",
        "        outlier_mask[series.dropna().index] = z_scores > threshold\n",
        "        return outlier_mask\n",
        "    \n",
        "    def _detect_outliers_isolation_forest(self, series: pd.Series) -> pd.Series:\n",
        "        \"\"\"Phát hiện outlier bằng Isolation Forest\"\"\"\n",
        "        from sklearn.ensemble import IsolationForest\n",
        "        \n",
        "        # Chuẩn bị dữ liệu\n",
        "        data = series.dropna().values.reshape(-1, 1)\n",
        "        \n",
        "        # Khởi tạo và fit model\n",
        "        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
        "        outlier_labels = iso_forest.fit_predict(data)\n",
        "        \n",
        "        # Tạo mask outlier\n",
        "        outlier_mask = pd.Series(False, index=series.index)\n",
        "        outlier_mask[series.dropna().index] = outlier_labels == -1\n",
        "        \n",
        "        return outlier_mask\n",
        "    \n",
        "    def _cap_outliers(self, df: pd.DataFrame, column: str, method: str, threshold: float) -> pd.DataFrame:\n",
        "        \"\"\"Giới hạn giá trị outlier trong khoảng cho phép\"\"\"\n",
        "        if method == 'iqr':\n",
        "            Q1 = df[column].quantile(0.25)\n",
        "            Q3 = df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold * IQR\n",
        "            upper_bound = Q3 + threshold * IQR\n",
        "        elif method == 'zscore':\n",
        "            mean = df[column].mean()\n",
        "            std = df[column].std()\n",
        "            lower_bound = mean - threshold * std\n",
        "            upper_bound = mean + threshold * std\n",
        "        \n",
        "        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "        return df\n",
        "    \n",
        "    def _transform_outliers(self, series: pd.Series) -> pd.Series:\n",
        "        \"\"\"Biến đổi outlier bằng log transformation\"\"\"\n",
        "        # Áp dụng log transformation (thêm 1 để tránh log(0))\n",
        "        return np.log1p(np.abs(series))\n",
        "\n",
        "# Đăng ký các công cụ data cleaning\n",
        "ml_registry.register_tool(MissingValueHandler())\n",
        "ml_registry.register_tool(OutlierDetector())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 3: Danh Mục 2 - Công Cụ Kỹ Thuật Đặc Trưng (Feature Engineering Tools)\n",
        "\n",
        "Danh mục này bao gồm các công cụ để tạo đặc trưng mới, biến đổi đặc trưng hiện có, mã hóa biến phân loại, và lựa chọn đặc trưng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, mutual_info_regression\n",
        "from sklearn.decomposition import PCA\n",
        "from category_encoders import TargetEncoder, BinaryEncoder, CatBoostEncoder\n",
        "\n",
        "class CategoricalEncoder(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ mã hóa biến phân loại với nhiều phương pháp khác nhau\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"categorical_encoder\",\n",
        "            category=ToolCategory.FEATURE_ENGINEERING,\n",
        "            description=\"Encode categorical variables using various methods (one-hot, label, target, binary encoding)\"\n",
        "        )\n",
        "        self.supported_methods = {\n",
        "            'onehot': self._onehot_encode,\n",
        "            'label': self._label_encode,\n",
        "            'target': self._target_encode,\n",
        "            'binary': self._binary_encode,\n",
        "            'frequency': self._frequency_encode,\n",
        "            'ordinal': self._ordinal_encode\n",
        "        }\n",
        "        self.encoders = {}\n",
        "    \n",
        "    def validate_input(self, df: pd.DataFrame, columns: List[str], method: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            return False\n",
        "        if not all(col in df.columns for col in columns):\n",
        "            return False\n",
        "        if method not in self.supported_methods:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, df: pd.DataFrame, columns: List[str], method: str = 'onehot', \n",
        "                target: Optional[str] = None, mapping: Optional[Dict] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Mã hóa biến phân loại\n",
        "        \n",
        "        Parameters:\n",
        "        - df: DataFrame cần xử lý\n",
        "        - columns: Danh sách cột phân loại cần mã hóa\n",
        "        - method: Phương pháp mã hóa\n",
        "        - target: Cột target (cần thiết cho target encoding)\n",
        "        - mapping: Mapping cho ordinal encoding\n",
        "        \n",
        "        Returns:\n",
        "        - DataFrame đã mã hóa\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(df, columns, method):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        df_processed = df.copy()\n",
        "        encoding_info = {}\n",
        "        \n",
        "        for column in columns:\n",
        "            if column not in df_processed.columns:\n",
        "                continue\n",
        "            \n",
        "            original_unique_count = df_processed[column].nunique()\n",
        "            \n",
        "            # Áp dụng phương pháp mã hóa\n",
        "            if method == 'target' and target:\n",
        "                df_processed = self.supported_methods[method](df_processed, column, target)\n",
        "            elif method == 'ordinal' and mapping:\n",
        "                df_processed = self.supported_methods[method](df_processed, column, mapping.get(column, {}))\n",
        "            else:\n",
        "                df_processed = self.supported_methods[method](df_processed, column)\n",
        "            \n",
        "            # Ghi nhận thông tin encoding\n",
        "            if method == 'onehot':\n",
        "                new_columns = [col for col in df_processed.columns if col.startswith(f\"{column}_\")]\n",
        "                encoding_info[column] = {\n",
        "                    'method': method,\n",
        "                    'original_unique_count': original_unique_count,\n",
        "                    'new_columns_count': len(new_columns),\n",
        "                    'new_columns': new_columns\n",
        "                }\n",
        "            else:\n",
        "                encoding_info[column] = {\n",
        "                    'method': method,\n",
        "                    'original_unique_count': original_unique_count,\n",
        "                    'new_columns_count': 1\n",
        "                }\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'dataframe_shape': df.shape, 'columns': columns, 'method': method},\n",
        "            outputs={'processed_shape': df_processed.shape, 'encoding_info': encoding_info},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return df_processed\n",
        "    \n",
        "    def _onehot_encode(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"One-hot encoding\"\"\"\n",
        "        dummies = pd.get_dummies(df[column], prefix=column, dummy_na=False)\n",
        "        df = pd.concat([df.drop(column, axis=1), dummies], axis=1)\n",
        "        return df\n",
        "    \n",
        "    def _label_encode(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Label encoding\"\"\"\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column].astype(str))\n",
        "        self.encoders[f\"{column}_label\"] = le\n",
        "        return df\n",
        "    \n",
        "    def _target_encode(self, df: pd.DataFrame, column: str, target: str) -> pd.DataFrame:\n",
        "        \"\"\"Target encoding\"\"\"\n",
        "        te = TargetEncoder()\n",
        "        df[column] = te.fit_transform(df[column], df[target])\n",
        "        self.encoders[f\"{column}_target\"] = te\n",
        "        return df\n",
        "    \n",
        "    def _binary_encode(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Binary encoding\"\"\"\n",
        "        be = BinaryEncoder(cols=[column])\n",
        "        encoded_df = be.fit_transform(df[[column]])\n",
        "        df = pd.concat([df.drop(column, axis=1), encoded_df], axis=1)\n",
        "        self.encoders[f\"{column}_binary\"] = be\n",
        "        return df\n",
        "    \n",
        "    def _frequency_encode(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "        \"\"\"Frequency encoding\"\"\"\n",
        "        freq_map = df[column].value_counts(normalize=True).to_dict()\n",
        "        df[f\"{column}_freq\"] = df[column].map(freq_map)\n",
        "        df.drop(column, axis=1, inplace=True)\n",
        "        self.encoders[f\"{column}_frequency\"] = freq_map\n",
        "        return df\n",
        "    \n",
        "    def _ordinal_encode(self, df: pd.DataFrame, column: str, mapping: Dict) -> pd.DataFrame:\n",
        "        \"\"\"Ordinal encoding với mapping tùy chỉnh\"\"\"\n",
        "        df[column] = df[column].map(mapping)\n",
        "        return df\n",
        "\n",
        "class FeatureCreator(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ tạo đặc trưng mới từ các đặc trưng hiện có\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"feature_creator\",\n",
        "            category=ToolCategory.FEATURE_ENGINEERING,\n",
        "            description=\"Create new features through mathematical operations, polynomial features, and interactions\"\n",
        "        )\n",
        "        self.supported_operations = {\n",
        "            'polynomial': self._create_polynomial_features,\n",
        "            'interaction': self._create_interaction_features, \n",
        "            'mathematical': self._create_mathematical_features,\n",
        "            'binning': self._create_binned_features,\n",
        "            'datetime': self._create_datetime_features\n",
        "        }\n",
        "    \n",
        "    def validate_input(self, df: pd.DataFrame, operation: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            return False\n",
        "        if operation not in self.supported_operations:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, df: pd.DataFrame, operation: str, \n",
        "                columns: Optional[List[str]] = None, \n",
        "                degree: int = 2, \n",
        "                bins: int = 5,\n",
        "                math_operations: List[str] = ['log', 'sqrt', 'square']) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Tạo đặc trưng mới\n",
        "        \n",
        "        Parameters:\n",
        "        - df: DataFrame cần xử lý\n",
        "        - operation: Loại operation ('polynomial', 'interaction', 'mathematical', 'binning', 'datetime')\n",
        "        - columns: Danh sách cột để áp dụng (None để áp dụng cho tất cả cột số)\n",
        "        - degree: Bậc cho polynomial features\n",
        "        - bins: Số bins cho binning\n",
        "        - math_operations: Danh sách phép toán số học\n",
        "        \n",
        "        Returns:\n",
        "        - DataFrame với các đặc trưng mới\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(df, operation):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        df_processed = df.copy()\n",
        "        \n",
        "        # Xác định cột để xử lý\n",
        "        if columns is None:\n",
        "            if operation == 'datetime':\n",
        "                columns = df_processed.select_dtypes(include=['datetime64', 'object']).columns.tolist()\n",
        "            else:\n",
        "                columns = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        \n",
        "        original_columns = df_processed.shape[1]\n",
        "        \n",
        "        # Áp dụng operation\n",
        "        if operation == 'polynomial':\n",
        "            df_processed = self.supported_operations[operation](df_processed, columns, degree)\n",
        "        elif operation == 'binning':\n",
        "            df_processed = self.supported_operations[operation](df_processed, columns, bins)\n",
        "        elif operation == 'mathematical':\n",
        "            df_processed = self.supported_operations[operation](df_processed, columns, math_operations)\n",
        "        else:\n",
        "            df_processed = self.supported_operations[operation](df_processed, columns)\n",
        "        \n",
        "        new_columns = df_processed.shape[1]\n",
        "        features_created = new_columns - original_columns\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'dataframe_shape': df.shape, 'operation': operation, 'columns': columns},\n",
        "            outputs={'processed_shape': df_processed.shape, 'features_created': features_created},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return df_processed\n",
        "    \n",
        "    def _create_polynomial_features(self, df: pd.DataFrame, columns: List[str], degree: int) -> pd.DataFrame:\n",
        "        \"\"\"Tạo polynomial features\"\"\"\n",
        "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "        \n",
        "        # Chỉ áp dụng cho cột số\n",
        "        numeric_columns = [col for col in columns if pd.api.types.is_numeric_dtype(df[col])]\n",
        "        \n",
        "        if numeric_columns:\n",
        "            poly_features = poly.fit_transform(df[numeric_columns])\n",
        "            poly_feature_names = poly.get_feature_names_out(numeric_columns)\n",
        "            \n",
        "            # Loại bỏ các features gốc (đã có sẵn)\n",
        "            new_features = poly_features[:, len(numeric_columns):]\n",
        "            new_feature_names = poly_feature_names[len(numeric_columns):]\n",
        "            \n",
        "            # Thêm vào DataFrame\n",
        "            for i, name in enumerate(new_feature_names):\n",
        "                df[f\"poly_{name}\"] = new_features[:, i]\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _create_interaction_features(self, df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Tạo interaction features\"\"\"\n",
        "        numeric_columns = [col for col in columns if pd.api.types.is_numeric_dtype(df[col])]\n",
        "        \n",
        "        # Tạo tất cả các cặp tương tác\n",
        "        for i in range(len(numeric_columns)):\n",
        "            for j in range(i+1, len(numeric_columns)):\n",
        "                col1, col2 = numeric_columns[i], numeric_columns[j]\n",
        "                df[f\"{col1}_x_{col2}\"] = df[col1] * df[col2]\n",
        "                df[f\"{col1}_div_{col2}\"] = df[col1] / (df[col2] + 1e-8)  # Tránh chia cho 0\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _create_mathematical_features(self, df: pd.DataFrame, columns: List[str], operations: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Tạo mathematical features\"\"\"\n",
        "        numeric_columns = [col for col in columns if pd.api.types.is_numeric_dtype(df[col])]\n",
        "        \n",
        "        for col in numeric_columns:\n",
        "            if 'log' in operations:\n",
        "                df[f\"{col}_log\"] = np.log1p(np.abs(df[col]))  # log(1+x) để tránh log(0)\n",
        "            if 'sqrt' in operations:\n",
        "                df[f\"{col}_sqrt\"] = np.sqrt(np.abs(df[col]))\n",
        "            if 'square' in operations:\n",
        "                df[f\"{col}_square\"] = df[col] ** 2\n",
        "            if 'reciprocal' in operations:\n",
        "                df[f\"{col}_reciprocal\"] = 1 / (df[col] + 1e-8)\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _create_binned_features(self, df: pd.DataFrame, columns: List[str], bins: int) -> pd.DataFrame:\n",
        "        \"\"\"Tạo binned features\"\"\"\n",
        "        numeric_columns = [col for col in columns if pd.api.types.is_numeric_dtype(df[col])]\n",
        "        \n",
        "        for col in numeric_columns:\n",
        "            df[f\"{col}_binned\"] = pd.cut(df[col], bins=bins, labels=False)\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _create_datetime_features(self, df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Tạo datetime features\"\"\"\n",
        "        for col in columns:\n",
        "            # Thử convert sang datetime nếu chưa phải\n",
        "            if not pd.api.types.is_datetime64_any_dtype(df[col]):\n",
        "                try:\n",
        "                    df[col] = pd.to_datetime(df[col])\n",
        "                except:\n",
        "                    continue\n",
        "            \n",
        "            # Tạo các features từ datetime\n",
        "            df[f\"{col}_year\"] = df[col].dt.year\n",
        "            df[f\"{col}_month\"] = df[col].dt.month\n",
        "            df[f\"{col}_day\"] = df[col].dt.day\n",
        "            df[f\"{col}_dayofweek\"] = df[col].dt.dayofweek\n",
        "            df[f\"{col}_hour\"] = df[col].dt.hour\n",
        "            df[f\"{col}_is_weekend\"] = (df[col].dt.dayofweek >= 5).astype(int)\n",
        "        \n",
        "        return df\n",
        "\n",
        "# Đăng ký các công cụ feature engineering\n",
        "ml_registry.register_tool(CategoricalEncoder())\n",
        "ml_registry.register_tool(FeatureCreator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 4: Danh Mục 3 - Công Cụ Xây Dựng, Xác Thực và Dự Đoán Mô Hình\n",
        "\n",
        "Danh mục này bao gồm các công cụ để huấn luyện mô hình, đánh giá hiệu suất, thực hiện cross-validation, và tạo dự đoán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import joblib\n",
        "\n",
        "class ModelTrainer(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ huấn luyện và so sánh nhiều mô hình học máy\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"model_trainer\",\n",
        "            category=ToolCategory.MODEL_BUILDING,\n",
        "            description=\"Train and compare multiple machine learning models with automatic hyperparameter tuning\"\n",
        "        )\n",
        "        self.supported_models = {\n",
        "            # Classification models\n",
        "            'random_forest_clf': RandomForestClassifier,\n",
        "            'gradient_boosting_clf': GradientBoostingClassifier,\n",
        "            'logistic_regression': LogisticRegression,\n",
        "            'svm_clf': SVC,\n",
        "            'knn_clf': KNeighborsClassifier,\n",
        "            'naive_bayes': GaussianNB,\n",
        "            'decision_tree_clf': DecisionTreeClassifier,\n",
        "            'xgboost_clf': xgb.XGBClassifier,\n",
        "            'lightgbm_clf': lgb.LGBMClassifier,\n",
        "            \n",
        "            # Regression models\n",
        "            'random_forest_reg': RandomForestRegressor,\n",
        "            'gradient_boosting_reg': GradientBoostingRegressor,\n",
        "            'ridge': Ridge,\n",
        "            'lasso': Lasso,\n",
        "            'svm_reg': SVR,\n",
        "            'xgboost_reg': xgb.XGBRegressor,\n",
        "            'lightgbm_reg': lgb.LGBMRegressor\n",
        "        }\n",
        "        self.trained_models = {}\n",
        "    \n",
        "    def validate_input(self, X: pd.DataFrame, y: pd.Series, problem_type: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(X, pd.DataFrame) or not isinstance(y, pd.Series):\n",
        "            return False\n",
        "        if len(X) != len(y):\n",
        "            return False\n",
        "        if problem_type not in ['classification', 'regression']:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, X: pd.DataFrame, y: pd.Series, \n",
        "                problem_type: str = 'classification',\n",
        "                models_to_try: Optional[List[str]] = None,\n",
        "                cv_folds: int = 5,\n",
        "                scoring: Optional[str] = None,\n",
        "                test_size: float = 0.2,\n",
        "                random_state: int = 42) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Huấn luyện và so sánh nhiều mô hình\n",
        "        \n",
        "        Parameters:\n",
        "        - X: Features\n",
        "        - y: Target variable\n",
        "        - problem_type: 'classification' hoặc 'regression'\n",
        "        - models_to_try: Danh sách mô hình muốn thử (None để thử tất cả)\n",
        "        - cv_folds: Số fold cho cross-validation\n",
        "        - scoring: Metric đánh giá\n",
        "        - test_size: Tỷ lệ test set\n",
        "        - random_state: Random seed\n",
        "        \n",
        "        Returns:\n",
        "        - Dictionary chứa kết quả huấn luyện và so sánh\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(X, y, problem_type):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        # Xác định models và scoring mặc định\n",
        "        if models_to_try is None:\n",
        "            if problem_type == 'classification':\n",
        "                models_to_try = ['random_forest_clf', 'gradient_boosting_clf', 'logistic_regression', 'xgboost_clf']\n",
        "            else:\n",
        "                models_to_try = ['random_forest_reg', 'gradient_boosting_reg', 'ridge', 'xgboost_reg']\n",
        "        \n",
        "        if scoring is None:\n",
        "            scoring = 'accuracy' if problem_type == 'classification' else 'neg_mean_squared_error'\n",
        "        \n",
        "        # Chia dữ liệu\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state, \n",
        "            stratify=y if problem_type == 'classification' else None\n",
        "        )\n",
        "        \n",
        "        # Thiết lập cross-validation\n",
        "        if problem_type == 'classification':\n",
        "            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
        "        else:\n",
        "            cv = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
        "        \n",
        "        # Huấn luyện và đánh giá các mô hình\n",
        "        results = {}\n",
        "        model_performances = []\n",
        "        \n",
        "        for model_name in models_to_try:\n",
        "            if model_name not in self.supported_models:\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                # Khởi tạo mô hình với tham số mặc định\n",
        "                model_class = self.supported_models[model_name]\n",
        "                model = model_class(random_state=random_state)\n",
        "                \n",
        "                # Cross-validation\n",
        "                cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
        "                \n",
        "                # Huấn luyện trên toàn bộ training set\n",
        "                model.fit(X_train, y_train)\n",
        "                \n",
        "                # Đánh giá trên test set\n",
        "                test_score = model.score(X_test, y_test)\n",
        "                \n",
        "                # Lưu kết quả\n",
        "                model_result = {\n",
        "                    'model': model,\n",
        "                    'cv_mean': cv_scores.mean(),\n",
        "                    'cv_std': cv_scores.std(),\n",
        "                    'test_score': test_score,\n",
        "                    'cv_scores': cv_scores\n",
        "                }\n",
        "                \n",
        "                results[model_name] = model_result\n",
        "                self.trained_models[model_name] = model\n",
        "                \n",
        "                model_performances.append({\n",
        "                    'model_name': model_name,\n",
        "                    'cv_mean': cv_scores.mean(),\n",
        "                    'cv_std': cv_scores.std(),\n",
        "                    'test_score': test_score\n",
        "                })\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error training {model_name}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Tìm mô hình tốt nhất\n",
        "        if model_performances:\n",
        "            best_model_info = max(model_performances, key=lambda x: x['cv_mean'])\n",
        "            best_model_name = best_model_info['model_name']\n",
        "            best_model = results[best_model_name]['model']\n",
        "        else:\n",
        "            best_model_info = None\n",
        "            best_model_name = None\n",
        "            best_model = None\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Tạo DataFrame so sánh\n",
        "        comparison_df = pd.DataFrame(model_performances)\n",
        "        if not comparison_df.empty:\n",
        "            comparison_df = comparison_df.sort_values('cv_mean', ascending=False)\n",
        "        \n",
        "        final_results = {\n",
        "            'model_results': results,\n",
        "            'comparison_df': comparison_df,\n",
        "            'best_model': best_model,\n",
        "            'best_model_name': best_model_name,\n",
        "            'best_model_info': best_model_info,\n",
        "            'X_train': X_train,\n",
        "            'X_test': X_test,\n",
        "            'y_train': y_train,\n",
        "            'y_test': y_test\n",
        "        }\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'X_shape': X.shape, 'y_shape': y.shape, 'problem_type': problem_type, 'models_to_try': models_to_try},\n",
        "            outputs={'models_trained': len(results), 'best_model': best_model_name},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return final_results\n",
        "    \n",
        "    def save_model(self, model_name: str, filepath: str):\n",
        "        \"\"\"Lưu mô hình đã huấn luyện\"\"\"\n",
        "        if model_name in self.trained_models:\n",
        "            joblib.dump(self.trained_models[model_name], filepath)\n",
        "        else:\n",
        "            raise ValueError(f\"Model {model_name} not found in trained models\")\n",
        "    \n",
        "    def load_model(self, filepath: str, model_name: str):\n",
        "        \"\"\"Tải mô hình đã lưu\"\"\"\n",
        "        model = joblib.load(filepath)\n",
        "        self.trained_models[model_name] = model\n",
        "        return model\n",
        "\n",
        "class ModelEvaluator(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ đánh giá mô hình với nhiều metrics khác nhau\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"model_evaluator\",\n",
        "            category=ToolCategory.MODEL_BUILDING,\n",
        "            description=\"Evaluate model performance using various metrics and generate comprehensive reports\"\n",
        "        )\n",
        "    \n",
        "    def validate_input(self, y_true: pd.Series, y_pred: np.ndarray, problem_type: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if len(y_true) != len(y_pred):\n",
        "            return False\n",
        "        if problem_type not in ['classification', 'regression']:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, y_true: pd.Series, y_pred: np.ndarray, \n",
        "                problem_type: str = 'classification',\n",
        "                y_pred_proba: Optional[np.ndarray] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Đánh giá hiệu suất mô hình\n",
        "        \n",
        "        Parameters:\n",
        "        - y_true: Giá trị thực tế\n",
        "        - y_pred: Giá trị dự đoán\n",
        "        - problem_type: 'classification' hoặc 'regression'\n",
        "        - y_pred_proba: Xác suất dự đoán (cho classification)\n",
        "        \n",
        "        Returns:\n",
        "        - Dictionary chứa các metrics đánh giá\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(y_true, y_pred, problem_type):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        metrics = {}\n",
        "        \n",
        "        if problem_type == 'classification':\n",
        "            # Classification metrics\n",
        "            metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "            metrics['precision'] = precision_score(y_true, y_pred, average='weighted')\n",
        "            metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
        "            metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
        "            \n",
        "            # Classification report\n",
        "            from sklearn.metrics import classification_report, confusion_matrix\n",
        "            metrics['classification_report'] = classification_report(y_true, y_pred)\n",
        "            metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
        "            \n",
        "            # AUC-ROC nếu có probability\n",
        "            if y_pred_proba is not None:\n",
        "                from sklearn.metrics import roc_auc_score\n",
        "                try:\n",
        "                    if len(np.unique(y_true)) == 2:  # Binary classification\n",
        "                        metrics['auc_roc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
        "                    else:  # Multi-class\n",
        "                        metrics['auc_roc'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
        "                except Exception as e:\n",
        "                    metrics['auc_roc'] = f\"Cannot compute AUC-ROC: {e}\"\n",
        "        \n",
        "        else:  # Regression\n",
        "            # Regression metrics\n",
        "            metrics['mse'] = mean_squared_error(y_true, y_pred)\n",
        "            metrics['rmse'] = np.sqrt(metrics['mse'])\n",
        "            metrics['mae'] = mean_absolute_error(y_true, y_pred)\n",
        "            metrics['r2_score'] = r2_score(y_true, y_pred)\n",
        "            \n",
        "            # Additional regression metrics\n",
        "            from sklearn.metrics import mean_absolute_percentage_error\n",
        "            try:\n",
        "                metrics['mape'] = mean_absolute_percentage_error(y_true, y_pred)\n",
        "            except:\n",
        "                metrics['mape'] = \"Cannot compute MAPE (possible zero values)\"\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'y_true_shape': y_true.shape, 'y_pred_shape': y_pred.shape, 'problem_type': problem_type},\n",
        "            outputs={'metrics_computed': list(metrics.keys())},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def plot_evaluation_results(self, y_true: pd.Series, y_pred: np.ndarray, \n",
        "                               problem_type: str = 'classification',\n",
        "                               y_pred_proba: Optional[np.ndarray] = None):\n",
        "        \"\"\"Vẽ biểu đồ đánh giá kết quả\"\"\"\n",
        "        if problem_type == 'classification':\n",
        "            from sklearn.metrics import confusion_matrix\n",
        "            import seaborn as sns\n",
        "            \n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "            \n",
        "            # Confusion Matrix\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            sns.heatmap(cm, annot=True, fmt='d', ax=axes[0])\n",
        "            axes[0].set_title('Confusion Matrix')\n",
        "            axes[0].set_xlabel('Predicted')\n",
        "            axes[0].set_ylabel('Actual')\n",
        "            \n",
        "            # ROC Curve (nếu có probability)\n",
        "            if y_pred_proba is not None and len(np.unique(y_true)) == 2:\n",
        "                from sklearn.metrics import roc_curve, auc\n",
        "                fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
        "                roc_auc = auc(fpr, tpr)\n",
        "                \n",
        "                axes[1].plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "                axes[1].plot([0, 1], [0, 1], 'k--')\n",
        "                axes[1].set_xlim([0.0, 1.0])\n",
        "                axes[1].set_ylim([0.0, 1.05])\n",
        "                axes[1].set_xlabel('False Positive Rate')\n",
        "                axes[1].set_ylabel('True Positive Rate')\n",
        "                axes[1].set_title('ROC Curve')\n",
        "                axes[1].legend()\n",
        "            else:\n",
        "                axes[1].text(0.5, 0.5, 'ROC Curve\\nNot Available', \n",
        "                           ha='center', va='center', transform=axes[1].transAxes)\n",
        "        \n",
        "        else:  # Regression\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "            \n",
        "            # Actual vs Predicted\n",
        "            axes[0].scatter(y_true, y_pred, alpha=0.6)\n",
        "            axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "            axes[0].set_xlabel('Actual')\n",
        "            axes[0].set_ylabel('Predicted')\n",
        "            axes[0].set_title('Actual vs Predicted')\n",
        "            \n",
        "            # Residuals\n",
        "            residuals = y_true - y_pred\n",
        "            axes[1].scatter(y_pred, residuals, alpha=0.6)\n",
        "            axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "            axes[1].set_xlabel('Predicted')\n",
        "            axes[1].set_ylabel('Residuals')\n",
        "            axes[1].set_title('Residual Plot')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# Đăng ký các công cụ model building\n",
        "ml_registry.register_tool(ModelTrainer())\n",
        "ml_registry.register_tool(ModelEvaluator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 5: Quản Lý và Sử Dụng Thư Viện Công Cụ\n",
        "\n",
        "Bây giờ chúng ta sẽ tạo một interface để quản lý và sử dụng toàn bộ thư viện công cụ một cách hiệu quả:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLToolsManager:\n",
        "    \"\"\"\n",
        "    Manager class để quản lý và sử dụng toàn bộ thư viện công cụ ML\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, registry: MLToolRegistry):\n",
        "        self.registry = registry\n",
        "        self.workflow_history = []\n",
        "    \n",
        "    def list_available_tools(self) -> pd.DataFrame:\n",
        "        \"\"\"Liệt kê tất cả công cụ có sẵn\"\"\"\n",
        "        tools_info = []\n",
        "        \n",
        "        for category, tool_names in self.registry.list_all_tools().items():\n",
        "            for tool_name in tool_names:\n",
        "                tool = self.registry.get_tool(tool_name)\n",
        "                tools_info.append({\n",
        "                    'Tool Name': tool.name,\n",
        "                    'Category': tool.category,\n",
        "                    'Description': tool.description\n",
        "                })\n",
        "        \n",
        "        return pd.DataFrame(tools_info)\n",
        "    \n",
        "    def search_tools(self, keyword: str) -> pd.DataFrame:\n",
        "        \"\"\"Tìm kiếm công cụ theo từ khóa\"\"\"\n",
        "        tools = self.registry.search_tools(keyword)\n",
        "        tools_info = []\n",
        "        \n",
        "        for tool in tools:\n",
        "            tools_info.append({\n",
        "                'Tool Name': tool.name,\n",
        "                'Category': tool.category,\n",
        "                'Description': tool.description\n",
        "            })\n",
        "        \n",
        "        return pd.DataFrame(tools_info)\n",
        "    \n",
        "    def get_tool_usage_stats(self) -> pd.DataFrame:\n",
        "        \"\"\"Thống kê sử dụng công cụ\"\"\"\n",
        "        stats = []\n",
        "        \n",
        "        for category, tool_names in self.registry.list_all_tools().items():\n",
        "            for tool_name in tool_names:\n",
        "                tool = self.registry.get_tool(tool_name)\n",
        "                usage_count = len(tool.execution_log)\n",
        "                \n",
        "                if usage_count > 0:\n",
        "                    total_time = sum(log['execution_time'] for log in tool.execution_log)\n",
        "                    avg_time = total_time / usage_count\n",
        "                else:\n",
        "                    total_time = 0\n",
        "                    avg_time = 0\n",
        "                \n",
        "                stats.append({\n",
        "                    'Tool Name': tool.name,\n",
        "                    'Category': tool.category,\n",
        "                    'Usage Count': usage_count,\n",
        "                    'Total Execution Time (s)': round(total_time, 3),\n",
        "                    'Average Execution Time (s)': round(avg_time, 3)\n",
        "                })\n",
        "        \n",
        "        return pd.DataFrame(stats).sort_values('Usage Count', ascending=False)\n",
        "    \n",
        "    def create_ml_pipeline(self, steps: List[Dict]) -> 'MLPipeline':\n",
        "        \"\"\"Tạo pipeline ML từ danh sách các bước\"\"\"\n",
        "        return MLPipeline(self.registry, steps)\n",
        "    \n",
        "    def recommend_tools(self, problem_type: str, data_info: Dict) -> List[str]:\n",
        "        \"\"\"Đề xuất công cụ dựa trên loại bài toán và thông tin dữ liệu\"\"\"\n",
        "        recommendations = []\n",
        "        \n",
        "        # Luôn đề xuất xử lý missing values nếu có\n",
        "        if data_info.get('has_missing_values', False):\n",
        "            recommendations.append('missing_value_handler')\n",
        "        \n",
        "        # Đề xuất outlier detection cho dữ liệu số\n",
        "        if data_info.get('has_numeric_columns', False):\n",
        "            recommendations.append('outlier_detector')\n",
        "        \n",
        "        # Đề xuất categorical encoding cho dữ liệu phân loại\n",
        "        if data_info.get('has_categorical_columns', False):\n",
        "            recommendations.append('categorical_encoder')\n",
        "        \n",
        "        # Đề xuất feature creation\n",
        "        if data_info.get('feature_count', 0) < 20:  # Ít đặc trưng\n",
        "            recommendations.append('feature_creator')\n",
        "        \n",
        "        # Đề xuất model trainer\n",
        "        recommendations.append('model_trainer')\n",
        "        recommendations.append('model_evaluator')\n",
        "        \n",
        "        return recommendations\n",
        "\n",
        "class MLPipeline:\n",
        "    \"\"\"\n",
        "    Class để tạo và thực thi pipeline ML tự động\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, registry: MLToolRegistry, steps: List[Dict]):\n",
        "        self.registry = registry\n",
        "        self.steps = steps\n",
        "        self.execution_log = []\n",
        "        self.intermediate_results = {}\n",
        "    \n",
        "    def execute(self, initial_data: Dict) -> Dict:\n",
        "        \"\"\"Thực thi toàn bộ pipeline\"\"\"\n",
        "        current_data = initial_data.copy()\n",
        "        \n",
        "        for i, step in enumerate(self.steps):\n",
        "            step_name = step.get('name', f'step_{i}')\n",
        "            tool_name = step['tool']\n",
        "            params = step.get('params', {})\n",
        "            \n",
        "            print(f\"Executing step {i+1}: {step_name} using {tool_name}\")\n",
        "            \n",
        "            # Lấy công cụ từ registry\n",
        "            tool = self.registry.get_tool(tool_name)\n",
        "            if tool is None:\n",
        "                raise ValueError(f\"Tool {tool_name} not found in registry\")\n",
        "            \n",
        "            # Thực thi công cụ\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "                \n",
        "                # Truyền current_data vào params\n",
        "                execution_params = {**params}\n",
        "                for key, value in params.items():\n",
        "                    if isinstance(value, str) and value.startswith('$'):\n",
        "                        # Tham chiếu đến dữ liệu từ bước trước\n",
        "                        data_key = value[1:]  # Bỏ ký tự '$'\n",
        "                        execution_params[key] = current_data.get(data_key)\n",
        "                \n",
        "                result = tool.execute(**execution_params)\n",
        "                execution_time = time.time() - start_time\n",
        "                \n",
        "                # Lưu kết quả\n",
        "                current_data[f'{step_name}_result'] = result\n",
        "                self.intermediate_results[step_name] = result\n",
        "                \n",
        "                # Log thực thi\n",
        "                self.execution_log.append({\n",
        "                    'step': step_name,\n",
        "                    'tool': tool_name,\n",
        "                    'execution_time': execution_time,\n",
        "                    'success': True,\n",
        "                    'error': None\n",
        "                })\n",
        "                \n",
        "                print(f\"  ✓ Completed in {execution_time:.2f}s\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                error_msg = str(e)\n",
        "                print(f\"  ✗ Error: {error_msg}\")\n",
        "                \n",
        "                self.execution_log.append({\n",
        "                    'step': step_name,\n",
        "                    'tool': tool_name,\n",
        "                    'execution_time': 0,\n",
        "                    'success': False,\n",
        "                    'error': error_msg\n",
        "                })\n",
        "                \n",
        "                # Quyết định có tiếp tục hay không\n",
        "                if step.get('critical', True):\n",
        "                    raise Exception(f\"Critical step {step_name} failed: {error_msg}\")\n",
        "        \n",
        "        return {\n",
        "            'final_data': current_data,\n",
        "            'intermediate_results': self.intermediate_results,\n",
        "            'execution_log': self.execution_log\n",
        "        }\n",
        "    \n",
        "    def get_execution_summary(self) -> pd.DataFrame:\n",
        "        \"\"\"Tóm tắt quá trình thực thi pipeline\"\"\"\n",
        "        return pd.DataFrame(self.execution_log)\n",
        "\n",
        "# Khởi tạo manager\n",
        "ml_manager = MLToolsManager(ml_registry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 6: Ví Dụ Minh Họa Sử Dụng Thư Viện\n",
        "\n",
        "Hãy tạo một ví dụ hoàn chỉnh về cách sử dụng thư viện công cụ ML trong một quy trình khoa học dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tạo dữ liệu mẫu để demo\n",
        "def create_sample_dataset():\n",
        "    \"\"\"Tạo dữ liệu mẫu cho demo\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "    \n",
        "    # Tạo dữ liệu\n",
        "    data = {\n",
        "        'age': np.random.normal(35, 10, n_samples),\n",
        "        'salary': np.random.normal(50000, 15000, n_samples),\n",
        "        'experience': np.random.exponential(5, n_samples),\n",
        "        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples, p=[0.3, 0.4, 0.2, 0.1]),\n",
        "        'department': np.random.choice(['IT', 'HR', 'Finance', 'Marketing'], n_samples, p=[0.3, 0.2, 0.25, 0.25]),\n",
        "        'performance_score': np.random.normal(75, 15, n_samples)\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Thêm một số giá trị thiếu\n",
        "    missing_indices = np.random.choice(df.index, size=int(0.1 * n_samples), replace=False)\n",
        "    df.loc[missing_indices[:50], 'salary'] = np.nan\n",
        "    df.loc[missing_indices[50:], 'experience'] = np.nan\n",
        "    \n",
        "    # Thêm một số outliers\n",
        "    outlier_indices = np.random.choice(df.index, size=20, replace=False)\n",
        "    df.loc[outlier_indices, 'salary'] = df.loc[outlier_indices, 'salary'] * 3\n",
        "    \n",
        "    # Tạo target variable (high performer: performance_score > 80)\n",
        "    df['high_performer'] = (df['performance_score'] > 80).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Tạo dữ liệu mẫu\n",
        "sample_data = create_sample_dataset()\n",
        "print(\"Sample dataset created:\")\n",
        "print(f\"Shape: {sample_data.shape}\")\n",
        "print(f\"\\nColumns: {list(sample_data.columns)}\")\n",
        "print(f\"\\nMissing values:\")\n",
        "print(sample_data.isnull().sum())\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "print(sample_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo sử dụng các công cụ riêng lẻ\n",
        "print(\"=== DEMO SỬ DỤNG CÁC CÔNG CỤ RIÊNG LẺ ===\")\n",
        "\n",
        "# 1. Xử lý missing values\n",
        "print(\"\\n1. Xử lý Missing Values:\")\n",
        "missing_handler = ml_registry.get_tool('missing_value_handler')\n",
        "strategy = {\n",
        "    'salary': 'median',\n",
        "    'experience': 'mean'\n",
        "}\n",
        "data_cleaned = missing_handler.execute(sample_data, strategy)\n",
        "print(f\"Missing values after cleaning: {data_cleaned.isnull().sum().sum()}\")\n",
        "\n",
        "# 2. Phát hiện và xử lý outliers  \n",
        "print(\"\\n2. Xử lý Outliers:\")\n",
        "outlier_detector = ml_registry.get_tool('outlier_detector')\n",
        "data_no_outliers, outlier_info = outlier_detector.execute(\n",
        "    data_cleaned, \n",
        "    columns=['salary', 'age', 'experience'], \n",
        "    method='iqr', \n",
        "    action='cap'\n",
        ")\n",
        "print(\"Outlier information:\")\n",
        "for col, info in outlier_info.items():\n",
        "    print(f\"  {col}: {info['outlier_count']} outliers ({info['outlier_percentage']:.1f}%)\")\n",
        "\n",
        "# 3. Mã hóa categorical variables\n",
        "print(\"\\n3. Mã hóa Categorical Variables:\")\n",
        "categorical_encoder = ml_registry.get_tool('categorical_encoder')\n",
        "data_encoded = categorical_encoder.execute(\n",
        "    data_no_outliers,\n",
        "    columns=['education', 'department'],\n",
        "    method='onehot'\n",
        ")\n",
        "print(f\"Columns after encoding: {data_encoded.shape[1]} (was {data_no_outliers.shape[1]})\")\n",
        "\n",
        "# 4. Tạo features mới\n",
        "print(\"\\n4. Tạo Features Mới:\")\n",
        "feature_creator = ml_registry.get_tool('feature_creator')\n",
        "data_with_features = feature_creator.execute(\n",
        "    data_encoded,\n",
        "    operation='mathematical',\n",
        "    columns=['age', 'salary', 'experience'],\n",
        "    math_operations=['log', 'square']\n",
        ")\n",
        "print(f\"Columns after feature creation: {data_with_features.shape[1]} (was {data_encoded.shape[1]})\")\n",
        "\n",
        "# 5. Huấn luyện mô hình\n",
        "print(\"\\n5. Huấn luyện Mô hình:\")\n",
        "model_trainer = ml_registry.get_tool('model_trainer')\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "X = data_with_features.drop(['high_performer', 'performance_score'], axis=1)\n",
        "y = data_with_features['high_performer']\n",
        "\n",
        "# Loại bỏ cột có giá trị NaN hoặc inf\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "X = X.fillna(0)\n",
        "X = X.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "print(f\"Final feature matrix shape: {X.shape}\")\n",
        "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "training_results = model_trainer.execute(\n",
        "    X, y,\n",
        "    problem_type='classification',\n",
        "    models_to_try=['random_forest_clf', 'logistic_regression', 'xgboost_clf'],\n",
        "    cv_folds=3\n",
        ")\n",
        "\n",
        "print(\"\\nModel comparison:\")\n",
        "print(training_results['comparison_df'])\n",
        "print(f\"\\nBest model: {training_results['best_model_name']}\")\n",
        "print(f\"Best CV score: {training_results['best_model_info']['cv_mean']:.4f}\")\n",
        "\n",
        "# 6. Đánh giá mô hình\n",
        "print(\"\\n6. Đánh giá Mô hình:\")\n",
        "model_evaluator = ml_registry.get_tool('model_evaluator')\n",
        "best_model = training_results['best_model']\n",
        "X_test = training_results['X_test']\n",
        "y_test = training_results['y_test']\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_proba = best_model.predict_proba(X_test)\n",
        "\n",
        "evaluation_results = model_evaluator.execute(\n",
        "    y_test, y_pred,\n",
        "    problem_type='classification',\n",
        "    y_pred_proba=y_pred_proba\n",
        ")\n",
        "\n",
        "print(\"Evaluation metrics:\")\n",
        "for metric, value in evaluation_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "    elif metric not in ['classification_report', 'confusion_matrix']:\n",
        "        print(f\"  {metric}: {value}\")\n",
        "\n",
        "print(\"\\n=== DEMO HOÀN THÀNH ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo sử dụng MLToolsManager\n",
        "print(\"=== DEMO SỬ DỤNG ML TOOLS MANAGER ===\")\n",
        "\n",
        "# Liệt kê tất cả công cụ có sẵn\n",
        "print(\"\\n1. Danh sách tất cả công cụ:\")\n",
        "available_tools = ml_manager.list_available_tools()\n",
        "print(available_tools)\n",
        "\n",
        "# Tìm kiếm công cụ\n",
        "print(\"\\n2. Tìm kiếm công cụ với từ khóa 'feature':\")\n",
        "search_results = ml_manager.search_tools('feature')\n",
        "print(search_results)\n",
        "\n",
        "# Thống kê sử dụng\n",
        "print(\"\\n3. Thống kê sử dụng công cụ:\")\n",
        "usage_stats = ml_manager.get_tool_usage_stats()\n",
        "print(usage_stats)\n",
        "\n",
        "# Đề xuất công cụ\n",
        "print(\"\\n4. Đề xuất công cụ cho bài toán classification:\")\n",
        "data_info = {\n",
        "    'has_missing_values': True,\n",
        "    'has_numeric_columns': True,\n",
        "    'has_categorical_columns': True,\n",
        "    'feature_count': 5\n",
        "}\n",
        "recommendations = ml_manager.recommend_tools('classification', data_info)\n",
        "print(f\"Recommended tools: {recommendations}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 7: Mở Rộng Thư Viện Với Công Cụ Mới\n",
        "\n",
        "Một trong những ưu điểm quan trọng của thiết kế này là khả năng mở rộng. Hãy xem cách thêm một công cụ mới vào thư viện:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ví dụ tạo công cụ mới: Feature Selector\n",
        "class FeatureSelector(MLTool):\n",
        "    \"\"\"\n",
        "    Công cụ lựa chọn đặc trưng sử dụng nhiều phương pháp khác nhau\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            name=\"feature_selector\",\n",
        "            category=ToolCategory.FEATURE_ENGINEERING,\n",
        "            description=\"Select best features using statistical tests, mutual information, or model-based methods\"\n",
        "        )\n",
        "        self.supported_methods = {\n",
        "            'correlation': self._correlation_selection,\n",
        "            'mutual_info': self._mutual_info_selection,\n",
        "            'chi2': self._chi2_selection,\n",
        "            'lasso': self._lasso_selection,\n",
        "            'random_forest': self._rf_selection\n",
        "        }\n",
        "        self.selected_features = {}\n",
        "    \n",
        "    def validate_input(self, X: pd.DataFrame, y: pd.Series, method: str) -> bool:\n",
        "        \"\"\"Kiểm tra tính hợp lệ của đầu vào\"\"\"\n",
        "        if not isinstance(X, pd.DataFrame) or not isinstance(y, pd.Series):\n",
        "            return False\n",
        "        if len(X) != len(y):\n",
        "            return False\n",
        "        if method not in self.supported_methods:\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def execute(self, X: pd.DataFrame, y: pd.Series, \n",
        "                method: str = 'correlation',\n",
        "                k_features: int = 10,\n",
        "                threshold: float = 0.1) -> Tuple[pd.DataFrame, Dict]:\n",
        "        \"\"\"\n",
        "        Lựa chọn đặc trưng tốt nhất\n",
        "        \n",
        "        Parameters:\n",
        "        - X: DataFrame features\n",
        "        - y: Series target\n",
        "        - method: Phương pháp lựa chọn\n",
        "        - k_features: Số lượng features muốn chọn\n",
        "        - threshold: Ngưỡng cho một số phương pháp\n",
        "        \n",
        "        Returns:\n",
        "        - Tuple của (DataFrame với features đã chọn, thông tin selection)\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        if not self.validate_input(X, y, method):\n",
        "            raise ValueError(\"Invalid input parameters\")\n",
        "        \n",
        "        # Chỉ xử lý cột số\n",
        "        X_numeric = X.select_dtypes(include=[np.number])\n",
        "        X_numeric = X_numeric.fillna(0)\n",
        "        X_numeric = X_numeric.replace([np.inf, -np.inf], 0)\n",
        "        \n",
        "        # Áp dụng phương pháp lựa chọn\n",
        "        selected_features, feature_scores = self.supported_methods[method](\n",
        "            X_numeric, y, k_features, threshold\n",
        "        )\n",
        "        \n",
        "        # Tạo DataFrame kết quả\n",
        "        X_selected = X_numeric[selected_features]\n",
        "        \n",
        "        # Thông tin về quá trình lựa chọn\n",
        "        selection_info = {\n",
        "            'method': method,\n",
        "            'original_features': X_numeric.shape[1],\n",
        "            'selected_features': len(selected_features),\n",
        "            'selected_feature_names': selected_features,\n",
        "            'feature_scores': feature_scores,\n",
        "            'reduction_percentage': (1 - len(selected_features) / X_numeric.shape[1]) * 100\n",
        "        }\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Lưu thông tin\n",
        "        self.selected_features[method] = selected_features\n",
        "        \n",
        "        # Log thực thi\n",
        "        self.log_execution(\n",
        "            inputs={'X_shape': X.shape, 'y_shape': y.shape, 'method': method, 'k_features': k_features},\n",
        "            outputs={'selected_features': len(selected_features), 'X_selected_shape': X_selected.shape},\n",
        "            execution_time=execution_time\n",
        "        )\n",
        "        \n",
        "        return X_selected, selection_info\n",
        "    \n",
        "    def _correlation_selection(self, X: pd.DataFrame, y: pd.Series, k: int, threshold: float) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"Lựa chọn dựa trên correlation với target\"\"\"\n",
        "        correlations = X.corrwith(y).abs()\n",
        "        correlations = correlations.sort_values(ascending=False)\n",
        "        selected = correlations.head(k).index.tolist()\n",
        "        scores = correlations.head(k).to_dict()\n",
        "        return selected, scores\n",
        "    \n",
        "    def _mutual_info_selection(self, X: pd.DataFrame, y: pd.Series, k: int, threshold: float) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"Lựa chọn dựa trên mutual information\"\"\"\n",
        "        from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
        "        \n",
        "        # Xác định loại bài toán\n",
        "        if len(y.unique()) <= 10:  # Classification\n",
        "            mi_scores = mutual_info_classif(X, y)\n",
        "        else:  # Regression\n",
        "            mi_scores = mutual_info_regression(X, y)\n",
        "        \n",
        "        # Tạo DataFrame để sort\n",
        "        mi_df = pd.DataFrame({'feature': X.columns, 'score': mi_scores})\n",
        "        mi_df = mi_df.sort_values('score', ascending=False)\n",
        "        \n",
        "        selected = mi_df.head(k)['feature'].tolist()\n",
        "        scores = dict(zip(mi_df.head(k)['feature'], mi_df.head(k)['score']))\n",
        "        \n",
        "        return selected, scores\n",
        "    \n",
        "    def _chi2_selection(self, X: pd.DataFrame, y: pd.Series, k: int, threshold: float) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"Lựa chọn dựa trên Chi-square test (chỉ cho classification)\"\"\"\n",
        "        from sklearn.feature_selection import chi2\n",
        "        \n",
        "        # Đảm bảo tất cả giá trị không âm\n",
        "        X_positive = X - X.min() + 1e-8\n",
        "        \n",
        "        chi2_scores, p_values = chi2(X_positive, y)\n",
        "        \n",
        "        # Tạo DataFrame để sort\n",
        "        chi2_df = pd.DataFrame({\n",
        "            'feature': X.columns, \n",
        "            'chi2_score': chi2_scores,\n",
        "            'p_value': p_values\n",
        "        })\n",
        "        chi2_df = chi2_df.sort_values('chi2_score', ascending=False)\n",
        "        \n",
        "        selected = chi2_df.head(k)['feature'].tolist()\n",
        "        scores = dict(zip(chi2_df.head(k)['feature'], chi2_df.head(k)['chi2_score']))\n",
        "        \n",
        "        return selected, scores\n",
        "    \n",
        "    def _lasso_selection(self, X: pd.DataFrame, y: pd.Series, k: int, threshold: float) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"Lựa chọn dựa trên Lasso regularization\"\"\"\n",
        "        from sklearn.linear_model import Lasso\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        \n",
        "        # Chuẩn hóa dữ liệu\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        \n",
        "        # Fit Lasso\n",
        "        lasso = Lasso(alpha=threshold, random_state=42)\n",
        "        lasso.fit(X_scaled, y)\n",
        "        \n",
        "        # Lấy coefficients\n",
        "        coef_abs = np.abs(lasso.coef_)\n",
        "        \n",
        "        # Tạo DataFrame để sort\n",
        "        coef_df = pd.DataFrame({\n",
        "            'feature': X.columns,\n",
        "            'coefficient': coef_abs\n",
        "        })\n",
        "        coef_df = coef_df.sort_values('coefficient', ascending=False)\n",
        "        \n",
        "        # Chọn features có coefficient > 0\n",
        "        non_zero_features = coef_df[coef_df['coefficient'] > 0]\n",
        "        selected = non_zero_features.head(k)['feature'].tolist()\n",
        "        scores = dict(zip(non_zero_features.head(k)['feature'], non_zero_features.head(k)['coefficient']))\n",
        "        \n",
        "        return selected, scores\n",
        "    \n",
        "    def _rf_selection(self, X: pd.DataFrame, y: pd.Series, k: int, threshold: float) -> Tuple[List[str], Dict]:\n",
        "        \"\"\"Lựa chọn dựa trên feature importance từ Random Forest\"\"\"\n",
        "        from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "        \n",
        "        # Xác định loại bài toán\n",
        "        if len(y.unique()) <= 10:  # Classification\n",
        "            rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        else:  # Regression\n",
        "            rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        \n",
        "        rf.fit(X, y)\n",
        "        \n",
        "        # Lấy feature importance\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': X.columns,\n",
        "            'importance': rf.feature_importances_\n",
        "        })\n",
        "        importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "        \n",
        "        selected = importance_df.head(k)['feature'].tolist()\n",
        "        scores = dict(zip(importance_df.head(k)['feature'], importance_df.head(k)['importance']))\n",
        "        \n",
        "        return selected, scores\n",
        "\n",
        "# Đăng ký công cụ mới\n",
        "ml_registry.register_tool(FeatureSelector())\n",
        "\n",
        "print(\"Đã thêm công cụ Feature Selector vào thư viện!\")\n",
        "print(\"\\nDanh sách công cụ mới:\")\n",
        "print(ml_manager.list_available_tools())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kết Luận\n",
        "\n",
        "Thư viện công cụ học máy (Machine Learning Tools Library) trong AutoKaggle là một thành phần quan trọng và được thiết kế rất tốt. Thông qua notebook này, chúng ta đã học được:\n",
        "\n",
        "### Những Điểm Chính:\n",
        "\n",
        "1. **Tổ Chức Có Hệ Thống**: Thư viện được tổ chức thành 3 danh mục chính (Data Cleaning, Feature Engineering, Model Building) với các công cụ chuyên biệt cho từng giai đoạn\n",
        "\n",
        "2. **Thiết Kế Nhất Quán**: Tất cả công cụ đều kế thừa từ MLTool base class, đảm bảo interface nhất quán và dễ sử dụng\n",
        "\n",
        "3. **Khả Năng Mở Rộng**: Kiến trúc Registry pattern cho phép dễ dàng thêm công cụ mới mà không cần sửa đổi code hiện có\n",
        "\n",
        "4. **Tự Động Hóa Cao**: Các công cụ được thiết kế để tự động hóa các tác vụ phức tạp, từ xử lý dữ liệu đến huấn luyện mô hình\n",
        "\n",
        "5. **Logging và Monitoring**: Mỗi công cụ đều có khả năng ghi log quá trình thực thi, giúp debug và tối ưu hóa\n",
        "\n",
        "### Lợi Ích Của Thiết Kế:\n",
        "\n",
        "- **Tái Sử Dụng**: Các công cụ có thể được sử dụng độc lập hoặc kết hợp trong pipeline\n",
        "- **Tin Cậy**: Các công cụ đã được kiểm thử và validate, đảm bảo tính đúng đắn\n",
        "- **Hiệu Quả**: Tự động hóa các tác vụ lặp đi lặp lại, tiết kiệm thời gian\n",
        "- **Dễ Bảo Trì**: Kiến trúc module hóa giúp dễ dàng cập nhật và sửa lỗi\n",
        "\n",
        "### Ứng Dụng Thực Tế:\n",
        "\n",
        "Thiết kế này có thể được áp dụng cho:\n",
        "- Xây dựng platform AutoML\n",
        "- Tạo công cụ hỗ trợ data scientist\n",
        "- Phát triển hệ thống ML-as-a-Service\n",
        "- Giáo dục và đào tạo về khoa học dữ liệu\n",
        "\n",
        "Thư viện công cụ ML trong AutoKaggle thể hiện một cách tiếp cận chuyên nghiệp và có hệ thống để tự động hóa quy trình khoa học dữ liệu, đồng thời duy trì tính linh hoạt và khả năng mở rộng."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}