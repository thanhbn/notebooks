{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AutoKaggle: Error Analysis and Debugging Workflow\n",
        "\n",
        "## Mục Tiêu\n",
        "\n",
        "Notebook này tập trung vào phân tích chuyên sâu về quy trình phân tích lỗi và debugging được giới thiệu trong bài báo \"AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions\". Chúng ta sẽ khám phá cách thiết kế và triển khai một hệ thống debug tự động có khả năng phát hiện, phân tích và sửa chữa lỗi trong quá trình phát triển code.\n",
        "\n",
        "Sau khi hoàn thành notebook này, bạn sẽ:\n",
        "1. Hiểu được các loại lỗi phổ biến trong quy trình khoa học dữ liệu\n",
        "2. Nắm được quy trình debug tự động và iterative testing\n",
        "3. Hiểu được cách phân tích và xử lý lỗi một cách có hệ thống\n",
        "4. Có thể triển khai hệ thống debug tự động cho các dự án ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trích Xuất Từ Bài Báo\n",
        "\n",
        "> \"AutoKaggle employs iterative debugging and testing to ensure the generated code meets requirements and is reliable. This process includes code execution, error detection, debugging, and unit testing.\" (Section 3.2 Development-Based Iterative Debugging and Testing, Page 5)\n",
        "\n",
        "> \"The iterative debugging process involves three main steps: 1) Execute the generated code and capture any runtime errors, 2) If errors are detected, analyze the error messages and identify the root cause, 3) Generate corrected code and test again until the code executes successfully.\" (Section 3.2 Development-Based Iterative Debugging and Testing, Page 5)\n",
        "\n",
        "> \"Unit testing is performed to validate the correctness of the generated code. Each phase has specific test cases designed to verify that the code produces the expected outputs and handles edge cases appropriately.\" (Section 3.2 Development-Based Iterative Debugging and Testing, Page 5)\n",
        "\n",
        "> \"The system tracks error patterns and maintains a history of common issues and their solutions. This knowledge base helps improve the debugging process over time by providing context-aware suggestions for similar errors.\" (Section 3.2 Development-Based Iterative Debugging and Testing, Page 5)\n",
        "\n",
        "![Error Analysis Workflow](https://m-a-p.ai/AutoKaggle.github.io/assets/images/fig2.png)\n",
        "*(Note: Diagram representation - actual image not included)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cài Đặt Môi Trường"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn\n",
        "!pip install -q langchain langchain-openai\n",
        "!pip install -q ast traceback sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Optional, Tuple, Any, Union, Callable\n",
        "from enum import Enum\n",
        "import ast\n",
        "import traceback\n",
        "import sys\n",
        "import io\n",
        "import contextlib\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from abc import ABC, abstractmethod\n",
        "import logging\n",
        "\n",
        "# Import cho LLM integration\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Thiết lập logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Thiết lập môi trường\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 1: Định Nghĩa Các Loại Lỗi và Mức Độ Nghiêm Trọng\n",
        "\n",
        "Trước khi xây dựng hệ thống debug, chúng ta cần phân loại các loại lỗi có thể gặp phải trong quy trình khoa học dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ErrorType(Enum):\n",
        "    \"\"\"Phân loại các loại lỗi trong quy trình khoa học dữ liệu\"\"\"\n",
        "    SYNTAX_ERROR = \"Syntax Error\"\n",
        "    IMPORT_ERROR = \"Import Error\"\n",
        "    TYPE_ERROR = \"Type Error\"\n",
        "    VALUE_ERROR = \"Value Error\"\n",
        "    KEY_ERROR = \"Key Error\"\n",
        "    INDEX_ERROR = \"Index Error\"\n",
        "    ATTRIBUTE_ERROR = \"Attribute Error\"\n",
        "    MEMORY_ERROR = \"Memory Error\"\n",
        "    RUNTIME_ERROR = \"Runtime Error\"\n",
        "    LOGIC_ERROR = \"Logic Error\"\n",
        "    DATA_ERROR = \"Data Error\"\n",
        "    MODEL_ERROR = \"Model Error\"\n",
        "    PERFORMANCE_ERROR = \"Performance Error\"\n",
        "    UNKNOWN_ERROR = \"Unknown Error\"\n",
        "\n",
        "class ErrorSeverity(Enum):\n",
        "    \"\"\"Mức độ nghiêm trọng của lỗi\"\"\"\n",
        "    CRITICAL = \"Critical\"  # Lỗi ngăn cản hoàn toàn việc thực thi\n",
        "    HIGH = \"High\"         # Lỗi ảnh hưởng nghiêm trọng đến kết quả\n",
        "    MEDIUM = \"Medium\"     # Lỗi có thể ảnh hưởng đến chất lượng\n",
        "    LOW = \"Low\"           # Lỗi nhỏ, không ảnh hưởng nhiều\n",
        "    WARNING = \"Warning\"   # Cảnh báo, không phải lỗi thực sự\n",
        "\n",
        "@dataclass\n",
        "class ErrorInfo:\n",
        "    \"\"\"Thông tin chi tiết về một lỗi\"\"\"\n",
        "    error_type: ErrorType\n",
        "    severity: ErrorSeverity\n",
        "    message: str\n",
        "    traceback: str\n",
        "    line_number: Optional[int]\n",
        "    code_snippet: Optional[str]\n",
        "    suggested_fix: Optional[str]\n",
        "    timestamp: float\n",
        "    context: Dict[str, Any]\n",
        "\n",
        "class ErrorClassifier:\n",
        "    \"\"\"Phân loại lỗi dựa trên thông tin exception\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.error_patterns = {\n",
        "            ErrorType.SYNTAX_ERROR: [\n",
        "                r\"SyntaxError\",\n",
        "                r\"invalid syntax\",\n",
        "                r\"unexpected EOF\",\n",
        "                r\"IndentationError\"\n",
        "            ],\n",
        "            ErrorType.IMPORT_ERROR: [\n",
        "                r\"ImportError\",\n",
        "                r\"ModuleNotFoundError\",\n",
        "                r\"No module named\"\n",
        "            ],\n",
        "            ErrorType.TYPE_ERROR: [\n",
        "                r\"TypeError\",\n",
        "                r\"unsupported operand type\",\n",
        "                r\"object is not callable\",\n",
        "                r\"takes .* positional arguments\"\n",
        "            ],\n",
        "            ErrorType.VALUE_ERROR: [\n",
        "                r\"ValueError\",\n",
        "                r\"invalid literal\",\n",
        "                r\"could not convert\",\n",
        "                r\"empty sequence\"\n",
        "            ],\n",
        "            ErrorType.KEY_ERROR: [\n",
        "                r\"KeyError\",\n",
        "                r\"key not found\"\n",
        "            ],\n",
        "            ErrorType.INDEX_ERROR: [\n",
        "                r\"IndexError\",\n",
        "                r\"list index out of range\",\n",
        "                r\"index out of bounds\"\n",
        "            ],\n",
        "            ErrorType.ATTRIBUTE_ERROR: [\n",
        "                r\"AttributeError\",\n",
        "                r\"has no attribute\"\n",
        "            ],\n",
        "            ErrorType.MEMORY_ERROR: [\n",
        "                r\"MemoryError\",\n",
        "                r\"out of memory\",\n",
        "                r\"OutOfMemoryError\"\n",
        "            ],\n",
        "            ErrorType.DATA_ERROR: [\n",
        "                r\"data type.*not understood\",\n",
        "                r\"input contains NaN\",\n",
        "                r\"input contains infinity\",\n",
        "                r\"empty DataFrame\",\n",
        "                r\"no columns to parse\"\n",
        "            ],\n",
        "            ErrorType.MODEL_ERROR: [\n",
        "                r\"convergence\",\n",
        "                r\"not fitted\",\n",
        "                r\"singular matrix\",\n",
        "                r\"ill-conditioned\"\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        self.severity_patterns = {\n",
        "            ErrorSeverity.CRITICAL: [\n",
        "                r\"SyntaxError\", r\"ImportError\", r\"MemoryError\"\n",
        "            ],\n",
        "            ErrorSeverity.HIGH: [\n",
        "                r\"TypeError\", r\"ValueError\", r\"AttributeError\"\n",
        "            ],\n",
        "            ErrorSeverity.MEDIUM: [\n",
        "                r\"KeyError\", r\"IndexError\", r\"RuntimeWarning\"\n",
        "            ],\n",
        "            ErrorSeverity.LOW: [\n",
        "                r\"FutureWarning\", r\"DeprecationWarning\"\n",
        "            ]\n",
        "        }\n",
        "    \n",
        "    def classify_error(self, error_message: str, traceback_str: str) -> Tuple[ErrorType, ErrorSeverity]:\n",
        "        \"\"\"Phân loại lỗi dựa trên error message và traceback\"\"\"\n",
        "        combined_text = f\"{error_message} {traceback_str}\"\n",
        "        \n",
        "        # Xác định loại lỗi\n",
        "        error_type = ErrorType.UNKNOWN_ERROR\n",
        "        for etype, patterns in self.error_patterns.items():\n",
        "            for pattern in patterns:\n",
        "                if re.search(pattern, combined_text, re.IGNORECASE):\n",
        "                    error_type = etype\n",
        "                    break\n",
        "            if error_type != ErrorType.UNKNOWN_ERROR:\n",
        "                break\n",
        "        \n",
        "        # Xác định mức độ nghiêm trọng\n",
        "        severity = ErrorSeverity.MEDIUM  # Mặc định\n",
        "        for sev, patterns in self.severity_patterns.items():\n",
        "            for pattern in patterns:\n",
        "                if re.search(pattern, combined_text, re.IGNORECASE):\n",
        "                    severity = sev\n",
        "                    break\n",
        "            if severity != ErrorSeverity.MEDIUM:\n",
        "                break\n",
        "        \n",
        "        return error_type, severity\n",
        "    \n",
        "    def extract_line_number(self, traceback_str: str) -> Optional[int]:\n",
        "        \"\"\"Trích xuất số dòng từ traceback\"\"\"\n",
        "        line_pattern = r\"line (\\d+)\"\n",
        "        matches = re.findall(line_pattern, traceback_str)\n",
        "        if matches:\n",
        "            return int(matches[-1])  # Lấy dòng cuối cùng (thường là dòng gây lỗi)\n",
        "        return None\n",
        "    \n",
        "    def extract_code_snippet(self, code: str, line_number: Optional[int], context_lines: int = 3) -> Optional[str]:\n",
        "        \"\"\"Trích xuất đoạn code xung quanh dòng lỗi\"\"\"\n",
        "        if line_number is None:\n",
        "            return None\n",
        "        \n",
        "        lines = code.split('\\n')\n",
        "        start = max(0, line_number - context_lines - 1)\n",
        "        end = min(len(lines), line_number + context_lines)\n",
        "        \n",
        "        snippet_lines = []\n",
        "        for i in range(start, end):\n",
        "            marker = \">>> \" if i == line_number - 1 else \"    \"\n",
        "            snippet_lines.append(f\"{marker}{i+1}: {lines[i]}\")\n",
        "        \n",
        "        return \"\\n\".join(snippet_lines)\n",
        "\n",
        "# Khởi tạo classifier\n",
        "error_classifier = ErrorClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 2: Hệ Thống Thực Thi Code An Toàn\n",
        "\n",
        "Để debug hiệu quả, chúng ta cần một hệ thống có thể thực thi code an toàn và capture tất cả các lỗi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SafeCodeExecutor:\n",
        "    \"\"\"Hệ thống thực thi code an toàn với error capturing\"\"\"\n",
        "    \n",
        "    def __init__(self, timeout: int = 30):\n",
        "        self.timeout = timeout\n",
        "        self.execution_history = []\n",
        "        self.global_namespace = {\n",
        "            '__builtins__': __builtins__,\n",
        "            'pd': pd,\n",
        "            'np': np,\n",
        "            'plt': plt,\n",
        "            'sns': sns\n",
        "        }\n",
        "    \n",
        "    def execute_code(self, code: str, context: Dict[str, Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Thực thi code và capture kết quả/lỗi\n",
        "        \n",
        "        Parameters:\n",
        "        - code: Code Python cần thực thi\n",
        "        - context: Context variables để inject vào namespace\n",
        "        \n",
        "        Returns:\n",
        "        - Dictionary chứa kết quả thực thi\n",
        "        \"\"\"\n",
        "        execution_result = {\n",
        "            'success': False,\n",
        "            'output': '',\n",
        "            'error': None,\n",
        "            'error_info': None,\n",
        "            'execution_time': 0,\n",
        "            'variables_created': [],\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "        \n",
        "        # Chuẩn bị namespace\n",
        "        local_namespace = self.global_namespace.copy()\n",
        "        if context:\n",
        "            local_namespace.update(context)\n",
        "        \n",
        "        # Capture variables trước khi thực thi\n",
        "        vars_before = set(local_namespace.keys())\n",
        "        \n",
        "        # Capture stdout\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = captured_output = io.StringIO()\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Kiểm tra syntax trước\n",
        "            try:\n",
        "                ast.parse(code)\n",
        "            except SyntaxError as e:\n",
        "                raise SyntaxError(f\"Syntax error at line {e.lineno}: {e.msg}\")\n",
        "            \n",
        "            # Thực thi code\n",
        "            exec(code, local_namespace)\n",
        "            \n",
        "            execution_result['success'] = True\n",
        "            execution_result['output'] = captured_output.getvalue()\n",
        "            \n",
        "            # Xác định variables mới được tạo\n",
        "            vars_after = set(local_namespace.keys())\n",
        "            execution_result['variables_created'] = list(vars_after - vars_before)\n",
        "            \n",
        "            # Cập nhật global namespace\n",
        "            self.global_namespace.update(local_namespace)\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Capture error information\n",
        "            error_message = str(e)\n",
        "            traceback_str = traceback.format_exc()\n",
        "            \n",
        "            # Phân loại lỗi\n",
        "            error_type, severity = error_classifier.classify_error(error_message, traceback_str)\n",
        "            line_number = error_classifier.extract_line_number(traceback_str)\n",
        "            code_snippet = error_classifier.extract_code_snippet(code, line_number)\n",
        "            \n",
        "            # Tạo ErrorInfo object\n",
        "            error_info = ErrorInfo(\n",
        "                error_type=error_type,\n",
        "                severity=severity,\n",
        "                message=error_message,\n",
        "                traceback=traceback_str,\n",
        "                line_number=line_number,\n",
        "                code_snippet=code_snippet,\n",
        "                suggested_fix=None,  # Sẽ được fill bởi FixSuggester\n",
        "                timestamp=time.time(),\n",
        "                context=context or {}\n",
        "            )\n",
        "            \n",
        "            execution_result['error'] = error_message\n",
        "            execution_result['error_info'] = error_info\n",
        "        \n",
        "        finally:\n",
        "            # Khôi phục stdout\n",
        "            sys.stdout = old_stdout\n",
        "            execution_result['execution_time'] = time.time() - start_time\n",
        "        \n",
        "        # Lưu vào history\n",
        "        self.execution_history.append({\n",
        "            'code': code,\n",
        "            'result': execution_result\n",
        "        })\n",
        "        \n",
        "        return execution_result\n",
        "    \n",
        "    def get_variable(self, var_name: str) -> Any:\n",
        "        \"\"\"Lấy giá trị của một variable từ namespace\"\"\"\n",
        "        return self.global_namespace.get(var_name)\n",
        "    \n",
        "    def set_variable(self, var_name: str, value: Any) -> None:\n",
        "        \"\"\"Set giá trị cho một variable trong namespace\"\"\"\n",
        "        self.global_namespace[var_name] = value\n",
        "    \n",
        "    def clear_namespace(self) -> None:\n",
        "        \"\"\"Clear các variables (giữ lại built-ins và imports cơ bản)\"\"\"\n",
        "        basic_vars = {\n",
        "            '__builtins__': __builtins__,\n",
        "            'pd': pd,\n",
        "            'np': np,\n",
        "            'plt': plt,\n",
        "            'sns': sns\n",
        "        }\n",
        "        self.global_namespace = basic_vars\n",
        "    \n",
        "    def get_execution_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Thống kê về quá trình thực thi\"\"\"\n",
        "        if not self.execution_history:\n",
        "            return {'total_executions': 0, 'success_rate': 0, 'average_time': 0}\n",
        "        \n",
        "        total = len(self.execution_history)\n",
        "        successful = sum(1 for entry in self.execution_history if entry['result']['success'])\n",
        "        total_time = sum(entry['result']['execution_time'] for entry in self.execution_history)\n",
        "        \n",
        "        return {\n",
        "            'total_executions': total,\n",
        "            'successful_executions': successful,\n",
        "            'failed_executions': total - successful,\n",
        "            'success_rate': successful / total * 100,\n",
        "            'average_time': total_time / total,\n",
        "            'total_time': total_time\n",
        "        }\n",
        "\n",
        "# Khởi tạo safe executor\n",
        "safe_executor = SafeCodeExecutor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 3: Hệ Thống Đề Xuất Sửa Lỗi Tự Động\n",
        "\n",
        "Đây là thành phần quan trọng nhất - hệ thống AI có thể phân tích lỗi và đề xuất cách sửa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ErrorFixSuggester:\n",
        "    \"\"\"Hệ thống đề xuất cách sửa lỗi sử dụng LLM\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = \"gpt-3.5-turbo\"):\n",
        "        self.model = ChatOpenAI(model=model_name, temperature=0.1)\n",
        "        self.fix_history = []  # Lịch sử các lần fix\n",
        "        self.common_fixes = self._load_common_fixes()\n",
        "        \n",
        "        # Template cho error analysis\n",
        "        self.analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=\"\"\"\n",
        "            You are an expert Python debugger and data science code analyst. Your task is to analyze errors and provide specific, actionable fixes.\n",
        "            \n",
        "            Follow this analysis framework:\n",
        "            1. ROOT CAUSE ANALYSIS: Identify the exact cause of the error\n",
        "            2. IMPACT ASSESSMENT: Determine how this error affects the overall workflow\n",
        "            3. FIX STRATEGY: Provide a specific solution\n",
        "            4. ALTERNATIVE APPROACHES: Suggest alternative methods if applicable\n",
        "            5. PREVENTION: How to avoid this error in the future\n",
        "            \n",
        "            Focus on data science and machine learning context. Provide working code fixes.\n",
        "            \"\"\"),\n",
        "            HumanMessage(content=\"\"\"\n",
        "            Analyze this error and provide a fix:\n",
        "            \n",
        "            ERROR TYPE: {error_type}\n",
        "            SEVERITY: {severity}\n",
        "            ERROR MESSAGE: {error_message}\n",
        "            \n",
        "            CODE THAT FAILED:\n",
        "            ```python\n",
        "            {code_snippet}\n",
        "            ```\n",
        "            \n",
        "            FULL TRACEBACK:\n",
        "            {traceback}\n",
        "            \n",
        "            CONTEXT: {context}\n",
        "            \n",
        "            Please provide:\n",
        "            1. A clear explanation of what went wrong\n",
        "            2. The corrected code\n",
        "            3. Alternative approaches if applicable\n",
        "            4. How to prevent this error in the future\n",
        "            \"\"\")\n",
        "        ])\n",
        "        \n",
        "        self.chain = self.analysis_prompt | self.model | StrOutputParser()\n",
        "    \n",
        "    def _load_common_fixes(self) -> Dict[ErrorType, List[str]]:\n",
        "        \"\"\"Load common fixes for frequent error types\"\"\"\n",
        "        return {\n",
        "            ErrorType.IMPORT_ERROR: [\n",
        "                \"Install missing package with pip install\",\n",
        "                \"Check package name spelling\",\n",
        "                \"Import from correct module path\"\n",
        "            ],\n",
        "            ErrorType.KEY_ERROR: [\n",
        "                \"Check if key exists before accessing\",\n",
        "                \"Use .get() method with default value\",\n",
        "                \"Verify dataframe column names\"\n",
        "            ],\n",
        "            ErrorType.TYPE_ERROR: [\n",
        "                \"Check data types of variables\",\n",
        "                \"Convert to appropriate type\",\n",
        "                \"Verify function arguments\"\n",
        "            ],\n",
        "            ErrorType.VALUE_ERROR: [\n",
        "                \"Check input data validity\",\n",
        "                \"Handle missing or invalid values\",\n",
        "                \"Verify data ranges and constraints\"\n",
        "            ],\n",
        "            ErrorType.DATA_ERROR: [\n",
        "                \"Clean data before processing\",\n",
        "                \"Handle NaN and infinite values\",\n",
        "                \"Check data schema and types\"\n",
        "            ]\n",
        "        }\n",
        "    \n",
        "    def suggest_fix(self, error_info: ErrorInfo, original_code: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Đề xuất cách sửa lỗi\n",
        "        \n",
        "        Parameters:\n",
        "        - error_info: Thông tin lỗi đã được phân tích\n",
        "        - original_code: Code gốc gây lỗi\n",
        "        \n",
        "        Returns:\n",
        "        - Dictionary chứa các đề xuất sửa lỗi\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Kiểm tra xem có fix nhanh không\n",
        "        quick_fix = self._try_quick_fix(error_info, original_code)\n",
        "        \n",
        "        # Sử dụng LLM để phân tích sâu\n",
        "        llm_analysis = self._get_llm_analysis(error_info, original_code)\n",
        "        \n",
        "        # Tạo suggested fixes\n",
        "        suggested_fixes = {\n",
        "            'quick_fix': quick_fix,\n",
        "            'llm_analysis': llm_analysis,\n",
        "            'common_fixes': self.common_fixes.get(error_info.error_type, []),\n",
        "            'analysis_time': time.time() - start_time,\n",
        "            'confidence': self._calculate_confidence(error_info, quick_fix, llm_analysis)\n",
        "        }\n",
        "        \n",
        "        # Lưu vào history\n",
        "        self.fix_history.append({\n",
        "            'error_info': error_info,\n",
        "            'original_code': original_code,\n",
        "            'suggested_fixes': suggested_fixes,\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "        \n",
        "        return suggested_fixes\n",
        "    \n",
        "    def _try_quick_fix(self, error_info: ErrorInfo, code: str) -> Optional[str]:\n",
        "        \"\"\"Thử các quick fix patterns cho lỗi phổ biến\"\"\"\n",
        "        error_type = error_info.error_type\n",
        "        message = error_info.message.lower()\n",
        "        \n",
        "        # Import error fixes\n",
        "        if error_type == ErrorType.IMPORT_ERROR:\n",
        "            if \"no module named\" in message:\n",
        "                module_name = re.search(r\"no module named ['\\\"]([^'\\\"]+)['\\\"], message)\n",
        "                if module_name:\n",
        "                    return f\"# Install missing module\\n!pip install {module_name.group(1)}\\n\\n{code}\"\n",
        "        \n",
        "        # KeyError fixes\n",
        "        elif error_type == ErrorType.KEY_ERROR:\n",
        "            if \"'\" in message:  # Extract key name\n",
        "                key_match = re.search(r\"'([^']+)'\", message)\n",
        "                if key_match:\n",
        "                    key_name = key_match.group(1)\n",
        "                    # Suggest using .get() method\n",
        "                    lines = code.split('\\n')\n",
        "                    fixed_lines = []\n",
        "                    for line in lines:\n",
        "                        if f\"['{key_name}']\" in line or f'[\"{key_name}\"]' in line:\n",
        "                            # Replace with .get() method\n",
        "                            fixed_line = re.sub(\n",
        "                                r\"\\[['\\\"]\" + re.escape(key_name) + r\"['\\\"]\\]\",\n",
        "                                f\".get('{key_name}', None)\",\n",
        "                                line\n",
        "                            )\n",
        "                            fixed_lines.append(fixed_line)\n",
        "                        else:\n",
        "                            fixed_lines.append(line)\n",
        "                    return '\\n'.join(fixed_lines)\n",
        "        \n",
        "        # Type error fixes\n",
        "        elif error_type == ErrorType.TYPE_ERROR:\n",
        "            if \"unsupported operand type\" in message:\n",
        "                # Suggest type conversion\n",
        "                return f\"# Add type conversion\\n# Check data types before operations\\n{code}\"\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def _get_llm_analysis(self, error_info: ErrorInfo, code: str) -> str:\n",
        "        \"\"\"Sử dụng LLM để phân tích lỗi và đề xuất fix\"\"\"\n",
        "        try:\n",
        "            # Chuẩn bị context\n",
        "            context_str = json.dumps(error_info.context, indent=2) if error_info.context else \"No additional context\"\n",
        "            \n",
        "            # Gọi LLM\n",
        "            analysis = self.chain.invoke({\n",
        "                'error_type': error_info.error_type.value,\n",
        "                'severity': error_info.severity.value,\n",
        "                'error_message': error_info.message,\n",
        "                'code_snippet': error_info.code_snippet or code,\n",
        "                'traceback': error_info.traceback,\n",
        "                'context': context_str\n",
        "            })\n",
        "            \n",
        "            return analysis\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"Error during LLM analysis: {str(e)}\"\n",
        "    \n",
        "    def _calculate_confidence(self, error_info: ErrorInfo, quick_fix: Optional[str], llm_analysis: str) -> float:\n",
        "        \"\"\"Tính confidence score cho fix suggestion\"\"\"\n",
        "        confidence = 0.5  # Base confidence\n",
        "        \n",
        "        # Tăng confidence nếu có quick fix\n",
        "        if quick_fix:\n",
        "            confidence += 0.2\n",
        "        \n",
        "        # Tăng confidence dựa trên error type\n",
        "        if error_info.error_type in [ErrorType.IMPORT_ERROR, ErrorType.SYNTAX_ERROR]:\n",
        "            confidence += 0.2\n",
        "        \n",
        "        # Tăng confidence nếu LLM analysis có code block\n",
        "        if \"```python\" in llm_analysis:\n",
        "            confidence += 0.1\n",
        "        \n",
        "        return min(confidence, 1.0)\n",
        "    \n",
        "    def extract_fixed_code_from_analysis(self, llm_analysis: str) -> Optional[str]:\n",
        "        \"\"\"Trích xuất code đã fix từ LLM analysis\"\"\"\n",
        "        # Tìm code blocks trong analysis\n",
        "        code_pattern = r\"```python\\s*\\n(.*?)\\n\\s*```\"\n",
        "        matches = re.findall(code_pattern, llm_analysis, re.DOTALL)\n",
        "        \n",
        "        if matches:\n",
        "            # Lấy code block đầu tiên (thường là fixed code)\n",
        "            return matches[0].strip()\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_fix_success_rate(self) -> Dict[str, float]:\n",
        "        \"\"\"Thống kê tỷ lệ thành công của các loại fix\"\"\"\n",
        "        if not self.fix_history:\n",
        "            return {}\n",
        "        \n",
        "        success_by_type = {}\n",
        "        total_by_type = {}\n",
        "        \n",
        "        for entry in self.fix_history:\n",
        "            error_type = entry['error_info'].error_type.value\n",
        "            total_by_type[error_type] = total_by_type.get(error_type, 0) + 1\n",
        "            \n",
        "            # Check if fix was successful (simplified - would need actual validation)\n",
        "            confidence = entry['suggested_fixes']['confidence']\n",
        "            if confidence > 0.7:  # Consider high confidence as successful\n",
        "                success_by_type[error_type] = success_by_type.get(error_type, 0) + 1\n",
        "        \n",
        "        success_rates = {}\n",
        "        for error_type in total_by_type:\n",
        "            success_rates[error_type] = success_by_type.get(error_type, 0) / total_by_type[error_type]\n",
        "        \n",
        "        return success_rates\n",
        "\n",
        "# Khởi tạo fix suggester (comment để tránh lỗi API key)\n",
        "# fix_suggester = ErrorFixSuggester()\n",
        "print(\"Error Fix Suggester class defined (API key required for instantiation)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 4: Unit Testing Framework\n",
        "\n",
        "Hệ thống unit testing để verify tính đúng đắn của code đã fix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestCase:\n",
        "    \"\"\"Định nghĩa một test case\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, test_code: str, expected_result: Any = None, \n",
        "                 validation_func: Callable = None, description: str = \"\"):\n",
        "        self.name = name\n",
        "        self.test_code = test_code\n",
        "        self.expected_result = expected_result\n",
        "        self.validation_func = validation_func\n",
        "        self.description = description\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f\"TestCase(name='{self.name}', description='{self.description}')\"\n",
        "\n",
        "class TestResult:\n",
        "    \"\"\"Kết quả của một test case\"\"\"\n",
        "    \n",
        "    def __init__(self, test_case: TestCase, passed: bool, \n",
        "                 actual_result: Any = None, error: str = None, \n",
        "                 execution_time: float = 0):\n",
        "        self.test_case = test_case\n",
        "        self.passed = passed\n",
        "        self.actual_result = actual_result\n",
        "        self.error = error\n",
        "        self.execution_time = execution_time\n",
        "        self.timestamp = time.time()\n",
        "\n",
        "class UnitTestFramework:\n",
        "    \"\"\"Framework for running unit tests on code\"\"\"\n",
        "    \n",
        "    def __init__(self, executor: SafeCodeExecutor):\n",
        "        self.executor = executor\n",
        "        self.test_suites = {}\n",
        "        self.test_results = []\n",
        "    \n",
        "    def create_test_suite(self, suite_name: str, test_cases: List[TestCase]):\n",
        "        \"\"\"Tạo một test suite\"\"\"\n",
        "        self.test_suites[suite_name] = test_cases\n",
        "    \n",
        "    def add_test_case(self, suite_name: str, test_case: TestCase):\n",
        "        \"\"\"Thêm test case vào suite\"\"\"\n",
        "        if suite_name not in self.test_suites:\n",
        "            self.test_suites[suite_name] = []\n",
        "        self.test_suites[suite_name].append(test_case)\n",
        "    \n",
        "    def run_test_case(self, test_case: TestCase, context: Dict[str, Any] = None) -> TestResult:\n",
        "        \"\"\"Chạy một test case đơn lẻ\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Thực thi test code\n",
        "            execution_result = self.executor.execute_code(test_case.test_code, context)\n",
        "            execution_time = time.time() - start_time\n",
        "            \n",
        "            if not execution_result['success']:\n",
        "                # Test failed due to execution error\n",
        "                return TestResult(\n",
        "                    test_case=test_case,\n",
        "                    passed=False,\n",
        "                    error=execution_result['error'],\n",
        "                    execution_time=execution_time\n",
        "                )\n",
        "            \n",
        "            # Kiểm tra kết quả\n",
        "            actual_result = execution_result.get('output', '')\n",
        "            \n",
        "            # Sử dụng validation function nếu có\n",
        "            if test_case.validation_func:\n",
        "                try:\n",
        "                    passed = test_case.validation_func(actual_result, self.executor.global_namespace)\n",
        "                except Exception as e:\n",
        "                    return TestResult(\n",
        "                        test_case=test_case,\n",
        "                        passed=False,\n",
        "                        error=f\"Validation function error: {str(e)}\",\n",
        "                        execution_time=execution_time\n",
        "                    )\n",
        "            else:\n",
        "                # So sánh với expected result\n",
        "                if test_case.expected_result is not None:\n",
        "                    passed = str(actual_result).strip() == str(test_case.expected_result).strip()\n",
        "                else:\n",
        "                    # Nếu không có expected result, chỉ cần code chạy thành công\n",
        "                    passed = True\n",
        "            \n",
        "            return TestResult(\n",
        "                test_case=test_case,\n",
        "                passed=passed,\n",
        "                actual_result=actual_result,\n",
        "                execution_time=execution_time\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            execution_time = time.time() - start_time\n",
        "            return TestResult(\n",
        "                test_case=test_case,\n",
        "                passed=False,\n",
        "                error=str(e),\n",
        "                execution_time=execution_time\n",
        "            )\n",
        "    \n",
        "    def run_test_suite(self, suite_name: str, context: Dict[str, Any] = None) -> List[TestResult]:\n",
        "        \"\"\"Chạy toàn bộ test suite\"\"\"\n",
        "        if suite_name not in self.test_suites:\n",
        "            raise ValueError(f\"Test suite '{suite_name}' not found\")\n",
        "        \n",
        "        results = []\n",
        "        test_cases = self.test_suites[suite_name]\n",
        "        \n",
        "        print(f\"Running test suite: {suite_name}\")\n",
        "        print(f\"Total test cases: {len(test_cases)}\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        for i, test_case in enumerate(test_cases, 1):\n",
        "            print(f\"Running test {i}/{len(test_cases)}: {test_case.name}\")\n",
        "            \n",
        "            result = self.run_test_case(test_case, context)\n",
        "            results.append(result)\n",
        "            \n",
        "            # Log kết quả\n",
        "            status = \"PASS\" if result.passed else \"FAIL\"\n",
        "            print(f\"  {status} - {result.execution_time:.3f}s\")\n",
        "            \n",
        "            if not result.passed and result.error:\n",
        "                print(f\"  Error: {result.error}\")\n",
        "        \n",
        "        # Tổng kết\n",
        "        passed_count = sum(1 for r in results if r.passed)\n",
        "        total_count = len(results)\n",
        "        success_rate = passed_count / total_count * 100\n",
        "        \n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Test Results: {passed_count}/{total_count} passed ({success_rate:.1f}%)\")\n",
        "        \n",
        "        # Lưu kết quả\n",
        "        self.test_results.extend(results)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def create_data_science_test_suite(self, phase: str) -> List[TestCase]:\n",
        "        \"\"\"Tạo test suite cho các phase khác nhau của data science\"\"\"\n",
        "        if phase == \"data_loading\":\n",
        "            return [\n",
        "                TestCase(\n",
        "                    name=\"test_data_loading\",\n",
        "                    test_code=\"assert 'df' in globals(), 'DataFrame df should be created'\",\n",
        "                    description=\"Check if data is loaded into df variable\",\n",
        "                    validation_func=lambda output, namespace: 'df' in namespace and hasattr(namespace['df'], 'shape')\n",
        "                ),\n",
        "                TestCase(\n",
        "                    name=\"test_data_not_empty\",\n",
        "                    test_code=\"assert df.shape[0] > 0, 'DataFrame should not be empty'\",\n",
        "                    description=\"Check if loaded data is not empty\",\n",
        "                    validation_func=lambda output, namespace: namespace.get('df') is not None and len(namespace['df']) > 0\n",
        "                )\n",
        "            ]\n",
        "        \n",
        "        elif phase == \"data_cleaning\":\n",
        "            return [\n",
        "                TestCase(\n",
        "                    name=\"test_no_infinite_values\",\n",
        "                    test_code=\"assert not np.isinf(df.select_dtypes(include=[np.number]).values).any(), 'No infinite values should remain'\",\n",
        "                    description=\"Check for infinite values in numeric columns\"\n",
        "                ),\n",
        "                TestCase(\n",
        "                    name=\"test_data_types_valid\",\n",
        "                    test_code=\"assert all(df.dtypes.notna()), 'All columns should have valid data types'\",\n",
        "                    description=\"Verify data types are valid\"\n",
        "                )\n",
        "            ]\n",
        "        \n",
        "        elif phase == \"feature_engineering\":\n",
        "            return [\n",
        "                TestCase(\n",
        "                    name=\"test_features_created\",\n",
        "                    test_code=\"original_cols = globals().get('original_columns', [])\\nassert len(df.columns) >= len(original_cols), 'New features should be created'\",\n",
        "                    description=\"Check if new features were created\"\n",
        "                ),\n",
        "                TestCase(\n",
        "                    name=\"test_no_null_targets\",\n",
        "                    test_code=\"target_col = globals().get('target_column')\\nif target_col and target_col in df.columns:\\n    assert df[target_col].notna().all(), 'Target column should not have null values'\",\n",
        "                    description=\"Check target column validity\"\n",
        "                )\n",
        "            ]\n",
        "        \n",
        "        elif phase == \"model_training\":\n",
        "            return [\n",
        "                TestCase(\n",
        "                    name=\"test_model_created\",\n",
        "                    test_code=\"assert 'model' in globals(), 'Model should be created'\",\n",
        "                    description=\"Check if model variable exists\",\n",
        "                    validation_func=lambda output, namespace: 'model' in namespace\n",
        "                ),\n",
        "                TestCase(\n",
        "                    name=\"test_model_fitted\",\n",
        "                    test_code=\"assert hasattr(model, 'predict'), 'Model should have predict method'\",\n",
        "                    description=\"Check if model is fitted and ready for prediction\"\n",
        "                )\n",
        "            ]\n",
        "        \n",
        "        else:\n",
        "            return [\n",
        "                TestCase(\n",
        "                    name=\"test_basic_execution\",\n",
        "                    test_code=\"pass  # Basic execution test\",\n",
        "                    description=\"Basic test to ensure code executes without errors\"\n",
        "                )\n",
        "            ]\n",
        "    \n",
        "    def generate_test_report(self) -> pd.DataFrame:\n",
        "        \"\"\"Tạo báo cáo chi tiết về test results\"\"\"\n",
        "        if not self.test_results:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        report_data = []\n",
        "        for result in self.test_results:\n",
        "            report_data.append({\n",
        "                'Test Name': result.test_case.name,\n",
        "                'Description': result.test_case.description,\n",
        "                'Status': 'PASS' if result.passed else 'FAIL',\n",
        "                'Execution Time (s)': result.execution_time,\n",
        "                'Error': result.error if result.error else '',\n",
        "                'Timestamp': pd.to_datetime(result.timestamp, unit='s')\n",
        "            })\n",
        "        \n",
        "        return pd.DataFrame(report_data)\n",
        "\n",
        "# Khởi tạo test framework\n",
        "test_framework = UnitTestFramework(safe_executor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 5: Iterative Debugging Engine\n",
        "\n",
        "Đây là engine chính kết hợp tất cả các thành phần để thực hiện iterative debugging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class IterativeDebuggingEngine:\n",
        "    \"\"\"Engine chính cho iterative debugging và testing\"\"\"\n",
        "    \n",
        "    def __init__(self, safe_executor: SafeCodeExecutor, \n",
        "                 test_framework: UnitTestFramework,\n",
        "                 fix_suggester: Optional[ErrorFixSuggester] = None,\n",
        "                 max_iterations: int = 5):\n",
        "        self.executor = safe_executor\n",
        "        self.test_framework = test_framework\n",
        "        self.fix_suggester = fix_suggester\n",
        "        self.max_iterations = max_iterations\n",
        "        self.debugging_sessions = []\n",
        "    \n",
        "    def debug_code(self, code: str, phase: str = \"general\", \n",
        "                   context: Dict[str, Any] = None,\n",
        "                   custom_tests: List[TestCase] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Thực hiện iterative debugging cho một đoạn code\n",
        "        \n",
        "        Parameters:\n",
        "        - code: Code cần debug\n",
        "        - phase: Phase của data science workflow\n",
        "        - context: Context variables\n",
        "        - custom_tests: Custom test cases\n",
        "        \n",
        "        Returns:\n",
        "        - Dictionary chứa kết quả debugging\n",
        "        \"\"\"\n",
        "        session_start = time.time()\n",
        "        session_id = f\"debug_session_{int(session_start)}\"\n",
        "        \n",
        "        debugging_session = {\n",
        "            'session_id': session_id,\n",
        "            'original_code': code,\n",
        "            'phase': phase,\n",
        "            'context': context or {},\n",
        "            'iterations': [],\n",
        "            'final_code': None,\n",
        "            'success': False,\n",
        "            'total_time': 0\n",
        "        }\n",
        "        \n",
        "        current_code = code\n",
        "        iteration = 0\n",
        "        \n",
        "        print(f\"Starting debugging session: {session_id}\")\n",
        "        print(f\"Phase: {phase}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        while iteration < self.max_iterations:\n",
        "            iteration += 1\n",
        "            iteration_start = time.time()\n",
        "            \n",
        "            print(f\"\\nIteration {iteration}/{self.max_iterations}\")\n",
        "            print(\"-\" * 30)\n",
        "            \n",
        "            # Step 1: Execute code\n",
        "            print(\"Step 1: Executing code...\")\n",
        "            execution_result = self.executor.execute_code(current_code, context)\n",
        "            \n",
        "            iteration_data = {\n",
        "                'iteration': iteration,\n",
        "                'code': current_code,\n",
        "                'execution_result': execution_result,\n",
        "                'test_results': None,\n",
        "                'fix_suggestions': None,\n",
        "                'iteration_time': 0\n",
        "            }\n",
        "            \n",
        "            if execution_result['success']:\n",
        "                print(\"✓ Code executed successfully\")\n",
        "                \n",
        "                # Step 2: Run unit tests\n",
        "                print(\"Step 2: Running unit tests...\")\n",
        "                test_results = self._run_tests(phase, context, custom_tests)\n",
        "                iteration_data['test_results'] = test_results\n",
        "                \n",
        "                passed_tests = sum(1 for r in test_results if r.passed)\n",
        "                total_tests = len(test_results)\n",
        "                \n",
        "                print(f\"Test results: {passed_tests}/{total_tests} passed\")\n",
        "                \n",
        "                if passed_tests == total_tests:\n",
        "                    print(\"🎉 All tests passed! Debugging successful.\")\n",
        "                    debugging_session['success'] = True\n",
        "                    debugging_session['final_code'] = current_code\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"⚠️ Some tests failed. Analyzing failures...\")\n",
        "                    # Tạo error info từ failed tests\n",
        "                    failed_tests = [r for r in test_results if not r.passed]\n",
        "                    error_info = self._create_error_info_from_tests(failed_tests)\n",
        "            else:\n",
        "                print(\"✗ Code execution failed\")\n",
        "                error_info = execution_result['error_info']\n",
        "                print(f\"Error: {error_info.message}\")\n",
        "            \n",
        "            # Step 3: Get fix suggestions\n",
        "            if not execution_result['success'] or (iteration_data['test_results'] and \n",
        "                                                   not all(r.passed for r in iteration_data['test_results'])):\n",
        "                print(\"Step 3: Generating fix suggestions...\")\n",
        "                \n",
        "                if self.fix_suggester:\n",
        "                    fix_suggestions = self.fix_suggester.suggest_fix(error_info, current_code)\n",
        "                    iteration_data['fix_suggestions'] = fix_suggestions\n",
        "                    \n",
        "                    # Try to extract fixed code\n",
        "                    fixed_code = self._extract_best_fix(fix_suggestions, current_code)\n",
        "                    if fixed_code:\n",
        "                        current_code = fixed_code\n",
        "                        print(\"✓ Applied suggested fix\")\n",
        "                    else:\n",
        "                        print(\"⚠️ Could not extract actionable fix\")\n",
        "                        break\n",
        "                else:\n",
        "                    print(\"⚠️ No fix suggester available\")\n",
        "                    break\n",
        "            \n",
        "            iteration_data['iteration_time'] = time.time() - iteration_start\n",
        "            debugging_session['iterations'].append(iteration_data)\n",
        "        \n",
        "        debugging_session['total_time'] = time.time() - session_start\n",
        "        \n",
        "        # Final summary\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"DEBUGGING SESSION SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Session ID: {session_id}\")\n",
        "        print(f\"Total iterations: {iteration}\")\n",
        "        print(f\"Success: {'Yes' if debugging_session['success'] else 'No'}\")\n",
        "        print(f\"Total time: {debugging_session['total_time']:.2f}s\")\n",
        "        \n",
        "        if not debugging_session['success']:\n",
        "            debugging_session['final_code'] = current_code  # Best attempt\n",
        "            print(\"\\n⚠️ Debugging did not fully succeed. Manual intervention may be needed.\")\n",
        "        \n",
        "        self.debugging_sessions.append(debugging_session)\n",
        "        return debugging_session\n",
        "    \n",
        "    def _run_tests(self, phase: str, context: Dict[str, Any], \n",
        "                   custom_tests: List[TestCase] = None) -> List[TestResult]:\n",
        "        \"\"\"Chạy tests cho phase hiện tại\"\"\"\n",
        "        if custom_tests:\n",
        "            test_cases = custom_tests\n",
        "        else:\n",
        "            test_cases = self.test_framework.create_data_science_test_suite(phase)\n",
        "        \n",
        "        results = []\n",
        "        for test_case in test_cases:\n",
        "            result = self.test_framework.run_test_case(test_case, context)\n",
        "            results.append(result)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def _create_error_info_from_tests(self, failed_tests: List[TestResult]) -> ErrorInfo:\n",
        "        \"\"\"Tạo ErrorInfo từ failed tests\"\"\"\n",
        "        # Tổng hợp thông tin từ các test thất bại\n",
        "        error_messages = []\n",
        "        for test in failed_tests:\n",
        "            if test.error:\n",
        "                error_messages.append(f\"{test.test_case.name}: {test.error}\")\n",
        "        \n",
        "        combined_message = \"; \".join(error_messages)\n",
        "        \n",
        "        return ErrorInfo(\n",
        "            error_type=ErrorType.LOGIC_ERROR,\n",
        "            severity=ErrorSeverity.MEDIUM,\n",
        "            message=combined_message,\n",
        "            traceback=\"Test failures\",\n",
        "            line_number=None,\n",
        "            code_snippet=None,\n",
        "            suggested_fix=None,\n",
        "            timestamp=time.time(),\n",
        "            context={'failed_tests': [t.test_case.name for t in failed_tests]}\n",
        "        )\n",
        "    \n",
        "    def _extract_best_fix(self, fix_suggestions: Dict[str, Any], current_code: str) -> Optional[str]:\n",
        "        \"\"\"Trích xuất fix tốt nhất từ suggestions\"\"\"\n",
        "        # Thử quick fix trước\n",
        "        if fix_suggestions.get('quick_fix'):\n",
        "            return fix_suggestions['quick_fix']\n",
        "        \n",
        "        # Thử extract từ LLM analysis\n",
        "        if self.fix_suggester and fix_suggestions.get('llm_analysis'):\n",
        "            fixed_code = self.fix_suggester.extract_fixed_code_from_analysis(\n",
        "                fix_suggestions['llm_analysis']\n",
        "            )\n",
        "            if fixed_code:\n",
        "                return fixed_code\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_debugging_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Thống kê về các session debugging\"\"\"\n",
        "        if not self.debugging_sessions:\n",
        "            return {}\n",
        "        \n",
        "        total_sessions = len(self.debugging_sessions)\n",
        "        successful_sessions = sum(1 for s in self.debugging_sessions if s['success'])\n",
        "        total_iterations = sum(len(s['iterations']) for s in self.debugging_sessions)\n",
        "        total_time = sum(s['total_time'] for s in self.debugging_sessions)\n",
        "        \n",
        "        return {\n",
        "            'total_sessions': total_sessions,\n",
        "            'successful_sessions': successful_sessions,\n",
        "            'success_rate': successful_sessions / total_sessions * 100,\n",
        "            'average_iterations': total_iterations / total_sessions,\n",
        "            'average_time_per_session': total_time / total_sessions,\n",
        "            'total_debugging_time': total_time\n",
        "        }\n",
        "    \n",
        "    def export_session_report(self, session_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Export chi tiết của một debugging session\"\"\"\n",
        "        session = next((s for s in self.debugging_sessions if s['session_id'] == session_id), None)\n",
        "        if not session:\n",
        "            return None\n",
        "        \n",
        "        # Tạo báo cáo chi tiết\n",
        "        report = {\n",
        "            'session_summary': {\n",
        "                'session_id': session['session_id'],\n",
        "                'phase': session['phase'],\n",
        "                'success': session['success'],\n",
        "                'total_iterations': len(session['iterations']),\n",
        "                'total_time': session['total_time']\n",
        "            },\n",
        "            'code_evolution': [],\n",
        "            'error_patterns': [],\n",
        "            'fix_effectiveness': []\n",
        "        }\n",
        "        \n",
        "        for iteration in session['iterations']:\n",
        "            report['code_evolution'].append({\n",
        "                'iteration': iteration['iteration'],\n",
        "                'code_length': len(iteration['code']),\n",
        "                'execution_success': iteration['execution_result']['success'],\n",
        "                'tests_passed': sum(1 for r in iteration.get('test_results', []) if r.passed) if iteration.get('test_results') else 0\n",
        "            })\n",
        "            \n",
        "            if not iteration['execution_result']['success']:\n",
        "                error_info = iteration['execution_result']['error_info']\n",
        "                report['error_patterns'].append({\n",
        "                    'iteration': iteration['iteration'],\n",
        "                    'error_type': error_info.error_type.value,\n",
        "                    'severity': error_info.severity.value,\n",
        "                    'message': error_info.message\n",
        "                })\n",
        "        \n",
        "        return report\n",
        "\n",
        "# Khởi tạo debugging engine (without fix suggester for now)\n",
        "debugging_engine = IterativeDebuggingEngine(\n",
        "    safe_executor=safe_executor,\n",
        "    test_framework=test_framework,\n",
        "    fix_suggester=None,  # Would be fix_suggester if API key available\n",
        "    max_iterations=3\n",
        ")\n",
        "\n",
        "print(\"Iterative Debugging Engine initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 6: Demo Và Ví Dụ Thực Tế\n",
        "\n",
        "Hãy demo hệ thống debugging với một số ví dụ code có lỗi phổ biến:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 1: Lỗi cơ bản - KeyError\n",
        "print(\"=== DEMO 1: KeyError Example ===\")\n",
        "\n",
        "buggy_code_1 = \"\"\"\n",
        "# Sample data loading with KeyError\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create sample dataframe\n",
        "data = {\n",
        "    'name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'age': [25, 30, 35],\n",
        "    'salary': [50000, 60000, 70000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# This will cause KeyError\n",
        "average_income = df['income'].mean()  # Column 'income' doesn't exist\n",
        "print(f\"Average income: {average_income}\")\n",
        "\"\"\"\n",
        "\n",
        "# Custom tests for this example\n",
        "custom_tests_1 = [\n",
        "    TestCase(\n",
        "        name=\"test_dataframe_created\",\n",
        "        test_code=\"assert 'df' in globals() and hasattr(df, 'shape')\",\n",
        "        description=\"Check if DataFrame is created\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        name=\"test_average_calculated\",\n",
        "        test_code=\"assert 'average_income' in globals()\",\n",
        "        description=\"Check if average income is calculated\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Run debugging session\n",
        "session_1 = debugging_engine.debug_code(\n",
        "    code=buggy_code_1,\n",
        "    phase=\"data_loading\",\n",
        "    custom_tests=custom_tests_1\n",
        ")\n",
        "\n",
        "print(f\"\\nSession 1 Result: {'SUCCESS' if session_1['success'] else 'FAILED'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 2: Lỗi Type Error\n",
        "print(\"\\n=== DEMO 2: TypeError Example ===\")\n",
        "\n",
        "buggy_code_2 = \"\"\"\n",
        "# Sample data processing with TypeError\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create sample data with mixed types\n",
        "data = {\n",
        "    'numbers': [1, 2, 3, '4', 5],  # Mixed types\n",
        "    'values': [10.5, 20.1, 30.7, 40.2, 50.9]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# This will cause TypeError\n",
        "total = df['numbers'].sum()  # Can't sum mixed types directly\n",
        "print(f\"Total: {total}\")\n",
        "\n",
        "# Convert to numeric properly\n",
        "df['numbers_clean'] = pd.to_numeric(df['numbers'], errors='coerce')\n",
        "total_clean = df['numbers_clean'].sum()\n",
        "print(f\"Clean total: {total_clean}\")\n",
        "\"\"\"\n",
        "\n",
        "custom_tests_2 = [\n",
        "    TestCase(\n",
        "        name=\"test_total_calculated\",\n",
        "        test_code=\"assert 'total' in globals() or 'total_clean' in globals()\",\n",
        "        description=\"Check if total is calculated\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        name=\"test_clean_column_created\",\n",
        "        test_code=\"assert 'numbers_clean' in df.columns\",\n",
        "        description=\"Check if clean numbers column is created\"\n",
        "    )\n",
        "]\n",
        "\n",
        "session_2 = debugging_engine.debug_code(\n",
        "    code=buggy_code_2,\n",
        "    phase=\"data_cleaning\",\n",
        "    custom_tests=custom_tests_2\n",
        ")\n",
        "\n",
        "print(f\"\\nSession 2 Result: {'SUCCESS' if session_2['success'] else 'FAILED'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 3: Lỗi Logic (không crash nhưng kết quả sai)\n",
        "print(\"\\n=== DEMO 3: Logic Error Example ===\")\n",
        "\n",
        "buggy_code_3 = \"\"\"\n",
        "# Sample feature engineering with logic error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create sample dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 100\n",
        "X = np.random.randn(n_samples, 3)\n",
        "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # Binary target\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(X, columns=['feature1', 'feature2', 'feature3'])\n",
        "df['target'] = y\n",
        "\n",
        "# Logic error: Using target in features for training\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[['feature1', 'feature2', 'feature3', 'target']],  # BUG: including target in features\n",
        "    df['target'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "train_score = model.score(X_train, y_train)\n",
        "test_score = model.score(X_test, y_test)\n",
        "\n",
        "print(f\"Train accuracy: {train_score:.3f}\")\n",
        "print(f\"Test accuracy: {test_score:.3f}\")\n",
        "\"\"\"\n",
        "\n",
        "custom_tests_3 = [\n",
        "    TestCase(\n",
        "        name=\"test_model_created\",\n",
        "        test_code=\"assert 'model' in globals()\",\n",
        "        description=\"Check if model is created\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        name=\"test_no_data_leakage\",\n",
        "        test_code=\"assert X_train.shape[1] == 3, 'Features should not include target'\",\n",
        "        description=\"Check for data leakage\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        name=\"test_reasonable_accuracy\",\n",
        "        test_code=\"assert test_score < 0.99, 'Test accuracy too high - possible data leakage'\",\n",
        "        description=\"Check for suspiciously high accuracy\"\n",
        "    )\n",
        "]\n",
        "\n",
        "session_3 = debugging_engine.debug_code(\n",
        "    code=buggy_code_3,\n",
        "    phase=\"model_training\",\n",
        "    custom_tests=custom_tests_3\n",
        ")\n",
        "\n",
        "print(f\"\\nSession 3 Result: {'SUCCESS' if session_3['success'] else 'FAILED'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hiển thị thống kê tổng quan\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OVERALL DEBUGGING STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "stats = debugging_engine.get_debugging_stats()\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "# Hiển thị test results summary\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"TEST FRAMEWORK STATISTICS\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "test_report = test_framework.generate_test_report()\n",
        "if not test_report.empty:\n",
        "    print(f\"Total tests run: {len(test_report)}\")\n",
        "    passed = len(test_report[test_report['Status'] == 'PASS'])\n",
        "    failed = len(test_report[test_report['Status'] == 'FAIL'])\n",
        "    print(f\"Tests passed: {passed}\")\n",
        "    print(f\"Tests failed: {failed}\")\n",
        "    print(f\"Success rate: {passed/len(test_report)*100:.1f}%\")\n",
        "    print(f\"Average execution time: {test_report['Execution Time (s)'].mean():.3f}s\")\n",
        "else:\n",
        "    print(\"No test results available\")\n",
        "\n",
        "# Hiển thị execution statistics\n",
        "print(\"\\n\" + \"-\"*40)\n",
        "print(\"CODE EXECUTION STATISTICS\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "exec_stats = safe_executor.get_execution_stats()\n",
        "for key, value in exec_stats.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phần 7: Hệ Thống Learning và Knowledge Base\n",
        "\n",
        "Cuối cùng, chúng ta sẽ tạo một hệ thống học hỏi từ các lỗi đã xử lý để cải thiện hiệu suất debug trong tương lai:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ErrorKnowledgeBase:\n",
        "    \"\"\"Knowledge base để lưu trữ và học hỏi từ các lỗi đã xử lý\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.error_patterns = []\n",
        "        self.successful_fixes = []\n",
        "        self.failed_fixes = []\n",
        "        self.pattern_to_fix_mapping = {}\n",
        "    \n",
        "    def add_error_case(self, error_info: ErrorInfo, original_code: str, \n",
        "                      fix_applied: str, fix_successful: bool):\n",
        "        \"\"\"Thêm một case lỗi vào knowledge base\"\"\"\n",
        "        case = {\n",
        "            'error_info': error_info,\n",
        "            'original_code': original_code,\n",
        "            'fix_applied': fix_applied,\n",
        "            'fix_successful': fix_successful,\n",
        "            'timestamp': time.time(),\n",
        "            'error_pattern': self._extract_error_pattern(error_info)\n",
        "        }\n",
        "        \n",
        "        if fix_successful:\n",
        "            self.successful_fixes.append(case)\n",
        "        else:\n",
        "            self.failed_fixes.append(case)\n",
        "        \n",
        "        # Update pattern mapping\n",
        "        pattern = case['error_pattern']\n",
        "        if pattern not in self.pattern_to_fix_mapping:\n",
        "            self.pattern_to_fix_mapping[pattern] = []\n",
        "        self.pattern_to_fix_mapping[pattern].append(case)\n",
        "    \n",
        "    def _extract_error_pattern(self, error_info: ErrorInfo) -> str:\n",
        "        \"\"\"Trích xuất pattern từ error info\"\"\"\n",
        "        # Simplified pattern extraction\n",
        "        pattern_elements = [\n",
        "            error_info.error_type.value,\n",
        "            error_info.severity.value\n",
        "        ]\n",
        "        \n",
        "        # Extract key words from error message\n",
        "        message_words = re.findall(r'\\b\\w+\\b', error_info.message.lower())\n",
        "        key_words = [word for word in message_words if len(word) > 3 and \n",
        "                    word not in ['error', 'exception', 'traceback']]\n",
        "        \n",
        "        if key_words:\n",
        "            pattern_elements.extend(key_words[:3])  # Top 3 key words\n",
        "        \n",
        "        return \"|\".join(pattern_elements)\n",
        "    \n",
        "    def find_similar_cases(self, error_info: ErrorInfo, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Tìm các case tương tự đã xử lý trước đó\"\"\"\n",
        "        current_pattern = self._extract_error_pattern(error_info)\n",
        "        \n",
        "        # Simple similarity based on pattern matching\n",
        "        similar_cases = []\n",
        "        \n",
        "        all_cases = self.successful_fixes + self.failed_fixes\n",
        "        for case in all_cases:\n",
        "            similarity = self._calculate_similarity(current_pattern, case['error_pattern'])\n",
        "            if similarity > 0.3:  # Threshold for similarity\n",
        "                case_with_similarity = case.copy()\n",
        "                case_with_similarity['similarity'] = similarity\n",
        "                similar_cases.append(case_with_similarity)\n",
        "        \n",
        "        # Sort by similarity and success\n",
        "        similar_cases.sort(key=lambda x: (x['similarity'], x['fix_successful']), reverse=True)\n",
        "        \n",
        "        return similar_cases[:top_k]\n",
        "    \n",
        "    def _calculate_similarity(self, pattern1: str, pattern2: str) -> float:\n",
        "        \"\"\"Tính similarity giữa hai patterns\"\"\"\n",
        "        elements1 = set(pattern1.split('|'))\n",
        "        elements2 = set(pattern2.split('|'))\n",
        "        \n",
        "        if not elements1 or not elements2:\n",
        "            return 0.0\n",
        "        \n",
        "        intersection = elements1.intersection(elements2)\n",
        "        union = elements1.union(elements2)\n",
        "        \n",
        "        return len(intersection) / len(union) if union else 0.0\n",
        "    \n",
        "    def suggest_fix_from_history(self, error_info: ErrorInfo) -> Optional[str]:\n",
        "        \"\"\"Đề xuất fix dựa trên lịch sử\"\"\"\n",
        "        similar_cases = self.find_similar_cases(error_info)\n",
        "        \n",
        "        # Tìm fix thành công với similarity cao nhất\n",
        "        for case in similar_cases:\n",
        "            if case['fix_successful'] and case['similarity'] > 0.7:\n",
        "                return case['fix_applied']\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def get_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Thống kê về knowledge base\"\"\"\n",
        "        total_cases = len(self.successful_fixes) + len(self.failed_fixes)\n",
        "        \n",
        "        if total_cases == 0:\n",
        "            return {'total_cases': 0}\n",
        "        \n",
        "        # Error type distribution\n",
        "        error_type_counts = {}\n",
        "        for case in self.successful_fixes + self.failed_fixes:\n",
        "            error_type = case['error_info'].error_type.value\n",
        "            error_type_counts[error_type] = error_type_counts.get(error_type, 0) + 1\n",
        "        \n",
        "        # Success rate by error type\n",
        "        success_rates = {}\n",
        "        for error_type in error_type_counts:\n",
        "            successful = sum(1 for case in self.successful_fixes \n",
        "                           if case['error_info'].error_type.value == error_type)\n",
        "            total = error_type_counts[error_type]\n",
        "            success_rates[error_type] = successful / total * 100\n",
        "        \n",
        "        return {\n",
        "            'total_cases': total_cases,\n",
        "            'successful_fixes': len(self.successful_fixes),\n",
        "            'failed_fixes': len(self.failed_fixes),\n",
        "            'overall_success_rate': len(self.successful_fixes) / total_cases * 100,\n",
        "            'error_type_distribution': error_type_counts,\n",
        "            'success_rates_by_type': success_rates,\n",
        "            'unique_patterns': len(self.pattern_to_fix_mapping)\n",
        "        }\n",
        "    \n",
        "    def export_knowledge_base(self) -> Dict[str, Any]:\n",
        "        \"\"\"Export knowledge base để save/load\"\"\"\n",
        "        return {\n",
        "            'successful_fixes': self.successful_fixes,\n",
        "            'failed_fixes': self.failed_fixes,\n",
        "            'pattern_to_fix_mapping': self.pattern_to_fix_mapping\n",
        "        }\n",
        "    \n",
        "    def load_knowledge_base(self, data: Dict[str, Any]):\n",
        "        \"\"\"Load knowledge base từ saved data\"\"\"\n",
        "        self.successful_fixes = data.get('successful_fixes', [])\n",
        "        self.failed_fixes = data.get('failed_fixes', [])\n",
        "        self.pattern_to_fix_mapping = data.get('pattern_to_fix_mapping', {})\n",
        "\n",
        "# Khởi tạo knowledge base\n",
        "knowledge_base = ErrorKnowledgeBase()\n",
        "\n",
        "# Thêm một số sample cases để demo\n",
        "sample_error = ErrorInfo(\n",
        "    error_type=ErrorType.KEY_ERROR,\n",
        "    severity=ErrorSeverity.HIGH,\n",
        "    message=\"KeyError: 'column_name'\",\n",
        "    traceback=\"KeyError in line 10\",\n",
        "    line_number=10,\n",
        "    code_snippet=\"df['column_name']\",\n",
        "    suggested_fix=None,\n",
        "    timestamp=time.time(),\n",
        "    context={}\n",
        ")\n",
        "\n",
        "knowledge_base.add_error_case(\n",
        "    error_info=sample_error,\n",
        "    original_code=\"df['column_name']\",\n",
        "    fix_applied=\"df.get('column_name', default_value)\",\n",
        "    fix_successful=True\n",
        ")\n",
        "\n",
        "print(\"Error Knowledge Base initialized with sample data\")\n",
        "print(\"Knowledge Base Statistics:\")\n",
        "kb_stats = knowledge_base.get_statistics()\n",
        "for key, value in kb_stats.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kết Luận\n",
        "\n",
        "Hệ thống phân tích lỗi và debugging tự động trong AutoKaggle là một thiết kế rất tiên tiến và toàn diện. Thông qua notebook này, chúng ta đã học được:\n",
        "\n",
        "### Những Điểm Chính:\n",
        "\n",
        "1. **Phân Loại Lỗi Có Hệ Thống**: Framework phân loại lỗi theo type và severity giúp xử lý targeted và hiệu quả\n",
        "\n",
        "2. **Safe Code Execution**: Hệ thống thực thi code an toàn với error capturing và namespace isolation\n",
        "\n",
        "3. **AI-Powered Error Analysis**: Sử dụng LLM để phân tích root cause và đề xuất fix strategies\n",
        "\n",
        "4. **Automated Testing**: Unit testing framework để validate tính đúng đắn của code đã fix\n",
        "\n",
        "5. **Iterative Debugging**: Quy trình lặp cho phép multiple attempts với learning từ previous failures\n",
        "\n",
        "6. **Knowledge Base Learning**: Hệ thống học hỏi từ historical errors để cải thiện future debugging\n",
        "\n",
        "### Lợi Ích Của Thiết Kế:\n",
        "\n",
        "- **Tự Động Hóa Cao**: Giảm thiểu can thiệp manual trong quá trình debug\n",
        "- **Học Hỏi Liên Tục**: Hệ thống được cải thiện qua thời gian\n",
        "- **Comprehensive Testing**: Đảm bảo code quality thông qua automated testing\n",
        "- **Scalability**: Có thể xử lý nhiều loại lỗi và domain khác nhau\n",
        "- **Transparency**: Cung cấp detailed logging và analysis cho user\n",
        "\n",
        "### Ứng Dụng Thực Tế:\n",
        "\n",
        "Hệ thống này có thể được áp dụng cho:\n",
        "- **Code Review Automation**: Tự động detect và suggest fixes cho common issues\n",
        "- **Educational Tools**: Giúp học viên hiểu và fix errors trong code\n",
        "- **Production Monitoring**: Debug runtime errors trong production environment\n",
        "- **CI/CD Pipeline**: Integrate debugging vào development workflow\n",
        "\n",
        "### Hướng Phát Triển:\n",
        "\n",
        "1. **Advanced Pattern Recognition**: Sử dụng ML models để recognize error patterns\n",
        "2. **Domain-Specific Knowledge**: Specialized debugging cho different ML domains\n",
        "3. **Real-time Collaboration**: Integration với team debugging workflows\n",
        "4. **Performance Optimization**: Faster debugging through parallel processing\n",
        "\n",
        "Hệ thống error analysis và debugging trong AutoKaggle thể hiện một approach rất mature và practical cho việc tự động hóa debugging process, đặc biệt quan trọng trong context của autonomous data science workflows."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}