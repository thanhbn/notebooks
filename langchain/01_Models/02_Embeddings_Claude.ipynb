{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Embeddings với Claude và LangChain\n",
    "\n",
    "## Mục tiêu\n",
    "- Hiểu vai trò của embeddings trong hệ thống AI\n",
    "- Tạo embeddings cho queries và documents\n",
    "- So sánh các embedding models khác nhau\n",
    "- Hiểu về Anthropic/Claude embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Embeddings là gì?\n",
    "\n",
    "### Định nghĩa\n",
    "Embeddings là cách biểu diễn văn bản dưới dạng vector số học trong không gian nhiều chiều. Mỗi văn bản được chuyển thành một vector, và các văn bản có ý nghĩa tương tự sẽ có vector gần nhau trong không gian.\n",
    "\n",
    "### Vai trò của Embeddings\n",
    "1. **Semantic Search**: Tìm kiếm dựa trên ý nghĩa thay vì từ khóa\n",
    "2. **Similarity Matching**: So sánh độ tương đồng giữa các văn bản\n",
    "3. **Clustering**: Nhóm các văn bản có nội dung liên quan\n",
    "4. **RAG Systems**: Tìm kiếm thông tin liên quan từ knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tình hình Anthropic/Claude Embeddings\n",
    "\n",
    "### Hiện tại (2024)\n",
    "- Anthropic chưa cung cấp public embedding API\n",
    "- Claude models (Opus, Sonnet, Haiku) chỉ hỗ trợ text generation\n",
    "- `langchain-anthropic` package chưa có embedding class\n",
    "\n",
    "### Giải pháp thay thế\n",
    "Khi làm việc với Claude, chúng ta có thể sử dụng:\n",
    "1. **OpenAI Embeddings**: Chất lượng cao, dễ tích hợp\n",
    "2. **HuggingFace Embeddings**: Miễn phí, nhiều model lựa chọn\n",
    "3. **Cohere Embeddings**: Hiệu suất tốt cho multilingual\n",
    "4. **Local Embeddings**: Sentence-transformers cho privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các packages cần thiết\n",
    "!pip install langchain langchain-openai langchain-huggingface sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sử dụng OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo OpenAI Embeddings\n",
    "# Lưu ý: Cần có OPENAI_API_KEY trong environment\n",
    "openai_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # hoặc text-embedding-3-large\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo embeddings cho một query\n",
    "query = \"Claude là gì và có những khả năng nào?\"\n",
    "query_embedding = openai_embeddings.embed_query(query)\n",
    "\n",
    "print(f\"Embedding dimension: {len(query_embedding)}\")\n",
    "print(f\"Embedding vector (first 10 values): {query_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo embeddings cho nhiều documents\n",
    "documents = [\n",
    "    \"Claude là một AI assistant được phát triển bởi Anthropic\",\n",
    "    \"Claude có khả năng hiểu ngữ cảnh và trả lời câu hỏi phức tạp\",\n",
    "    \"Python là ngôn ngữ lập trình phổ biến\",\n",
    "    \"Machine Learning là một nhánh của AI\"\n",
    "]\n",
    "\n",
    "doc_embeddings = openai_embeddings.embed_documents(documents)\n",
    "\n",
    "print(f\"Number of documents: {len(doc_embeddings)}\")\n",
    "print(f\"Each embedding dimension: {len(doc_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sử dụng HuggingFace Embeddings (Miễn phí)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Sử dụng model all-MiniLM-L6-v2 (nhẹ và hiệu quả)\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo embeddings với HuggingFace\n",
    "hf_query_embedding = hf_embeddings.embed_query(query)\n",
    "hf_doc_embeddings = hf_embeddings.embed_documents(documents)\n",
    "\n",
    "print(f\"HF Embedding dimension: {len(hf_query_embedding)}\")\n",
    "print(f\"HF Number of doc embeddings: {len(hf_doc_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tính toán Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Tính cosine similarity giữa 2 vectors\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Tính similarity giữa query và các documents\n",
    "print(\"Similarity scores với OpenAI embeddings:\")\n",
    "for i, doc in enumerate(documents):\n",
    "    similarity = cosine_similarity(query_embedding, doc_embeddings[i])\n",
    "    print(f\"Document {i+1}: {similarity:.4f} - {doc[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So sánh với HuggingFace embeddings\n",
    "print(\"\\nSimilarity scores với HuggingFace embeddings:\")\n",
    "for i, doc in enumerate(documents):\n",
    "    similarity = cosine_similarity(hf_query_embedding, hf_doc_embeddings[i])\n",
    "    print(f\"Document {i+1}: {similarity:.4f} - {doc[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multilingual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng multilingual model\n",
    "multilingual_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# Test với nhiều ngôn ngữ\n",
    "multilingual_texts = [\n",
    "    \"Claude is an AI assistant\",  # English\n",
    "    \"Claude là một trợ lý AI\",     # Vietnamese\n",
    "    \"Claude est un assistant IA\",  # French\n",
    "    \"Claudeは AIアシスタントです\"    # Japanese\n",
    "]\n",
    "\n",
    "ml_embeddings = multilingual_embeddings.embed_documents(multilingual_texts)\n",
    "\n",
    "# So sánh similarity giữa các ngôn ngữ\n",
    "print(\"Cross-lingual similarity:\")\n",
    "for i in range(len(multilingual_texts)):\n",
    "    for j in range(i+1, len(multilingual_texts)):\n",
    "        sim = cosine_similarity(ml_embeddings[i], ml_embeddings[j])\n",
    "        print(f\"{multilingual_texts[i]} <-> {multilingual_texts[j]}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices cho Embeddings\n",
    "\n",
    "### 1. Chọn Model phù hợp\n",
    "- **OpenAI**: Chất lượng cao, tốn phí\n",
    "- **HuggingFace**: Miễn phí, nhiều lựa chọn\n",
    "- **Cohere**: Tốt cho multilingual\n",
    "\n",
    "### 2. Preprocessing văn bản\n",
    "- Loại bỏ ký tự đặc biệt không cần thiết\n",
    "- Chuẩn hóa format (lowercase, spacing)\n",
    "- Chunk documents hợp lý\n",
    "\n",
    "### 3. Caching embeddings\n",
    "- Lưu embeddings đã tính để tái sử dụng\n",
    "- Sử dụng vector databases (Pinecone, Weaviate, ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ: Caching embeddings với dict\n",
    "embedding_cache = {}\n",
    "\n",
    "def get_embedding_cached(text, embeddings_model):\n",
    "    \"\"\"Lấy embedding với caching\"\"\"\n",
    "    if text in embedding_cache:\n",
    "        print(f\"Using cached embedding for: {text[:30]}...\")\n",
    "        return embedding_cache[text]\n",
    "    \n",
    "    print(f\"Computing new embedding for: {text[:30]}...\")\n",
    "    embedding = embeddings_model.embed_query(text)\n",
    "    embedding_cache[text] = embedding\n",
    "    return embedding\n",
    "\n",
    "# Test caching\n",
    "text1 = \"Claude là AI assistant\"\n",
    "emb1 = get_embedding_cached(text1, hf_embeddings)\n",
    "emb2 = get_embedding_cached(text1, hf_embeddings)  # Sẽ dùng cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tích hợp Embeddings với Claude\n",
    "\n",
    "Mặc dù Claude không có embedding API, chúng ta có thể kết hợp:\n",
    "1. Dùng embedding model khác để search/retrieve\n",
    "2. Dùng Claude để generate responses\n",
    "\n",
    "Đây chính là pattern của RAG systems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ workflow RAG với Claude\n",
    "from typing import List, Tuple\n",
    "\n",
    "def simple_rag_with_claude(query: str, knowledge_base: List[str]) -> Tuple[List[str], str]:\n",
    "    \"\"\"\n",
    "    Simple RAG workflow:\n",
    "    1. Embed query và documents\n",
    "    2. Tìm relevant documents\n",
    "    3. Dùng Claude để generate response\n",
    "    \"\"\"\n",
    "    # Bước 1: Tạo embeddings\n",
    "    query_emb = hf_embeddings.embed_query(query)\n",
    "    doc_embs = hf_embeddings.embed_documents(knowledge_base)\n",
    "    \n",
    "    # Bước 2: Tính similarity và rank\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embs):\n",
    "        sim = cosine_similarity(query_emb, doc_emb)\n",
    "        similarities.append((sim, i, knowledge_base[i]))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Lấy top 2 documents\n",
    "    top_docs = [item[2] for item in similarities[:2]]\n",
    "    \n",
    "    # Bước 3: Tạo prompt cho Claude (giả lập)\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following information:\n",
    "    {' '.join(top_docs)}\n",
    "    \n",
    "    Answer the question: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    return top_docs, prompt\n",
    "\n",
    "# Test\n",
    "kb = [\n",
    "    \"Claude can analyze images and documents\",\n",
    "    \"Claude was created by Anthropic with focus on safety\",\n",
    "    \"Python is used for data science\",\n",
    "    \"Claude can write and debug code\"\n",
    "]\n",
    "\n",
    "relevant_docs, prompt = simple_rag_with_claude(\"What can Claude do?\", kb)\n",
    "print(\"Relevant documents found:\")\n",
    "for doc in relevant_docs:\n",
    "    print(f\"- {doc}\")\n",
    "print(f\"\\nPrompt for Claude:\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tổng kết\n",
    "\n",
    "1. **Embeddings** là nền tảng cho semantic search và RAG\n",
    "2. **Anthropic/Claude** chưa có embedding API, nhưng có thể kết hợp với các embedding models khác\n",
    "3. **OpenAI Embeddings** cho chất lượng tốt nhất nhưng tốn phí\n",
    "4. **HuggingFace Embeddings** miễn phí và đủ tốt cho nhiều use cases\n",
    "5. **Cosine similarity** là metric phổ biến để so sánh embeddings\n",
    "6. **Caching** embeddings giúp tiết kiệm chi phí và thời gian\n",
    "\n",
    "### Next Steps\n",
    "- Tìm hiểu về Vector Databases\n",
    "- Xây dựng RAG system hoàn chỉnh\n",
    "- Optimize embedding search với indexing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}