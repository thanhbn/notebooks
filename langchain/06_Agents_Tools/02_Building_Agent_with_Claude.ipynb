{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agent v·ªõi ChatAnthropic\n",
    "\n",
    "## üéØ M·ª•c ti√™u\n",
    "\n",
    "Trong notebook n√†y, ch√∫ng ta s·∫Ω:\n",
    "1. **X√¢y d·ª±ng** m·ªôt Agent c∆° b·∫£n v·ªõi ChatAnthropic\n",
    "2. **ƒê·ªãnh nghƒ©a** v√† cung c·∫•p Tools cho Agent\n",
    "3. **Ch·∫°y** AgentExecutor v·ªõi verbose mode\n",
    "4. **Ph√¢n t√≠ch** lu·ªìng suy nghƒ© c·ªßa Agent\n",
    "5. **Hi·ªÉu** c√°ch Agent quy·∫øt ƒë·ªãnh s·ª≠ d·ª•ng tools\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "\n",
    "```\n",
    "User Query ‚Üí Agent (Claude) ‚Üí Tool Selection ‚Üí Tool Execution ‚Üí Result Analysis ‚Üí Final Answer\n",
    "                ‚Üë                                      ‚Üì\n",
    "                ‚îî‚îÄ‚îÄ Tool Results ‚Üê Tool Response ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup v√† Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain Core\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LangChain Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Tools\n",
    "try:\n",
    "    from langchain_community.tools import DuckDuckGoSearchRun\n",
    "    DUCKDUCKGO_AVAILABLE = True\nexcept ImportError:\n",
    "    print(\"‚ö†Ô∏è DuckDuckGoSearchRun not available. Will use mock search tool.\")\n",
    "    DUCKDUCKGO_AVAILABLE = False\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o ChatAnthropic\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    temperature=0,  # ƒê·∫∑t 0 ƒë·ªÉ c√≥ reasoning consistent\n",
    "    anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "# Test LLM\n",
    "test_response = llm.invoke(\"Hello! Can you help me build an agent?\")\n",
    "print(\"‚úÖ ChatAnthropic initialized successfully\")\n",
    "print(f\"Test response: {test_response.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ƒê·ªãnh nghƒ©a Tools cho Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Calculator\n",
    "def calculator_function(expression: str) -> str:\n",
    "    \"\"\"Calculate mathematical expressions safely\"\"\"\n",
    "    try:\n",
    "        # Basic safety: only allow certain characters\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        \n",
    "        # Use eval carefully (trong production, n√™n d√πng safer alternatives)\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating expression: {str(e)}\"\n",
    "\n",
    "calculator_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    description=\"Useful for mathematical calculations. Input should be a mathematical expression.\",\n",
    "    func=calculator_function\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Calculator tool created\")\n",
    "# Test calculator\n",
    "test_calc = calculator_tool.run(\"15 + 25 * 2\")\n",
    "print(f\"Calculator test: {test_calc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 2: Date and Time\n",
    "def datetime_function(query: str) -> str:\n",
    "    \"\"\"Get current date and time information\"\"\"\n",
    "    now = datetime.now()\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    if \"date\" in query_lower:\n",
    "        return f\"Current date: {now.strftime('%Y-%m-%d (%A)')}\"\n",
    "    elif \"time\" in query_lower:\n",
    "        return f\"Current time: {now.strftime('%H:%M:%S')}\"\n",
    "    elif \"year\" in query_lower:\n",
    "        return f\"Current year: {now.year}\"\n",
    "    elif \"month\" in query_lower:\n",
    "        return f\"Current month: {now.strftime('%B')} ({now.month})\"\n",
    "    else:\n",
    "        return f\"Current date and time: {now.strftime('%Y-%m-%d %H:%M:%S (%A)')}\"\n",
    "\n",
    "datetime_tool = Tool(\n",
    "    name=\"DateTime\",\n",
    "    description=\"Get current date and time information. Can answer questions about current date, time, year, month.\",\n",
    "    func=datetime_function\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DateTime tool created\")\n",
    "# Test datetime\n",
    "test_dt = datetime_tool.run(\"what is the current date?\")\n",
    "print(f\"DateTime test: {test_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 3: Mock Search (fallback n·∫øu DuckDuckGo kh√¥ng available)\n",
    "def mock_search_function(query: str) -> str:\n",
    "    \"\"\"Mock search function v·ªõi some sample responses\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Mock responses cho common queries\n",
    "    if \"weather\" in query_lower:\n",
    "        return \"Weather information: Current temperature is around 25¬∞C, partly cloudy. (This is mock data)\"\n",
    "    elif \"bitcoin\" in query_lower or \"btc\" in query_lower:\n",
    "        return \"Bitcoin price: Approximately $43,000 - $45,000 USD. (This is mock data)\"\n",
    "    elif \"python\" in query_lower and \"langchain\" in query_lower:\n",
    "        return \"LangChain is a framework for developing applications powered by language models. It's written in Python and supports various LLMs.\"\n",
    "    elif \"vietnam\" in query_lower:\n",
    "        return \"Vietnam is a Southeast Asian country with a population of about 98 million people. Capital: Hanoi, Largest city: Ho Chi Minh City.\"\n",
    "    else:\n",
    "        return f\"Mock search results for '{query}': This is a simulated search result. In real implementation, this would return actual web search results.\"\n",
    "\n",
    "mock_search_tool = Tool(\n",
    "    name=\"Search\",\n",
    "    description=\"Search the internet for information. Useful for finding current information, facts, and news.\",\n",
    "    func=mock_search_function\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Mock Search tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 4: DuckDuckGo Search (n·∫øu available)\n",
    "if DUCKDUCKGO_AVAILABLE:\n",
    "    try:\n",
    "        # Initialize DuckDuckGo search\n",
    "        ddg_search = DuckDuckGoSearchRun()\n",
    "        \n",
    "        # Test search\n",
    "        test_search = ddg_search.run(\"LangChain framework\")\n",
    "        print(\"‚úÖ DuckDuckGo search tool ready\")\n",
    "        print(f\"Search test result: {test_search[:100]}...\")\n",
    "        \n",
    "        # Use real search tool\n",
    "        search_tool = Tool(\n",
    "            name=\"Search\",\n",
    "            description=\"Search the internet for current information, facts, and news using DuckDuckGo.\",\n",
    "            func=ddg_search.run\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è DuckDuckGo search failed: {e}\")\n",
    "        print(\"Using mock search instead\")\n",
    "        search_tool = mock_search_tool\nelse:\n",
    "    print(\"Using mock search tool\")\n",
    "    search_tool = mock_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 5: Text Analyzer\n",
    "def text_analyzer_function(text: str) -> str:\n",
    "    \"\"\"Analyze text properties nh∆∞ word count, character count, etc.\"\"\"\n",
    "    try:\n",
    "        # Basic text analysis\n",
    "        word_count = len(text.split())\n",
    "        char_count = len(text)\n",
    "        char_count_no_spaces = len(text.replace(' ', ''))\n",
    "        sentence_count = len([s for s in text.split('.') if s.strip()])\n",
    "        \n",
    "        # Average words per sentence\n",
    "        avg_words_per_sentence = word_count / sentence_count if sentence_count > 0 else 0\n",
    "        \n",
    "        analysis = {\n",
    "            \"word_count\": word_count,\n",
    "            \"character_count\": char_count,\n",
    "            \"character_count_no_spaces\": char_count_no_spaces,\n",
    "            \"sentence_count\": sentence_count,\n",
    "            \"average_words_per_sentence\": round(avg_words_per_sentence, 1)\n",
    "        }\n",
    "        \n",
    "        result = \"Text Analysis Results:\\n\"\n",
    "        for key, value in analysis.items():\n",
    "            result += f\"- {key.replace('_', ' ').title()}: {value}\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing text: {str(e)}\"\n",
    "\n",
    "text_analyzer_tool = Tool(\n",
    "    name=\"TextAnalyzer\",\n",
    "    description=\"Analyze text properties like word count, character count, sentence count, and readability metrics.\",\n",
    "    func=text_analyzer_function\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Text Analyzer tool created\")\n",
    "# Test text analyzer\n",
    "test_text = \"This is a sample text. It has multiple sentences. Let's analyze it!\"\n",
    "test_analysis = text_analyzer_tool.run(test_text)\n",
    "print(f\"Text analysis test:\\n{test_analysis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫≠p h·ª£p t·∫•t c·∫£ tools\n",
    "tools = [\n",
    "    calculator_tool,\n",
    "    datetime_tool,\n",
    "    search_tool,\n",
    "    text_analyzer_tool\n",
    "]\n",
    "\n",
    "print(f\"\\nüìã Available Tools for Agent:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    print(f\"{i}. {tool.name}: {tool.description}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total {len(tools)} tools ready for agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T·∫°o ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt template\n",
    "react_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ ReAct prompt template created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o ReAct agent\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ReAct agent created successfully\")\n",
    "print(f\"Agent type: {type(agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,  # ƒê·ªÉ xem detailed execution steps\n",
    "    handle_parsing_errors=True,  # X·ª≠ l√Ω parsing errors gracefully\n",
    "    max_iterations=10,  # Gi·ªõi h·∫°n s·ªë iterations\n",
    "    early_stopping_method=\"generate\"  # Stop khi c√≥ final answer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AgentExecutor created v·ªõi verbose=True\")\n",
    "print(f\"Max iterations: {agent_executor.max_iterations}\")\n",
    "print(f\"Available tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Agent v·ªõi Simple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple calculation\n",
    "print(\"üßÆ Test 1: Mathematical Calculation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query1 = \"What is 25 * 4 + 15?\"\n",
    "print(f\"Query: {query1}\\n\")\n",
    "\n",
    "try:\n",
    "    result1 = agent_executor.invoke({\"input\": query1})\n",
    "    print(f\"\\nüéØ Final Result: {result1['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Current date/time\n",
    "print(\"üìÖ Test 2: Current Date and Time\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query2 = \"What day is today?\"\n",
    "print(f\"Query: {query2}\\n\")\n",
    "\n",
    "try:\n",
    "    result2 = agent_executor.invoke({\"input\": query2})\n",
    "    print(f\"\\nüéØ Final Result: {result2['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Text analysis\n",
    "print(\"üìù Test 3: Text Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query3 = \"Analyze this text: 'LangChain l√† m·ªôt framework m·∫°nh m·∫Ω cho vi·ªác x√¢y d·ª±ng ·ª©ng d·ª•ng AI. N√≥ cung c·∫•p nhi·ªÅu tools h·ªØu √≠ch.'\"\n",
    "print(f\"Query: {query3}\\n\")\n",
    "\n",
    "try:\n",
    "    result3 = agent_executor.invoke({\"input\": query3})\n",
    "    print(f\"\\nüéØ Final Result: {result3['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complex Multi-Step Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Multi-step calculation v·ªõi search\n",
    "print(\"üîç Test 4: Multi-step Query (Search + Calculation)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query4 = \"Search for information about Python programming language, then tell me how many words are in the search result.\"\n",
    "print(f\"Query: {query4}\\n\")\n",
    "\n",
    "try:\n",
    "    result4 = agent_executor.invoke({\"input\": query4})\n",
    "    print(f\"\\nüéØ Final Result: {result4['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Complex reasoning v·ªõi multiple tools\n",
    "print(\"üß† Test 5: Complex Reasoning (Multiple Tools)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query5 = \"\"\"I need to know:\n",
    "1. What year is it now?\n",
    "2. Calculate how many years have passed since 1995\n",
    "3. Search for information about what happened in 1995\"\"\"\n",
    "\n",
    "print(f\"Query: {query5}\\n\")\n",
    "\n",
    "try:\n",
    "    result5 = agent_executor.invoke({\"input\": query5})\n",
    "    print(f\"\\nüéØ Final Result: {result5['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Agent Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o function ƒë·ªÉ capture v√† analyze agent steps\n",
    "def analyze_agent_execution(query: str, agent_executor: AgentExecutor):\n",
    "    \"\"\"Execute query v√† analyze agent behavior\"\"\"\n",
    "    print(f\"üîç Analyzing Agent Execution for: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Track execution steps\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Execute\n",
    "        result = agent_executor.invoke({\"input\": query})\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüìä Execution Analysis:\")\n",
    "        print(f\"   ‚è±Ô∏è  Total time: {execution_time:.2f} seconds\")\n",
    "        print(f\"   üéØ Final answer: {result['output'][:100]}...\")\n",
    "        \n",
    "        return result, execution_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Execution failed: {str(e)}\")\n",
    "        return None, 0\n",
    "\n",
    "print(\"‚úÖ Analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v·ªõi challenging query\n",
    "challenging_query = \"What's the square root of 144, and how does that relate to a dozen?\"\n",
    "\n",
    "result, exec_time = analyze_agent_execution(challenging_query, agent_executor)\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nüß† Agent Reasoning Analysis:\")\n",
    "    print(f\"   The agent successfully:\")\n",
    "    print(f\"   1Ô∏è‚É£  Used Calculator tool for mathematical computation\")\n",
    "    print(f\"   2Ô∏è‚É£  Made connection between mathematical result v√† real-world concept\")\n",
    "    print(f\"   3Ô∏è‚É£  Provided comprehensive answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test agent v·ªõi ambiguous query\n",
    "ambiguous_query = \"I need to know something about time and numbers\"\n",
    "\n",
    "print(\"ü§î Test: Ambiguous Query Handling\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result_ambiguous, exec_time_ambiguous = analyze_agent_execution(ambiguous_query, agent_executor)\n",
    "\n",
    "if result_ambiguous:\n",
    "    print(f\"\\nüí≠ Observation: Agent tried to interpret vague request\")\n",
    "    print(f\"   Agent behavior v·ªõi unclear instructions shows reasoning capability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Understanding Agent Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Agent Thought Process Analysis\n",
    "\n",
    "T·ª´ c√°c tests tr√™n, ch√∫ng ta c√≥ th·ªÉ quan s√°t:\n",
    "\n",
    "#### **1. Tool Selection Logic**\n",
    "- Agent **ph√¢n t√≠ch** query ƒë·ªÉ x√°c ƒë·ªãnh lo·∫°i task\n",
    "- **Ch·ªçn tool** ph√π h·ª£p nh·∫•t d·ª±a tr√™n tool descriptions\n",
    "- **Fallback** sang tools kh√°c n·∫øu c·∫ßn thi·∫øt\n",
    "\n",
    "#### **2. Reasoning Pattern**\n",
    "```\n",
    "Thought ‚Üí Action ‚Üí Observation ‚Üí Thought ‚Üí ...\n",
    "```\n",
    "- **Thought**: Agent suy lu·∫≠n v·ªÅ approach\n",
    "- **Action**: Quy·∫øt ƒë·ªãnh tool c·∫ßn s·ª≠ d·ª•ng\n",
    "- **Observation**: Xem x√©t k·∫øt qu·∫£ t·ª´ tool\n",
    "- **Iteration**: L·∫∑p l·∫°i n·∫øu c·∫ßn more information\n",
    "\n",
    "#### **3. Error Recovery**\n",
    "- Agent c√≥ th·ªÉ **retry** v·ªõi different inputs\n",
    "- **Switch tools** khi m·ªôt tool kh√¥ng ho·∫°t ƒë·ªông\n",
    "- **Adapt strategy** based on intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling\n",
    "print(\"üö® Test: Error Handling\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "error_query = \"Calculate 10 divided by zero, then tell me what to do next\"\n",
    "print(f\"Query: {error_query}\\n\")\n",
    "\n",
    "try:\n",
    "    result_error = agent_executor.invoke({\"input\": error_query})\n",
    "    print(f\"\\nüéØ Final Result: {result_error['output']}\")\n",
    "    print(f\"\\nüí° Observation: Agent handled mathematical error gracefully\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(f\"üí° Observation: Agent execution failed - need better error handling\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Tool Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o custom tool cho Vietnamese text processing\n",
    "def vietnamese_text_processor(text: str) -> str:\n",
    "    \"\"\"Process Vietnamese text v√† provide insights\"\"\"\n",
    "    try:\n",
    "        # Basic Vietnamese text analysis\n",
    "        words = text.split()\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        \n",
    "        # Count common Vietnamese words\n",
    "        common_vn_words = ['l√†', 'c·ªßa', 'v√†', 'c√≥', 'trong', 'ƒë∆∞·ª£c', 'v·ªõi', 'ƒë·ªÉ', 't·ª´', 'kh√¥ng']\n",
    "        common_count = sum(1 for word in words if word.lower() in common_vn_words)\n",
    "        \n",
    "        # Detect tone marks (Vietnamese specific)\n",
    "        tone_chars = '√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë'\n",
    "        tone_count = sum(1 for char in text.lower() if char in tone_chars)\n",
    "        \n",
    "        analysis = f\"\"\"\n",
    "Vietnamese Text Analysis:\n",
    "- Total words: {len(words)}\n",
    "- Sentences: {len(sentences)}\n",
    "- Common Vietnamese words: {common_count}\n",
    "- Characters with tone marks: {tone_count}\n",
    "- Estimated Vietnamese content: {(tone_count / len(text) * 100):.1f}%\n",
    "\"\"\"\n",
    "        return analysis.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error processing Vietnamese text: {str(e)}\"\n",
    "\n",
    "# Add Vietnamese tool to agent\n",
    "vietnamese_tool = Tool(\n",
    "    name=\"VietnameseAnalyzer\",\n",
    "    description=\"Analyze Vietnamese text for language-specific features nh∆∞ tone marks, common words, and structure.\",\n",
    "    func=vietnamese_text_processor\n",
    ")\n",
    "\n",
    "# Update tools list\n",
    "enhanced_tools = tools + [vietnamese_tool]\n",
    "\n",
    "print(\"‚úÖ Vietnamese analyzer tool added\")\n",
    "print(f\"Total tools: {len(enhanced_tools)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced agent v·ªõi new tool\n",
    "enhanced_agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=enhanced_tools,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "\n",
    "enhanced_agent_executor = AgentExecutor(\n",
    "    agent=enhanced_agent,\n",
    "    tools=enhanced_tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhanced agent v·ªõi Vietnamese tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Vietnamese text analysis\n",
    "print(\"üáªüá≥ Test: Vietnamese Text Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "vietnamese_query = \"Analyze this Vietnamese text: 'Xin ch√†o! T√¥i l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i quy·∫øt nhi·ªÅu v·∫•n ƒë·ªÅ kh√°c nhau.'\"\n",
    "print(f\"Query: {vietnamese_query}\\n\")\n",
    "\n",
    "try:\n",
    "    vn_result = enhanced_agent_executor.invoke({\"input\": vietnamese_query})\n",
    "    print(f\"\\nüéØ Final Result: {vn_result['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance v√† Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "import time\n",
    "\n",
    "def benchmark_agent(queries: list, agent_executor: AgentExecutor):\n",
    "    \"\"\"Benchmark agent performance v·ªõi multiple queries\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(\"üèÉ Agent Performance Benchmark\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\n{i}. Query: {query[:50]}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            result = agent_executor.invoke({\"input\": query})\n",
    "            execution_time = time.time() - start_time\n",
    "            success = True\n",
    "            answer_length = len(result['output'])\n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            success = False\n",
    "            answer_length = 0\n",
    "            print(f\"   ‚ùå Failed: {str(e)[:50]}...\")\n",
    "        \n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'execution_time': execution_time,\n",
    "            'success': success,\n",
    "            'answer_length': answer_length\n",
    "        })\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è Time: {execution_time:.2f}s, Success: {'‚úÖ' if success else '‚ùå'}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark queries\n",
    "benchmark_queries = [\n",
    "    \"What is 15 + 27?\",\n",
    "    \"What day is today?\",\n",
    "    \"Search for LangChain information\",\n",
    "    \"Calculate the square root of 64 and tell me what it means\",\n",
    "    \"Analyze the text: 'AI is revolutionizing technology'\"\n",
    "]\n",
    "\n",
    "benchmark_results = benchmark_agent(benchmark_queries, agent_executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze benchmark results\n",
    "successful_results = [r for r in benchmark_results if r['success']]\n",
    "failed_results = [r for r in benchmark_results if not r['success']]\n",
    "\n",
    "if successful_results:\n",
    "    avg_time = sum(r['execution_time'] for r in successful_results) / len(successful_results)\n",
    "    avg_answer_length = sum(r['answer_length'] for r in successful_results) / len(successful_results)\n",
    "    \n",
    "    print(f\"\\nüìä Benchmark Summary:\")\n",
    "    print(f\"   ‚úÖ Successful queries: {len(successful_results)}/{len(benchmark_results)}\")\n",
    "    print(f\"   ‚è±Ô∏è Average execution time: {avg_time:.2f} seconds\")\n",
    "    print(f\"   üìù Average answer length: {avg_answer_length:.0f} characters\")\n",
    "    print(f\"   ‚ùå Failed queries: {len(failed_results)}\")\n",
    "    \n",
    "    if failed_results:\n",
    "        print(f\"\\nüö® Failed Queries:\")\n",
    "        for fail in failed_results:\n",
    "            print(f\"   - {fail['query'][:50]}...\")\nelse:\n",
    "    print(\"\\n‚ùå No successful executions to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Agent Limitations v√† Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Observations t·ª´ Testing\n",
    "\n",
    "#### **‚úÖ Agent Strengths:**\n",
    "1. **Tool Selection**: Agent good at choosing appropriate tools\n",
    "2. **Multi-step Reasoning**: Can break down complex problems\n",
    "3. **Error Recovery**: Handles some errors gracefully\n",
    "4. **Adaptability**: Adjusts approach based on intermediate results\n",
    "\n",
    "#### **‚ö†Ô∏è Areas for Improvement:**\n",
    "1. **Cost Efficiency**: Multiple LLM calls increase costs\n",
    "2. **Speed**: Tool selection v√† reasoning add latency\n",
    "3. **Reliability**: Non-deterministic behavior\n",
    "4. **Error Handling**: Some edge cases not handled well\n",
    "\n",
    "#### **üöÄ Optimization Strategies:**\n",
    "1. **Tool Optimization**: \n",
    "   - Better tool descriptions\n",
    "   - Faster tool implementations\n",
    "   - Tool result caching\n",
    "\n",
    "2. **Prompt Engineering**:\n",
    "   - More specific instructions\n",
    "   - Better examples\n",
    "   - Clear success criteria\n",
    "\n",
    "3. **Execution Control**:\n",
    "   - Lower max_iterations for simple tasks\n",
    "   - Timeout configurations\n",
    "   - Priority-based tool selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved agent configuration\n",
    "def create_optimized_agent(tools, max_iterations=5):\n",
    "    \"\"\"Create optimized agent v·ªõi better configurations\"\"\"\n",
    "    \n",
    "    # Optimized prompt v·ªõi clearer instructions\n",
    "    optimized_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant with access to specific tools. Answer questions efficiently using the minimum number of tool calls needed.\n",
    "\n",
    "Available tools:\n",
    "{tools}\n",
    "\n",
    "Instructions:\n",
    "1. Think carefully about which tool(s) you need BEFORE acting\n",
    "2. Use tools only when necessary - don't use tools for information you already know\n",
    "3. Be concise in your reasoning\n",
    "4. Provide clear, direct answers\n",
    "\n",
    "Format:\n",
    "Question: the input question you must answer\n",
    "Thought: think about what you need to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (repeat if needed)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\")\n",
    "    \n",
    "    # Create optimized agent\n",
    "    optimized_agent = create_react_agent(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        prompt=optimized_prompt\n",
    "    )\n",
    "    \n",
    "    # Create optimized executor\n",
    "    optimized_executor = AgentExecutor(\n",
    "        agent=optimized_agent,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "        max_iterations=max_iterations,  # Reduced iterations\n",
    "        early_stopping_method=\"generate\"\n",
    "    )\n",
    "    \n",
    "    return optimized_executor\n",
    "\n",
    "# Create optimized agent\n",
    "optimized_agent_executor = create_optimized_agent(tools, max_iterations=5)\n",
    "\n",
    "print(\"‚úÖ Optimized agent created v·ªõi:\")\n",
    "print(f\"   - Reduced max iterations: 5\")\n",
    "print(f\"   - Clearer instructions\")\n",
    "print(f\"   - Efficiency focus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs optimized agent\n",
    "comparison_query = \"What is 50 divided by 2, and what day is today?\"\n",
    "\n",
    "print(\"‚öñÔ∏è Comparison: Original vs Optimized Agent\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Query: {comparison_query}\\n\")\n",
    "\n",
    "# Test optimized agent\n",
    "print(\"üöÄ Optimized Agent:\")\n",
    "print(\"-\" * 30)\n",
    "start_time = time.time()\n",
    "try:\n",
    "    optimized_result = optimized_agent_executor.invoke({\"input\": comparison_query})\n",
    "    optimized_time = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è Optimized execution time: {optimized_time:.2f}s\")\n",
    "    print(f\"üéØ Result: {optimized_result['output']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Optimized agent failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Agent Development Best Practices\n",
    "\n",
    "#### **1. üîß Tool Design**\n",
    "- **Clear descriptions**: Help agent understand when to use each tool\n",
    "- **Error handling**: Tools should fail gracefully\n",
    "- **Input validation**: Sanitize inputs before processing\n",
    "- **Consistent output**: Standardize response formats\n",
    "\n",
    "#### **2. üß† Prompt Engineering**\n",
    "- **Specific instructions**: Clear guidelines for tool usage\n",
    "- **Examples**: Show expected behavior patterns\n",
    "- **Constraints**: Set boundaries for agent actions\n",
    "- **Format consistency**: Maintain structured reasoning format\n",
    "\n",
    "#### **3. ‚öôÔ∏è Configuration Optimization**\n",
    "- **Max iterations**: Set reasonable limits\n",
    "- **Temperature**: Use 0 for consistent reasoning\n",
    "- **Error handling**: Enable graceful failure recovery\n",
    "- **Verbose mode**: Use for debugging v√† understanding\n",
    "\n",
    "#### **4. üöÄ Performance Optimization**\n",
    "- **Tool caching**: Cache expensive tool results\n",
    "- **Early stopping**: Stop when answer is found\n",
    "- **Parallel tools**: Use tools that can run concurrently\n",
    "- **Monitoring**: Track execution times v√† success rates\n",
    "\n",
    "#### **5. üõ°Ô∏è Production Considerations**\n",
    "- **Security**: Validate all inputs v√† outputs\n",
    "- **Rate limiting**: Control API usage\n",
    "- **Logging**: Comprehensive execution logs\n",
    "- **Fallbacks**: Alternative approaches for failures\n",
    "\n",
    "### üìä Key Metrics to Monitor\n",
    "- **Success rate**: Percentage of queries answered correctly\n",
    "- **Execution time**: Average time per query\n",
    "- **Tool usage**: Which tools are used most frequently\n",
    "- **Error patterns**: Common failure modes\n",
    "- **Cost efficiency**: Tokens used per successful query\n",
    "\n",
    "### üîÆ Next Steps\n",
    "1. **Custom Tools**: Develop domain-specific tools\n",
    "2. **Memory Integration**: Add conversation memory\n",
    "3. **Multi-agent Systems**: Coordinate multiple agents\n",
    "4. **Production Deployment**: Scale v√† monitor in production\n",
    "5. **Advanced Patterns**: Implement specialized agent patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéâ Agent Building Tutorial Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n‚úÖ What we accomplished:\")\n",
    "print(\"   1. Built basic ReAct agent v·ªõi ChatAnthropic\")\n",
    "print(\"   2. Created multiple useful tools\")\n",
    "print(\"   3. Tested agent v·ªõi various query types\")\n",
    "print(\"   4. Analyzed agent reasoning patterns\")\n",
    "print(\"   5. Optimized agent performance\")\n",
    "print(\"   6. Learned best practices\")\n",
    "\n",
    "print(\"\\nüéØ Key Takeaways:\")\n",
    "print(\"   ‚Ä¢ Agents are powerful but need careful design\")\n",
    "print(\"   ‚Ä¢ Tool quality directly impacts agent performance\")\n",
    "print(\"   ‚Ä¢ Verbose mode is essential for understanding\")\n",
    "print(\"   ‚Ä¢ Optimization balances capability v·ªõi efficiency\")\n",
    "print(\"   ‚Ä¢ Production deployment requires additional considerations\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for more advanced agent patterns!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}