{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Memory trong LangChain\n",
    "\n",
    "## üß† T·∫°i sao c·∫ßn Memory?\n",
    "\n",
    "### **V·∫•n ƒë·ªÅ v·ªõi LLMs**\n",
    "Large Language Models v·ªÅ c∆° b·∫£n l√† **stateless** - ch√∫ng kh√¥ng \"nh·ªõ\" g√¨ v·ªÅ c√°c conversations tr∆∞·ªõc ƒë√≥. M·ªói l·∫ßn call LLM l√† m·ªôt interaction ƒë·ªôc l·∫≠p:\n",
    "\n",
    "```\n",
    "User: \"T√™n t√¥i l√† Nam\"\n",
    "LLM:  \"Ch√†o Nam! R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n.\"\n",
    "\n",
    "User: \"B·∫°n c√≥ nh·ªõ t√™n t√¥i kh√¥ng?\"\n",
    "LLM:  \"Xin l·ªói, t√¥i kh√¥ng c√≥ th√¥ng tin v·ªÅ t√™n c·ªßa b·∫°n.\" ‚ùå\n",
    "```\n",
    "\n",
    "### **T·∫°i sao Memory quan tr·ªçng?**\n",
    "\n",
    "#### **1. ü§ù Natural Conversations**\n",
    "- Con ng∆∞·ªùi expect chatbots \"nh·ªõ\" context\n",
    "- Conversations flow naturally khi c√≥ memory\n",
    "- Tr√°nh ph·∫£i repeat information\n",
    "\n",
    "#### **2. üéØ Personalized Experience**\n",
    "- Remember user preferences\n",
    "- Adapt responses based on conversation history\n",
    "- Build rapport over time\n",
    "\n",
    "#### **3. üîÑ Multi-turn Tasks**\n",
    "- Complex tasks require multiple exchanges\n",
    "- Context from previous turns informs current response\n",
    "- Enable iterative problem-solving\n",
    "\n",
    "#### **4. üìö Context Continuity**\n",
    "- Maintain thread of conversation\n",
    "- Reference previous topics naturally\n",
    "- Build on established context\n",
    "\n",
    "### **Memory Solution**\n",
    "LangChain Memory components gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y b·∫±ng c√°ch:\n",
    "- **Store** conversation history\n",
    "- **Retrieve** relevant context\n",
    "- **Format** context cho LLM\n",
    "- **Manage** memory size v√† performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup v√† Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Core\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationSummaryBufferMemory\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LangChain Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o ChatAnthropic\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    temperature=0.7,  # Slightly creative for natural conversation\n",
    "    anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "# Test LLM\n",
    "test_response = llm.invoke(\"Hello! How are you today?\")\n",
    "print(\"‚úÖ ChatAnthropic initialized\")\n",
    "print(f\"Test response: {test_response.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No Memory - Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o conversation chain WITHOUT memory\n",
    "no_memory_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"üö´ Conversation Chain WITHOUT Memory\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulate conversation without memory\n",
    "print(\"\\nüë§ User: T√™n t√¥i l√† Alice v√† t√¥i ƒëang h·ªçc v·ªÅ AI\")\n",
    "response1 = no_memory_chain.predict(input=\"T√™n t√¥i l√† Alice v√† t√¥i ƒëang h·ªçc v·ªÅ AI\")\n",
    "print(f\"ü§ñ Assistant: {response1}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "print(\"\\nüë§ User: B·∫°n c√≥ nh·ªõ t√™n t√¥i kh√¥ng?\")\n",
    "response2 = no_memory_chain.predict(input=\"B·∫°n c√≥ nh·ªõ t√™n t√¥i kh√¥ng?\")\n",
    "print(f\"ü§ñ Assistant: {response2}\")\n",
    "\n",
    "print(\"\\nüí≠ Observation: Chain kh√¥ng nh·ªõ previous conversation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ConversationBufferMemory - Store All History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o ConversationBufferMemory\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    return_messages=True,  # Return as message objects\n",
    "    memory_key=\"history\"   # Key ƒë·ªÉ store history trong prompt\n",
    ")\n",
    "\n",
    "print(\"üìö ConversationBufferMemory created\")\n",
    "print(f\"Memory type: {type(buffer_memory)}\")\n",
    "print(f\"Memory key: {buffer_memory.memory_key}\")\n",
    "\n",
    "# Inspect empty memory\n",
    "print(f\"\\nEmpty memory variables: {buffer_memory.load_memory_variables({})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o conversation chain WITH buffer memory\n",
    "buffer_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"üß† Conversation Chain WITH ConversationBufferMemory\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Start conversation\n",
    "print(\"\\nüë§ User: Xin ch√†o! T√™n t√¥i l√† Bob v√† t√¥i l√† m·ªôt developer Python\")\n",
    "response1 = buffer_chain.predict(input=\"Xin ch√†o! T√™n t√¥i l√† Bob v√† t√¥i l√† m·ªôt developer Python\")\n",
    "print(f\"ü§ñ Assistant: {response1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue conversation\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nüë§ User: T√¥i ƒëang h·ªçc v·ªÅ LangChain ƒë·ªÉ build chatbots\")\n",
    "response2 = buffer_chain.predict(input=\"T√¥i ƒëang h·ªçc v·ªÅ LangChain ƒë·ªÉ build chatbots\")\n",
    "print(f\"ü§ñ Assistant: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test memory recall\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nüë§ User: B·∫°n c√≥ nh·ªõ t√™n t√¥i v√† c√¥ng vi·ªác c·ªßa t√¥i kh√¥ng?\")\n",
    "response3 = buffer_chain.predict(input=\"B·∫°n c√≥ nh·ªõ t√™n t√¥i v√† c√¥ng vi·ªác c·ªßa t√¥i kh√¥ng?\")\n",
    "print(f\"ü§ñ Assistant: {response3}\")\n",
    "\n",
    "print(\"\\n‚úÖ Observation: Chain now remembers previous conversation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect memory contents\n",
    "print(\"\\nüîç Memory Contents Inspection:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "memory_vars = buffer_memory.load_memory_variables({})\n",
    "print(f\"Memory variables keys: {list(memory_vars.keys())}\")\n",
    "\n",
    "# Show conversation history\n",
    "history = memory_vars['history']\n",
    "print(f\"\\nConversation History ({len(history)} messages):\")\n",
    "for i, message in enumerate(history):\n",
    "    role = \"üë§ Human\" if message.type == \"human\" else \"ü§ñ AI\"\n",
    "    content = message.content[:100] + \"...\" if len(message.content) > 100 else message.content\n",
    "    print(f\"{i+1}. {role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ConversationBufferWindowMemory - Limited History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o ConversationBufferWindowMemory v·ªõi window size\n",
    "window_memory = ConversationBufferWindowMemory(\n",
    "    k=2,  # Keep only last 2 exchanges (4 messages: human + ai + human + ai)\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"\n",
    ")\n",
    "\n",
    "print(\"ü™ü ConversationBufferWindowMemory created\")\n",
    "print(f\"Window size (k): {window_memory.k}\")\n",
    "print(f\"This keeps last {window_memory.k} conversation exchanges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o conversation chain v·ªõi window memory\n",
    "window_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ü™ü Conversation Chain WITH ConversationBufferWindowMemory (k=2)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Start long conversation ƒë·ªÉ test window behavior\n",
    "conversations = [\n",
    "    \"T√¥i t√™n l√† Charlie v√† t√¥i 25 tu·ªïi\",\n",
    "    \"T√¥i l√†m vi·ªác t·∫°i m·ªôt c√¥ng ty fintech ·ªü TP.HCM\",\n",
    "    \"S·ªü th√≠ch c·ªßa t√¥i l√† ch∆°i guitar v√† ƒë·ªçc s√°ch\",\n",
    "    \"Hi·ªán t·∫°i t√¥i ƒëang h·ªçc machine learning\",\n",
    "    \"B·∫°n c√≥ nh·ªõ t√™n v√† tu·ªïi c·ªßa t√¥i kh√¥ng?\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "for i, user_input in enumerate(conversations, 1):\n",
    "    print(f\"\\n--- Exchange {i} ---\")\n",
    "    print(f\"üë§ User: {user_input}\")\n",
    "    \n",
    "    response = window_chain.predict(input=user_input)\n",
    "    responses.append(response)\n",
    "    print(f\"ü§ñ Assistant: {response}\")\n",
    "    \n",
    "    # Show current memory window\n",
    "    current_memory = window_memory.load_memory_variables({})['history']\n",
    "    print(f\"üìä Current memory window size: {len(current_memory)} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze window memory behavior\n",
    "print(\"\\nüîç Window Memory Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "final_memory = window_memory.load_memory_variables({})['history']\n",
    "print(f\"Final memory contains {len(final_memory)} messages:\")\n",
    "\n",
    "for i, message in enumerate(final_memory):\n",
    "    role = \"üë§ Human\" if message.type == \"human\" else \"ü§ñ AI\"\n",
    "    content = message.content[:80] + \"...\" if len(message.content) > 80 else message.content\n",
    "    print(f\"{i+1}. {role}: {content}\")\n",
    "\n",
    "print(f\"\\nüí≠ Observation: Window memory forgotten early information (name, age)\")\n",
    "print(f\"   but remembers recent context (machine learning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. So s√°nh Buffer vs Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ƒë·ªÉ test memory recall\n",
    "def test_memory_recall(chain, memory_type, test_questions):\n",
    "    \"\"\"Test memory recall capability\"\"\"\n",
    "    print(f\"\\nüß™ Testing {memory_type} Memory Recall\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    for question in test_questions:\n",
    "        print(f\"\\n‚ùì Question: {question}\")\n",
    "        try:\n",
    "            response = chain.predict(input=question)\n",
    "            print(f\"üí¨ Response: {response[:150]}...\")\n",
    "            \n",
    "            # Simple heuristic ƒë·ªÉ check if information is recalled\n",
    "            recalled = any(keyword in response.lower() for keyword in ['charlie', '25', 'fintech', 'guitar'])\n",
    "            results.append(recalled)\n",
    "            print(f\"üìù Recall detected: {'‚úÖ' if recalled else '‚ùå'}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            results.append(False)\n",
    "    \n",
    "    success_rate = sum(results) / len(results) * 100\n",
    "    print(f\"\\nüìä Recall Success Rate: {success_rate:.1f}%\")\n",
    "    return results\n",
    "\n",
    "# Test questions\n",
    "test_questions = [\n",
    "    \"T√™n t√¥i l√† g√¨?\",\n",
    "    \"T√¥i bao nhi√™u tu·ªïi?\",\n",
    "    \"T√¥i l√†m vi·ªác ·ªü ƒë√¢u?\",\n",
    "    \"S·ªü th√≠ch c·ªßa t√¥i l√† g√¨?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset memories v√† test both\n",
    "# Create fresh memories\n",
    "fresh_buffer_memory = ConversationBufferMemory(return_messages=True)\n",
    "fresh_window_memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "fresh_buffer_chain = ConversationChain(llm=llm, memory=fresh_buffer_memory, verbose=False)\n",
    "fresh_window_chain = ConversationChain(llm=llm, memory=fresh_window_memory, verbose=False)\n",
    "\n",
    "# Setup conversations for both chains\n",
    "setup_conversations = [\n",
    "    \"T√¥i t√™n l√† David v√† t√¥i 30 tu·ªïi\",\n",
    "    \"T√¥i l√† software engineer t·∫°i Google\",\n",
    "    \"T√¥i th√≠ch ch∆°i tennis v√† du l·ªãch\",\n",
    "    \"G·∫ßn ƒë√¢y t√¥i ƒëang quan t√¢m ƒë·∫øn blockchain\"\n",
    "]\n",
    "\n",
    "print(\"üîÑ Setting up conversations for comparison...\")\n",
    "\n",
    "# Feed same conversation to both chains\n",
    "for conv in setup_conversations:\n",
    "    fresh_buffer_chain.predict(input=conv)\n",
    "    fresh_window_chain.predict(input=conv)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test both memory types\n",
    "recall_questions = [\n",
    "    \"T√™n t√¥i l√† g√¨?\",\n",
    "    \"T√¥i bao nhi√™u tu·ªïi?\", \n",
    "    \"T√¥i l√†m vi·ªác ·ªü c√¥ng ty n√†o?\",\n",
    "    \"S·ªü th√≠ch c·ªßa t√¥i l√† g√¨?\"\n",
    "]\n",
    "\n",
    "# Test buffer memory\n",
    "buffer_results = test_memory_recall(fresh_buffer_chain, \"Buffer\", recall_questions)\n",
    "\n",
    "# Test window memory  \n",
    "window_results = test_memory_recall(fresh_window_chain, \"Window\", recall_questions)\n",
    "\n",
    "# Comparison summary\n",
    "print(\"\\nüìä Memory Comparison Summary:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Buffer Memory Success: {sum(buffer_results)}/{len(buffer_results)} ({sum(buffer_results)/len(buffer_results)*100:.1f}%)\")\n",
    "print(f\"Window Memory Success: {sum(window_results)}/{len(window_results)} ({sum(window_results)/len(window_results)*100:.1f}%)\")\n",
    "\n",
    "buffer_memory_size = len(fresh_buffer_memory.load_memory_variables({})['history'])\n",
    "window_memory_size = len(fresh_window_memory.load_memory_variables({})['history'])\n",
    "\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(f\"Buffer Memory: {buffer_memory_size} messages stored\")\n",
    "print(f\"Window Memory: {window_memory_size} messages stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory Management v√† Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze memory growth v√† performance\n",
    "import sys\n",
    "\n",
    "def analyze_memory_performance(memory_type, num_exchanges=10):\n",
    "    \"\"\"Analyze memory growth v√† performance\"\"\"\n",
    "    print(f\"\\nüìà Memory Performance Analysis: {memory_type}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if memory_type == \"buffer\":\n",
    "        test_memory = ConversationBufferMemory(return_messages=True)\n",
    "    else:\n",
    "        test_memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n",
    "    \n",
    "    test_chain = ConversationChain(llm=llm, memory=test_memory, verbose=False)\n",
    "    \n",
    "    memory_sizes = []\n",
    "    execution_times = []\n",
    "    \n",
    "    for i in range(num_exchanges):\n",
    "        # Generate test conversation\n",
    "        test_input = f\"This is message number {i+1}. I'm talking about topic {i+1}.\"\n",
    "        \n",
    "        # Measure execution time\n",
    "        start_time = time.time()\n",
    "        response = test_chain.predict(input=test_input)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Measure memory size\n",
    "        current_memory = test_memory.load_memory_variables({})['history']\n",
    "        memory_size = len(current_memory)\n",
    "        \n",
    "        memory_sizes.append(memory_size)\n",
    "        execution_times.append(execution_time)\n",
    "        \n",
    "        if i % 3 == 0:  # Print every 3rd exchange\n",
    "            print(f\"Exchange {i+1:2d}: Memory={memory_size:2d} messages, Time={execution_time:.2f}s\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    avg_time = sum(execution_times) / len(execution_times)\n",
    "    final_memory_size = memory_sizes[-1]\n",
    "    \n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Final memory size: {final_memory_size} messages\")\n",
    "    print(f\"   Average execution time: {avg_time:.2f}s\")\n",
    "    print(f\"   Memory growth pattern: {memory_sizes[0]} ‚Üí {final_memory_size}\")\n",
    "    \n",
    "    return memory_sizes, execution_times\n",
    "\n",
    "# Test both memory types\n",
    "buffer_sizes, buffer_times = analyze_memory_performance(\"buffer\", 8)\n",
    "window_sizes, window_times = analyze_memory_performance(\"window\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"\\n‚öñÔ∏è Performance Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Buffer Memory:\")\n",
    "print(f\"   Average time: {sum(buffer_times)/len(buffer_times):.3f}s\")\n",
    "print(f\"   Memory growth: {buffer_sizes[0]} ‚Üí {buffer_sizes[-1]} messages\")\n",
    "print(f\"   Final memory size: {buffer_sizes[-1]} messages\")\n",
    "\n",
    "print(f\"\\nWindow Memory (k=3):\")\n",
    "print(f\"   Average time: {sum(window_times)/len(window_times):.3f}s\")\n",
    "print(f\"   Memory pattern: {window_sizes}\")\n",
    "print(f\"   Stable memory size: {window_sizes[-1]} messages\")\n",
    "\n",
    "print(f\"\\nüí° Insights:\")\n",
    "print(f\"   üìà Buffer memory grows linearly v·ªõi conversation length\")\n",
    "print(f\"   üîÑ Window memory maintains constant size after initial fill\")\n",
    "print(f\"   ‚ö° Window memory c√≥ predictable performance characteristics\")\n",
    "print(f\"   üí∞ Window memory more cost-effective for long conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Use Cases v√† Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case demonstrations\n",
    "def demonstrate_use_cases():\n",
    "    print(\"üéØ Memory Type Recommendations\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    use_cases = {\n",
    "        \"ConversationBufferMemory\": {\n",
    "            \"best_for\": [\n",
    "                \"üìù Short conversations (< 10 exchanges)\",\n",
    "                \"üìö Educational tutoring sessions\", \n",
    "                \"üîç Detailed analysis tasks\",\n",
    "                \"üìã Interview or survey applications\",\n",
    "                \"üéØ When full context is critical\"\n",
    "            ],\n",
    "            \"considerations\": [\n",
    "                \"‚ö†Ô∏è Memory grows linearly\",\n",
    "                \"üí∞ Higher token costs over time\",\n",
    "                \"üêå Slower responses v·ªõi long history\",\n",
    "                \"üß† Perfect recall c·ªßa all information\"\n",
    "            ]\n",
    "        },\n",
    "        \"ConversationBufferWindowMemory\": {\n",
    "            \"best_for\": [\n",
    "                \"üí¨ Long-running chatbots\",\n",
    "                \"üéÆ Gaming companions\",\n",
    "                \"üõí E-commerce assistants\",\n",
    "                \"üì± Mobile app assistants\", \n",
    "                \"üîÑ Ongoing customer support\"\n",
    "            ],\n",
    "            \"considerations\": [\n",
    "                \"‚úÖ Predictable memory usage\",\n",
    "                \"üí∞ Constant token costs\",\n",
    "                \"‚ö° Consistent performance\",\n",
    "                \"üòî Forgets old information\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for memory_type, info in use_cases.items():\n",
    "        print(f\"\\nüß† {memory_type}:\")\n",
    "        print(f\"   Best for:\")\n",
    "        for use_case in info[\"best_for\"]:\n",
    "            print(f\"     {use_case}\")\n",
    "        print(f\"   Considerations:\")\n",
    "        for consideration in info[\"considerations\"]:\n",
    "            print(f\"     {consideration}\")\n",
    "\n",
    "demonstrate_use_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision framework\n",
    "def memory_selection_guide():\n",
    "    print(\"\\nü§î Memory Selection Decision Tree:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    decision_tree = \"\"\"\n",
    "    üìù Conversation Length?\n",
    "    ‚îú‚îÄ‚îÄ Short (< 10 exchanges)\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ üß† ConversationBufferMemory\n",
    "    ‚îÇ       ‚úÖ Full context preserved\n",
    "    ‚îÇ       ‚úÖ Best accuracy\n",
    "    ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ Long (> 10 exchanges)\n",
    "        ‚îú‚îÄ‚îÄ üí∞ Cost Sensitive?\n",
    "        ‚îÇ   ‚îú‚îÄ‚îÄ Yes ‚Üí ü™ü ConversationBufferWindowMemory\n",
    "        ‚îÇ   ‚îÇ   ‚úÖ Predictable costs\n",
    "        ‚îÇ   ‚îÇ   ‚úÖ Stable performance\n",
    "        ‚îÇ   ‚îÇ\n",
    "        ‚îÇ   ‚îî‚îÄ‚îÄ No ‚Üí üìö ConversationSummaryMemory\n",
    "        ‚îÇ       ‚úÖ Compressed history\n",
    "        ‚îÇ       ‚úÖ Key information retained\n",
    "        ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ üéØ Context Importance?\n",
    "            ‚îú‚îÄ‚îÄ Critical ‚Üí üß† ConversationBufferMemory\n",
    "            ‚îÇ   ‚ö†Ô∏è Watch token limits\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ Moderate ‚Üí ü™ü ConversationBufferWindowMemory\n",
    "                ‚öôÔ∏è Tune window size (k=3-7)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(decision_tree)\n",
    "\n",
    "memory_selection_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Memory Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom memory v·ªõi filtering\n",
    "class FilteredConversationMemory(ConversationBufferMemory):\n",
    "    \"\"\"Custom memory v·ªõi content filtering\"\"\"\n",
    "    \n",
    "    def __init__(self, filter_keywords=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filter_keywords = filter_keywords or []\n",
    "    \n",
    "    def save_context(self, inputs, outputs):\n",
    "        \"\"\"Save context v·ªõi filtering\"\"\"\n",
    "        # Check if we should filter this exchange\n",
    "        input_text = inputs.get('input', '').lower()\n",
    "        output_text = outputs.get('response', '').lower()\n",
    "        \n",
    "        # Skip saving if contains filter keywords\n",
    "        if any(keyword in input_text or keyword in output_text \n",
    "               for keyword in self.filter_keywords):\n",
    "            print(f\"üö´ Filtered out exchange containing sensitive keywords\")\n",
    "            return\n",
    "        \n",
    "        # Save normally if no filters triggered\n",
    "        super().save_context(inputs, outputs)\n",
    "\n",
    "# Test filtered memory\n",
    "filtered_memory = FilteredConversationMemory(\n",
    "    filter_keywords=['password', 'secret', 'confidential'],\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "filtered_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=filtered_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"üîí Testing Filtered Memory:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Test normal conversation\n",
    "print(\"\\nüë§ User: T√¥i t√™n l√† Emma\")\n",
    "response1 = filtered_chain.predict(input=\"T√¥i t√™n l√† Emma\")\n",
    "print(f\"ü§ñ Assistant: {response1[:80]}...\")\n",
    "\n",
    "# Test filtered content\n",
    "print(\"\\nüë§ User: ƒê√¢y l√† password c·ªßa t√¥i: 123456\")\n",
    "response2 = filtered_chain.predict(input=\"ƒê√¢y l√† password c·ªßa t√¥i: 123456\")\n",
    "print(f\"ü§ñ Assistant: {response2[:80]}...\")\n",
    "\n",
    "# Check memory contents\n",
    "memory_contents = filtered_memory.load_memory_variables({})['history']\n",
    "print(f\"\\nüìä Memory contains {len(memory_contents)} messages (filtered content excluded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory with priority system\n",
    "class PriorityConversationMemory(ConversationBufferWindowMemory):\n",
    "    \"\"\"Memory with priority-based retention\"\"\"\n",
    "    \n",
    "    def __init__(self, priority_keywords=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.priority_keywords = priority_keywords or []\n",
    "        self.priority_messages = []  # Store high-priority messages separately\n",
    "    \n",
    "    def save_context(self, inputs, outputs):\n",
    "        \"\"\"Save context v·ªõi priority handling\"\"\"\n",
    "        input_text = inputs.get('input', '').lower()\n",
    "        \n",
    "        # Check if this is high priority\n",
    "        is_priority = any(keyword in input_text for keyword in self.priority_keywords)\n",
    "        \n",
    "        if is_priority:\n",
    "            # Store in priority memory\n",
    "            priority_entry = {\n",
    "                'input': inputs.get('input', ''),\n",
    "                'output': outputs.get('response', ''),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            self.priority_messages.append(priority_entry)\n",
    "            print(f\"‚≠ê High priority message saved!\")\n",
    "        \n",
    "        # Save normally as well\n",
    "        super().save_context(inputs, outputs)\n",
    "    \n",
    "    def load_memory_variables(self, inputs):\n",
    "        \"\"\"Load memory including priority messages\"\"\"\n",
    "        # Get regular window memory\n",
    "        memory_vars = super().load_memory_variables(inputs)\n",
    "        \n",
    "        # Add priority context if exists\n",
    "        if self.priority_messages:\n",
    "            priority_context = \"\\nImportant previous information:\\n\"\n",
    "            for msg in self.priority_messages[-3:]:  # Last 3 priority messages\n",
    "                priority_context += f\"- {msg['input'][:50]}...\\n\"\n",
    "            \n",
    "            # This would need proper integration v·ªõi prompt template\n",
    "            # For demo, we'll just show the concept\n",
    "        \n",
    "        return memory_vars\n",
    "\n",
    "# Test priority memory\n",
    "priority_memory = PriorityConversationMemory(\n",
    "    k=2,\n",
    "    priority_keywords=['important', 'remember', 'critical'],\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "priority_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=priority_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚≠ê Testing Priority Memory:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "test_messages = [\n",
    "    \"T√¥i th√≠ch ƒÉn pizza\",\n",
    "    \"Important: T√¥i allergic v·ªõi peanuts\",\n",
    "    \"H√¥m nay tr·ªùi ƒë·∫πp\",\n",
    "    \"Remember: Cu·ªôc h·ªçp l√∫c 3pm\",\n",
    "    \"T√¥i ƒëang ƒë·ªçc s√°ch\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nüë§ User: {msg}\")\n",
    "    response = priority_chain.predict(input=msg)\n",
    "\n",
    "print(f\"\\nüìä Priority messages stored: {len(priority_memory.priority_messages)}\")\n",
    "for i, priority_msg in enumerate(priority_memory.priority_messages):\n",
    "    print(f\"   {i+1}. {priority_msg['input']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production memory management\n",
    "def production_memory_tips():\n",
    "    print(\"üè≠ Production Memory Management\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    tips = {\n",
    "        \"üîí Security\": [\n",
    "            \"Never store sensitive information in memory\",\n",
    "            \"Implement content filtering for PII\",\n",
    "            \"Regular memory cleanup for compliance\",\n",
    "            \"Encrypt memory storage if persistent\"\n",
    "        ],\n",
    "        \"üí∞ Cost Optimization\": [\n",
    "            \"Monitor token usage with memory size\",\n",
    "            \"Use window memory for long conversations\", \n",
    "            \"Implement conversation summarization\",\n",
    "            \"Set reasonable memory limits\"\n",
    "        ],\n",
    "        \"‚ö° Performance\": [\n",
    "            \"Cache frequent memory operations\",\n",
    "            \"Async memory operations when possible\",\n",
    "            \"Batch memory updates\",\n",
    "            \"Monitor memory access patterns\"\n",
    "        ],\n",
    "        \"üîß Scalability\": [\n",
    "            \"Use external storage for persistence\",\n",
    "            \"Implement memory sharding for users\",\n",
    "            \"Stateless memory management\",\n",
    "            \"Load balancing considerations\"\n",
    "        ],\n",
    "        \"üìä Monitoring\": [\n",
    "            \"Track memory size growth\",\n",
    "            \"Monitor conversation quality\",\n",
    "            \"Alert on memory anomalies\",\n",
    "            \"User satisfaction metrics\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, tip_list in tips.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for tip in tip_list:\n",
    "            print(f\"   ‚Ä¢ {tip}\")\n",
    "\n",
    "production_memory_tips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example production configuration\n",
    "def create_production_memory_config(user_id, conversation_type=\"general\"):\n",
    "    \"\"\"Create production-ready memory configuration\"\"\"\n",
    "    \n",
    "    configs = {\n",
    "        \"customer_support\": {\n",
    "            \"memory_type\": \"window\",\n",
    "            \"window_size\": 5,\n",
    "            \"max_conversation_length\": 50,\n",
    "            \"filter_pii\": True\n",
    "        },\n",
    "        \"educational\": {\n",
    "            \"memory_type\": \"buffer\", \n",
    "            \"max_conversation_length\": 20,\n",
    "            \"summarize_after\": 15,\n",
    "            \"filter_pii\": True\n",
    "        },\n",
    "        \"general\": {\n",
    "            \"memory_type\": \"window\",\n",
    "            \"window_size\": 3,\n",
    "            \"max_conversation_length\": 30,\n",
    "            \"filter_pii\": True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = configs.get(conversation_type, configs[\"general\"])\n",
    "    config[\"user_id\"] = user_id\n",
    "    config[\"created_at\"] = datetime.now().isoformat()\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Example configurations\n",
    "print(\"üè≠ Production Memory Configurations:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "examples = [\n",
    "    (\"user123\", \"customer_support\"),\n",
    "    (\"student456\", \"educational\"),\n",
    "    (\"visitor789\", \"general\")\n",
    "]\n",
    "\n",
    "for user_id, conv_type in examples:\n",
    "    config = create_production_memory_config(user_id, conv_type)\n",
    "    print(f\"\\nüë§ {user_id} ({conv_type}):\")\n",
    "    for key, value in config.items():\n",
    "        if key != 'created_at':\n",
    "            print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary v√† Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "def memory_best_practices_summary():\n",
    "    print(\"üìö Conversation Memory: Key Takeaways\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    summary = {\n",
    "        \"üß† Memory Types\": {\n",
    "            \"ConversationBufferMemory\": \"Stores all history, perfect recall\",\n",
    "            \"ConversationBufferWindowMemory\": \"Fixed-size window, recent focus\",\n",
    "            \"ConversationSummaryMemory\": \"Compressed history, key points\",\n",
    "            \"Custom Memory\": \"Tailored for specific use cases\"\n",
    "        },\n",
    "        \"‚úÖ When to Use What\": {\n",
    "            \"Short conversations\": \"ConversationBufferMemory\",\n",
    "            \"Long conversations\": \"ConversationBufferWindowMemory\", \n",
    "            \"Cost-sensitive apps\": \"ConversationBufferWindowMemory\",\n",
    "            \"Critical context\": \"ConversationBufferMemory\"\n",
    "        },\n",
    "        \"‚ö° Performance Tips\": [\n",
    "            \"Monitor memory size growth\",\n",
    "            \"Set appropriate window sizes (k=3-7)\",\n",
    "            \"Use async operations when possible\",\n",
    "            \"Implement memory cleanup routines\"\n",
    "        ],\n",
    "        \"üîí Security Considerations\": [\n",
    "            \"Filter sensitive information\",\n",
    "            \"Implement data retention policies\", \n",
    "            \"Encrypt stored conversations\",\n",
    "            \"Regular security audits\"\n",
    "        ],\n",
    "        \"üí∞ Cost Management\": [\n",
    "            \"Window memory for predictable costs\",\n",
    "            \"Summary memory for compression\",\n",
    "            \"Monitor token usage patterns\",\n",
    "            \"Set conversation length limits\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for section, content in summary.items():\n",
    "        print(f\"\\n{section}:\")\n",
    "        if isinstance(content, dict):\n",
    "            for key, value in content.items():\n",
    "                print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "        elif isinstance(content, list):\n",
    "            for item in content:\n",
    "                print(f\"   ‚Ä¢ {item}\")\n",
    "\n",
    "memory_best_practices_summary()\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"   1. Experiment v·ªõi different memory types\")\n",
    "print(\"   2. Build custom memory solutions\")\n",
    "print(\"   3. Integrate memory v·ªõi production systems\")\n",
    "print(\"   4. Monitor v√† optimize memory performance\")\n",
    "print(\"   5. Explore advanced memory patterns\")\n",
    "\n",
    "print(\"\\nüéâ Conversation Memory Tutorial Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}