{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_LangFuse_Code_Review - T·ª± ƒë·ªông h√≥a Code Review v·ªõi LangFuse\n",
    "\n",
    "## M·ª•c ti√™u h·ªçc t·∫≠p\n",
    "- Hi·ªÉu c√°ch thi·∫øt k·∫ø v√† tri·ªÉn khai pipeline code review t·ª± ƒë·ªông v·ªõi LangFuse\n",
    "- Theo d√µi hi·ªáu su·∫•t v√† ch·∫•t l∆∞·ª£ng c·ªßa c√°c g·ª£i √Ω review code\n",
    "- T·ªëi ∆∞u h√≥a prompt cho c√°c lo·∫°i review kh√°c nhau (security, performance, best practices)\n",
    "- S·ª≠ d·ª•ng LangFuse ƒë·ªÉ thu th·∫≠p feedback v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng review\n",
    "\n",
    "## Gi·ªõi thi·ªáu\n",
    "Code review t·ª± ƒë·ªông b·∫±ng LLM gi√∫p:\n",
    "- **Ph√°t hi·ªán l·ªói ti·ªÅm ·∫©n** s·ªõm trong qu√° tr√¨nh ph√°t tri·ªÉn\n",
    "- **ƒê·∫£m b·∫£o tu√¢n th·ªß** coding standards v√† best practices\n",
    "- **G·ª£i √Ω c·∫£i ti·∫øn** v·ªÅ performance v√† security \n",
    "- **H·ªó tr·ª£ ƒë√†o t·∫°o** junior developers\n",
    "\n",
    "LangFuse gi√∫p:\n",
    "- Theo d√µi ch·∫•t l∆∞·ª£ng v√† ƒë·ªô ch√≠nh x√°c c·ªßa review comments\n",
    "- A/B test c√°c prompt templates kh√°c nhau\n",
    "- Thu th·∫≠p feedback t·ª´ developers ƒë·ªÉ c·∫£i thi·ªán model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√†i ƒë·∫∑t & C·∫•u h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh LangFuse\n",
    "langfuse = Langfuse(\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    host=\"http://localhost:3000\"\n",
    ")\n",
    "\n",
    "# C·∫•u h√¨nh Anthropic\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ C·∫•u h√¨nh ho√†n t·∫•t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒê·ªãnh nghƒ©a Code Review Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template cho security review\n",
    "SECURITY_REVIEW_TEMPLATE = \"\"\"\n",
    "B·∫°n l√† m·ªôt security expert. H√£y review ƒëo·∫°n code sau v√† t√¨m c√°c v·∫•n ƒë·ªÅ b·∫£o m·∫≠t ti·ªÅm ·∫©n:\n",
    "\n",
    "NG√îN NG·ªÆ: {language}\n",
    "CODE:\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "H√£y ph√¢n t√≠ch v√† ƒë∆∞a ra:\n",
    "1. **C√°c l·ªó h·ªïng b·∫£o m·∫≠t** (n·∫øu c√≥)\n",
    "2. **M·ª©c ƒë·ªô nghi√™m tr·ªçng** (Critical/High/Medium/Low)\n",
    "3. **G·ª£i √Ω kh·∫Øc ph·ª•c** c·ª• th·ªÉ\n",
    "4. **Code example** ƒë·ªÉ fix (n·∫øu c·∫ßn)\n",
    "\n",
    "Tr·∫£ l·ªùi b·∫±ng JSON format:\n",
    "{\n",
    "  \"issues\": [\n",
    "    {\n",
    "      \"type\": \"security\",\n",
    "      \"severity\": \"high\",\n",
    "      \"line\": 10,\n",
    "      \"description\": \"M√¥ t·∫£ v·∫•n ƒë·ªÅ\",\n",
    "      \"suggestion\": \"G·ª£i √Ω kh·∫Øc ph·ª•c\",\n",
    "      \"example\": \"Code example\"\n",
    "    }\n",
    "  ],\n",
    "  \"overall_score\": 7\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Template cho performance review\n",
    "PERFORMANCE_REVIEW_TEMPLATE = \"\"\"\n",
    "B·∫°n l√† m·ªôt performance optimization expert. H√£y review ƒëo·∫°n code sau v·ªÅ m·∫∑t hi·ªáu su·∫•t:\n",
    "\n",
    "NG√îN NG·ªÆ: {language}\n",
    "CODE:\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "H√£y ph√¢n t√≠ch:\n",
    "1. **Bottlenecks** ti·ªÅm ·∫©n\n",
    "2. **Memory usage** kh√¥ng t·ªëi ∆∞u\n",
    "3. **Algorithm complexity** c√≥ th·ªÉ c·∫£i thi·ªán\n",
    "4. **G·ª£i √Ω t·ªëi ∆∞u h√≥a** c·ª• th·ªÉ\n",
    "\n",
    "Tr·∫£ l·ªùi b·∫±ng JSON format:\n",
    "{\n",
    "  \"issues\": [\n",
    "    {\n",
    "      \"type\": \"performance\",\n",
    "      \"severity\": \"medium\",\n",
    "      \"line\": 5,\n",
    "      \"description\": \"V·∫•n ƒë·ªÅ hi·ªáu su·∫•t\",\n",
    "      \"suggestion\": \"C√°ch t·ªëi ∆∞u\",\n",
    "      \"impact\": \"C·∫£i thi·ªán 50% performance\"\n",
    "    }\n",
    "  ],\n",
    "  \"overall_score\": 6\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Template cho best practices review\n",
    "BEST_PRACTICES_TEMPLATE = \"\"\"\n",
    "B·∫°n l√† m·ªôt senior developer. H√£y review ƒëo·∫°n code sau v·ªÅ coding best practices:\n",
    "\n",
    "NG√îN NG·ªÆ: {language}\n",
    "CODE:\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "Ki·ªÉm tra:\n",
    "1. **Code style** v√† naming conventions\n",
    "2. **Code structure** v√† organization\n",
    "3. **Error handling** \n",
    "4. **Documentation** v√† comments\n",
    "5. **Maintainability** v√† readability\n",
    "\n",
    "Tr·∫£ l·ªùi b·∫±ng JSON format:\n",
    "{\n",
    "  \"issues\": [\n",
    "    {\n",
    "      \"type\": \"best_practice\",\n",
    "      \"severity\": \"low\",\n",
    "      \"line\": 3,\n",
    "      \"description\": \"V·∫•n ƒë·ªÅ v·ªÅ best practice\",\n",
    "      \"suggestion\": \"C√°ch c·∫£i thi·ªán\",\n",
    "      \"category\": \"naming\"\n",
    "    }\n",
    "  ],\n",
    "  \"overall_score\": 8\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Code Review Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeReviewPipeline:\n",
    "    def __init__(self, llm, langfuse_client):\n",
    "        self.llm = llm\n",
    "        self.langfuse = langfuse_client\n",
    "        \n",
    "    def detect_language(self, code: str) -> str:\n",
    "        \"\"\"Ph√°t hi·ªán ng√¥n ng·ªØ l·∫≠p tr√¨nh\"\"\"\n",
    "        if 'def ' in code or 'import ' in code or 'from ' in code:\n",
    "            return 'python'\n",
    "        elif 'function' in code or 'const ' in code or 'let ' in code:\n",
    "            return 'javascript'\n",
    "        elif 'public class' in code or 'import java' in code:\n",
    "            return 'java'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    \n",
    "    @observe()\n",
    "    def security_review(self, code: str, language: str) -> Dict:\n",
    "        \"\"\"Review code v·ªÅ m·∫∑t b·∫£o m·∫≠t\"\"\"\n",
    "        langfuse_context.update_current_observation(\n",
    "            name=\"security_review\",\n",
    "            metadata={\"language\": language, \"review_type\": \"security\"}\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(SECURITY_REVIEW_TEMPLATE)\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        result = chain.invoke({\n",
    "            \"code\": code,\n",
    "            \"language\": language\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            # Parse JSON response\n",
    "            json_match = re.search(r'{.*}', result, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "            else:\n",
    "                return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "    \n",
    "    @observe()\n",
    "    def performance_review(self, code: str, language: str) -> Dict:\n",
    "        \"\"\"Review code v·ªÅ m·∫∑t hi·ªáu su·∫•t\"\"\"\n",
    "        langfuse_context.update_current_observation(\n",
    "            name=\"performance_review\",\n",
    "            metadata={\"language\": language, \"review_type\": \"performance\"}\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(PERFORMANCE_REVIEW_TEMPLATE)\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        result = chain.invoke({\n",
    "            \"code\": code,\n",
    "            \"language\": language\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            json_match = re.search(r'{.*}', result, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "            else:\n",
    "                return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "    \n",
    "    @observe()\n",
    "    def best_practices_review(self, code: str, language: str) -> Dict:\n",
    "        \"\"\"Review code v·ªÅ best practices\"\"\"\n",
    "        langfuse_context.update_current_observation(\n",
    "            name=\"best_practices_review\",\n",
    "            metadata={\"language\": language, \"review_type\": \"best_practices\"}\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(BEST_PRACTICES_TEMPLATE)\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        result = chain.invoke({\n",
    "            \"code\": code,\n",
    "            \"language\": language\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            json_match = re.search(r'{.*}', result, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "            else:\n",
    "                return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"issues\": [], \"overall_score\": 5, \"raw_response\": result}\n",
    "    \n",
    "    @observe()\n",
    "    def comprehensive_review(self, code: str, filename: str = \"unknown\") -> Dict:\n",
    "        \"\"\"Th·ª±c hi·ªán review to√†n di·ªán code\"\"\"\n",
    "        langfuse_context.update_current_observation(\n",
    "            name=\"comprehensive_code_review\",\n",
    "            input={\"code\": code, \"filename\": filename},\n",
    "            metadata={\"filename\": filename}\n",
    "        )\n",
    "        \n",
    "        # Detect language\n",
    "        language = self.detect_language(code)\n",
    "        \n",
    "        # Perform all types of review\n",
    "        security_result = self.security_review(code, language)\n",
    "        performance_result = self.performance_review(code, language)\n",
    "        best_practices_result = self.best_practices_review(code, language)\n",
    "        \n",
    "        # Combine results\n",
    "        all_issues = []\n",
    "        all_issues.extend(security_result.get('issues', []))\n",
    "        all_issues.extend(performance_result.get('issues', []))\n",
    "        all_issues.extend(best_practices_result.get('issues', []))\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        critical_issues = len([i for i in all_issues if i.get('severity') == 'critical'])\n",
    "        high_issues = len([i for i in all_issues if i.get('severity') == 'high'])\n",
    "        medium_issues = len([i for i in all_issues if i.get('severity') == 'medium'])\n",
    "        low_issues = len([i for i in all_issues if i.get('severity') == 'low'])\n",
    "        \n",
    "        overall_score = (\n",
    "            security_result.get('overall_score', 5) +\n",
    "            performance_result.get('overall_score', 5) +\n",
    "            best_practices_result.get('overall_score', 5)\n",
    "        ) / 3\n",
    "        \n",
    "        result = {\n",
    "            \"filename\": filename,\n",
    "            \"language\": language,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"reviews\": {\n",
    "                \"security\": security_result,\n",
    "                \"performance\": performance_result,\n",
    "                \"best_practices\": best_practices_result\n",
    "            },\n",
    "            \"summary\": {\n",
    "                \"total_issues\": len(all_issues),\n",
    "                \"critical_issues\": critical_issues,\n",
    "                \"high_issues\": high_issues,\n",
    "                \"medium_issues\": medium_issues,\n",
    "                \"low_issues\": low_issues,\n",
    "                \"overall_score\": round(overall_score, 2)\n",
    "            },\n",
    "            \"all_issues\": all_issues\n",
    "        }\n",
    "        \n",
    "        langfuse_context.update_current_observation(\n",
    "            output=result,\n",
    "            metadata={\n",
    "                \"total_issues\": len(all_issues),\n",
    "                \"overall_score\": overall_score,\n",
    "                \"language\": language\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Kh·ªüi t·∫°o pipeline\n",
    "review_pipeline = CodeReviewPipeline(llm, langfuse)\n",
    "print(\"‚úÖ Code Review Pipeline ƒë√£ s·∫µn s√†ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√≠ d·ª• 1: Review Python Code c√≥ v·∫•n ƒë·ªÅ b·∫£o m·∫≠t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Python c√≥ v·∫•n ƒë·ªÅ b·∫£o m·∫≠t\n",
    "vulnerable_python_code = \"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/execute')\n",
    "def execute_command():\n",
    "    cmd = request.args.get('cmd')\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    return result.stdout\n",
    "\n",
    "@app.route('/login')\n",
    "def login():\n",
    "    username = request.args.get('username')\n",
    "    password = request.args.get('password')\n",
    "    \n",
    "    # Vulnerable SQL query\n",
    "    query = f\"SELECT * FROM users WHERE username='{username}' AND password='{password}'\"\n",
    "    \n",
    "    # Execute query (gi·∫£ l·∫≠p)\n",
    "    print(f\"Executing: {query}\")\n",
    "    return \"Login successful\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç ƒêang review code Python c√≥ v·∫•n ƒë·ªÅ b·∫£o m·∫≠t...\")\n",
    "result = review_pipeline.comprehensive_review(vulnerable_python_code, \"vulnerable_app.py\")\n",
    "\n",
    "print(f\"\\nüìä K·∫æT QU·∫¢ REVIEW:\")\n",
    "print(f\"File: {result['filename']}\")\n",
    "print(f\"Ng√¥n ng·ªØ: {result['language']}\")\n",
    "print(f\"T·ªïng s·ªë v·∫•n ƒë·ªÅ: {result['summary']['total_issues']}\")\n",
    "print(f\"ƒêi·ªÉm t·ªïng th·ªÉ: {result['summary']['overall_score']}/10\")\n",
    "print(f\"V·∫•n ƒë·ªÅ nghi√™m tr·ªçng: {result['summary']['critical_issues']}\")\n",
    "print(f\"V·∫•n ƒë·ªÅ cao: {result['summary']['high_issues']}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã m·ªôt s·ªë issues quan tr·ªçng\n",
    "print(\"\\nüö® C√ÅC V·∫§N ƒê·ªÄ QUAN TR·ªåNG:\")\n",
    "for i, issue in enumerate(result['all_issues'][:3], 1):\n",
    "    print(f\"{i}. [{issue.get('type', 'unknown')}] {issue.get('description', 'No description')}\")\n",
    "    if issue.get('suggestion'):\n",
    "        print(f\"   üí° G·ª£i √Ω: {issue['suggestion']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√≠ d·ª• 2: Review JavaScript Code c√≥ v·∫•n ƒë·ªÅ performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript code c√≥ v·∫•n ƒë·ªÅ performance\n",
    "performance_issue_js = \"\"\"\n",
    "function processLargeDataset(data) {\n",
    "    let result = [];\n",
    "    \n",
    "    // Inefficient nested loops\n",
    "    for (let i = 0; i < data.length; i++) {\n",
    "        for (let j = 0; j < data.length; j++) {\n",
    "            if (data[i].id === data[j].relatedId) {\n",
    "                result.push({\n",
    "                    item: data[i],\n",
    "                    related: data[j]\n",
    "                });\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Inefficient array operations\n",
    "    let filtered = [];\n",
    "    for (let item of result) {\n",
    "        if (item.item.active) {\n",
    "            filtered.push(item);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Inefficient sorting\n",
    "    filtered.sort((a, b) => {\n",
    "        return new Date(a.item.createdAt) - new Date(b.item.createdAt);\n",
    "    });\n",
    "    \n",
    "    return filtered;\n",
    "}\n",
    "\n",
    "// Memory leak potential\n",
    "let globalCache = {};\n",
    "function cacheData(key, data) {\n",
    "    globalCache[key] = data; // Never cleaned up\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç ƒêang review JavaScript code c√≥ v·∫•n ƒë·ªÅ performance...\")\n",
    "result = review_pipeline.comprehensive_review(performance_issue_js, \"inefficient_processor.js\")\n",
    "\n",
    "print(f\"\\nüìä K·∫æT QU·∫¢ REVIEW:\")\n",
    "print(f\"File: {result['filename']}\")\n",
    "print(f\"Ng√¥n ng·ªØ: {result['language']}\")\n",
    "print(f\"T·ªïng s·ªë v·∫•n ƒë·ªÅ: {result['summary']['total_issues']}\")\n",
    "print(f\"ƒêi·ªÉm t·ªïng th·ªÉ: {result['summary']['overall_score']}/10\")\n",
    "\n",
    "# Hi·ªÉn th·ªã performance issues\n",
    "performance_issues = [issue for issue in result['all_issues'] if issue.get('type') == 'performance']\n",
    "print(f\"\\n‚ö° V·∫§N ƒê·ªÄ PERFORMANCE ({len(performance_issues)}):\")\n",
    "for i, issue in enumerate(performance_issues, 1):\n",
    "    print(f\"{i}. {issue.get('description', 'No description')}\")\n",
    "    if issue.get('suggestion'):\n",
    "        print(f\"   üí° G·ª£i √Ω: {issue['suggestion']}\")\n",
    "    if issue.get('impact'):\n",
    "        print(f\"   üìà T√°c ƒë·ªông: {issue['impact']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√≠ d·ª• 3: Review Code v·ªõi Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code c·∫ßn c·∫£i thi·ªán best practices\n",
    "poor_practices_code = \"\"\"\n",
    "def calc(a,b,op):\n",
    "    if op==\"+\":\n",
    "        return a+b\n",
    "    elif op==\"-\":\n",
    "        return a-b\n",
    "    elif op==\"*\":\n",
    "        return a*b\n",
    "    elif op==\"/\":\n",
    "        return a/b\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_data(data):\n",
    "    result=[]\n",
    "    for item in data:\n",
    "        try:\n",
    "            val=item['value']\n",
    "            if val>0:\n",
    "                result.append(val*2)\n",
    "        except:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "# Global variables\n",
    "CONFIG={}\n",
    "TEMP_DATA=[]\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data=None\n",
    "        \n",
    "    def load_data(self,filename):\n",
    "        # No error handling\n",
    "        with open(filename) as f:\n",
    "            self.data=f.read()\n",
    "            \n",
    "    def process(self):\n",
    "        # Magic numbers\n",
    "        if len(self.data)>1000:\n",
    "            return self.data[:500]\n",
    "        return self.data\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç ƒêang review code v·ªÅ best practices...\")\n",
    "result = review_pipeline.comprehensive_review(poor_practices_code, \"poor_practices.py\")\n",
    "\n",
    "print(f\"\\nüìä K·∫æT QU·∫¢ REVIEW:\")\n",
    "print(f\"File: {result['filename']}\")\n",
    "print(f\"T·ªïng s·ªë v·∫•n ƒë·ªÅ: {result['summary']['total_issues']}\")\n",
    "print(f\"ƒêi·ªÉm t·ªïng th·ªÉ: {result['summary']['overall_score']}/10\")\n",
    "\n",
    "# Hi·ªÉn th·ªã best practice issues\n",
    "bp_issues = [issue for issue in result['all_issues'] if issue.get('type') == 'best_practice']\n",
    "print(f\"\\nüìã V·∫§N ƒê·ªÄ BEST PRACTICES ({len(bp_issues)}):\")\n",
    "for i, issue in enumerate(bp_issues, 1):\n",
    "    print(f\"{i}. [{issue.get('category', 'general')}] {issue.get('description', 'No description')}\")\n",
    "    if issue.get('suggestion'):\n",
    "        print(f\"   üí° G·ª£i √Ω: {issue['suggestion']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T√≠nh nƒÉng Feedback v√† ƒê√°nh gi√°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_review_feedback(review_id: str, feedback_data: Dict):\n",
    "    \"\"\"G·ª≠i feedback cho review ƒë·ªÉ c·∫£i thi·ªán model\"\"\"\n",
    "    langfuse.score(\n",
    "        trace_id=review_id,\n",
    "        name=\"review_quality\",\n",
    "        value=feedback_data.get(\"quality_score\", 5),\n",
    "        comment=feedback_data.get(\"comment\", \"\")\n",
    "    )\n",
    "    \n",
    "    langfuse.score(\n",
    "        trace_id=review_id,\n",
    "        name=\"review_helpfulness\",\n",
    "        value=feedback_data.get(\"helpfulness_score\", 5),\n",
    "        comment=feedback_data.get(\"helpfulness_comment\", \"\")\n",
    "    )\n",
    "    \n",
    "    langfuse.score(\n",
    "        trace_id=review_id,\n",
    "        name=\"review_accuracy\",\n",
    "        value=feedback_data.get(\"accuracy_score\", 5),\n",
    "        comment=feedback_data.get(\"accuracy_comment\", \"\")\n",
    "    )\n",
    "\n",
    "# V√≠ d·ª• submit feedback\n",
    "sample_feedback = {\n",
    "    \"quality_score\": 8,\n",
    "    \"comment\": \"Review r·∫•t chi ti·∫øt v√† c√≥ g·ª£i √Ω c·ª• th·ªÉ\",\n",
    "    \"helpfulness_score\": 9,\n",
    "    \"helpfulness_comment\": \"Gi√∫p ph√°t hi·ªán ƒë∆∞·ª£c l·ªói nghi√™m tr·ªçng\",\n",
    "    \"accuracy_score\": 7,\n",
    "    \"accuracy_comment\": \"M·ªôt v√†i g·ª£i √Ω ch∆∞a ho√†n to√†n ch√≠nh x√°c\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ T√≠nh nƒÉng feedback ƒë√£ ƒë∆∞·ª£c setup\")\n",
    "print(\"Developers c√≥ th·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng review ƒë·ªÉ c·∫£i thi·ªán model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Review Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe()\n",
    "def batch_code_review(code_files: Dict[str, str]) -> Dict:\n",
    "    \"\"\"Review multiple files c√πng l√∫c\"\"\"\n",
    "    langfuse_context.update_current_observation(\n",
    "        name=\"batch_code_review\",\n",
    "        input={\"files_count\": len(code_files)},\n",
    "        metadata={\"files\": list(code_files.keys())}\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    total_issues = 0\n",
    "    critical_issues = 0\n",
    "    \n",
    "    for filename, code in code_files.items():\n",
    "        print(f\"üîç Reviewing {filename}...\")\n",
    "        result = review_pipeline.comprehensive_review(code, filename)\n",
    "        results[filename] = result\n",
    "        \n",
    "        total_issues += result['summary']['total_issues']\n",
    "        critical_issues += result['summary']['critical_issues']\n",
    "    \n",
    "    # T·∫°o summary report\n",
    "    summary = {\n",
    "        \"total_files\": len(code_files),\n",
    "        \"total_issues\": total_issues,\n",
    "        \"critical_issues\": critical_issues,\n",
    "        \"avg_score\": sum(r['summary']['overall_score'] for r in results.values()) / len(results),\n",
    "        \"files_with_critical\": len([r for r in results.values() if r['summary']['critical_issues'] > 0])\n",
    "    }\n",
    "    \n",
    "    langfuse_context.update_current_observation(\n",
    "        output=summary,\n",
    "        metadata=summary\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "# V√≠ d·ª• batch review\n",
    "sample_codebase = {\n",
    "    \"auth.py\": \"\"\"\n",
    "def authenticate(username, password):\n",
    "    # Vulnerable password check\n",
    "    if password == \"admin123\":\n",
    "        return True\n",
    "    return False\n",
    "\"\"\",\n",
    "    \"utils.py\": \"\"\"\n",
    "def slow_search(data, target):\n",
    "    # O(n¬≤) search\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            if data[i] == target:\n",
    "                return i\n",
    "    return -1\n",
    "\"\"\",\n",
    "    \"config.py\": \"\"\"\n",
    "DATABASE_URL=\"postgresql://user:pass@localhost/db\"\n",
    "API_KEY=\"sk-1234567890abcdef\"\n",
    "DEBUG=True\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"üîç B·∫Øt ƒë·∫ßu batch review...\")\n",
    "batch_results = batch_code_review(sample_codebase)\n",
    "\n",
    "print(f\"\\nüìä BATCH REVIEW SUMMARY:\")\n",
    "print(f\"T·ªïng s·ªë files: {batch_results['summary']['total_files']}\")\n",
    "print(f\"T·ªïng s·ªë v·∫•n ƒë·ªÅ: {batch_results['summary']['total_issues']}\")\n",
    "print(f\"V·∫•n ƒë·ªÅ nghi√™m tr·ªçng: {batch_results['summary']['critical_issues']}\")\n",
    "print(f\"ƒêi·ªÉm trung b√¨nh: {batch_results['summary']['avg_score']:.2f}/10\")\n",
    "print(f\"Files c√≥ v·∫•n ƒë·ªÅ nghi√™m tr·ªçng: {batch_results['summary']['files_with_critical']}\")\n",
    "\n",
    "# Top issues across all files\n",
    "all_issues = []\n",
    "for filename, result in batch_results['results'].items():\n",
    "    for issue in result['all_issues']:\n",
    "        issue['filename'] = filename\n",
    "        all_issues.append(issue)\n",
    "\n",
    "# Sort by severity\n",
    "severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}\n",
    "all_issues.sort(key=lambda x: severity_order.get(x.get('severity', 'low'), 3))\n",
    "\n",
    "print(f\"\\nüö® TOP 5 ISSUES NGHI√äM TR·ªåNG NH·∫§T:\")\n",
    "for i, issue in enumerate(all_issues[:5], 1):\n",
    "    print(f\"{i}. [{issue['filename']}] {issue.get('description', 'No description')}\")\n",
    "    print(f\"   M·ª©c ƒë·ªô: {issue.get('severity', 'unknown')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics v√† Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_review_metrics():\n",
    "    \"\"\"Ph√¢n t√≠ch metrics t·ª´ LangFuse ƒë·ªÉ c·∫£i thi·ªán review quality\"\"\"\n",
    "    \n",
    "    print(\"üìà ANALYTICS DASHBOARD:\")\n",
    "    print(\"\\nüéØ ƒê·ªÉ xem chi ti·∫øt analytics:\")\n",
    "    print(\"1. Truy c·∫≠p LangFuse Dashboard: http://localhost:3000\")\n",
    "    print(\"2. Xem Traces tab ƒë·ªÉ theo d√µi t·ª´ng review session\")\n",
    "    print(\"3. Xem Scores tab ƒë·ªÉ ph√¢n t√≠ch feedback\")\n",
    "    print(\"4. S·ª≠ d·ª•ng Playground ƒë·ªÉ test v√† optimize prompts\")\n",
    "    \n",
    "    print(\"\\nüìä Key Metrics c·∫ßn theo d√µi:\")\n",
    "    metrics = {\n",
    "        \"Review Quality Score\": \"ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ c·ªßa review\",\n",
    "        \"Accuracy Score\": \"ƒê·ªô ch√≠nh x√°c c·ªßa vi·ªác ph√°t hi·ªán issues\", \n",
    "        \"Helpfulness Score\": \"M·ª©c ƒë·ªô h·ªØu √≠ch c·ªßa g·ª£i √Ω\",\n",
    "        \"Response Time\": \"Th·ªùi gian x·ª≠ l√Ω review\",\n",
    "        \"Issues Detection Rate\": \"T·ª∑ l·ªá ph√°t hi·ªán issues th·ª±c t·∫ø\",\n",
    "        \"False Positive Rate\": \"T·ª∑ l·ªá b√°o sai issues\"\n",
    "    }\n",
    "    \n",
    "    for metric, description in metrics.items():\n",
    "        print(f\"‚Ä¢ {metric}: {description}\")\n",
    "    \n",
    "    print(\"\\nüîß Optimization Strategies:\")\n",
    "    strategies = [\n",
    "        \"A/B test c√°c prompt templates kh√°c nhau\",\n",
    "        \"Fine-tune model d·ª±a tr√™n feedback\", \n",
    "        \"T·ªëi ∆∞u h√≥a prompt cho t·ª´ng lo·∫°i code (language-specific)\",\n",
    "        \"Implement rule-based post-processing ƒë·ªÉ filter false positives\",\n",
    "        \"S·ª≠ d·ª•ng ensemble c·ªßa multiple models\"\n",
    "    ]\n",
    "    \n",
    "    for i, strategy in enumerate(strategies, 1):\n",
    "        print(f\"{i}. {strategy}\")\n",
    "\n",
    "analyze_review_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Deployment Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√≠ d·ª• integration v·ªõi CI/CD pipeline\n",
    "cicd_integration_example = \"\"\"\n",
    "# .github/workflows/code-review.yml\n",
    "name: AI Code Review\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    types: [opened, synchronize]\n",
    "\n",
    "jobs:\n",
    "  ai-review:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.9'\n",
    "          \n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install langfuse langchain-anthropic\n",
    "          \n",
    "      - name: Run AI Code Review\n",
    "        env:\n",
    "          LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}\n",
    "          LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}\n",
    "          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n",
    "        run: |\n",
    "          python scripts/ai_code_review.py --pr-number ${{ github.event.number }}\n",
    "          \n",
    "      - name: Comment PR\n",
    "        uses: actions/github-script@v6\n",
    "        with:\n",
    "          script: |\n",
    "            const fs = require('fs');\n",
    "            const review = fs.readFileSync('review_results.json', 'utf8');\n",
    "            const data = JSON.parse(review);\n",
    "            \n",
    "            let comment = '## ü§ñ AI Code Review\\n\\n';\n",
    "            comment += `**Overall Score**: ${data.overall_score}/10\\n`;\n",
    "            comment += `**Total Issues**: ${data.total_issues}\\n\\n`;\n",
    "            \n",
    "            if (data.critical_issues > 0) {\n",
    "              comment += 'üö® **Critical Issues Found**\\n\\n';\n",
    "            }\n",
    "            \n",
    "            github.rest.issues.createComment({\n",
    "              issue_number: context.issue.number,\n",
    "              owner: context.repo.owner,\n",
    "              repo: context.repo.repo,\n",
    "              body: comment\n",
    "            });\n",
    "\"\"\"\n",
    "\n",
    "print(\"üöÄ PRODUCTION DEPLOYMENT PATTERNS:\")\n",
    "print(\"\\n1. üîÑ CI/CD Integration:\")\n",
    "print(\"   ‚Ä¢ T·ª± ƒë·ªông review m·ªói Pull Request\")\n",
    "print(\"   ‚Ä¢ Comment k·∫øt qu·∫£ tr·ª±c ti·∫øp tr√™n PR\")\n",
    "print(\"   ‚Ä¢ Block merge n·∫øu c√≥ critical issues\")\n",
    "\n",
    "print(\"\\n2. üìä Monitoring & Alerts:\")\n",
    "print(\"   ‚Ä¢ Setup alerts khi review quality gi·∫£m\")\n",
    "print(\"   ‚Ä¢ Monitor API usage v√† costs\")\n",
    "print(\"   ‚Ä¢ Track false positive rates\")\n",
    "\n",
    "print(\"\\n3. üîß Configuration Management:\")\n",
    "print(\"   ‚Ä¢ Environment-specific prompts\")\n",
    "print(\"   ‚Ä¢ Language-specific review rules\")\n",
    "print(\"   ‚Ä¢ Team-specific coding standards\")\n",
    "\n",
    "print(\"\\n4. üõ°Ô∏è Security & Compliance:\")\n",
    "print(\"   ‚Ä¢ Ensure code kh√¥ng ƒë∆∞·ª£c g·ª≠i ra external services\")\n",
    "print(\"   ‚Ä¢ Implement rate limiting\")\n",
    "print(\"   ‚Ä¢ Audit logs cho all review activities\")\n",
    "\n",
    "with open('/tmp/example_cicd.yml', 'w') as f:\n",
    "    f.write(cicd_integration_example)\n",
    "    \n",
    "print(\"\\n‚úÖ Example CI/CD config ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i /tmp/example_cicd.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T√†i li·ªáu Tham kh·∫£o\n",
    "\n",
    "### LangFuse Documentation\n",
    "- **Tracing & Observability**: https://langfuse.com/docs/tracing\n",
    "- **Prompt Management**: https://langfuse.com/docs/prompts\n",
    "- **Evaluation & Scoring**: https://langfuse.com/docs/scores\n",
    "- **Python Integration**: https://langfuse.com/docs/integrations/langchain\n",
    "- **Dashboard & Analytics**: https://langfuse.com/docs/analytics\n",
    "\n",
    "### Best Practices\n",
    "- **Production Deployment**: https://langfuse.com/docs/deployment\n",
    "- **Security Guidelines**: https://langfuse.com/docs/data-security-privacy\n",
    "- **Performance Optimization**: https://langfuse.com/docs/performance\n",
    "\n",
    "### Code Review Resources\n",
    "- **OWASP Code Review Guide**: https://owasp.org/www-project-code-review-guide/\n",
    "- **Google Code Review Guidelines**: https://google.github.io/eng-practices/review/\n",
    "- **Static Analysis Tools**: SonarQube, CodeClimate, ESLint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n & B∆∞·ªõc ti·∫øp theo\n",
    "\n",
    "### Nh·ªØng g√¨ ƒë√£ h·ªçc ƒë∆∞·ª£c:\n",
    "1. **Thi·∫øt k·∫ø Code Review Pipeline** v·ªõi LangFuse ƒë·ªÉ theo d√µi ch·∫•t l∆∞·ª£ng\n",
    "2. **Implement Multi-aspect Review** (security, performance, best practices)\n",
    "3. **Batch Processing** cho multiple files\n",
    "4. **Feedback Loop** ƒë·ªÉ c·∫£i thi·ªán model li√™n t·ª•c\n",
    "5. **Production Deployment** patterns v√† CI/CD integration\n",
    "\n",
    "### B∆∞·ªõc ti·∫øp theo:\n",
    "1. **Customize Prompts** cho specific domains/languages\n",
    "2. **Implement Rule-based Post-processing** ƒë·ªÉ gi·∫£m false positives\n",
    "3. **Integrate v·ªõi IDE** (VS Code extension, IntelliJ plugin)\n",
    "4. **Setup A/B Testing** cho different prompt strategies\n",
    "5. **Build Knowledge Base** t·ª´ historical review data\n",
    "6. **Implement Real-time Review** trong development workflow\n",
    "\n",
    "### Advanced Features:\n",
    "- **Multi-model Ensemble** (combine multiple LLMs)\n",
    "- **Context-aware Review** (understand project architecture)\n",
    "- **Learning from Fixes** (track how developers fix reported issues)\n",
    "- **Team-specific Customization** (different standards for different teams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}