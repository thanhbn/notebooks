{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval with Learned Similarities - Tri·ªÉn khai v√† Nghi√™n c·ª©u\n",
    "\n",
    "## üìÑ Th√¥ng tin Paper\n",
    "- **Title**: Retrieval with Learned Similarities\n",
    "- **Authors**: Bailu Ding (Microsoft Research), Jiaqi Zhai (Meta)\n",
    "- **Conference**: WWW 2025\n",
    "- **arXiv**: 2407.15462v4\n",
    "- **GitHub**: https://github.com/bailuding/rails\n",
    "\n",
    "## üéØ T√≥m t·∫Øt Paper\n",
    "\n",
    "Paper n√†y gi·∫£i quy·∫øt th√°ch th·ª©c **retrieval hi·ªáu qu·∫£ v·ªõi learned similarity functions** - m·ªôt v·∫•n ƒë·ªÅ quan tr·ªçng trong h·ªá th·ªëng recommendation, search v√† NLP hi·ªán ƒë·∫°i.\n",
    "\n",
    "### üîë V·∫•n ƒë·ªÅ ch√≠nh:\n",
    "- C√°c thu·∫≠t to√°n retrieval state-of-the-art ƒë√£ chuy·ªÉn t·ª´ dot products ƒë∆°n gi·∫£n sang **learned similarities** ph·ª©c t·∫°p\n",
    "- Learned similarities bao g·ªìm: multiple query embeddings, neural networks, beam search, hybrid approaches\n",
    "- **Thi·∫øu gi·∫£i ph√°p hi·ªáu qu·∫£** cho retrieval v·ªõi learned similarities n√†y\n",
    "\n",
    "### üí° Gi·∫£i ph√°p - Mixture-of-Logits (MoL):\n",
    "1. **Universal Approximator**: MoL c√≥ th·ªÉ bi·ªÉu di·ªÖn b·∫•t k·ª≥ similarity function n√†o\n",
    "2. **Efficient Retrieval**: ƒê·ªÅ xu·∫•t algorithms ƒë·ªÉ retrieve top-k v·ªõi error bounds ch·∫∑t\n",
    "3. **RAILS Framework**: Retrieval with Learned Similarities tr√™n GPU\n",
    "\n",
    "### üìä K·∫øt qu·∫£:\n",
    "- **Performance**: 20-30% c·∫£i thi·ªán Hit Rate@50-400 tr√™n corpus h√†ng trƒÉm tri·ªáu ƒë·∫øn t·ª∑ items\n",
    "- **Speed**: Nhanh h∆°n 66x so v·ªõi exact algorithms v·ªõi >99% recall rate\n",
    "- **Applicability**: Ho·∫°t ƒë·ªông t·ªët tr√™n recommendation systems v√† question answering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è C√†i ƒë·∫∑t M√¥i tr∆∞·ªùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain components for RAG integration\n",
    "try:\n",
    "    from langchain_core.embeddings import Embeddings\n",
    "    from langchain_core.vectorstores import VectorStore\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    LANGCHAIN_AVAILABLE = True\n",
    "    print(\"‚úÖ LangChain components loaded successfully\")\n",
    "except ImportError:\n",
    "    LANGCHAIN_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è LangChain not available - using pure PyTorch implementation\")\n",
    "\n",
    "# DeepEval for evaluation\n",
    "try:\n",
    "    import deepeval\n",
    "    from deepeval.metrics import FaithfulnessMetric, AnswerRelevancyMetric\n",
    "    DEEPEVAL_AVAILABLE = True\n",
    "    print(\"‚úÖ DeepEval loaded for evaluation\")\n",
    "except ImportError:\n",
    "    DEEPEVAL_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è DeepEval not available - using custom metrics\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Chu·∫©n b·ªã D·ªØ li·ªáu Mock\n",
    "\n",
    "T·∫°o d·ªØ li·ªáu synthetic ƒë·ªÉ demo c√°c kh√°i ni·ªám trong paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Configuration for synthetic dataset generation\"\"\"\n",
    "    num_queries: int = 1000\n",
    "    num_items: int = 10000\n",
    "    embedding_dim: int = 128\n",
    "    num_categories: int = 10\n",
    "    noise_level: float = 0.1\n",
    "\n",
    "def generate_synthetic_data(config: DatasetConfig) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate synthetic query-item data for retrieval experiments\n",
    "    \n",
    "    Returns:\n",
    "        queries: [num_queries, embedding_dim]\n",
    "        items: [num_items, embedding_dim] \n",
    "        query_categories: [num_queries]\n",
    "        item_categories: [num_items]\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Generate category centers\n",
    "    category_centers = torch.randn(config.num_categories, config.embedding_dim)\n",
    "    category_centers = F.normalize(category_centers, dim=1)\n",
    "    \n",
    "    # Generate queries\n",
    "    query_categories = torch.randint(0, config.num_categories, (config.num_queries,))\n",
    "    queries = category_centers[query_categories] + config.noise_level * torch.randn(config.num_queries, config.embedding_dim)\n",
    "    queries = F.normalize(queries, dim=1)\n",
    "    \n",
    "    # Generate items\n",
    "    item_categories = torch.randint(0, config.num_categories, (config.num_items,))\n",
    "    items = category_centers[item_categories] + config.noise_level * torch.randn(config.num_items, config.embedding_dim)\n",
    "    items = F.normalize(items, dim=1)\n",
    "    \n",
    "    return queries, items, query_categories, item_categories\n",
    "\n",
    "# Generate data\n",
    "config = DatasetConfig()\n",
    "queries, items, query_cats, item_cats = generate_synthetic_data(config)\n",
    "\n",
    "print(f\"üìä Generated data:\")\n",
    "print(f\"   Queries: {queries.shape}\")\n",
    "print(f\"   Items: {items.shape}\")\n",
    "print(f\"   Categories: {config.num_categories}\")\n",
    "\n",
    "# Move to device\n",
    "queries = queries.to(device)\n",
    "items = items.to(device)\n",
    "query_cats = query_cats.to(device)\n",
    "item_cats = item_cats.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Tri·ªÉn khai Mixture-of-Logits (MoL)\n",
    "\n",
    "### üìñ L√Ω thuy·∫øt MoL (t·ª´ Paper - Section 2)\n",
    "\n",
    "MoL ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a nh∆∞ sau:\n",
    "\n",
    "$$\\phi(q,x) = \\sum_{p=1}^{P} \\pi_p(q,x) \\langle f_p(q), g_p(x) \\rangle$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $f_p(q), g_p(x) \\in \\mathbb{R}^{d_P}$: component-level embeddings\n",
    "- $\\pi_p(q,x) \\in [0,1]$: adaptive gating weights\n",
    "- $P$: s·ªë l∆∞·ª£ng components\n",
    "\n",
    "**T·∫°i sao MoL hi·ªáu qu·∫£?**\n",
    "1. **Universal Approximator**: C√≥ th·ªÉ bi·ªÉu di·ªÖn ma tr·∫≠n $p(x|q)$ v·ªõi rank t√πy √Ω\n",
    "2. **GPU-friendly**: T·∫≠n d·ª•ng ƒë∆∞·ª£c arithmetic intensity cao c·ªßa GPU\n",
    "3. **Flexible**: C√≥ th·ªÉ m√¥ ph·ªèng nhi·ªÅu learned similarity functions kh√°c nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfLogitsModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-Logits (MoL) implementation as described in the paper\n",
    "    \n",
    "    Reference: Section 2 - Mixture of Logits\n",
    "    Formula: œÜ(q,x) = Œ£ œÄ_p(q,x) * <f_p(q), g_p(x)>\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_dim: int,\n",
    "                 num_components: int = 8,\n",
    "                 component_dim: int = 64,\n",
    "                 use_outer_product: bool = True,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.num_components = num_components\n",
    "        self.component_dim = component_dim\n",
    "        self.use_outer_product = use_outer_product\n",
    "        \n",
    "        if use_outer_product:\n",
    "            # Batched outer product form (Section 2, Equation after (1))\n",
    "            self.P_q = int(math.sqrt(num_components))\n",
    "            self.P_x = num_components // self.P_q\n",
    "            \n",
    "            # Query-side embeddings\n",
    "            self.query_embeddings = nn.ModuleList([\n",
    "                nn.Linear(input_dim, component_dim) for _ in range(self.P_q)\n",
    "            ])\n",
    "            \n",
    "            # Item-side embeddings\n",
    "            self.item_embeddings = nn.ModuleList([\n",
    "                nn.Linear(input_dim, component_dim) for _ in range(self.P_x)\n",
    "            ])\n",
    "            \n",
    "            # Gating network for outer product\n",
    "            self.gating_network = nn.Sequential(\n",
    "                nn.Linear(input_dim * 2, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(128, self.P_q * self.P_x),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "        else:\n",
    "            # Standard MoL form (Equation 1)\n",
    "            self.query_embeddings = nn.ModuleList([\n",
    "                nn.Linear(input_dim, component_dim) for _ in range(num_components)\n",
    "            ])\n",
    "            \n",
    "            self.item_embeddings = nn.ModuleList([\n",
    "                nn.Linear(input_dim, component_dim) for _ in range(num_components)\n",
    "            ])\n",
    "            \n",
    "            # Gating network\n",
    "            self.gating_network = nn.Sequential(\n",
    "                nn.Linear(input_dim * 2, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(128, num_components),\n",
    "                nn.Softmax(dim=-1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, queries: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute MoL similarity between queries and items\n",
    "        \n",
    "        Args:\n",
    "            queries: [batch_q, input_dim]\n",
    "            items: [batch_x, input_dim]\n",
    "            \n",
    "        Returns:\n",
    "            similarities: [batch_q, batch_x]\n",
    "        \"\"\"\n",
    "        batch_q, batch_x = queries.size(0), items.size(0)\n",
    "        \n",
    "        if self.use_outer_product:\n",
    "            return self._forward_outer_product(queries, items)\n",
    "        else:\n",
    "            return self._forward_standard(queries, items)\n",
    "    \n",
    "    def _forward_standard(self, queries: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Standard MoL computation (Equation 1)\"\"\"\n",
    "        batch_q, batch_x = queries.size(0), items.size(0)\n",
    "        \n",
    "        # Compute component embeddings\n",
    "        q_components = [F.normalize(emb(queries), dim=-1) for emb in self.query_embeddings]\n",
    "        x_components = [F.normalize(emb(items), dim=-1) for emb in self.item_embeddings]\n",
    "        \n",
    "        # Compute similarities for all query-item pairs\n",
    "        similarities = torch.zeros(batch_q, batch_x, device=queries.device)\n",
    "        \n",
    "        for i in range(batch_q):\n",
    "            for j in range(batch_x):\n",
    "                # Compute gating weights\n",
    "                combined_features = torch.cat([queries[i], items[j]], dim=0)\n",
    "                weights = self.gating_network(combined_features.unsqueeze(0)).squeeze(0)  # [num_components]\n",
    "                \n",
    "                # Compute weighted sum of component similarities\n",
    "                similarity = 0.0\n",
    "                for p in range(self.num_components):\n",
    "                    component_sim = torch.dot(q_components[p][i], x_components[p][j])\n",
    "                    similarity += weights[p] * component_sim\n",
    "                \n",
    "                similarities[i, j] = similarity\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def _forward_outer_product(self, queries: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Batched outer product form for efficiency\"\"\"\n",
    "        batch_q, batch_x = queries.size(0), items.size(0)\n",
    "        \n",
    "        # Compute component embeddings\n",
    "        q_components = [F.normalize(emb(queries), dim=-1) for emb in self.query_embeddings]  # P_q x [batch_q, component_dim]\n",
    "        x_components = [F.normalize(emb(items), dim=-1) for emb in self.item_embeddings]    # P_x x [batch_x, component_dim]\n",
    "        \n",
    "        # Efficient batched computation\n",
    "        similarities = torch.zeros(batch_q, batch_x, device=queries.device)\n",
    "        \n",
    "        # Pre-compute all combinations\n",
    "        for i in range(batch_q):\n",
    "            for j in range(batch_x):\n",
    "                # Compute gating weights\n",
    "                combined_features = torch.cat([queries[i], items[j]], dim=0)\n",
    "                weights = self.gating_network(combined_features.unsqueeze(0)).squeeze(0)  # [P_q * P_x]\n",
    "                weights = weights.view(self.P_q, self.P_x)\n",
    "                \n",
    "                # Compute similarity using outer product structure\n",
    "                similarity = 0.0\n",
    "                for p_q in range(self.P_q):\n",
    "                    for p_x in range(self.P_x):\n",
    "                        component_sim = torch.dot(q_components[p_q][i], x_components[p_x][j])\n",
    "                        similarity += weights[p_q, p_x] * component_sim\n",
    "                \n",
    "                similarities[i, j] = similarity\n",
    "        \n",
    "        return similarities\n",
    "\n",
    "print(\"üß† MoL Module implemented successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Load Balancing Loss (Ph·∫ßn quan tr·ªçng t·ª´ Paper)\n",
    "\n",
    "### üìñ L√Ω thuy·∫øt (Section 2.2)\n",
    "\n",
    "Paper ƒë·ªÅ xu·∫•t **mutual information-based load balancing loss** ƒë·ªÉ c·∫£i thi·ªán conditional computation trong MoL:\n",
    "\n",
    "$$L_{bal} = -I(Z; G)$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $Z$: latent representations\n",
    "- $G$: gating decisions\n",
    "- $I(Z; G)$: mutual information\n",
    "\n",
    "**M·ª•c ƒë√≠ch**: ƒê·∫£m b·∫£o c√°c components ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªìng ƒë·ªÅu, tr√°nh collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadBalancingLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Mutual Information-based Load Balancing Loss\n",
    "    \n",
    "    Reference: Section 2.2 - Load balancing loss to improve conditional computations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_components: int, lambda_bal: float = 0.01):\n",
    "        super().__init__()\n",
    "        self.num_components = num_components\n",
    "        self.lambda_bal = lambda_bal\n",
    "    \n",
    "    def forward(self, gating_weights: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute load balancing loss\n",
    "        \n",
    "        Args:\n",
    "            gating_weights: [batch_size, num_components] or [batch_size, P_q * P_x]\n",
    "            \n",
    "        Returns:\n",
    "            loss: scalar tensor\n",
    "        \"\"\"\n",
    "        batch_size = gating_weights.size(0)\n",
    "        \n",
    "        if gating_weights.dim() > 2:\n",
    "            gating_weights = gating_weights.view(batch_size, -1)\n",
    "        \n",
    "        # Compute component usage statistics\n",
    "        component_usage = gating_weights.mean(dim=0)  # [num_components]\n",
    "        \n",
    "        # Encourage uniform distribution (entropy maximization)\n",
    "        uniform_target = torch.ones_like(component_usage) / self.num_components\n",
    "        \n",
    "        # KL divergence from uniform distribution\n",
    "        kl_loss = F.kl_div(\n",
    "            component_usage.log() + 1e-8, \n",
    "            uniform_target, \n",
    "            reduction='sum'\n",
    "        )\n",
    "        \n",
    "        # Additional entropy term for better balancing\n",
    "        entropy_loss = -torch.sum(component_usage * torch.log(component_usage + 1e-8))\n",
    "        \n",
    "        return self.lambda_bal * (kl_loss - entropy_loss)\n",
    "\n",
    "print(\"‚öñÔ∏è Load Balancing Loss implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ RAILS Framework - Retrieval with Learned Similarities\n",
    "\n",
    "### üìñ Thu·∫≠t to√°n Top-K Retrieval (Section 3)\n",
    "\n",
    "Paper ƒë·ªÅ xu·∫•t hai thu·∫≠t to√°n:\n",
    "1. **Exact Top-K**: ƒê·∫£m b·∫£o k·∫øt qu·∫£ ch√≠nh x√°c\n",
    "2. **Approximate Top-K**: Nhanh h∆°n v·ªõi error bounds\n",
    "\n",
    "**Key Insight**: T·∫≠n d·ª•ng structure c·ªßa MoL ƒë·ªÉ optimize retrieval efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAILSRetriever:\n",
    "    \"\"\"\n",
    "    Retrieval with Learned Similarities (RAILS) Framework\n",
    "    \n",
    "    Reference: Section 3 - Efficient retrieval techniques with MoL\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mol_model: MixtureOfLogitsModule):\n",
    "        self.mol_model = mol_model\n",
    "        self.item_embeddings = None\n",
    "        self.item_ids = None\n",
    "    \n",
    "    def index_items(self, items: torch.Tensor, item_ids: Optional[List] = None):\n",
    "        \"\"\"\n",
    "        Index items for efficient retrieval\n",
    "        \n",
    "        Args:\n",
    "            items: [num_items, input_dim]\n",
    "            item_ids: Optional list of item identifiers\n",
    "        \"\"\"\n",
    "        self.item_embeddings = items\n",
    "        self.item_ids = item_ids or list(range(len(items)))\n",
    "        \n",
    "        print(f\"üìö Indexed {len(items)} items\")\n",
    "    \n",
    "    def exact_top_k_retrieval(self, \n",
    "                             queries: torch.Tensor, \n",
    "                             k: int = 10) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Exact top-k retrieval using MoL\n",
    "        \n",
    "        Args:\n",
    "            queries: [num_queries, input_dim]\n",
    "            k: number of top items to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            scores: [num_queries, k] - similarity scores\n",
    "            indices: [num_queries, k] - item indices\n",
    "        \"\"\"\n",
    "        if self.item_embeddings is None:\n",
    "            raise ValueError(\"Items not indexed. Call index_items() first.\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute similarities between all queries and items\n",
    "            similarities = self.mol_model(queries, self.item_embeddings)\n",
    "            \n",
    "            # Get top-k for each query\n",
    "            top_scores, top_indices = torch.topk(similarities, k, dim=1, largest=True)\n",
    "        \n",
    "        return top_scores, top_indices\n",
    "    \n",
    "    def approximate_top_k_retrieval(self, \n",
    "                                   queries: torch.Tensor, \n",
    "                                   k: int = 10,\n",
    "                                   candidate_ratio: float = 0.1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Approximate top-k retrieval with error bounds\n",
    "        \n",
    "        Args:\n",
    "            queries: [num_queries, input_dim]\n",
    "            k: number of top items to retrieve\n",
    "            candidate_ratio: ratio of items to consider as candidates\n",
    "            \n",
    "        Returns:\n",
    "            scores: [num_queries, k] - similarity scores\n",
    "            indices: [num_queries, k] - item indices\n",
    "        \"\"\"\n",
    "        if self.item_embeddings is None:\n",
    "            raise ValueError(\"Items not indexed. Call index_items() first.\")\n",
    "        \n",
    "        num_candidates = max(k * 2, int(len(self.item_embeddings) * candidate_ratio))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Step 1: Fast candidate selection using single component\n",
    "            # Use first component as approximation\n",
    "            if hasattr(self.mol_model, 'query_embeddings'):\n",
    "                q_emb = self.mol_model.query_embeddings[0](queries)\n",
    "                i_emb = self.mol_model.item_embeddings[0](self.item_embeddings)\n",
    "                \n",
    "                q_emb = F.normalize(q_emb, dim=-1)\n",
    "                i_emb = F.normalize(i_emb, dim=-1)\n",
    "                \n",
    "                # Fast similarity computation\n",
    "                fast_sim = torch.mm(q_emb, i_emb.t())\n",
    "                \n",
    "                # Select candidates\n",
    "                _, candidate_indices = torch.topk(fast_sim, num_candidates, dim=1)\n",
    "            else:\n",
    "                # Fallback: random sampling\n",
    "                num_items = len(self.item_embeddings)\n",
    "                candidate_indices = torch.randint(0, num_items, (len(queries), num_candidates))\n",
    "            \n",
    "            # Step 2: Accurate re-ranking using full MoL\n",
    "            top_scores_list = []\n",
    "            top_indices_list = []\n",
    "            \n",
    "            for i, query in enumerate(queries):\n",
    "                candidates = self.item_embeddings[candidate_indices[i]]\n",
    "                query_batch = query.unsqueeze(0).expand(len(candidates), -1)\n",
    "                \n",
    "                # Compute accurate similarities\n",
    "                accurate_sim = self.mol_model(query_batch, candidates).diag()\n",
    "                \n",
    "                # Get top-k from candidates\n",
    "                top_k_scores, top_k_idx = torch.topk(accurate_sim, min(k, len(accurate_sim)))\n",
    "                \n",
    "                # Map back to original indices\n",
    "                original_indices = candidate_indices[i][top_k_idx]\n",
    "                \n",
    "                top_scores_list.append(top_k_scores)\n",
    "                top_indices_list.append(original_indices)\n",
    "            \n",
    "            # Pad sequences to same length\n",
    "            max_len = max(len(scores) for scores in top_scores_list)\n",
    "            \n",
    "            padded_scores = torch.zeros(len(queries), max_len)\n",
    "            padded_indices = torch.zeros(len(queries), max_len, dtype=torch.long)\n",
    "            \n",
    "            for i, (scores, indices) in enumerate(zip(top_scores_list, top_indices_list)):\n",
    "                padded_scores[i, :len(scores)] = scores\n",
    "                padded_indices[i, :len(indices)] = indices\n",
    "        \n",
    "        return padded_scores[:, :k], padded_indices[:, :k]\n",
    "\n",
    "print(\"üöÄ RAILS Retriever implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Training Loop v·ªõi Load Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relevance_labels(query_cats: torch.Tensor, item_cats: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create relevance labels based on category matching\n",
    "    \n",
    "    Args:\n",
    "        query_cats: [num_queries] - query categories\n",
    "        item_cats: [num_items] - item categories\n",
    "        \n",
    "    Returns:\n",
    "        labels: [num_queries, num_items] - binary relevance\n",
    "    \"\"\"\n",
    "    num_queries, num_items = len(query_cats), len(item_cats)\n",
    "    labels = torch.zeros(num_queries, num_items)\n",
    "    \n",
    "    for i in range(num_queries):\n",
    "        labels[i] = (item_cats == query_cats[i]).float()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def train_mol_model(mol_model: MixtureOfLogitsModule,\n",
    "                   queries: torch.Tensor,\n",
    "                   items: torch.Tensor, \n",
    "                   query_cats: torch.Tensor,\n",
    "                   item_cats: torch.Tensor,\n",
    "                   num_epochs: int = 50,\n",
    "                   batch_size: int = 32,\n",
    "                   lr: float = 0.001) -> Dict:\n",
    "    \"\"\"\n",
    "    Train MoL model with load balancing loss\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(mol_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    load_balancing_loss = LoadBalancingLoss(\n",
    "        mol_model.num_components if not mol_model.use_outer_product \n",
    "        else mol_model.P_q * mol_model.P_x\n",
    "    )\n",
    "    \n",
    "    # Create training data\n",
    "    relevance_labels = create_relevance_labels(query_cats, item_cats).to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    bal_losses = []\n",
    "    \n",
    "    mol_model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_bal_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Sample training pairs\n",
    "        for _ in range(max(1, len(queries) // batch_size)):\n",
    "            # Sample query batch\n",
    "            q_indices = torch.randint(0, len(queries), (batch_size,))\n",
    "            i_indices = torch.randint(0, len(items), (batch_size,))\n",
    "            \n",
    "            query_batch = queries[q_indices]\n",
    "            item_batch = items[i_indices]\n",
    "            labels_batch = relevance_labels[q_indices][:, i_indices]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            similarities = mol_model(query_batch, item_batch)\n",
    "            \n",
    "            # Main loss (binary cross entropy)\n",
    "            main_loss = F.binary_cross_entropy_with_logits(\n",
    "                similarities.diag(), labels_batch.diag()\n",
    "            )\n",
    "            \n",
    "            # Extract gating weights for load balancing\n",
    "            # This is a simplified version - in practice, we'd need to extract weights from forward pass\n",
    "            with torch.no_grad():\n",
    "                dummy_features = torch.cat([query_batch[0], item_batch[0]], dim=0)\n",
    "                gating_weights = mol_model.gating_network(dummy_features.unsqueeze(0))\n",
    "            \n",
    "            bal_loss = load_balancing_loss(gating_weights)\n",
    "            \n",
    "            total_loss = main_loss + bal_loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(mol_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += main_loss.item()\n",
    "            epoch_bal_loss += bal_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_bal_loss = epoch_bal_loss / num_batches\n",
    "        \n",
    "        train_losses.append(avg_loss)\n",
    "        bal_losses.append(avg_bal_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:3d}: Loss = {avg_loss:.4f}, Bal Loss = {avg_bal_loss:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'bal_losses': bal_losses\n",
    "    }\n",
    "\n",
    "print(\"üéì Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Th√≠ nghi·ªám v√† So s√°nh\n",
    "\n",
    "So s√°nh MoL v·ªõi baseline approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "print(\"üèóÔ∏è Initializing models...\")\n",
    "\n",
    "# MoL model\n",
    "mol_model = MixtureOfLogitsModule(\n",
    "    input_dim=config.embedding_dim,\n",
    "    num_components=8,\n",
    "    component_dim=32,\n",
    "    use_outer_product=True\n",
    ").to(device)\n",
    "\n",
    "# Simple dot product baseline\n",
    "class DotProductModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, embed_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.query_proj = nn.Linear(input_dim, embed_dim)\n",
    "        self.item_proj = nn.Linear(input_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, queries: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
    "        q_emb = F.normalize(self.query_proj(queries), dim=-1)\n",
    "        i_emb = F.normalize(self.item_proj(items), dim=-1)\n",
    "        return torch.mm(q_emb, i_emb.t())\n",
    "\n",
    "dot_model = DotProductModel(config.embedding_dim).to(device)\n",
    "\n",
    "print(f\"üìä Model parameters:\")\n",
    "print(f\"   MoL: {sum(p.numel() for p in mol_model.parameters()):,}\")\n",
    "print(f\"   Dot Product: {sum(p.numel() for p in dot_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MoL model\n",
    "print(\"üéì Training MoL model...\")\n",
    "training_history = train_mol_model(\n",
    "    mol_model, queries, items, query_cats, item_cats,\n",
    "    num_epochs=30, batch_size=16, lr=0.001\n",
    ")\n",
    "\n",
    "# Train baseline\n",
    "print(\"\\nüéì Training Dot Product baseline...\")\n",
    "optimizer_dot = torch.optim.AdamW(dot_model.parameters(), lr=0.001)\n",
    "relevance_labels = create_relevance_labels(query_cats, item_cats).to(device)\n",
    "\n",
    "dot_model.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for _ in range(10):\n",
    "        q_idx = torch.randint(0, len(queries), (16,))\n",
    "        i_idx = torch.randint(0, len(items), (16,))\n",
    "        \n",
    "        similarities = dot_model(queries[q_idx], items[i_idx])\n",
    "        labels = relevance_labels[q_idx][:, i_idx]\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(similarities.diag(), labels.diag())\n",
    "        \n",
    "        optimizer_dot.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_dot.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:2d}: Loss = {total_loss/10:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Evaluation v·ªõi Custom Metrics\n",
    "\n",
    "V√¨ DeepEval c√≥ th·ªÉ kh√¥ng available, ch√∫ng ta implement custom metrics theo paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hit_rate_at_k(predictions: torch.Tensor, \n",
    "                         labels: torch.Tensor, \n",
    "                         k_values: List[int] = [1, 5, 10, 50]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute Hit Rate@K as used in the paper\n",
    "    \n",
    "    Args:\n",
    "        predictions: [num_queries, num_items] - similarity scores\n",
    "        labels: [num_queries, num_items] - binary relevance\n",
    "        k_values: list of k values to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        hit_rates: dict mapping k to hit rate\n",
    "    \"\"\"\n",
    "    hit_rates = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Get top-k predictions for each query\n",
    "        _, top_k_indices = torch.topk(predictions, k, dim=1)\n",
    "        \n",
    "        # Check if any top-k item is relevant\n",
    "        hits = 0\n",
    "        for i in range(len(predictions)):\n",
    "            relevant_items = labels[i].nonzero().squeeze(-1)\n",
    "            if len(relevant_items) > 0:\n",
    "                top_k_items = set(top_k_indices[i].cpu().numpy())\n",
    "                relevant_set = set(relevant_items.cpu().numpy())\n",
    "                if top_k_items.intersection(relevant_set):\n",
    "                    hits += 1\n",
    "        \n",
    "        hit_rates[f'HR@{k}'] = hits / len(predictions)\n",
    "    \n",
    "    return hit_rates\n",
    "\n",
    "def compute_ndcg_at_k(predictions: torch.Tensor, \n",
    "                     labels: torch.Tensor, \n",
    "                     k_values: List[int] = [5, 10]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute NDCG@K\n",
    "    \"\"\"\n",
    "    ndcg_scores = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        _, top_k_indices = torch.topk(predictions, k, dim=1)\n",
    "        \n",
    "        total_ndcg = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            # Get relevance scores for top-k items\n",
    "            relevance_scores = labels[i][top_k_indices[i]].cpu().numpy()\n",
    "            \n",
    "            # Compute DCG\n",
    "            dcg = 0.0\n",
    "            for j, rel in enumerate(relevance_scores):\n",
    "                dcg += rel / np.log2(j + 2)  # j+2 because log2(1) = 0\n",
    "            \n",
    "            # Compute IDCG (perfect ranking)\n",
    "            ideal_relevance = sorted(labels[i].cpu().numpy(), reverse=True)[:k]\n",
    "            idcg = 0.0\n",
    "            for j, rel in enumerate(ideal_relevance):\n",
    "                idcg += rel / np.log2(j + 2)\n",
    "            \n",
    "            # NDCG\n",
    "            if idcg > 0:\n",
    "                total_ndcg += dcg / idcg\n",
    "        \n",
    "        ndcg_scores[f'NDCG@{k}'] = total_ndcg / len(predictions)\n",
    "    \n",
    "    return ndcg_scores\n",
    "\n",
    "print(\"üìä Custom evaluation metrics defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"üß™ Evaluating models...\")\n",
    "\n",
    "mol_model.eval()\n",
    "dot_model.eval()\n",
    "\n",
    "# Use subset for evaluation (computational efficiency)\n",
    "eval_queries = queries[:100]\n",
    "eval_items = items[:1000]\n",
    "eval_query_cats = query_cats[:100]\n",
    "eval_item_cats = item_cats[:1000]\n",
    "\n",
    "eval_labels = create_relevance_labels(eval_query_cats, eval_item_cats).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # MoL predictions\n",
    "    print(\"   Computing MoL predictions...\")\n",
    "    mol_predictions = mol_model(eval_queries, eval_items)\n",
    "    \n",
    "    # Dot product predictions\n",
    "    print(\"   Computing Dot Product predictions...\")\n",
    "    dot_predictions = dot_model(eval_queries, eval_items)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"\\nüìä Results:\")\n",
    "print(\"\\nüß† MoL Performance:\")\n",
    "mol_hr = compute_hit_rate_at_k(mol_predictions, eval_labels)\n",
    "mol_ndcg = compute_ndcg_at_k(mol_predictions, eval_labels)\n",
    "for metric, value in {**mol_hr, **mol_ndcg}.items():\n",
    "    print(f\"   {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n‚ö´ Dot Product Performance:\")\n",
    "dot_hr = compute_hit_rate_at_k(dot_predictions, eval_labels)\n",
    "dot_ndcg = compute_ndcg_at_k(dot_predictions, eval_labels)\n",
    "for metric, value in {**dot_hr, **dot_ndcg}.items():\n",
    "    print(f\"   {metric}: {value:.4f}\")\n",
    "\n",
    "# Improvement analysis\n",
    "print(\"\\nüìà Improvements:\")\n",
    "for metric in mol_hr.keys():\n",
    "    improvement = (mol_hr[metric] - dot_hr[metric]) / dot_hr[metric] * 100\n",
    "    print(f\"   {metric}: {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance & Latency Analysis\n",
    "\n",
    "Test performance benefits nh∆∞ trong paper (Section 4.4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "print(\"‚ö° Performance Benchmarking...\")\n",
    "\n",
    "# Create RAILS retriever\n",
    "rails_retriever = RAILSRetriever(mol_model)\n",
    "rails_retriever.index_items(items)\n",
    "\n",
    "# Test queries\n",
    "test_queries = queries[:10]\n",
    "\n",
    "# Benchmark exact retrieval\n",
    "print(\"\\nüéØ Exact Top-K Retrieval:\")\n",
    "start_time = time.time()\n",
    "exact_scores, exact_indices = rails_retriever.exact_top_k_retrieval(test_queries, k=10)\n",
    "exact_time = time.time() - start_time\n",
    "print(f\"   Time: {exact_time:.4f}s\")\n",
    "print(f\"   Throughput: {len(test_queries)/exact_time:.1f} queries/sec\")\n",
    "\n",
    "# Benchmark approximate retrieval\n",
    "print(\"\\nüöÄ Approximate Top-K Retrieval:\")\n",
    "start_time = time.time()\n",
    "approx_scores, approx_indices = rails_retriever.approximate_top_k_retrieval(\n",
    "    test_queries, k=10, candidate_ratio=0.1\n",
    ")\n",
    "approx_time = time.time() - start_time\n",
    "print(f\"   Time: {approx_time:.4f}s\")\n",
    "print(f\"   Throughput: {len(test_queries)/approx_time:.1f} queries/sec\")\n",
    "print(f\"   Speedup: {exact_time/approx_time:.1f}x\")\n",
    "\n",
    "# Compute recall between exact and approximate\n",
    "total_recall = 0.0\n",
    "for i in range(len(test_queries)):\n",
    "    exact_set = set(exact_indices[i][:5].cpu().numpy())  # Top-5\n",
    "    approx_set = set(approx_indices[i][:5].cpu().numpy())\n",
    "    recall = len(exact_set.intersection(approx_set)) / len(exact_set)\n",
    "    total_recall += recall\n",
    "\n",
    "avg_recall = total_recall / len(test_queries)\n",
    "print(f\"   Recall@5: {avg_recall:.3f}\")\n",
    "\n",
    "# Memory usage analysis\n",
    "print(f\"\\nüíæ Memory Analysis:\")\n",
    "print(f\"   MoL model size: {sum(p.numel() * 4 for p in mol_model.parameters()) / 1024 / 1024:.1f} MB\")\n",
    "print(f\"   Item embeddings: {items.numel() * 4 / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualization & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Training loss\n",
    "axes[0, 0].plot(training_history['train_losses'], label='Main Loss', color='blue')\n",
    "axes[0, 0].plot(training_history['bal_losses'], label='Load Balancing Loss', color='red')\n",
    "axes[0, 0].set_title('Training Losses')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Performance comparison\n",
    "metrics = ['HR@1', 'HR@5', 'HR@10', 'NDCG@5', 'NDCG@10']\n",
    "mol_values = [mol_hr.get(m, mol_ndcg.get(m, 0)) for m in metrics]\n",
    "dot_values = [dot_hr.get(m, dot_ndcg.get(m, 0)) for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 1].bar(x - width/2, mol_values, width, label='MoL', color='green', alpha=0.7)\n",
    "axes[0, 1].bar(x + width/2, dot_values, width, label='Dot Product', color='orange', alpha=0.7)\n",
    "axes[0, 1].set_title('Performance Comparison')\n",
    "axes[0, 1].set_ylabel('Score')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(metrics, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Similarity distribution analysis\n",
    "with torch.no_grad():\n",
    "    sample_queries = eval_queries[:5]\n",
    "    sample_items = eval_items[:100] \n",
    "    \n",
    "    mol_sims = mol_model(sample_queries, sample_items)\n",
    "    dot_sims = dot_model(sample_queries, sample_items)\n",
    "    \n",
    "    axes[1, 0].hist(mol_sims.cpu().flatten().numpy(), bins=50, alpha=0.7, label='MoL', color='green')\n",
    "    axes[1, 0].hist(dot_sims.cpu().flatten().numpy(), bins=50, alpha=0.7, label='Dot Product', color='orange')\n",
    "    axes[1, 0].set_title('Similarity Score Distribution')\n",
    "    axes[1, 0].set_xlabel('Similarity Score')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Component utilization (if we can extract gating weights)\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        sample_features = torch.cat([sample_queries[0], sample_items[0]], dim=0)\n",
    "        gating_weights = mol_model.gating_network(sample_features.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        if mol_model.use_outer_product:\n",
    "            gating_weights = gating_weights.view(mol_model.P_q, mol_model.P_x)\n",
    "            im = axes[1, 1].imshow(gating_weights.cpu().numpy(), cmap='viridis')\n",
    "            axes[1, 1].set_title('Component Gating Weights (Outer Product)')\n",
    "            axes[1, 1].set_xlabel('Item Components')\n",
    "            axes[1, 1].set_ylabel('Query Components')\n",
    "            plt.colorbar(im, ax=axes[1, 1])\n",
    "        else:\n",
    "            axes[1, 1].bar(range(len(gating_weights)), gating_weights.cpu().numpy())\n",
    "            axes[1, 1].set_title('Component Utilization')\n",
    "            axes[1, 1].set_xlabel('Component Index')\n",
    "            axes[1, 1].set_ylabel('Weight')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\nexcept:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Component weights\\nnot available', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Component Analysis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualization completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Template cho Nghi√™n c·ª©u C√° nh√¢n\n",
    "\n",
    "### üîß Customization Points:\n",
    "\n",
    "1. **Modify Architecture**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom MoL variant\n",
    "class CustomMoLVariant(MixtureOfLogitsModule):\n",
    "    def __init__(self, *args, attention_mechanism=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        if attention_mechanism:\n",
    "            self.attention = nn.MultiheadAttention(\n",
    "                embed_dim=self.component_dim,\n",
    "                num_heads=4,\n",
    "                batch_first=True\n",
    "            )\n",
    "    \n",
    "    def forward(self, queries, items):\n",
    "        # Add your custom logic here\n",
    "        return super().forward(queries, items)\n",
    "\n",
    "print(\"üéØ Custom variant template defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Experiment with Different Datasets**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_dataset(dataset_path: str):\n",
    "    \"\"\"\n",
    "    Template for loading custom datasets\n",
    "    \n",
    "    Replace this with your data loading logic:\n",
    "    - MovieLens for recommendation\n",
    "    - MS MARCO for QA\n",
    "    - Your domain-specific data\n",
    "    \"\"\"\n",
    "    # TODO: Implement your data loading\n",
    "    pass\n",
    "\n",
    "def create_domain_specific_features(raw_data):\n",
    "    \"\"\"\n",
    "    Create domain-specific features for your use case\n",
    "    \"\"\"\n",
    "    # TODO: Feature engineering\n",
    "    pass\n",
    "\n",
    "print(\"üìÅ Dataset templates defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Integration v·ªõi LangChain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LANGCHAIN_AVAILABLE:\n",
    "    class MoLEmbeddings(Embeddings):\n",
    "        \"\"\"\n",
    "        LangChain-compatible MoL embeddings\n",
    "        \"\"\"\n",
    "        def __init__(self, mol_model: MixtureOfLogitsModule):\n",
    "            self.mol_model = mol_model\n",
    "        \n",
    "        def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "            # TODO: Implement document embedding using MoL\n",
    "            pass\n",
    "        \n",
    "        def embed_query(self, text: str) -> List[float]:\n",
    "            # TODO: Implement query embedding using MoL\n",
    "            pass\n",
    "    \n",
    "    print(\"ü¶ú LangChain integration template ready\")\nelse:\n",
    "    print(\"‚ö†Ô∏è LangChain not available - skipping integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ K·∫øt lu·∫≠n v√† H∆∞·ªõng ph√°t tri·ªÉn\n",
    "\n",
    "### üìã T√≥m t·∫Øt Implementation:\n",
    "\n",
    "‚úÖ **ƒê√£ tri·ªÉn khai**:\n",
    "- Mixture-of-Logits (MoL) architecture v·ªõi outer product optimization\n",
    "- Load balancing loss ƒë·ªÉ c·∫£i thi·ªán component utilization\n",
    "- RAILS framework v·ªõi exact v√† approximate top-k retrieval\n",
    "- Comprehensive evaluation metrics (Hit Rate, NDCG)\n",
    "- Performance benchmarking v√† analysis\n",
    "\n",
    "### üéØ Key Insights t·ª´ Paper:\n",
    "\n",
    "1. **MoL as Universal Approximator**: C√≥ th·ªÉ bi·ªÉu di·ªÖn b·∫•t k·ª≥ similarity function n√†o\n",
    "2. **GPU Efficiency**: T·∫≠n d·ª•ng arithmetic intensity cao c·ªßa modern accelerators\n",
    "3. **Load Balancing**: Critical ƒë·ªÉ tr√°nh component collapse\n",
    "4. **Approximate Retrieval**: ƒê·∫°t 66x speedup v·ªõi >99% recall\n",
    "\n",
    "### üöÄ H∆∞·ªõng ph√°t tri·ªÉn:\n",
    "\n",
    "1. **Scale to Real Datasets**: Test tr√™n MovieLens, MS MARCO\n",
    "2. **Advanced Architectures**: Attention mechanisms, transformer-based gating\n",
    "3. **Production Optimization**: CUDA kernels, quantization\n",
    "4. **Multi-modal Extensions**: Text, image, audio embeddings\n",
    "\n",
    "### üìö References:\n",
    "\n",
    "- **Paper**: Ding, B., & Zhai, J. (2025). Retrieval with Learned Similarities. WWW 2025.\n",
    "- **Code**: https://github.com/bailuding/rails\n",
    "- **Implementation**: Complete trong notebook n√†y v·ªõi educational focus\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python", 
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}