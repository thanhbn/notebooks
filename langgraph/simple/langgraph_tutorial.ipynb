{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147f9131",
   "metadata": {},
   "source": [
    "# KhÃ³a há»c LangGraph â€” Tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao ğŸ\n",
    "\n",
    "Notebook nÃ y giÃºp báº¡n **tá»± há»c toÃ n bá»™ LangGraph** thÃ´ng qua cÃ¡c pháº§n:\n",
    "\n",
    "1. CÃ i Ä‘áº·t & cáº¥u hÃ¬nh mÃ´i trÆ°á»ng  \n",
    "2. KhÃ¡i niá»‡m State Graph & Message State  \n",
    "3. XÃ¢y dá»±ng graph cÆ¡ báº£n (linear)  \n",
    "4. ThÃªm Ä‘iá»u kiá»‡n ráº½ nhÃ¡nh & vÃ²ng láº·p  \n",
    "5. TÃ­ch há»£p LangChain & OpenAI API  \n",
    "6. XÃ¢y dá»±ng Agent Ä‘a cÃ´ng cá»¥  \n",
    "7. Quan sÃ¡t & gá»¡ lá»—i (visualize, callbacks)  \n",
    "8. Báº¥t Ä‘á»“ng bá»™ & song song hoÃ¡  \n",
    "9. Case Study: Pipeline RAG Ä‘Æ¡n giáº£n  \n",
    "10. BÃ i táº­p thá»±c hÃ nh + gá»£i Ã½ Ä‘Ã¡p Ã¡n\n",
    "\n",
    "> **YÃªu cáº§u**: PythonÂ â‰¥Â 3.10, API key OpenAI (hoáº·c provider tÆ°Æ¡ng Ä‘Æ°Æ¡ng)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3cd7",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ CÃ i Ä‘áº·t gÃ³i cáº§n thiáº¿t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t LangGraph & phá»¥ thuá»™cÂ ( chá»‰ cháº¡y láº§n Ä‘áº§u )\n",
    "%pip install -q langgraph langchain openai tiktoken "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e73ddb",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ KhÃ¡i niá»‡m chÃ­nh\n",
    "\n",
    "* **StateGraph**: Ä‘á»“ thá»‹ xÃ¡c Ä‘á»‹nh cÃ¡c nÃºt (node) & cáº¡nh (edge) cho luá»“ng xá»­ lÃ½.  \n",
    "* **MessageState**: Ä‘á»‘i tÆ°á»£ng lÆ°u tráº¡ng thÃ¡i xuyÃªn suá»‘t khi graph cháº¡y.  \n",
    "* **Node**: hÃ m Python thuáº§n (hoáº·c lá»›p) â€” xá»­ lÃ½ State rá»“i tráº£ State.  \n",
    "* **Edge**: quy táº¯c Ä‘iá»u hÆ°á»›ng (máº·c Ä‘á»‹nh tuáº§n tá»±, cÃ³ thá»ƒ Ä‘iá»u kiá»‡n)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cd661",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ VÃ­ dá»¥: Graph tuyáº¿n tÃ­nh tá»‘i giáº£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessageState\n",
    "\n",
    "# BÆ°á»›c 1â€Šâ€”â€ŠÄá»‹nh nghÄ©a State class\n",
    "class ChatState(MessageState):\n",
    "    messages: list[str] = []\n",
    "\n",
    "# BÆ°á»›c 2â€Šâ€”â€ŠKhai bÃ¡o cÃ¡c node\n",
    "def greet(state: ChatState) -> ChatState:\n",
    "    state.messages.append(\"Xin chÃ o!\")\n",
    "    return state\n",
    "\n",
    "def ask_name(state: ChatState) -> ChatState:\n",
    "    state.messages.append(\"Báº¡n tÃªn gÃ¬?\")\n",
    "    return state\n",
    "\n",
    "# BÆ°á»›c 3â€Šâ€”â€ŠTáº¡o Ä‘á»“ thá»‹ & thÃªm node, cáº¡nh\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"greet\", greet)\n",
    "graph.add_node(\"ask_name\", ask_name)\n",
    "graph.set_entry_point(\"greet\")\n",
    "graph.add_edge(\"greet\", \"ask_name\")\n",
    "\n",
    "chat = graph.compile()\n",
    "\n",
    "# Cháº¡y thá»­\n",
    "final_state = chat.invoke(ChatState())\n",
    "print(final_state.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91062561",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Ráº½ nhÃ¡nh Ä‘iá»u kiá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def random_branch(state: ChatState) -> str:\n",
    "    return \"joke\" if random() < 0.5 else \"fact\"\n",
    "\n",
    "def tell_joke(state: ChatState) -> ChatState:\n",
    "    state.messages.append(\"ğŸ¤¡ ÄÃ¢y lÃ  má»™t cÃ¢u Ä‘Ã¹a!\")\n",
    "    return state\n",
    "\n",
    "def fun_fact(state: ChatState) -> ChatState:\n",
    "    state.messages.append(\"ğŸ“š Báº¡n biáº¿t khÃ´ngâ€¦\")\n",
    "    return state\n",
    "\n",
    "graph2 = StateGraph(ChatState)\n",
    "graph2.add_node(\"start\", greet)\n",
    "graph2.add_node(\"branch\", random_branch)          # tráº£ vá» id cáº¡nh káº¿ tiáº¿p\n",
    "graph2.add_conditional_edges(\"branch\", {\"joke\": \"joke\", \"fact\": \"fact\"})\n",
    "graph2.add_node(\"joke\", tell_joke)\n",
    "graph2.add_node(\"fact\", fun_fact)\n",
    "graph2.set_entry_point(\"start\")\n",
    "\n",
    "chat2 = graph2.compile()\n",
    "print(chat2.invoke(ChatState()).messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155caf4",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ TÃ­ch há»£p LangChain & OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "def llm_node(state: ChatState) -> ChatState:\n",
    "    last_msg = state.messages[-1] if state.messages else \"Xin chÃ o\"\n",
    "    response = llm([HumanMessage(content=last_msg)]).content\n",
    "    state.messages.append(response)\n",
    "    return state\n",
    "\n",
    "graph3 = StateGraph(ChatState)\n",
    "graph3.add_node(\"user_prompt\", ask_name)\n",
    "graph3.add_node(\"llm_response\", llm_node)\n",
    "graph3.set_entry_point(\"user_prompt\")\n",
    "graph3.add_edge(\"user_prompt\", \"llm_response\")\n",
    "\n",
    "chat3 = graph3.compile()\n",
    "print(chat3.invoke(ChatState()).messages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277673f",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Quan sÃ¡t & gá»¡ lá»—i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiá»ƒn thá»‹ cáº¥u trÃºc graph dÆ°á»›i dáº¡ng DOT (cÃ³ thá»ƒ render báº±ng graphviz)\n",
    "dot_code = graph3.get_graph().to_dot()\n",
    "print(dot_code[:400], \"...\")  # in preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907dbd9",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Báº¥t Ä‘á»“ng bá»™ vÃ  song song hoÃ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def greet_async(state: ChatState) -> ChatState:\n",
    "    await asyncio.sleep(0.2)\n",
    "    state.messages.append(\"Hello (async)!\")\n",
    "    return state\n",
    "\n",
    "g_async = StateGraph(ChatState)\n",
    "g_async.add_node(\"start\", greet_async, is_async=True)\n",
    "g_async.set_entry_point(\"start\")\n",
    "chat_async = g_async.compile()\n",
    "\n",
    "asyncio.run(chat_async.ainvoke(ChatState()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1637b",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Case Study: Pipeline RAG Ä‘Æ¡n giáº£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giáº£ láº­p bÆ°á»›c truy váº¥n vector store â†’ sinh cÃ¢u tráº£ lá»i\n",
    "def retrieve(state: ChatState) -> ChatState:\n",
    "    state.messages.append(\"ğŸ” ÄÃ£ truy xuáº¥t 3 tÃ i liá»‡u liÃªn quan.\")\n",
    "    return state\n",
    "\n",
    "def answer(state: ChatState) -> ChatState:\n",
    "    docs = \" \".join(state.messages[-1:])\n",
    "    reply = llm([HumanMessage(content=f\"Tráº£ lá»i dá»±a trÃªn: {docs}\")]).content\n",
    "    state.messages.append(reply)\n",
    "    return state\n",
    "\n",
    "rag = StateGraph(ChatState)    .add_node(\"user\", ask_name)    .add_node(\"retrieve\", retrieve)    .add_node(\"answer\", answer)    .set_entry_point(\"user\")    .add_edge(\"user\", \"retrieve\")    .add_edge(\"retrieve\", \"answer\")    .compile()\n",
    "\n",
    "print(rag.invoke(ChatState()).messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19600e2f",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ BÃ i táº­p\n",
    "\n",
    "âœï¸ **ExerciseÂ 1**: ThÃªm node `translate` Ä‘á»ƒ dá»‹ch cÃ¢u tráº£ lá»i cuá»‘i sang tiáº¿ng Anh.  \n",
    "âœï¸ **ExerciseÂ 2**: ThÃªm Ä‘iá»u kiá»‡n: náº¿u tÃªn ngÆ°á»i dÃ¹ng chá»©a â€œAIâ€ thÃ¬ nháº£y tá»›i node `special_greet`.  \n",
    "âœï¸ **ExerciseÂ 3**: Thá»­ connect LangGraph vá»›i tool truy váº¥n cÆ¡ sá»Ÿ dá»¯ liá»‡u (SQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb7032",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Tá»•ng káº¿t\n",
    "\n",
    "* LangGraph cung cáº¥p **stateful orchestration** máº¡nh máº½ cho agent.  \n",
    "* Káº¿t há»£p LangChainÂ +Â LangGraph giÃºp xÃ¢y LLM workflow nÃ¢ng cao.  \n",
    "* Tiáº¿p tá»¥c Ä‘á»c docs chÃ­nh thá»©c & source code Ä‘á»ƒ náº¯m chi tiáº¿t."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
