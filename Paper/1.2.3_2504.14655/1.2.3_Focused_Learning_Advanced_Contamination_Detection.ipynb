{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focused Learning: Advanced Contamination Detection & Dataset Versioning\n",
    "\n",
    "## Learning Objectives\n",
    "1. Master advanced techniques for detecting data contamination in LLM evaluation\n",
    "2. Understand the difference between memorization and true generalization\n",
    "3. Implement statistical methods for quantifying contamination risk\n",
    "4. Build robust dataset versioning systems for temporal benchmarks\n",
    "5. Learn to detect subtle forms of information leakage\n",
    "\n",
    "## Concept Source\n",
    "- **Paper Section**: Section 3 (Contamination Analysis) - Extended from basic temporal analysis\n",
    "- **Key Insight**: \"The minimal temporal overlap between GPT-4o-0806's release date and our test problem release window strongly suggests authentic model capability measurements\"\n",
    "- **Research Gap**: Paper only covers basic temporal analysis - we need deeper contamination detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Multi-Dimensional Contamination Problem\n",
    "\n",
    "### Beyond Simple Temporal Splits\n",
    "\n",
    "While the paper uses temporal splits as the primary contamination prevention method, real-world contamination is much more complex:\n",
    "\n",
    "1. **Direct Memorization**: Model has seen exact problem in training\n",
    "2. **Indirect Exposure**: Similar problems or solution patterns\n",
    "3. **Cross-Pollination**: Information leaked through related datasets\n",
    "4. **Synthetic Contamination**: Training data generated from test sets\n",
    "5. **Human Contamination**: Evaluators unconsciously biased by known solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "import json\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Similarity Detection\n",
    "\n",
    "### Detecting Near-Duplicate Problems Across Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Problem:\n",
    "    \"\"\"Enhanced problem representation for contamination analysis\"\"\"\n",
    "    id: str\n",
    "    title: str\n",
    "    description: str\n",
    "    solution_code: str\n",
    "    test_cases: List[Dict]\n",
    "    release_date: datetime\n",
    "    difficulty: str\n",
    "    tags: List[str]\n",
    "    source_platform: str\n",
    "    language: str = \"python\"\n",
    "\n",
    "class ProblemSimilarityDetector:\n",
    "    \"\"\"Advanced similarity detection for identifying potential contamination\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 3),\n",
    "            min_df=2\n",
    "        )\n",
    "        self.similarity_threshold = 0.8\n",
    "        \n",
    "    def extract_problem_features(self, problem: Problem) -> Dict:\n",
    "        \"\"\"Extract multi-dimensional features from problem\"\"\"\n",
    "        features = {\n",
    "            # Text features\n",
    "            'description_hash': hashlib.md5(problem.description.encode()).hexdigest(),\n",
    "            'description_length': len(problem.description),\n",
    "            'word_count': len(problem.description.split()),\n",
    "            \n",
    "            # Algorithmic features\n",
    "            'algorithm_keywords': self._extract_algorithm_keywords(problem.description),\n",
    "            'constraint_signature': self._extract_constraint_signature(problem.description),\n",
    "            'io_pattern': self._extract_io_pattern(problem.test_cases),\n",
    "            \n",
    "            # Code features\n",
    "            'solution_complexity': self._analyze_solution_complexity(problem.solution_code),\n",
    "            'code_patterns': self._extract_code_patterns(problem.solution_code),\n",
    "            \n",
    "            # Metadata\n",
    "            'difficulty': problem.difficulty,\n",
    "            'tags': set(problem.tags),\n",
    "            'release_date': problem.release_date\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_algorithm_keywords(self, description: str) -> Set[str]:\n",
    "        \"\"\"Extract algorithmic concepts from problem description\"\"\"\n",
    "        algorithm_patterns = {\n",
    "            'binary_search': r'\\b(binary search|search|sorted|log)\\b',\n",
    "            'dynamic_programming': r'\\b(dp|dynamic|optimal|subproblem|memoization)\\b',\n",
    "            'graph': r'\\b(graph|node|edge|tree|connected|path|cycle)\\b',\n",
    "            'greedy': r'\\b(greedy|optimal|maximize|minimize|best)\\b',\n",
    "            'two_pointer': r'\\b(two pointer|left|right|pointer)\\b',\n",
    "            'sliding_window': r'\\b(window|substring|subarray|contiguous)\\b',\n",
    "            'backtracking': r'\\b(backtrack|permutation|combination|generate)\\b'\n",
    "        }\n",
    "        \n",
    "        keywords = set()\n",
    "        text = description.lower()\n",
    "        \n",
    "        for keyword, pattern in algorithm_patterns.items():\n",
    "            if re.search(pattern, text):\n",
    "                keywords.add(keyword)\n",
    "        \n",
    "        return keywords\n",
    "    \n",
    "    def _extract_constraint_signature(self, description: str) -> str:\n",
    "        \"\"\"Extract constraint patterns that might indicate similar problems\"\"\"\n",
    "        # Extract numerical constraints\n",
    "        constraint_pattern = r'(\\d+)\\s*<=?\\s*(\\w+)\\s*<=?\\s*(\\d+)'\n",
    "        constraints = re.findall(constraint_pattern, description)\n",
    "        \n",
    "        # Normalize constraint ranges\n",
    "        normalized = []\n",
    "        for min_val, var, max_val in constraints:\n",
    "            try:\n",
    "                min_int, max_int = int(min_val), int(max_val)\n",
    "                range_type = 'small' if max_int < 100 else 'medium' if max_int < 10000 else 'large'\n",
    "                normalized.append(f\"{var}:{range_type}\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        return '|'.join(sorted(normalized))\n",
    "    \n",
    "    def _extract_io_pattern(self, test_cases: List[Dict]) -> str:\n",
    "        \"\"\"Extract input/output pattern signature\"\"\"\n",
    "        if not test_cases:\n",
    "            return \"no_tests\"\n",
    "            \n",
    "        patterns = []\n",
    "        for case in test_cases[:3]:  # Analyze first 3 test cases\n",
    "            input_data = case.get('input', {})\n",
    "            output_data = case.get('output')\n",
    "            \n",
    "            # Analyze input structure\n",
    "            input_types = []\n",
    "            for key, value in input_data.items():\n",
    "                if isinstance(value, list):\n",
    "                    input_types.append(f\"list[{len(value)}]\")\n",
    "                elif isinstance(value, int):\n",
    "                    input_types.append(\"int\")\n",
    "                elif isinstance(value, str):\n",
    "                    input_types.append(\"str\")\n",
    "            \n",
    "            # Analyze output type\n",
    "            if isinstance(output_data, list):\n",
    "                output_type = f\"list[{len(output_data)}]\"\n",
    "            elif isinstance(output_data, int):\n",
    "                output_type = \"int\"\n",
    "            elif isinstance(output_data, bool):\n",
    "                output_type = \"bool\"\n",
    "            else:\n",
    "                output_type = \"other\"\n",
    "            \n",
    "            patterns.append(f\"{'_'.join(input_types)}->{output_type}\")\n",
    "        \n",
    "        return '|'.join(patterns)\n",
    "    \n",
    "    def _analyze_solution_complexity(self, code: str) -> Dict:\n",
    "        \"\"\"Analyze solution complexity patterns\"\"\"\n",
    "        lines = [line.strip() for line in code.split('\\n') if line.strip()]\n",
    "        \n",
    "        complexity_indicators = {\n",
    "            'nested_loops': code.count('for') + code.count('while'),\n",
    "            'recursion': 'return' in code and any(func in code for func in ['def ', 'self.']),\n",
    "            'builtin_usage': sum(1 for builtin in ['sum(', 'max(', 'min(', 'sorted(', 'len('] if builtin in code),\n",
    "            'data_structures': sum(1 for ds in ['dict(', 'set(', 'list(', 'defaultdict'] if ds in code),\n",
    "            'line_count': len(lines)\n",
    "        }\n",
    "        \n",
    "        return complexity_indicators\n",
    "    \n",
    "    def _extract_code_patterns(self, code: str) -> Set[str]:\n",
    "        \"\"\"Extract common coding patterns\"\"\"\n",
    "        patterns = set()\n",
    "        \n",
    "        pattern_signatures = {\n",
    "            'two_pointer': r'(left.*right|i.*j.*while)',\n",
    "            'sliding_window': r'(window|start.*end)',\n",
    "            'binary_search': r'(left.*right.*mid|while.*left.*<=.*right)',\n",
    "            'dp_array': r'(dp\\[|memo\\[)',\n",
    "            'dfs_pattern': r'def.*dfs|def.*helper',\n",
    "            'early_return': r'if.*return.*(?:True|False|-1|0)'\n",
    "        }\n",
    "        \n",
    "        for pattern_name, regex in pattern_signatures.items():\n",
    "            if re.search(regex, code, re.IGNORECASE):\n",
    "                patterns.add(pattern_name)\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def calculate_similarity_matrix(self, problems: List[Problem]) -> np.ndarray:\n",
    "        \"\"\"Calculate comprehensive similarity matrix between problems\"\"\"\n",
    "        n = len(problems)\n",
    "        similarity_matrix = np.zeros((n, n))\n",
    "        \n",
    "        # Extract features for all problems\n",
    "        features = [self.extract_problem_features(p) for p in problems]\n",
    "        \n",
    "        # Calculate text similarity using TF-IDF\n",
    "        descriptions = [p.description for p in problems]\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(descriptions)\n",
    "        text_similarity = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                if i == j:\n",
    "                    similarity_matrix[i][j] = 1.0\n",
    "                    continue\n",
    "                \n",
    "                # Multi-dimensional similarity calculation\n",
    "                similarities = {\n",
    "                    'text': text_similarity[i][j],\n",
    "                    'algorithm': self._algorithm_similarity(features[i], features[j]),\n",
    "                    'constraint': self._constraint_similarity(features[i], features[j]),\n",
    "                    'io_pattern': self._io_similarity(features[i], features[j]),\n",
    "                    'code_pattern': self._code_similarity(features[i], features[j]),\n",
    "                    'metadata': self._metadata_similarity(features[i], features[j])\n",
    "                }\n",
    "                \n",
    "                # Weighted combination\n",
    "                weights = {\n",
    "                    'text': 0.3,\n",
    "                    'algorithm': 0.25,\n",
    "                    'constraint': 0.15,\n",
    "                    'io_pattern': 0.15,\n",
    "                    'code_pattern': 0.1,\n",
    "                    'metadata': 0.05\n",
    "                }\n",
    "                \n",
    "                total_similarity = sum(similarities[k] * weights[k] for k in similarities)\n",
    "                similarity_matrix[i][j] = similarity_matrix[j][i] = total_similarity\n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    def _algorithm_similarity(self, feat1: Dict, feat2: Dict) -> float:\n",
    "        \"\"\"Calculate algorithmic concept similarity\"\"\"\n",
    "        keywords1 = feat1.get('algorithm_keywords', set())\n",
    "        keywords2 = feat2.get('algorithm_keywords', set())\n",
    "        \n",
    "        if not keywords1 and not keywords2:\n",
    "            return 0.5  # Both have no clear algorithmic indicators\n",
    "        \n",
    "        intersection = len(keywords1 & keywords2)\n",
    "        union = len(keywords1 | keywords2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    def _constraint_similarity(self, feat1: Dict, feat2: Dict) -> float:\n",
    "        \"\"\"Calculate constraint pattern similarity\"\"\"\n",
    "        const1 = feat1.get('constraint_signature', '')\n",
    "        const2 = feat2.get('constraint_signature', '')\n",
    "        \n",
    "        if const1 == const2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Partial match for constraint patterns\n",
    "        parts1 = set(const1.split('|')) if const1 else set()\n",
    "        parts2 = set(const2.split('|')) if const2 else set()\n",
    "        \n",
    "        if not parts1 and not parts2:\n",
    "            return 0.5\n",
    "        \n",
    "        intersection = len(parts1 & parts2)\n",
    "        union = len(parts1 | parts2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    def _io_similarity(self, feat1: Dict, feat2: Dict) -> float:\n",
    "        \"\"\"Calculate input/output pattern similarity\"\"\"\n",
    "        pattern1 = feat1.get('io_pattern', '')\n",
    "        pattern2 = feat2.get('io_pattern', '')\n",
    "        \n",
    "        if pattern1 == pattern2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Check for similar patterns\n",
    "        parts1 = set(pattern1.split('|')) if pattern1 else set()\n",
    "        parts2 = set(pattern2.split('|')) if pattern2 else set()\n",
    "        \n",
    "        if not parts1 and not parts2:\n",
    "            return 0.5\n",
    "        \n",
    "        intersection = len(parts1 & parts2)\n",
    "        union = len(parts1 | parts2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    def _code_similarity(self, feat1: Dict, feat2: Dict) -> float:\n",
    "        \"\"\"Calculate code pattern similarity\"\"\"\n",
    "        patterns1 = feat1.get('code_patterns', set())\n",
    "        patterns2 = feat2.get('code_patterns', set())\n",
    "        \n",
    "        if not patterns1 and not patterns2:\n",
    "            return 0.5\n",
    "        \n",
    "        intersection = len(patterns1 & patterns2)\n",
    "        union = len(patterns1 | patterns2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    def _metadata_similarity(self, feat1: Dict, feat2: Dict) -> float:\n",
    "        \"\"\"Calculate metadata similarity\"\"\"\n",
    "        # Difficulty similarity\n",
    "        diff_sim = 1.0 if feat1.get('difficulty') == feat2.get('difficulty') else 0.0\n",
    "        \n",
    "        # Tag similarity\n",
    "        tags1 = feat1.get('tags', set())\n",
    "        tags2 = feat2.get('tags', set())\n",
    "        \n",
    "        if tags1 and tags2:\n",
    "            tag_sim = len(tags1 & tags2) / len(tags1 | tags2)\n",
    "        else:\n",
    "            tag_sim = 0.5\n",
    "        \n",
    "        return (diff_sim + tag_sim) / 2\n",
    "\n",
    "# Test the similarity detector\n",
    "def create_mock_problems() -> List[Problem]:\n",
    "    \"\"\"Create mock problems for testing similarity detection\"\"\"\n",
    "    problems = []\n",
    "    \n",
    "    # Problem 1: Original missing number in AP\n",
    "    problems.append(Problem(\n",
    "        id=\"missing_ap_1\",\n",
    "        title=\"Missing Number in Arithmetic Progression\",\n",
    "        description=\"\"\"Given an array representing an arithmetic progression with one missing element,\n",
    "        find the missing number. Constraints: 3 <= arr.length <= 1000, 0 <= arr[i] <= 10^5\"\"\",\n",
    "        solution_code=\"\"\"def missingNumber(arr):\n",
    "            n = len(arr)\n",
    "            expected = (n + 1) * (arr[0] + arr[-1]) // 2\n",
    "            return expected - sum(arr)\"\"\",\n",
    "        test_cases=[{\"input\": {\"arr\": [5, 7, 11, 13]}, \"output\": 9}],\n",
    "        release_date=datetime(2019, 10, 15),\n",
    "        difficulty=\"Easy\",\n",
    "        tags=[\"Array\", \"Math\"],\n",
    "        source_platform=\"LeetCode\"\n",
    "    ))\n",
    "    \n",
    "    # Problem 2: Very similar problem (potential contamination)\n",
    "    problems.append(Problem(\n",
    "        id=\"missing_ap_2\",\n",
    "        title=\"Find Missing Element in Sequence\",\n",
    "        description=\"\"\"You are given an arithmetic sequence with one element removed.\n",
    "        Return the missing element. Constraints: 3 <= sequence.length <= 1000, 0 <= sequence[i] <= 10^5\"\"\",\n",
    "        solution_code=\"\"\"def findMissing(sequence):\n",
    "            length = len(sequence)\n",
    "            total_sum = (length + 1) * (sequence[0] + sequence[-1]) // 2\n",
    "            return total_sum - sum(sequence)\"\"\",\n",
    "        test_cases=[{\"input\": {\"sequence\": [2, 4, 8, 10]}, \"output\": 6}],\n",
    "        release_date=datetime(2024, 8, 20),\n",
    "        difficulty=\"Easy\",\n",
    "        tags=[\"Array\", \"Math\"],\n",
    "        source_platform=\"CodeForces\"\n",
    "    ))\n",
    "    \n",
    "    # Problem 3: Different problem (binary search)\n",
    "    problems.append(Problem(\n",
    "        id=\"binary_search_1\",\n",
    "        title=\"Search in Sorted Array\",\n",
    "        description=\"\"\"Given a sorted array and target value, return the index if found.\n",
    "        Constraints: 1 <= nums.length <= 10^4, -10^4 <= nums[i] <= 10^4\"\"\",\n",
    "        solution_code=\"\"\"def search(nums, target):\n",
    "            left, right = 0, len(nums) - 1\n",
    "            while left <= right:\n",
    "                mid = (left + right) // 2\n",
    "                if nums[mid] == target: return mid\n",
    "                elif nums[mid] < target: left = mid + 1\n",
    "                else: right = mid - 1\n",
    "            return -1\"\"\",\n",
    "        test_cases=[{\"input\": {\"nums\": [1, 3, 5, 7, 9], \"target\": 5}, \"output\": 2}],\n",
    "        release_date=datetime(2020, 3, 10),\n",
    "        difficulty=\"Easy\",\n",
    "        tags=[\"Array\", \"Binary Search\"],\n",
    "        source_platform=\"LeetCode\"\n",
    "    ))\n",
    "    \n",
    "    # Problem 4: Another AP problem with different approach\n",
    "    problems.append(Problem(\n",
    "        id=\"missing_ap_3\",\n",
    "        title=\"Arithmetic Progression Gap\",\n",
    "        description=\"\"\"Find the gap in an arithmetic progression array.\n",
    "        Constraints: 3 <= arr.length <= 500, -1000 <= arr[i] <= 1000\"\"\",\n",
    "        solution_code=\"\"\"def findGap(arr):\n",
    "            n = len(arr)\n",
    "            diff = (arr[-1] - arr[0]) // n\n",
    "            for i in range(n - 1):\n",
    "                if arr[i + 1] - arr[i] != diff:\n",
    "                    return arr[i] + diff\n",
    "            return arr[-1] + diff\"\"\",\n",
    "        test_cases=[{\"input\": {\"arr\": [1, 3, 7, 9]}, \"output\": 5}],\n",
    "        release_date=datetime(2024, 12, 1),\n",
    "        difficulty=\"Medium\",\n",
    "        tags=[\"Array\", \"Math\"],\n",
    "        source_platform=\"AtCoder\"\n",
    "    ))\n",
    "    \n",
    "    return problems\n",
    "\n",
    "# Test similarity detection\n",
    "detector = ProblemSimilarityDetector()\n",
    "mock_problems = create_mock_problems()\n",
    "\n",
    "print(\"Problem Similarity Analysis:\")\n",
    "print(\"===========================\\n\")\n",
    "\n",
    "# Extract features\n",
    "for i, problem in enumerate(mock_problems):\n",
    "    features = detector.extract_problem_features(problem)\n",
    "    print(f\"Problem {i+1}: {problem.title}\")\n",
    "    print(f\"  Algorithm Keywords: {features['algorithm_keywords']}\")\n",
    "    print(f\"  Constraint Signature: {features['constraint_signature']}\")\n",
    "    print(f\"  IO Pattern: {features['io_pattern']}\")\n",
    "    print(f\"  Code Patterns: {features['code_patterns']}\")\n",
    "    print()\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = detector.calculate_similarity_matrix(mock_problems)\n",
    "\n",
    "print(\"Similarity Matrix:\")\n",
    "print(\"==================\")\n",
    "problem_names = [p.title[:20] + \"...\" for p in mock_problems]\n",
    "df = pd.DataFrame(similarity_matrix, index=problem_names, columns=problem_names)\n",
    "print(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Contamination Detection\n",
    "\n",
    "### Advanced Statistical Methods for Detecting Memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticalContaminationDetector:\n",
    "    \"\"\"Advanced statistical methods for contamination detection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.confidence_level = 0.95\n",
    "        self.effect_size_threshold = 0.5  # Cohen's d\n",
    "        \n",
    "    def analyze_performance_distribution(self, results: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze performance distribution for contamination signals\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for model in results['model'].unique():\n",
    "            model_data = results[results['model'] == model]\n",
    "            \n",
    "            # Basic statistics\n",
    "            scores = model_data['score']\n",
    "            analysis[model] = {\n",
    "                'mean': scores.mean(),\n",
    "                'std': scores.std(),\n",
    "                'skewness': stats.skew(scores),\n",
    "                'kurtosis': stats.kurtosis(scores),\n",
    "                'outlier_count': self._count_outliers(scores),\n",
    "                'distribution_test': self._test_normality(scores)\n",
    "            }\n",
    "            \n",
    "            # Contamination indicators\n",
    "            analysis[model]['contamination_indicators'] = {\n",
    "                'high_outliers': (scores > scores.mean() + 2*scores.std()).sum(),\n",
    "                'perfect_scores': (scores == 100).sum(),\n",
    "                'score_clustering': self._detect_score_clustering(scores),\n",
    "                'bimodal_distribution': self._test_bimodality(scores)\n",
    "            }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _count_outliers(self, scores: pd.Series) -> int:\n",
    "        \"\"\"Count outliers using IQR method\"\"\"\n",
    "        Q1 = scores.quantile(0.25)\n",
    "        Q3 = scores.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        return ((scores < lower_bound) | (scores > upper_bound)).sum()\n",
    "    \n",
    "    def _test_normality(self, scores: pd.Series) -> Dict:\n",
    "        \"\"\"Test if score distribution is normal\"\"\"\n",
    "        if len(scores) < 8:\n",
    "            return {'test': 'insufficient_data', 'p_value': None, 'is_normal': None}\n",
    "        \n",
    "        # Shapiro-Wilk test for normality\n",
    "        statistic, p_value = stats.shapiro(scores)\n",
    "        \n",
    "        return {\n",
    "            'test': 'shapiro_wilk',\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'is_normal': p_value > 0.05\n",
    "        }\n",
    "    \n",
    "    def _detect_score_clustering(self, scores: pd.Series) -> Dict:\n",
    "        \"\"\"Detect unusual clustering in scores\"\"\"\n",
    "        if len(scores) < 5:\n",
    "            return {'clusters_detected': False, 'num_clusters': 0}\n",
    "        \n",
    "        # Use DBSCAN to detect clusters\n",
    "        scores_array = scores.values.reshape(-1, 1)\n",
    "        \n",
    "        # Try different epsilon values\n",
    "        best_clustering = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for eps in [1, 2, 5, 10]:\n",
    "            clustering = DBSCAN(eps=eps, min_samples=2).fit(scores_array)\n",
    "            n_clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "            \n",
    "            if n_clusters > 1 and n_clusters < len(scores) / 2:\n",
    "                # Calculate silhouette score if possible\n",
    "                if n_clusters > 1 and len(set(clustering.labels_)) > 1:\n",
    "                    from sklearn.metrics import silhouette_score\n",
    "                    try:\n",
    "                        score = silhouette_score(scores_array, clustering.labels_)\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_clustering = clustering\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        if best_clustering is not None:\n",
    "            return {\n",
    "                'clusters_detected': True,\n",
    "                'num_clusters': len(set(best_clustering.labels_)) - (1 if -1 in best_clustering.labels_ else 0),\n",
    "                'silhouette_score': best_score\n",
    "            }\n",
    "        \n",
    "        return {'clusters_detected': False, 'num_clusters': 0}\n",
    "    \n",
    "    def _test_bimodality(self, scores: pd.Series) -> Dict:\n",
    "        \"\"\"Test for bimodal distribution (sign of contamination)\"\"\"\n",
    "        if len(scores) < 10:\n",
    "            return {'bimodal': False, 'confidence': 0}\n",
    "        \n",
    "        # Calculate Hartigan's dip test statistic (simplified)\n",
    "        hist, bin_edges = np.histogram(scores, bins=min(10, len(scores)//2))\n",
    "        \n",
    "        # Look for two distinct peaks\n",
    "        peaks = []\n",
    "        for i in range(1, len(hist)-1):\n",
    "            if hist[i] > hist[i-1] and hist[i] > hist[i+1]:\n",
    "                peaks.append(i)\n",
    "        \n",
    "        # Check if peaks are separated by a valley\n",
    "        bimodal = False\n",
    "        if len(peaks) >= 2:\n",
    "            # Find minimum between peaks\n",
    "            peak1, peak2 = peaks[0], peaks[-1]\n",
    "            valley_min = min(hist[peak1+1:peak2])\n",
    "            peak_min = min(hist[peak1], hist[peak2])\n",
    "            \n",
    "            # Bimodal if valley is significantly lower than peaks\n",
    "            if valley_min < peak_min * 0.5:\n",
    "                bimodal = True\n",
    "        \n",
    "        return {\n",
    "            'bimodal': bimodal,\n",
    "            'num_peaks': len(peaks),\n",
    "            'confidence': 0.8 if bimodal else 0.2\n",
    "        }\n",
    "    \n",
    "    def temporal_performance_analysis(self, results: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze performance changes over time to detect contamination\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for model in results['model'].unique():\n",
    "            model_data = results[results['model'] == model].copy()\n",
    "            model_data = model_data.sort_values('release_date')\n",
    "            \n",
    "            # Convert dates to numeric for correlation\n",
    "            dates_numeric = pd.to_numeric(model_data['release_date'])\n",
    "            scores = model_data['score']\n",
    "            \n",
    "            # Calculate temporal correlation\n",
    "            correlation, p_value = stats.pearsonr(dates_numeric, scores)\n",
    "            \n",
    "            # Detect change points\n",
    "            change_points = self._detect_change_points(scores)\n",
    "            \n",
    "            # Calculate trend\n",
    "            if len(scores) >= 3:\n",
    "                slope, intercept, r_value, p_value_trend, std_err = stats.linregress(\n",
    "                    range(len(scores)), scores\n",
    "                )\n",
    "            else:\n",
    "                slope = p_value_trend = 0\n",
    "                r_value = 0\n",
    "            \n",
    "            analysis[model] = {\n",
    "                'temporal_correlation': correlation,\n",
    "                'correlation_p_value': p_value,\n",
    "                'trend_slope': slope,\n",
    "                'trend_r_squared': r_value**2,\n",
    "                'trend_p_value': p_value_trend,\n",
    "                'change_points': change_points,\n",
    "                'contamination_risk': self._calculate_contamination_risk(\n",
    "                    correlation, slope, change_points\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _detect_change_points(self, scores: pd.Series) -> List[int]:\n",
    "        \"\"\"Detect significant change points in performance\"\"\"\n",
    "        if len(scores) < 6:\n",
    "            return []\n",
    "        \n",
    "        change_points = []\n",
    "        window_size = max(3, len(scores) // 4)\n",
    "        \n",
    "        for i in range(window_size, len(scores) - window_size):\n",
    "            before = scores.iloc[:i]\n",
    "            after = scores.iloc[i:]\n",
    "            \n",
    "            # T-test for significant difference\n",
    "            if len(before) >= 2 and len(after) >= 2:\n",
    "                t_stat, p_value = stats.ttest_ind(before, after)\n",
    "                \n",
    "                # Significant change if p < 0.05 and effect size > threshold\n",
    "                if p_value < 0.05:\n",
    "                    effect_size = abs(before.mean() - after.mean()) / np.sqrt(\n",
    "                        ((len(before)-1)*before.var() + (len(after)-1)*after.var()) / \n",
    "                        (len(before) + len(after) - 2)\n",
    "                    )\n",
    "                    \n",
    "                    if effect_size > self.effect_size_threshold:\n",
    "                        change_points.append(i)\n",
    "        \n",
    "        return change_points\n",
    "    \n",
    "    def _calculate_contamination_risk(self, correlation: float, \n",
    "                                    slope: float, \n",
    "                                    change_points: List[int]) -> Dict:\n",
    "        \"\"\"Calculate overall contamination risk score\"\"\"\n",
    "        risk_factors = {\n",
    "            'negative_temporal_correlation': max(0, -correlation) * 0.4,\n",
    "            'negative_trend': max(0, -slope) * 0.3,\n",
    "            'change_points': min(1.0, len(change_points) / 3) * 0.3\n",
    "        }\n",
    "        \n",
    "        total_risk = sum(risk_factors.values())\n",
    "        \n",
    "        # Risk classification\n",
    "        if total_risk > 0.7:\n",
    "            risk_level = \"HIGH\"\n",
    "        elif total_risk > 0.4:\n",
    "            risk_level = \"MEDIUM\"\n",
    "        elif total_risk > 0.2:\n",
    "            risk_level = \"LOW\"\n",
    "        else:\n",
    "            risk_level = \"MINIMAL\"\n",
    "        \n",
    "        return {\n",
    "            'total_score': total_risk,\n",
    "            'risk_level': risk_level,\n",
    "            'factors': risk_factors\n",
    "        }\n",
    "\n",
    "# Create mock performance data for testing\n",
    "def create_mock_performance_data() -> pd.DataFrame:\n",
    "    \"\"\"Create mock performance data with contamination signals\"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = []\n",
    "    \n",
    "    # Clean model (consistent performance)\n",
    "    clean_dates = pd.date_range('2024-07-01', '2024-12-31', freq='W')\n",
    "    clean_scores = np.random.normal(65, 8, len(clean_dates))  # Consistent performance\n",
    "    \n",
    "    for date, score in zip(clean_dates, clean_scores):\n",
    "        data.append({\n",
    "            'model': 'CleanModel',\n",
    "            'release_date': date,\n",
    "            'score': max(0, min(100, score))\n",
    "        })\n",
    "    \n",
    "    # Contaminated model (declining performance over time)\n",
    "    cont_dates = pd.date_range('2024-07-01', '2024-12-31', freq='W')\n",
    "    # High performance initially, declining over time\n",
    "    cont_base = 85 - np.linspace(0, 25, len(cont_dates))  # Declining trend\n",
    "    cont_scores = cont_base + np.random.normal(0, 5, len(cont_dates))\n",
    "    \n",
    "    for date, score in zip(cont_dates, cont_scores):\n",
    "        data.append({\n",
    "            'model': 'ContaminatedModel',\n",
    "            'release_date': date,\n",
    "            'score': max(0, min(100, score))\n",
    "        })\n",
    "    \n",
    "    # Suspicious model (bimodal distribution)\n",
    "    susp_dates = pd.date_range('2024-07-01', '2024-12-31', freq='W')\n",
    "    # Mix of high and low scores (memorized vs. new problems)\n",
    "    susp_scores = []\n",
    "    for i in range(len(susp_dates)):\n",
    "        if np.random.random() < 0.6:  # 60% high scores (memorized)\n",
    "            score = np.random.normal(85, 5)\n",
    "        else:  # 40% low scores (new problems)\n",
    "            score = np.random.normal(35, 8)\n",
    "        susp_scores.append(max(0, min(100, score)))\n",
    "    \n",
    "    for date, score in zip(susp_dates, susp_scores):\n",
    "        data.append({\n",
    "            'model': 'SuspiciousModel',\n",
    "            'release_date': date,\n",
    "            'score': score\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Test statistical contamination detection\n",
    "stat_detector = StatisticalContaminationDetector()\n",
    "mock_performance = create_mock_performance_data()\n",
    "\n",
    "print(\"Statistical Contamination Analysis:\")\n",
    "print(\"==================================\\n\")\n",
    "\n",
    "# Analyze performance distributions\n",
    "distribution_analysis = stat_detector.analyze_performance_distribution(mock_performance)\n",
    "\n",
    "for model, analysis in distribution_analysis.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"  Mean Score: {analysis['mean']:.2f} ± {analysis['std']:.2f}\")\n",
    "    print(f\"  Skewness: {analysis['skewness']:.3f}\")\n",
    "    print(f\"  Outliers: {analysis['outlier_count']}\")\n",
    "    print(f\"  Perfect Scores: {analysis['contamination_indicators']['perfect_scores']}\")\n",
    "    print(f\"  Bimodal: {analysis['contamination_indicators']['bimodal_distribution']['bimodal']}\")\n",
    "    print()\n",
    "\n",
    "# Temporal analysis\n",
    "temporal_analysis = stat_detector.temporal_performance_analysis(mock_performance)\n",
    "\n",
    "print(\"Temporal Contamination Analysis:\")\n",
    "print(\"===============================\\n\")\n",
    "\n",
    "for model, analysis in temporal_analysis.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"  Temporal Correlation: {analysis['temporal_correlation']:.3f}\")\n",
    "    print(f\"  Trend Slope: {analysis['trend_slope']:.3f}\")\n",
    "    print(f\"  Change Points: {len(analysis['change_points'])}\")\n",
    "    print(f\"  Contamination Risk: {analysis['contamination_risk']['risk_level']} ({analysis['contamination_risk']['total_score']:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Versioning and Provenance Tracking\n",
    "\n",
    "### Building Robust Dataset Management Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional, Union\n",
    "from enum import Enum\n",
    "import sqlite3\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "class ChangeType(Enum):\n",
    "    \"\"\"Types of changes in dataset\"\"\"\n",
    "    ADDITION = \"addition\"\n",
    "    MODIFICATION = \"modification\"\n",
    "    REMOVAL = \"removal\"\n",
    "    SPLIT_UPDATE = \"split_update\"\n",
    "    METADATA_UPDATE = \"metadata_update\"\n",
    "\n",
    "@dataclass\n",
    "class DatasetChange:\n",
    "    \"\"\"Record of a change to the dataset\"\"\"\n",
    "    change_id: str\n",
    "    timestamp: datetime\n",
    "    change_type: ChangeType\n",
    "    affected_items: List[str]  # Problem IDs\n",
    "    description: str\n",
    "    author: str\n",
    "    checksum_before: Optional[str]\n",
    "    checksum_after: str\n",
    "    metadata: Dict\n",
    "\n",
    "@dataclass \n",
    "class DatasetVersion:\n",
    "    \"\"\"Complete dataset version\"\"\"\n",
    "    version_id: str\n",
    "    version_number: str\n",
    "    creation_date: datetime\n",
    "    description: str\n",
    "    total_problems: int\n",
    "    train_count: int\n",
    "    test_count: int\n",
    "    checksum: str\n",
    "    parent_version: Optional[str]\n",
    "    changes_since_parent: List[str]  # Change IDs\n",
    "    contamination_score: float\n",
    "    quality_metrics: Dict\n",
    "\n",
    "class DatasetVersionControl:\n",
    "    \"\"\"Complete version control system for temporal datasets\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \":memory:\"):\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.similarity_detector = ProblemSimilarityDetector()\n",
    "        self.contamination_detector = StatisticalContaminationDetector()\n",
    "        self._init_database()\n",
    "        \n",
    "    def _init_database(self):\n",
    "        \"\"\"Initialize database schema\"\"\"\n",
    "        self.conn.executescript(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS problems (\n",
    "            id TEXT PRIMARY KEY,\n",
    "            title TEXT,\n",
    "            description TEXT,\n",
    "            solution_code TEXT,\n",
    "            test_cases BLOB,\n",
    "            release_date TEXT,\n",
    "            difficulty TEXT,\n",
    "            tags TEXT,\n",
    "            source_platform TEXT,\n",
    "            checksum TEXT,\n",
    "            created_at TEXT,\n",
    "            updated_at TEXT\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS dataset_versions (\n",
    "            version_id TEXT PRIMARY KEY,\n",
    "            version_number TEXT,\n",
    "            creation_date TEXT,\n",
    "            description TEXT,\n",
    "            total_problems INTEGER,\n",
    "            train_count INTEGER,\n",
    "            test_count INTEGER,\n",
    "            checksum TEXT,\n",
    "            parent_version TEXT,\n",
    "            contamination_score REAL,\n",
    "            quality_metrics BLOB\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS dataset_changes (\n",
    "            change_id TEXT PRIMARY KEY,\n",
    "            timestamp TEXT,\n",
    "            change_type TEXT,\n",
    "            affected_items BLOB,\n",
    "            description TEXT,\n",
    "            author TEXT,\n",
    "            checksum_before TEXT,\n",
    "            checksum_after TEXT,\n",
    "            metadata BLOB\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS version_changes (\n",
    "            version_id TEXT,\n",
    "            change_id TEXT,\n",
    "            PRIMARY KEY (version_id, change_id)\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS similarity_cache (\n",
    "            problem1_id TEXT,\n",
    "            problem2_id TEXT,\n",
    "            similarity_score REAL,\n",
    "            computed_at TEXT,\n",
    "            PRIMARY KEY (problem1_id, problem2_id)\n",
    "        );\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def add_problem(self, problem: Problem, author: str = \"system\") -> str:\n",
    "        \"\"\"Add a new problem and track the change\"\"\"\n",
    "        # Calculate checksum\n",
    "        problem_data = f\"{problem.title}{problem.description}{problem.solution_code}\"\n",
    "        checksum = hashlib.sha256(problem_data.encode()).hexdigest()\n",
    "        \n",
    "        # Check for duplicates\n",
    "        existing = self._find_similar_problems(problem)\n",
    "        if existing:\n",
    "            print(f\"Warning: Similar problems found: {[p['id'] for p in existing]}\")\n",
    "        \n",
    "        # Insert problem\n",
    "        now = datetime.now().isoformat()\n",
    "        test_cases_blob = gzip.compress(pickle.dumps(problem.test_cases))\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "        INSERT INTO problems \n",
    "        (id, title, description, solution_code, test_cases, release_date, \n",
    "         difficulty, tags, source_platform, checksum, created_at, updated_at)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            problem.id, problem.title, problem.description, problem.solution_code,\n",
    "            test_cases_blob, problem.release_date.isoformat(),\n",
    "            problem.difficulty, json.dumps(problem.tags), problem.source_platform,\n",
    "            checksum, now, now\n",
    "        ))\n",
    "        \n",
    "        # Record change\n",
    "        change = DatasetChange(\n",
    "            change_id=str(uuid.uuid4()),\n",
    "            timestamp=datetime.now(),\n",
    "            change_type=ChangeType.ADDITION,\n",
    "            affected_items=[problem.id],\n",
    "            description=f\"Added problem: {problem.title}\",\n",
    "            author=author,\n",
    "            checksum_before=None,\n",
    "            checksum_after=self._calculate_dataset_checksum(),\n",
    "            metadata={'similarity_warnings': len(existing)}\n",
    "        )\n",
    "        \n",
    "        self._record_change(change)\n",
    "        self.conn.commit()\n",
    "        \n",
    "        return change.change_id\n",
    "    \n",
    "    def _find_similar_problems(self, problem: Problem, threshold: float = 0.8) -> List[Dict]:\n",
    "        \"\"\"Find similar problems in database\"\"\"\n",
    "        # Get all existing problems\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT id, title, description, solution_code, release_date, difficulty, tags FROM problems\"\n",
    "        )\n",
    "        \n",
    "        similar_problems = []\n",
    "        for row in cursor.fetchall():\n",
    "            existing = Problem(\n",
    "                id=row[0], title=row[1], description=row[2], solution_code=row[3],\n",
    "                test_cases=[], release_date=datetime.fromisoformat(row[4]),\n",
    "                difficulty=row[5], tags=json.loads(row[6]),\n",
    "                source_platform=\"unknown\"\n",
    "            )\n",
    "            \n",
    "            # Calculate similarity\n",
    "            similarity = self._calculate_problem_similarity(problem, existing)\n",
    "            \n",
    "            if similarity > threshold:\n",
    "                similar_problems.append({\n",
    "                    'id': existing.id,\n",
    "                    'title': existing.title,\n",
    "                    'similarity': similarity\n",
    "                })\n",
    "        \n",
    "        return similar_problems\n",
    "    \n",
    "    def _calculate_problem_similarity(self, problem1: Problem, problem2: Problem) -> float:\n",
    "        \"\"\"Calculate similarity between two problems\"\"\"\n",
    "        # Use cached similarity if available\n",
    "        cache_key = tuple(sorted([problem1.id, problem2.id]))\n",
    "        \n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT similarity_score FROM similarity_cache WHERE problem1_id=? AND problem2_id=?\",\n",
    "            cache_key\n",
    "        )\n",
    "        cached = cursor.fetchone()\n",
    "        \n",
    "        if cached:\n",
    "            return cached[0]\n",
    "        \n",
    "        # Calculate similarity\n",
    "        similarity_matrix = self.similarity_detector.calculate_similarity_matrix([problem1, problem2])\n",
    "        similarity = similarity_matrix[0, 1]\n",
    "        \n",
    "        # Cache result\n",
    "        self.conn.execute(\n",
    "            \"INSERT OR REPLACE INTO similarity_cache VALUES (?, ?, ?, ?)\",\n",
    "            (cache_key[0], cache_key[1], similarity, datetime.now().isoformat())\n",
    "        )\n",
    "        \n",
    "        return similarity\n",
    "    \n",
    "    def create_version(self, version_number: str, description: str, \n",
    "                      cutoff_date: Optional[datetime] = None,\n",
    "                      author: str = \"system\") -> str:\n",
    "        \"\"\"Create a new dataset version with temporal split\"\"\"\n",
    "        version_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Get current dataset state\n",
    "        cursor = self.conn.execute(\"SELECT COUNT(*) FROM problems\")\n",
    "        total_problems = cursor.fetchone()[0]\n",
    "        \n",
    "        # Calculate train/test split\n",
    "        if cutoff_date:\n",
    "            cursor = self.conn.execute(\n",
    "                \"SELECT COUNT(*) FROM problems WHERE release_date < ?\",\n",
    "                (cutoff_date.isoformat(),)\n",
    "            )\n",
    "            train_count = cursor.fetchone()[0]\n",
    "            test_count = total_problems - train_count\n",
    "        else:\n",
    "            # Default 80/20 split\n",
    "            train_count = int(total_problems * 0.8)\n",
    "            test_count = total_problems - train_count\n",
    "        \n",
    "        # Calculate quality metrics\n",
    "        quality_metrics = self._calculate_version_quality_metrics(cutoff_date)\n",
    "        \n",
    "        # Calculate contamination score\n",
    "        contamination_score = self._calculate_version_contamination_score()\n",
    "        \n",
    "        # Get parent version\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT version_id FROM dataset_versions ORDER BY creation_date DESC LIMIT 1\"\n",
    "        )\n",
    "        parent = cursor.fetchone()\n",
    "        parent_version = parent[0] if parent else None\n",
    "        \n",
    "        # Calculate dataset checksum\n",
    "        checksum = self._calculate_dataset_checksum()\n",
    "        \n",
    "        # Create version\n",
    "        version = DatasetVersion(\n",
    "            version_id=version_id,\n",
    "            version_number=version_number,\n",
    "            creation_date=datetime.now(),\n",
    "            description=description,\n",
    "            total_problems=total_problems,\n",
    "            train_count=train_count,\n",
    "            test_count=test_count,\n",
    "            checksum=checksum,\n",
    "            parent_version=parent_version,\n",
    "            changes_since_parent=[],\n",
    "            contamination_score=contamination_score,\n",
    "            quality_metrics=quality_metrics\n",
    "        )\n",
    "        \n",
    "        # Insert version\n",
    "        quality_blob = gzip.compress(pickle.dumps(quality_metrics))\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "        INSERT INTO dataset_versions\n",
    "        (version_id, version_number, creation_date, description, total_problems,\n",
    "         train_count, test_count, checksum, parent_version, contamination_score, quality_metrics)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            version.version_id, version.version_number, version.creation_date.isoformat(),\n",
    "            version.description, version.total_problems, version.train_count,\n",
    "            version.test_count, version.checksum, version.parent_version,\n",
    "            version.contamination_score, quality_blob\n",
    "        ))\n",
    "        \n",
    "        self.conn.commit()\n",
    "        return version_id\n",
    "    \n",
    "    def _calculate_dataset_checksum(self) -> str:\n",
    "        \"\"\"Calculate checksum of entire dataset\"\"\"\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT checksum FROM problems ORDER BY id\"\n",
    "        )\n",
    "        checksums = [row[0] for row in cursor.fetchall()]\n",
    "        combined = ''.join(checksums)\n",
    "        return hashlib.sha256(combined.encode()).hexdigest()\n",
    "    \n",
    "    def _calculate_version_quality_metrics(self, cutoff_date: Optional[datetime]) -> Dict:\n",
    "        \"\"\"Calculate quality metrics for version\"\"\"\n",
    "        metrics = {\n",
    "            'duplicate_pairs': 0,\n",
    "            'high_similarity_pairs': 0,\n",
    "            'temporal_coverage_days': 0,\n",
    "            'difficulty_distribution': {},\n",
    "            'tag_diversity': 0\n",
    "        }\n",
    "        \n",
    "        # Get all problems\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT id, release_date, difficulty, tags FROM problems\"\n",
    "        )\n",
    "        problems = cursor.fetchall()\n",
    "        \n",
    "        if not problems:\n",
    "            return metrics\n",
    "        \n",
    "        # Calculate temporal coverage\n",
    "        dates = [datetime.fromisoformat(p[1]) for p in problems]\n",
    "        metrics['temporal_coverage_days'] = (max(dates) - min(dates)).days\n",
    "        \n",
    "        # Difficulty distribution\n",
    "        difficulties = [p[2] for p in problems]\n",
    "        metrics['difficulty_distribution'] = dict(pd.Series(difficulties).value_counts())\n",
    "        \n",
    "        # Tag diversity\n",
    "        all_tags = set()\n",
    "        for p in problems:\n",
    "            tags = json.loads(p[3])\n",
    "            all_tags.update(tags)\n",
    "        metrics['tag_diversity'] = len(all_tags)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_version_contamination_score(self) -> float:\n",
    "        \"\"\"Calculate contamination risk score for version\"\"\"\n",
    "        # Get similarity matrix for all problems\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT AVG(similarity_score) FROM similarity_cache WHERE similarity_score > 0.8\"\n",
    "        )\n",
    "        high_sim_avg = cursor.fetchone()[0] or 0\n",
    "        \n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT COUNT(*) FROM similarity_cache WHERE similarity_score > 0.9\"\n",
    "        )\n",
    "        very_high_sim_count = cursor.fetchone()[0] or 0\n",
    "        \n",
    "        # Simple contamination score (0-1)\n",
    "        contamination_score = min(1.0, (high_sim_avg * 0.5) + (very_high_sim_count * 0.1))\n",
    "        \n",
    "        return contamination_score\n",
    "    \n",
    "    def _record_change(self, change: DatasetChange):\n",
    "        \"\"\"Record a change in the database\"\"\"\n",
    "        affected_blob = gzip.compress(pickle.dumps(change.affected_items))\n",
    "        metadata_blob = gzip.compress(pickle.dumps(change.metadata))\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "        INSERT INTO dataset_changes\n",
    "        (change_id, timestamp, change_type, affected_items, description,\n",
    "         author, checksum_before, checksum_after, metadata)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            change.change_id, change.timestamp.isoformat(), change.change_type.value,\n",
    "            affected_blob, change.description, change.author,\n",
    "            change.checksum_before, change.checksum_after, metadata_blob\n",
    "        ))\n",
    "    \n",
    "    def get_version_history(self) -> pd.DataFrame:\n",
    "        \"\"\"Get version history with quality metrics\"\"\"\n",
    "        cursor = self.conn.execute(\"\"\"\n",
    "        SELECT version_number, creation_date, description, total_problems,\n",
    "               train_count, test_count, contamination_score\n",
    "        FROM dataset_versions\n",
    "        ORDER BY creation_date\n",
    "        \"\"\")\n",
    "        \n",
    "        columns = ['Version', 'Date', 'Description', 'Total', 'Train', 'Test', 'Contamination']\n",
    "        return pd.DataFrame(cursor.fetchall(), columns=columns)\n",
    "    \n",
    "    def audit_contamination_risk(self, version_id: Optional[str] = None) -> Dict:\n",
    "        \"\"\"Comprehensive contamination risk audit\"\"\"\n",
    "        # Get high similarity pairs\n",
    "        cursor = self.conn.execute(\"\"\"\n",
    "        SELECT problem1_id, problem2_id, similarity_score\n",
    "        FROM similarity_cache\n",
    "        WHERE similarity_score > 0.8\n",
    "        ORDER BY similarity_score DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        high_sim_pairs = cursor.fetchall()\n",
    "        \n",
    "        # Get temporal distribution\n",
    "        cursor = self.conn.execute(\n",
    "            \"SELECT release_date, COUNT(*) FROM problems GROUP BY release_date ORDER BY release_date\"\n",
    "        )\n",
    "        temporal_dist = cursor.fetchall()\n",
    "        \n",
    "        audit_result = {\n",
    "            'high_similarity_pairs': len(high_sim_pairs),\n",
    "            'max_similarity': max([pair[2] for pair in high_sim_pairs]) if high_sim_pairs else 0,\n",
    "            'temporal_gaps': self._detect_temporal_gaps(temporal_dist),\n",
    "            'risk_recommendations': self._generate_risk_recommendations(high_sim_pairs)\n",
    "        }\n",
    "        \n",
    "        return audit_result\n",
    "    \n",
    "    def _detect_temporal_gaps(self, temporal_dist: List[Tuple]) -> List[Dict]:\n",
    "        \"\"\"Detect suspicious gaps in temporal distribution\"\"\"\n",
    "        if len(temporal_dist) < 2:\n",
    "            return []\n",
    "        \n",
    "        gaps = []\n",
    "        for i in range(len(temporal_dist) - 1):\n",
    "            date1 = datetime.fromisoformat(temporal_dist[i][0])\n",
    "            date2 = datetime.fromisoformat(temporal_dist[i+1][0])\n",
    "            gap_days = (date2 - date1).days\n",
    "            \n",
    "            if gap_days > 30:  # Gap larger than 30 days\n",
    "                gaps.append({\n",
    "                    'start_date': date1.isoformat(),\n",
    "                    'end_date': date2.isoformat(),\n",
    "                    'gap_days': gap_days\n",
    "                })\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def _generate_risk_recommendations(self, high_sim_pairs: List[Tuple]) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on contamination risk\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if len(high_sim_pairs) > 10:\n",
    "            recommendations.append(\"HIGH RISK: Many similar problems detected. Consider manual review.\")\n",
    "        \n",
    "        very_high_sim = [p for p in high_sim_pairs if p[2] > 0.95]\n",
    "        if very_high_sim:\n",
    "            recommendations.append(f\"CRITICAL: {len(very_high_sim)} near-duplicate problems found.\")\n",
    "        \n",
    "        if len(high_sim_pairs) > 0:\n",
    "            recommendations.append(\"Review similar problems for potential contamination.\")\n",
    "            recommendations.append(\"Consider increasing temporal split buffer.\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Test the version control system\n",
    "print(\"Dataset Version Control System Demo:\")\n",
    "print(\"===================================\\n\")\n",
    "\n",
    "# Initialize version control\n",
    "vcs = DatasetVersionControl()\n",
    "\n",
    "# Add some problems\n",
    "problems = create_mock_problems()\n",
    "for problem in problems:\n",
    "    change_id = vcs.add_problem(problem, author=\"demo_user\")\n",
    "    print(f\"Added problem {problem.id} (change: {change_id[:8]}...)\")\n",
    "\n",
    "# Create a version\n",
    "version_id = vcs.create_version(\n",
    "    version_number=\"v1.0.0\",\n",
    "    description=\"Initial dataset version\",\n",
    "    cutoff_date=datetime(2024, 7, 1)\n",
    ")\n",
    "print(f\"\\nCreated version v1.0.0 (ID: {version_id[:8]}...)\")\n",
    "\n",
    "# Get version history\n",
    "history = vcs.get_version_history()\n",
    "print(\"\\nVersion History:\")\n",
    "print(history.to_string(index=False))\n",
    "\n",
    "# Audit contamination risk\n",
    "audit = vcs.audit_contamination_risk()\n",
    "print(\"\\nContamination Risk Audit:\")\n",
    "print(f\"High similarity pairs: {audit['high_similarity_pairs']}\")\n",
    "print(f\"Max similarity: {audit['max_similarity']:.3f}\")\n",
    "print(\"Recommendations:\")\n",
    "for rec in audit['risk_recommendations']:\n",
    "    print(f\"  - {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Visualization and Monitoring\n",
    "\n",
    "### Real-time Contamination Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContaminationMonitoringDashboard:\n",
    "    \"\"\"Advanced dashboard for monitoring contamination in real-time\"\"\"\n",
    "    \n",
    "    def __init__(self, vcs: DatasetVersionControl):\n",
    "        self.vcs = vcs\n",
    "        \n",
    "    def create_comprehensive_dashboard(self, mock_performance: pd.DataFrame):\n",
    "        \"\"\"Create comprehensive contamination monitoring dashboard\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # Create grid layout\n",
    "        gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Similarity Matrix Heatmap (top-left)\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        self._plot_similarity_heatmap(ax1)\n",
    "        \n",
    "        # 2. Temporal Performance Trends (top-right)\n",
    "        ax2 = fig.add_subplot(gs[0, 2:])\n",
    "        self._plot_temporal_trends(ax2, mock_performance)\n",
    "        \n",
    "        # 3. Score Distribution Analysis (middle-left)\n",
    "        ax3 = fig.add_subplot(gs[1, :2])\n",
    "        self._plot_score_distributions(ax3, mock_performance)\n",
    "        \n",
    "        # 4. Contamination Risk Gauge (middle-right)\n",
    "        ax4 = fig.add_subplot(gs[1, 2:])\n",
    "        self._plot_contamination_gauge(ax4)\n",
    "        \n",
    "        # 5. Problem Release Timeline (bottom-left)\n",
    "        ax5 = fig.add_subplot(gs[2, :2])\n",
    "        self._plot_release_timeline(ax5)\n",
    "        \n",
    "        # 6. Quality Metrics Over Time (bottom-right)\n",
    "        ax6 = fig.add_subplot(gs[2, 2:])\n",
    "        self._plot_quality_metrics(ax6)\n",
    "        \n",
    "        # 7. Alert Summary (bottom)\n",
    "        ax7 = fig.add_subplot(gs[3, :])\n",
    "        self._plot_alert_summary(ax7)\n",
    "        \n",
    "        plt.suptitle('Contamination Monitoring Dashboard', fontsize=20, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_similarity_heatmap(self, ax):\n",
    "        \"\"\"Plot similarity heatmap of problems\"\"\"\n",
    "        # Get similarity data from cache\n",
    "        cursor = self.vcs.conn.execute(\n",
    "            \"SELECT problem1_id, problem2_id, similarity_score FROM similarity_cache\"\n",
    "        )\n",
    "        similarity_data = cursor.fetchall()\n",
    "        \n",
    "        if not similarity_data:\n",
    "            ax.text(0.5, 0.5, 'No similarity data available', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title('Problem Similarity Matrix')\n",
    "            return\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        problem_ids = list(set([d[0] for d in similarity_data] + [d[1] for d in similarity_data]))\n",
    "        n = len(problem_ids)\n",
    "        similarity_matrix = np.eye(n)\n",
    "        \n",
    "        id_to_idx = {pid: i for i, pid in enumerate(problem_ids)}\n",
    "        \n",
    "        for p1, p2, sim in similarity_data:\n",
    "            i, j = id_to_idx[p1], id_to_idx[p2]\n",
    "            similarity_matrix[i, j] = similarity_matrix[j, i] = sim\n",
    "        \n",
    "        # Plot heatmap\n",
    "        im = ax.imshow(similarity_matrix, cmap='Reds', vmin=0, vmax=1)\n",
    "        ax.set_title('Problem Similarity Matrix')\n",
    "        ax.set_xlabel('Problems')\n",
    "        ax.set_ylabel('Problems')\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax, shrink=0.6)\n",
    "        \n",
    "        # Highlight high similarity\n",
    "        high_sim_coords = np.where(similarity_matrix > 0.8)\n",
    "        for i, j in zip(high_sim_coords[0], high_sim_coords[1]):\n",
    "            if i != j:  # Don't highlight diagonal\n",
    "                ax.add_patch(plt.Rectangle((j-0.5, i-0.5), 1, 1, \n",
    "                                         fill=False, edgecolor='yellow', linewidth=2))\n",
    "    \n",
    "    def _plot_temporal_trends(self, ax, performance_data):\n",
    "        \"\"\"Plot temporal performance trends\"\"\"\n",
    "        for model in performance_data['model'].unique():\n",
    "            model_data = performance_data[performance_data['model'] == model]\n",
    "            model_data = model_data.sort_values('release_date')\n",
    "            \n",
    "            ax.plot(model_data['release_date'], model_data['score'], \n",
    "                   marker='o', label=model, alpha=0.7)\n",
    "        \n",
    "        ax.set_title('Performance Trends Over Time')\n",
    "        ax.set_xlabel('Release Date')\n",
    "        ax.set_ylabel('Performance Score')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add contamination warning zone\n",
    "        ax.axhline(y=performance_data['score'].mean() - 2*performance_data['score'].std(), \n",
    "                  color='red', linestyle='--', alpha=0.5, label='Warning Threshold')\n",
    "    \n",
    "    def _plot_score_distributions(self, ax, performance_data):\n",
    "        \"\"\"Plot score distributions for contamination detection\"\"\"\n",
    "        models = performance_data['model'].unique()\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            scores = performance_data[performance_data['model'] == model]['score']\n",
    "            ax.hist(scores, bins=15, alpha=0.6, label=model, \n",
    "                   density=True, histtype='stepfilled')\n",
    "        \n",
    "        ax.set_title('Score Distribution Analysis')\n",
    "        ax.set_xlabel('Performance Score')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add bimodality indicators\n",
    "        for model in models:\n",
    "            scores = performance_data[performance_data['model'] == model]['score']\n",
    "            if len(scores) > 10:\n",
    "                # Simple bimodality test\n",
    "                hist, bins = np.histogram(scores, bins=10)\n",
    "                peaks = []\n",
    "                for i in range(1, len(hist)-1):\n",
    "                    if hist[i] > hist[i-1] and hist[i] > hist[i+1]:\n",
    "                        peaks.append(bins[i])\n",
    "                \n",
    "                if len(peaks) >= 2:\n",
    "                    ax.axvline(x=scores.mean(), color='red', linestyle=':', \n",
    "                             alpha=0.8, label=f'{model} Bimodal Warning')\n",
    "    \n",
    "    def _plot_contamination_gauge(self, ax):\n",
    "        \"\"\"Plot contamination risk gauge\"\"\"\n",
    "        # Get latest contamination score\n",
    "        cursor = self.vcs.conn.execute(\n",
    "            \"SELECT contamination_score FROM dataset_versions ORDER BY creation_date DESC LIMIT 1\"\n",
    "        )\n",
    "        result = cursor.fetchone()\n",
    "        contamination_score = result[0] if result else 0\n",
    "        \n",
    "        # Create gauge\n",
    "        theta = np.linspace(0, np.pi, 100)\n",
    "        \n",
    "        # Background arc\n",
    "        ax.plot(theta, np.ones_like(theta), 'k-', linewidth=10, alpha=0.3)\n",
    "        \n",
    "        # Risk zones\n",
    "        low_zone = theta[theta <= np.pi * 0.33]\n",
    "        medium_zone = theta[(theta > np.pi * 0.33) & (theta <= np.pi * 0.66)]\n",
    "        high_zone = theta[theta > np.pi * 0.66]\n",
    "        \n",
    "        ax.plot(low_zone, np.ones_like(low_zone), 'g-', linewidth=10, alpha=0.7, label='Low Risk')\n",
    "        ax.plot(medium_zone, np.ones_like(medium_zone), 'y-', linewidth=10, alpha=0.7, label='Medium Risk')\n",
    "        ax.plot(high_zone, np.ones_like(high_zone), 'r-', linewidth=10, alpha=0.7, label='High Risk')\n",
    "        \n",
    "        # Needle\n",
    "        needle_angle = contamination_score * np.pi\n",
    "        ax.arrow(0, 0, np.cos(needle_angle) * 0.8, np.sin(needle_angle) * 0.8,\n",
    "                head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
    "        \n",
    "        ax.set_xlim(-1.2, 1.2)\n",
    "        ax.set_ylim(-0.2, 1.2)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Contamination Risk: {contamination_score:.2f}')\n",
    "        \n",
    "        # Add score text\n",
    "        ax.text(0, -0.1, f'{contamination_score:.3f}', ha='center', va='center', \n",
    "               fontsize=16, fontweight='bold')\n",
    "    \n",
    "    def _plot_release_timeline(self, ax):\n",
    "        \"\"\"Plot problem release timeline\"\"\"\n",
    "        cursor = self.vcs.conn.execute(\n",
    "            \"SELECT release_date, difficulty FROM problems ORDER BY release_date\"\n",
    "        )\n",
    "        problems = cursor.fetchall()\n",
    "        \n",
    "        if not problems:\n",
    "            ax.text(0.5, 0.5, 'No problems in database', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title('Problem Release Timeline')\n",
    "            return\n",
    "        \n",
    "        dates = [datetime.fromisoformat(p[0]) for p in problems]\n",
    "        difficulties = [p[1] for p in problems]\n",
    "        \n",
    "        # Color mapping\n",
    "        color_map = {'Easy': 'green', 'Medium': 'orange', 'Hard': 'red'}\n",
    "        colors = [color_map.get(d, 'blue') for d in difficulties]\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(dates, range(len(dates)), c=colors, alpha=0.7, s=50)\n",
    "        \n",
    "        ax.set_title('Problem Release Timeline')\n",
    "        ax.set_xlabel('Release Date')\n",
    "        ax.set_ylabel('Problem Index')\n",
    "        \n",
    "        # Add legend\n",
    "        for difficulty, color in color_map.items():\n",
    "            ax.scatter([], [], c=color, label=difficulty, s=50)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    def _plot_quality_metrics(self, ax):\n",
    "        \"\"\"Plot quality metrics over time\"\"\"\n",
    "        cursor = self.vcs.conn.execute(\n",
    "            \"SELECT creation_date, total_problems, contamination_score FROM dataset_versions ORDER BY creation_date\"\n",
    "        )\n",
    "        versions = cursor.fetchall()\n",
    "        \n",
    "        if not versions:\n",
    "            ax.text(0.5, 0.5, 'No versions available', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title('Quality Metrics Over Time')\n",
    "            return\n",
    "        \n",
    "        dates = [datetime.fromisoformat(v[0]) for v in versions]\n",
    "        total_problems = [v[1] for v in versions]\n",
    "        contamination_scores = [v[2] for v in versions]\n",
    "        \n",
    "        # Dual y-axis plot\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        line1 = ax.plot(dates, total_problems, 'b-o', label='Total Problems')\n",
    "        line2 = ax2.plot(dates, contamination_scores, 'r-s', label='Contamination Score')\n",
    "        \n",
    "        ax.set_xlabel('Version Date')\n",
    "        ax.set_ylabel('Total Problems', color='b')\n",
    "        ax2.set_ylabel('Contamination Score', color='r')\n",
    "        ax.set_title('Dataset Quality Metrics')\n",
    "        \n",
    "        # Combine legends\n",
    "        lines = line1 + line2\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax.legend(lines, labels, loc='upper left')\n",
    "    \n",
    "    def _plot_alert_summary(self, ax):\n",
    "        \"\"\"Plot alert summary\"\"\"\n",
    "        # Get contamination audit\n",
    "        audit = self.vcs.audit_contamination_risk()\n",
    "        \n",
    "        # Create alert summary\n",
    "        alerts = {\n",
    "            'High Similarity Pairs': audit['high_similarity_pairs'],\n",
    "            'Max Similarity': f\"{audit['max_similarity']:.3f}\",\n",
    "            'Temporal Gaps': len(audit['temporal_gaps']),\n",
    "            'Risk Level': 'HIGH' if audit['max_similarity'] > 0.9 else 'MEDIUM' if audit['max_similarity'] > 0.8 else 'LOW'\n",
    "        }\n",
    "        \n",
    "        # Create table\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Alert table\n",
    "        table_data = [[k, str(v)] for k, v in alerts.items()]\n",
    "        table = ax.table(cellText=table_data,\n",
    "                        colLabels=['Alert Type', 'Value'],\n",
    "                        cellLoc='center',\n",
    "                        loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1, 2)\n",
    "        \n",
    "        # Color code by risk\n",
    "        if alerts['Risk Level'] == 'HIGH':\n",
    "            table[(4, 1)].set_facecolor('#ffcccc')\n",
    "        elif alerts['Risk Level'] == 'MEDIUM':\n",
    "            table[(4, 1)].set_facecolor('#ffffcc')\n",
    "        else:\n",
    "            table[(4, 1)].set_facecolor('#ccffcc')\n",
    "        \n",
    "        ax.set_title('Contamination Alert Summary', pad=20)\n",
    "        \n",
    "        # Add recommendations\n",
    "        recommendations_text = \"\\n\".join(audit['risk_recommendations'][:3])\n",
    "        ax.text(0.5, 0.1, f\"Recommendations:\\n{recommendations_text}\", \n",
    "               ha='center', va='bottom', transform=ax.transAxes,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "# Create monitoring dashboard\n",
    "dashboard = ContaminationMonitoringDashboard(vcs)\n",
    "dashboard.create_comprehensive_dashboard(mock_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Implementation Guide\n",
    "\n",
    "### Complete Framework for Real-World Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionContaminationFramework:\n",
    "    \"\"\"Production-ready contamination detection and prevention framework\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.vcs = DatasetVersionControl(config.get('db_path', ':memory:'))\n",
    "        self.similarity_detector = ProblemSimilarityDetector()\n",
    "        self.stat_detector = StatisticalContaminationDetector()\n",
    "        self.monitoring_enabled = config.get('monitoring_enabled', True)\n",
    "        \n",
    "    def create_deployment_checklist(self) -> Dict:\n",
    "        \"\"\"Create comprehensive deployment checklist\"\"\"\n",
    "        checklist = {\n",
    "            'data_quality': {\n",
    "                'duplicate_detection': 'Configure similarity thresholds',\n",
    "                'temporal_validation': 'Set up temporal split validation',\n",
    "                'quality_metrics': 'Define quality metric baselines',\n",
    "                'automated_testing': 'Implement automated quality tests'\n",
    "            },\n",
    "            'contamination_prevention': {\n",
    "                'similarity_monitoring': 'Set up real-time similarity monitoring',\n",
    "                'temporal_analysis': 'Configure temporal trend analysis',\n",
    "                'statistical_tests': 'Implement statistical contamination tests',\n",
    "                'alert_system': 'Configure contamination alert system'\n",
    "            },\n",
    "            'version_control': {\n",
    "                'change_tracking': 'Enable comprehensive change tracking',\n",
    "                'version_tagging': 'Set up semantic versioning',\n",
    "                'rollback_capability': 'Implement version rollback',\n",
    "                'audit_logging': 'Enable full audit logging'\n",
    "            },\n",
    "            'monitoring': {\n",
    "                'dashboard_setup': 'Deploy monitoring dashboard',\n",
    "                'metric_collection': 'Configure metric collection',\n",
    "                'alert_rules': 'Set up alerting rules',\n",
    "                'reporting': 'Configure automated reporting'\n",
    "            },\n",
    "            'compliance': {\n",
    "                'data_provenance': 'Implement data provenance tracking',\n",
    "                'privacy_controls': 'Set up privacy controls',\n",
    "                'audit_trails': 'Ensure complete audit trails',\n",
    "                'documentation': 'Maintain comprehensive documentation'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return checklist\n",
    "    \n",
    "    def generate_implementation_code(self) -> Dict[str, str]:\n",
    "        \"\"\"Generate production-ready implementation code\"\"\"\n",
    "        \n",
    "        code_templates = {\n",
    "            'api_endpoint': '''\n",
    "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(title=\"Contamination Detection API\")\n\n@app.post(\"/detect-contamination\")\nasync def detect_contamination(problem_data: ProblemData):\n    \"\"\"Detect potential contamination in new problem\"\"\"\n    try:\n        # Initialize detector\n        detector = ProblemSimilarityDetector()\n        \n        # Check similarity with existing problems\n        similar_problems = detector.find_similar_problems(problem_data)\n        \n        # Calculate contamination risk\n        risk_score = detector.calculate_contamination_risk(similar_problems)\n        \n        return {\n            \"contamination_risk\": risk_score,\n            \"similar_problems\": similar_problems,\n            \"recommendation\": \"REJECT\" if risk_score > 0.8 else \"ACCEPT\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n''',\n            \n            'monitoring_job': '''\nimport schedule\nimport time\nfrom datetime import datetime\n\ndef run_contamination_monitoring():\n    \"\"\"Scheduled job for contamination monitoring\"\"\"\n    detector = StatisticalContaminationDetector()\n    \n    # Get recent performance data\n    performance_data = get_recent_performance_data()\n    \n    # Run contamination analysis\n    analysis = detector.temporal_performance_analysis(performance_data)\n    \n    # Check for alerts\n    for model, stats in analysis.items():\n        if stats['contamination_risk']['risk_level'] == 'HIGH':\n            send_alert(f\"HIGH contamination risk detected for {model}\")\n    \n    # Log results\n    log_monitoring_results(analysis)\n\n# Schedule monitoring\nschedule.every(1).hours.do(run_contamination_monitoring)\n\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n''',\n            \n            'data_pipeline': '''\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom datetime import datetime, timedelta\n\ndef validate_new_problems(**context):\n    \"\"\"Validate new problems for contamination\"\"\"\n    vcs = DatasetVersionControl()\n    new_problems = context['task_instance'].xcom_pull(task_ids='extract_problems')\n    \n    validated_problems = []\n    for problem in new_problems:\n        # Check similarity\n        similar = vcs.find_similar_problems(problem, threshold=0.8)\n        \n        if not similar:\n            validated_problems.append(problem)\n            vcs.add_problem(problem)\n        else:\n            log_rejected_problem(problem, similar)\n    \n    return validated_problems\n\ndag = DAG(\n    'contamination_prevention_pipeline',\n    default_args={\n        'owner': 'data-team',\n        'depends_on_past': False,\n        'start_date': datetime(2024, 1, 1),\n        'retries': 1,\n        'retry_delay': timedelta(minutes=5)\n    },\n    schedule_interval='@daily'\n)\n\nvalidate_task = PythonOperator(\n    task_id='validate_contamination',\n    python_callable=validate_new_problems,\n    dag=dag\n)\n'''\n        }\n        \n        return code_templates\n    \n    def create_testing_suite(self) -> Dict[str, str]:\n",
    "        \"\"\"Create comprehensive testing suite\"\"\"\n",
    "        \n",
    "        test_suite = {\n",
    "            'unit_tests': '''\nimport unittest\nfrom contamination_detector import ProblemSimilarityDetector\n\nclass TestContaminationDetection(unittest.TestCase):\n    \n    def setUp(self):\n        self.detector = ProblemSimilarityDetector()\n    \n    def test_similarity_calculation(self):\n        \"\"\"Test similarity calculation between problems\"\"\"\n        problem1 = create_mock_problem(\"problem1\")\n        problem2 = create_mock_problem(\"problem2\")\n        \n        similarity = self.detector.calculate_similarity(problem1, problem2)\n        \n        self.assertIsInstance(similarity, float)\n        self.assertGreaterEqual(similarity, 0)\n        self.assertLessEqual(similarity, 1)\n    \n    def test_contamination_detection(self):\n        \"\"\"Test contamination detection logic\"\"\"\n        # Test with high similarity (should detect contamination)\n        high_sim_problems = [create_similar_problems()]\n        risk = self.detector.calculate_contamination_risk(high_sim_problems)\n        self.assertGreater(risk, 0.8)\n        \n        # Test with low similarity (should not detect contamination)\n        low_sim_problems = [create_different_problems()]\n        risk = self.detector.calculate_contamination_risk(low_sim_problems)\n        self.assertLess(risk, 0.3)\n\nif __name__ == '__main__':\n    unittest.main()\n''',\n            \n            'integration_tests': '''\nimport pytest\nfrom contamination_framework import ProductionContaminationFramework\n\n@pytest.fixture\ndef framework():\n    config = {\n        'db_path': ':memory:',\n        'monitoring_enabled': True,\n        'similarity_threshold': 0.8\n    }\n    return ProductionContaminationFramework(config)\n\ndef test_end_to_end_workflow(framework):\n    \"\"\"Test complete contamination detection workflow\"\"\"\n    # Add initial problems\n    problems = create_test_problems(10)\n    for problem in problems:\n        framework.vcs.add_problem(problem)\n    \n    # Create version\n    version_id = framework.vcs.create_version(\"v1.0.0\", \"Test version\")\n    assert version_id is not None\n    \n    # Test contamination detection\n    new_problem = create_similar_problem(problems[0])\n    result = framework.detect_contamination(new_problem)\n    \n    assert result['contamination_risk'] > 0.8\n    assert result['recommendation'] == 'REJECT'\n\ndef test_performance_monitoring(framework):\n    \"\"\"Test performance monitoring functionality\"\"\"\n    # Create mock performance data\n    performance_data = create_mock_performance_data()\n    \n    # Run analysis\n    analysis = framework.stat_detector.temporal_performance_analysis(performance_data)\n    \n    assert 'CleanModel' in analysis\n    assert 'ContaminatedModel' in analysis\n    assert analysis['ContaminatedModel']['contamination_risk']['risk_level'] == 'HIGH'\n''',\n            \n            'load_tests': '''\nimport time\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_test_similarity_detection():\n    \"\"\"Load test similarity detection performance\"\"\"\n    detector = ProblemSimilarityDetector()\n    problems = create_test_problems(100)\n    \n    start_time = time.time()\n    \n    # Test with multiple threads\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        futures = []\n        for i in range(0, len(problems), 10):\n            batch = problems[i:i+10]\n            future = executor.submit(detector.calculate_similarity_matrix, batch)\n            futures.append(future)\n        \n        # Wait for all to complete\n        for future in futures:\n            future.result()\n    \n    end_time = time.time()\n    \n    print(f\"Processed {len(problems)} problems in {end_time - start_time:.2f} seconds\")\n    print(f\"Throughput: {len(problems) / (end_time - start_time):.2f} problems/second\")\n\nif __name__ == '__main__':\n    load_test_similarity_detection()\n'''\n        }\n        \n        return test_suite\n    \n    def generate_documentation(self) -> str:\n",
    "        \"\"\"Generate comprehensive documentation\"\"\"\n",
    "        \n",
    "        documentation = '''\n# Advanced Contamination Detection Framework\n\n## Overview\n\nThis framework provides comprehensive contamination detection and prevention for ML datasets, particularly focusing on temporal datasets used for LLM evaluation.\n\n## Key Features\n\n### 1. Multi-Dimensional Similarity Detection\n- Text similarity using TF-IDF and cosine similarity\n- Algorithmic pattern matching\n- Constraint signature analysis\n- Input/output pattern recognition\n- Code pattern detection\n\n### 2. Statistical Contamination Detection\n- Performance distribution analysis\n- Temporal trend analysis\n- Change point detection\n- Bimodality testing\n- Outlier detection\n\n### 3. Dataset Version Control\n- Complete change tracking\n- Checksums and integrity verification\n- Rollback capabilities\n- Quality metrics tracking\n- Contamination scoring\n\n### 4. Real-time Monitoring\n- Live contamination monitoring\n- Alert system\n- Dashboard visualization\n- Automated reporting\n\n## Usage Examples\n\n### Basic Setup\n```python\nfrom contamination_framework import ProductionContaminationFramework\n\n# Initialize framework\nconfig = {\n    'db_path': 'contamination.db',\n    'similarity_threshold': 0.8,\n    'monitoring_enabled': True\n}\nframework = ProductionContaminationFramework(config)\n```\n\n### Add Problems with Contamination Check\n```python\n# Add new problem\nproblem = Problem(...)\nresult = framework.add_problem_with_validation(problem)\n\nif result['accepted']:\n    print(\"Problem accepted\")\nelse:\n    print(f\"Problem rejected: {result['reason']}\")\n```\n\n### Monitor Performance\n```python\n# Get performance data\nperformance_data = get_model_performance()\n\n# Analyze for contamination\nanalysis = framework.analyze_contamination(performance_data)\n\nfor model, risk in analysis.items():\n    if risk['level'] == 'HIGH':\n        send_alert(f\"Contamination detected in {model}\")\n```\n\n## Configuration\n\n### Similarity Thresholds\n- `similarity_threshold`: 0.8 (default) - Problems above this similarity are flagged\n- `high_risk_threshold`: 0.95 - Problems above this are automatically rejected\n\n### Statistical Thresholds\n- `contamination_risk_threshold`: 0.7 - Performance patterns above this trigger alerts\n- `temporal_correlation_threshold`: -0.5 - Negative correlations below this are suspicious\n\n### Monitoring Settings\n- `monitoring_interval`: 3600 (1 hour) - How often to run contamination checks\n- `alert_cooldown`: 1800 (30 minutes) - Minimum time between similar alerts\n\n## Best Practices\n\n### 1. Data Ingestion\n- Always run similarity checks before adding new problems\n- Maintain proper temporal ordering\n- Validate all metadata\n- Use checksums for integrity\n\n### 2. Monitoring\n- Set up automated monitoring jobs\n- Configure appropriate alert thresholds\n- Regularly review contamination reports\n- Maintain audit logs\n\n### 3. Version Management\n- Create versions at regular intervals\n- Tag versions with semantic versioning\n- Maintain rollback capabilities\n- Document all changes\n\n## Troubleshooting\n\n### High False Positive Rate\n- Adjust similarity thresholds\n- Review algorithm keyword detection\n- Check constraint extraction logic\n\n### Performance Issues\n- Enable similarity caching\n- Use batch processing for large datasets\n- Consider distributed processing for very large datasets\n\n### Memory Usage\n- Use streaming for large similarity calculations\n- Implement data pagination\n- Clear caches periodically\n\n## API Reference\n\n[Detailed API documentation would follow...]\n        '''\n        \n        return documentation\n    \n    def create_deployment_plan(self) -> Dict:\n",
    "        \"\"\"Create detailed deployment plan\"\"\"\n",
    "        \n        plan = {\n            'phase_1_preparation': {\n                'duration': '1-2 weeks',\n                'tasks': [\n                    'Set up development environment',\n                    'Install dependencies',\n                    'Configure database',\n                    'Set up monitoring infrastructure',\n                    'Create test data'\n                ],\n                'deliverables': [\n                    'Development environment ready',\n                    'Database schema deployed',\n                    'Monitoring stack configured'\n                ]\n            },\n            'phase_2_implementation': {\n                'duration': '2-3 weeks',\n                'tasks': [\n                    'Implement core contamination detection',\n                    'Build similarity detection algorithms',\n                    'Create statistical analysis modules',\n                    'Develop version control system',\n                    'Build monitoring dashboard'\n                ],\n                'deliverables': [\n                    'Core framework implemented',\n                    'All detection algorithms working',\n                    'Dashboard deployed'\n                ]\n            },\n            'phase_3_testing': {\n                'duration': '1-2 weeks',\n                'tasks': [\n                    'Unit testing',\n                    'Integration testing',\n                    'Load testing',\n                    'Security testing',\n                    'User acceptance testing'\n                ],\n                'deliverables': [\n                    'All tests passing',\n                    'Performance validated',\n                    'Security cleared'\n                ]\n            },\n            'phase_4_deployment': {\n                'duration': '1 week',\n                'tasks': [\n                    'Production deployment',\n                    'Data migration',\n                    'Monitor configuration',\n                    'Alert setup',\n                    'Documentation delivery'\n                ],\n                'deliverables': [\n                    'System live in production',\n                    'Monitoring active',\n                    'Team trained'\n                ]\n            },\n            'phase_5_optimization': {\n                'duration': 'Ongoing',\n                'tasks': [\n                    'Performance optimization',\n                    'Threshold tuning',\n                    'Feature enhancements',\n                    'Regular maintenance'\n                ],\n                'deliverables': [\n                    'Optimized performance',\n                    'Regular reports',\n                    'Continuous improvements'\n                ]\n            }\n        }\n        \n        return plan\n\n# Create production framework demonstration\nproduction_config = {\n    'db_path': ':memory:',\n    'similarity_threshold': 0.8,\n    'monitoring_enabled': True,\n    'high_risk_threshold': 0.95,\n    'contamination_risk_threshold': 0.7\n}\n\nframework = ProductionContaminationFramework(production_config)\n\nprint(\"Production Framework Implementation Guide\")\nprint(\"=========================================\\n\")\n\n# Generate deployment checklist\nchecklist = framework.create_deployment_checklist()\nprint(\"Deployment Checklist:\")\nfor category, items in checklist.items():\n    print(f\"\\n{category.upper()}:\")\n    for item, description in items.items():\n        print(f\"  ☐ {item}: {description}\")\n\n# Generate implementation code\ncode_templates = framework.generate_implementation_code()\nprint(\"\\n\\nCode Templates Generated:\")\nfor template_name in code_templates.keys():\n    print(f\"  - {template_name}.py\")\n\n# Generate testing suite\ntest_suite = framework.create_testing_suite()\nprint(\"\\nTesting Suite Generated:\")\nfor test_type in test_suite.keys():\n    print(f\"  - {test_type}.py\")\n\n# Generate deployment plan\ndeployment_plan = framework.create_deployment_plan()\nprint(\"\\nDeployment Plan:\")\nfor phase, details in deployment_plan.items():\n    print(f\"\\n{phase.upper()} ({details['duration']}):\")\n    for task in details['tasks'][:3]:  # Show first 3 tasks\n        print(f\"  • {task}\")\n    if len(details['tasks']) > 3:\n        print(f\"  ... and {len(details['tasks']) - 3} more tasks\")\n\nprint(\"\\n\\n🎯 Framework ready for production deployment!\")\nprint(\"Complete documentation and code templates generated.\")\nprint(\"Follow the deployment plan for systematic implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways and Best Practices\n",
    "\n",
    "### Critical Insights Beyond the Paper:\n",
    "\n",
    "1. **Multi-Dimensional Contamination**: Simple temporal splits are insufficient - need text, algorithmic, and code pattern analysis\n",
    "2. **Statistical Detection Methods**: Performance distribution analysis reveals memorization patterns\n",
    "3. **Proactive Prevention**: Real-time similarity monitoring prevents contamination at ingestion\n",
    "4. **Version Control is Essential**: Complete audit trails and rollback capabilities are production requirements\n",
    "\n",
    "### Advanced Contamination Patterns:\n",
    "\n",
    "**Subtle Contamination Types:**\n",
    "- **Paraphrased Problems**: Same logic, different wording\n",
    "- **Cross-Platform Leakage**: LeetCode → CodeForces → AtCoder\n",
    "- **Synthetic Contamination**: Generated problems based on test sets\n",
    "- **Human Contamination**: Evaluator bias from known solutions\n",
    "\n",
    "**Detection Signatures:**\n",
    "- **Bimodal Performance**: Clear separation between \"seen\" and \"unseen\" problems\n",
    "- **Temporal Degradation**: Performance decline for post-training problems\n",
    "- **Outlier Clustering**: Unusually high scores on specific problem types\n",
    "- **Pattern Consistency**: Identical solution patterns across similar problems\n",
    "\n",
    "### Production Implementation Guidelines:\n",
    "\n",
    "1. **Similarity Thresholds**:\n",
    "   - Warning: 0.8+ similarity\n",
    "   - Rejection: 0.95+ similarity\n",
    "   - Manual review: 0.85-0.94 range\n",
    "\n",
    "2. **Statistical Monitoring**:\n",
    "   - Track temporal correlations < -0.5\n",
    "   - Monitor bimodality in score distributions\n",
    "   - Alert on performance degradation > 2 standard deviations\n",
    "\n",
    "3. **Version Control Requirements**:\n",
    "   - Immutable versions with checksums\n",
    "   - Complete change audit trails\n",
    "   - Rollback capabilities\n",
    "   - Quality metric tracking\n",
    "\n",
    "4. **Real-time Monitoring**:\n",
    "   - Hourly contamination checks\n",
    "   - Automated alert system\n",
    "   - Dashboard with risk gauges\n",
    "   - Regular audit reports\n",
    "\n",
    "### Research Extensions:\n",
    "\n",
    "1. **Cross-Modal Contamination**: Detection across code/text/image modalities\n",
    "2. **Adversarial Contamination**: Sophisticated contamination designed to evade detection\n",
    "3. **Federated Learning Contamination**: Detection in distributed training scenarios\n",
    "4. **Dynamic Threshold Adjustment**: AI-driven threshold optimization\n",
    "\n",
    "### Key Implementation Priorities:\n",
    "\n",
    "1. **Start with Similarity Detection**: Highest ROI for contamination prevention\n",
    "2. **Add Statistical Monitoring**: Critical for detecting memorization patterns\n",
    "3. **Implement Version Control**: Essential for audit and compliance\n",
    "4. **Build Monitoring Dashboard**: Enables proactive contamination management\n",
    "5. **Create Alert System**: Ensures rapid response to contamination events\n",
    "\n",
    "This advanced contamination detection framework goes far beyond the paper's basic temporal analysis, providing production-ready tools for comprehensive contamination prevention and detection in modern AI evaluation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}