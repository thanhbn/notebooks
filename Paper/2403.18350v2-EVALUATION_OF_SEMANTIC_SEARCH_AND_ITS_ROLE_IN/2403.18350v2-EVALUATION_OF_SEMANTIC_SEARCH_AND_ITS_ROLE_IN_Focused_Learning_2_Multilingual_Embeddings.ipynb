{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focused Learning 2: Multilingual Embedding Models for Arabic Semantic Search\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Understand the architecture and training of multilingual embedding models\n",
    "- Analyze how different models handle Arabic language characteristics\n",
    "- Compare embedding dimensions and their impact on performance\n",
    "- Implement custom embedding analysis and visualization tools\n",
    "- Explore asymmetric vs symmetric semantic search scenarios\n",
    "\n",
    "## ðŸ“š Paper Context\n",
    "**Section 3.3.1**: \"The success of semantic search ranking relies significantly on the caliber of encoders used; higher-quality encoders produce more detailed embedding vectors, which in turn enable more accurate evaluations of similarity between search queries and documents.\"\n",
    "\n",
    "**Models Evaluated in Paper**:\n",
    "1. **Paraphrase Multilingual MiniLM** (384D) - Clustering and semantic search focused\n",
    "2. **CMLM Multilingual** (768D) - Universal sentence encoder for 109 languages\n",
    "3. **Paraphrase Multilingual MPNet** (768D) - 50+ languages with high performance\n",
    "4. **Multilingual DistilBERT** (512D) - Efficient 15-language model\n",
    "5. **XLM-RoBERTa** (768D) - Trained on SNLI, MNLI, ANLI, XNLI\n",
    "\n",
    "## ðŸ” Why Embedding Quality Matters for Arabic\n",
    "Arabic presents unique challenges:\n",
    "- **Rich morphology**: One root can generate hundreds of word forms\n",
    "- **Dialectical variations**: MSA vs. regional dialects\n",
    "- **Right-to-left script**: Different text processing requirements\n",
    "- **Diacritics**: Optional marks that change meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸš€ Multilingual Embeddings Learning Environment Ready!\")\n",
    "print(f\"ðŸ”§ PyTorch available: {torch.cuda.is_available()}\")\n",
    "print(f\"ðŸ“Š All visualization libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Multilingual Embedding Models\n",
    "\n",
    "### Paper's Model Selection Rationale\n",
    "The paper chose these 5 models based on:\n",
    "- **Language coverage**: All support Arabic\n",
    "- **Architecture diversity**: Different transformer variants\n",
    "- **Embedding dimensions**: Range from 384 to 768 dimensions\n",
    "- **Training objectives**: Different pre-training tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualEmbeddingAnalyzer:\n",
    "    \"\"\"Comprehensive analysis tool for multilingual embedding models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Model configurations from the paper\n",
    "        self.models_config = {\n",
    "            'MiniLM': {\n",
    "                'name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "                'dimensions': 384,\n",
    "                'languages': '50+',\n",
    "                'focus': 'Clustering & Semantic Search',\n",
    "                'architecture': 'MiniLM'\n",
    "            },\n",
    "            'CMLM': {\n",
    "                'name': 'sentence-transformers/use-cmlm-multilingual',\n",
    "                'dimensions': 768,\n",
    "                'languages': '109',\n",
    "                'focus': 'Universal Sentence Encoding',\n",
    "                'architecture': 'LaBSE-based'\n",
    "            },\n",
    "            'MPNet': {\n",
    "                'name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "                'dimensions': 768,\n",
    "                'languages': '50+',\n",
    "                'focus': 'Paraphrase & Similarity',\n",
    "                'architecture': 'MPNet'\n",
    "            },\n",
    "            'DistilBERT': {\n",
    "                'name': 'sentence-transformers/distiluse-base-multilingual-cased-v1',\n",
    "                'dimensions': 512,\n",
    "                'languages': '15',\n",
    "                'focus': 'Efficient Processing',\n",
    "                'architecture': 'DistilBERT'\n",
    "            },\n",
    "            'XLM-RoBERTa': {\n",
    "                'name': 'symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli',\n",
    "                'dimensions': 768,\n",
    "                'languages': '12+',\n",
    "                'focus': 'Natural Language Inference',\n",
    "                'architecture': 'XLM-RoBERTa'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.loaded_models = {}\n",
    "        \n",
    "        # Arabic test sentences covering different linguistic phenomena\n",
    "        self.arabic_test_sentences = {\n",
    "            'customer_support': [\n",
    "                \"Ø£Ø­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©\",\n",
    "                \"Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ÙŠ\",\n",
    "                \"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±ØŸ\",\n",
    "                \"Ù„Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ\",\n",
    "                \"Ø£Ø±ÙŠØ¯ Ø¥Ù„ØºØ§Ø¡ Ø§Ø´ØªØ±Ø§ÙƒÙŠ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©\"\n",
    "            ],\n",
    "            'morphological_variants': [\n",
    "                \"ÙƒØªØ¨ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ø¬Ø¨Ù‡\",  # Root: Ùƒ-Øª-Ø¨ (write)\n",
    "                \"ÙŠÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¨ÙˆØ±Ø©\",  # Same root, different form\n",
    "                \"Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù…Ù‡Ø§Ø±Ø© Ù…Ù‡Ù…Ø©\",  # Nominal form\n",
    "                \"Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ù„ÙŠØ¦Ø© Ø¨Ø§Ù„ÙƒØªØ¨\",  # Place noun + plural\n",
    "                \"Ø§Ù„ÙƒØ§ØªØ¨ Ù…Ø´Ù‡ÙˆØ± Ø¬Ø¯Ø§Ù‹\"  # Agent noun\n",
    "            ],\n",
    "            'dialectal_variations': [\n",
    "                \"Ø£ÙŠÙ† Ø§Ù„Ø­Ù…Ø§Ù…ØŸ\",  # MSA (Modern Standard Arabic)\n",
    "                \"ÙˆÙŠÙ† Ø§Ù„Ø­Ù…Ø§Ù…ØŸ\",  # Levantine dialect\n",
    "                \"ÙÙŠÙ† Ø§Ù„Ø­Ù…Ø§Ù…ØŸ\",  # Egyptian dialect\n",
    "                \"Ø¥ÙŠØ´ Ø±Ø§ÙŠÙƒØŸ\",  # Levantine: \"What do you think?\"\n",
    "                \"Ø¥ÙŠÙ‡ Ø±Ø£ÙŠÙƒØŸ\"  # Egyptian: \"What do you think?\"\n",
    "            ],\n",
    "            'semantic_similarity': [\n",
    "                \"Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø³Ø±ÙŠØ¹Ø© Ø¬Ø¯Ø§Ù‹\",\n",
    "                \"Ø§Ù„Ù…Ø±ÙƒØ¨Ø© ØªØªØ­Ø±Ùƒ Ø¨Ø³Ø±Ø¹Ø© Ø¹Ø§Ù„ÙŠØ©\",\n",
    "                \"Ø§Ù„Ø¹Ø±Ø¨Ø© ØªØ³ÙŠØ± Ø¨ÙˆØªÙŠØ±Ø© Ø³Ø±ÙŠØ¹Ø©\",\n",
    "                \"Ø§Ù„Ø·Ø§Ø¦Ø±Ø© ØªØ­Ù„Ù‚ ÙÙŠ Ø§Ù„Ø³Ù…Ø§Ø¡\",\n",
    "                \"Ø§Ù„Ù‚Ø·Ø§Ø± ÙŠØ³ÙŠØ± Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø¶Ø¨Ø§Ù†\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def load_model(self, model_key: str) -> SentenceTransformer:\n",
    "        \"\"\"Load and cache a specific model\"\"\"\n",
    "        if model_key not in self.loaded_models:\n",
    "            print(f\"ðŸ”„ Loading {model_key}...\")\n",
    "            model_name = self.models_config[model_key]['name']\n",
    "            try:\n",
    "                self.loaded_models[model_key] = SentenceTransformer(model_name)\n",
    "                print(f\"âœ… {model_key} loaded successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed to load {model_key}: {e}\")\n",
    "                return None\n",
    "        return self.loaded_models[model_key]\n",
    "    \n",
    "    def get_model_info_df(self) -> pd.DataFrame:\n",
    "        \"\"\"Create a DataFrame with model information\"\"\"\n",
    "        data = []\n",
    "        for key, config in self.models_config.items():\n",
    "            data.append({\n",
    "                'Model': key,\n",
    "                'Dimensions': config['dimensions'],\n",
    "                'Languages': config['languages'],\n",
    "                'Focus': config['focus'],\n",
    "                'Architecture': config['architecture']\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def analyze_embedding_spaces(self, model_keys: List[str] = None) -> Dict:\n",
    "        \"\"\"Analyze embedding spaces for different models\"\"\"\n",
    "        if model_keys is None:\n",
    "            model_keys = ['MiniLM', 'MPNet']  # Analyze 2 models for demo\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Test with customer support sentences\n",
    "        test_sentences = self.arabic_test_sentences['customer_support']\n",
    "        \n",
    "        for model_key in model_keys:\n",
    "            model = self.load_model(model_key)\n",
    "            if model is None:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nðŸ” Analyzing {model_key} embedding space...\")\n",
    "            \n",
    "            # Generate embeddings\n",
    "            embeddings = model.encode(test_sentences)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            embedding_stats = {\n",
    "                'dimensions': embeddings.shape[1],\n",
    "                'mean_magnitude': np.mean(np.linalg.norm(embeddings, axis=1)),\n",
    "                'std_magnitude': np.std(np.linalg.norm(embeddings, axis=1)),\n",
    "                'mean_cosine_similarity': np.mean(cosine_similarity(embeddings)),\n",
    "                'embedding_variance': np.var(embeddings.flatten()),\n",
    "                'sparsity': np.mean(embeddings == 0)\n",
    "            }\n",
    "            \n",
    "            results[model_key] = {\n",
    "                'embeddings': embeddings,\n",
    "                'sentences': test_sentences,\n",
    "                'stats': embedding_stats\n",
    "            }\n",
    "            \n",
    "            print(f\"  ðŸ“Š Dimensions: {embedding_stats['dimensions']}\")\n",
    "            print(f\"  ðŸ“ Mean magnitude: {embedding_stats['mean_magnitude']:.4f}\")\n",
    "            print(f\"  ðŸŽ¯ Mean cosine similarity: {embedding_stats['mean_cosine_similarity']:.4f}\")\n",
    "            print(f\"  ðŸ“ˆ Embedding variance: {embedding_stats['embedding_variance']:.6f}\")\n",
    "            print(f\"  ðŸ•³ï¸ Sparsity: {embedding_stats['sparsity']:.4f}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize analyzer and show model information\n",
    "analyzer = MultilingualEmbeddingAnalyzer()\n",
    "model_info_df = analyzer.get_model_info_df()\n",
    "\n",
    "print(\"ðŸ“Š Model Configurations from Paper:\")\n",
    "print(\"=\" * 80)\n",
    "print(model_info_df.to_string(index=False))\n",
    "\n",
    "# Analyze embedding spaces\n",
    "embedding_analysis = analyzer.analyze_embedding_spaces(['MiniLM', 'MPNet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Arabic Language Characteristics Analysis\n",
    "\n",
    "### Understanding How Models Handle Arabic Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_arabic_morphology(analyzer: MultilingualEmbeddingAnalyzer, model_key: str = 'MPNet'):\n",
    "    \"\"\"Analyze how models handle Arabic morphological variations\"\"\"\n",
    "    \n",
    "    model = analyzer.load_model(model_key)\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nðŸ” Arabic Morphology Analysis with {model_key}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test morphological variants\n",
    "    morphological_sentences = analyzer.arabic_test_sentences['morphological_variants']\n",
    "    embeddings = model.encode(morphological_sentences)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    print(\"\\nðŸ“ Morphological Variants (Root: Ùƒ-Øª-Ø¨ - 'write'):\")\n",
    "    for i, sentence in enumerate(morphological_sentences):\n",
    "        print(f\"{i+1}. {sentence}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Cosine Similarity Matrix:\")\n",
    "    print(\"    \", end=\"\")\n",
    "    for i in range(len(morphological_sentences)):\n",
    "        print(f\"{i+1:6}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(len(morphological_sentences)):\n",
    "        print(f\"{i+1:2}. \", end=\"\")\n",
    "        for j in range(len(morphological_sentences)):\n",
    "            print(f\"{similarity_matrix[i,j]:5.3f}\", end=\" \")\n",
    "        print()\n",
    "    \n",
    "    # Analyze dialectal variations\n",
    "    print(\"\\nðŸ—£ï¸ Dialectal Variations Analysis:\")\n",
    "    dialectal_sentences = analyzer.arabic_test_sentences['dialectal_variations']\n",
    "    dialectal_embeddings = model.encode(dialectal_sentences)\n",
    "    dialectal_similarity = cosine_similarity(dialectal_embeddings)\n",
    "    \n",
    "    for i, sentence in enumerate(dialectal_sentences):\n",
    "        print(f\"{i+1}. {sentence}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Dialectal Similarity Matrix:\")\n",
    "    print(\"    \", end=\"\")\n",
    "    for i in range(len(dialectal_sentences)):\n",
    "        print(f\"{i+1:6}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(len(dialectal_sentences)):\n",
    "        print(f\"{i+1:2}. \", end=\"\")\n",
    "        for j in range(len(dialectal_sentences)):\n",
    "            print(f\"{dialectal_similarity[i,j]:5.3f}\", end=\" \")\n",
    "        print()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Morphological similarity heatmap\n",
    "    im1 = ax1.imshow(similarity_matrix, cmap='Blues', vmin=0, vmax=1)\n",
    "    ax1.set_title(f'Morphological Similarity\\n({model_key})', fontweight='bold')\n",
    "    ax1.set_xlabel('Sentence Index')\n",
    "    ax1.set_ylabel('Sentence Index')\n",
    "    \n",
    "    # Add similarity values\n",
    "    for i in range(len(morphological_sentences)):\n",
    "        for j in range(len(morphological_sentences)):\n",
    "            ax1.text(j, i, f'{similarity_matrix[i,j]:.3f}', \n",
    "                    ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # Dialectal similarity heatmap\n",
    "    im2 = ax2.imshow(dialectal_similarity, cmap='Reds', vmin=0, vmax=1)\n",
    "    ax2.set_title(f'Dialectal Similarity\\n({model_key})', fontweight='bold')\n",
    "    ax2.set_xlabel('Sentence Index')\n",
    "    ax2.set_ylabel('Sentence Index')\n",
    "    \n",
    "    # Add similarity values\n",
    "    for i in range(len(dialectal_sentences)):\n",
    "        for j in range(len(dialectal_sentences)):\n",
    "            ax2.text(j, i, f'{dialectal_similarity[i,j]:.3f}', \n",
    "                    ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('arabic_linguistic_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'morphological_similarity': similarity_matrix,\n",
    "        'dialectal_similarity': dialectal_similarity,\n",
    "        'morphological_sentences': morphological_sentences,\n",
    "        'dialectal_sentences': dialectal_sentences\n",
    "    }\n",
    "\n",
    "# Run Arabic morphology analysis\n",
    "arabic_analysis = analyze_arabic_morphology(analyzer, 'MPNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Dimensionality Impact Analysis\n",
    "\n",
    "### Paper Finding: \"The size of the embedding vector also plays a crucial role, as larger vectors can encapsulate more information, potentially enhancing overall performance, particularly for Arabic.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dimensionality_impact(analyzer: MultilingualEmbeddingAnalyzer):\n",
    "    \"\"\"Analyze the impact of embedding dimensions on performance\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ“ Dimensionality Impact Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load models with different dimensions\n",
    "    models_to_test = ['MiniLM', 'DistilBERT', 'MPNet']  # 384, 512, 768 dimensions\n",
    "    \n",
    "    results = []\n",
    "    test_sentences = analyzer.arabic_test_sentences['semantic_similarity']\n",
    "    \n",
    "    for model_key in models_to_test:\n",
    "        model = analyzer.load_model(model_key)\n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        dimensions = analyzer.models_config[model_key]['dimensions']\n",
    "        print(f\"\\nðŸ” Testing {model_key} ({dimensions}D)...\")\n",
    "        \n",
    "        # Encode sentences\n",
    "        embeddings = model.encode(test_sentences)\n",
    "        \n",
    "        # Calculate various metrics\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "        \n",
    "        # Information capacity metrics\n",
    "        embedding_norms = np.linalg.norm(embeddings, axis=1)\n",
    "        pairwise_distances = euclidean_distances(embeddings)\n",
    "        \n",
    "        # Semantic coherence: how well related sentences cluster together\n",
    "        # Sentences 1-3 are about cars, 4-5 are about other transport\n",
    "        car_similarities = [\n",
    "            similarity_matrix[0, 1],  # Car 1 vs Car 2\n",
    "            similarity_matrix[0, 2],  # Car 1 vs Car 3\n",
    "            similarity_matrix[1, 2]   # Car 2 vs Car 3\n",
    "        ]\n",
    "        \n",
    "        cross_category_similarities = [\n",
    "            similarity_matrix[0, 3],  # Car vs Plane\n",
    "            similarity_matrix[0, 4],  # Car vs Train\n",
    "            similarity_matrix[1, 3],  # Car vs Plane\n",
    "            similarity_matrix[1, 4],  # Car vs Train\n",
    "            similarity_matrix[2, 3],  # Car vs Plane\n",
    "            similarity_matrix[2, 4]   # Car vs Train\n",
    "        ]\n",
    "        \n",
    "        semantic_coherence = np.mean(car_similarities) - np.mean(cross_category_similarities)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_key,\n",
    "            'Dimensions': dimensions,\n",
    "            'Mean_Norm': np.mean(embedding_norms),\n",
    "            'Std_Norm': np.std(embedding_norms),\n",
    "            'Mean_Distance': np.mean(pairwise_distances),\n",
    "            'Semantic_Coherence': semantic_coherence,\n",
    "            'Embedding_Variance': np.var(embeddings.flatten()),\n",
    "            'Information_Density': np.var(embeddings.flatten()) * dimensions\n",
    "        })\n",
    "        \n",
    "        print(f\"  ðŸ“Š Mean embedding norm: {np.mean(embedding_norms):.4f}\")\n",
    "        print(f\"  ðŸŽ¯ Semantic coherence: {semantic_coherence:.4f}\")\n",
    "        print(f\"  ðŸ“ˆ Information density: {np.var(embeddings.flatten()) * dimensions:.6f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def visualize_dimensionality_analysis(dim_results: pd.DataFrame):\n",
    "    \"\"\"Create comprehensive visualization of dimensionality impact\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Dimensions vs Semantic Coherence\n",
    "    ax1.scatter(dim_results['Dimensions'], dim_results['Semantic_Coherence'], \n",
    "               s=100, alpha=0.7, c=['red', 'blue', 'green'])\n",
    "    \n",
    "    for i, row in dim_results.iterrows():\n",
    "        ax1.annotate(row['Model'], \n",
    "                    (row['Dimensions'], row['Semantic_Coherence']),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax1.set_xlabel('Embedding Dimensions')\n",
    "    ax1.set_ylabel('Semantic Coherence Score')\n",
    "    ax1.set_title('Dimensions vs Semantic Coherence')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Information Density Comparison\n",
    "    bars = ax2.bar(dim_results['Model'], dim_results['Information_Density'], \n",
    "                   color=['red', 'blue', 'green'], alpha=0.7)\n",
    "    ax2.set_ylabel('Information Density')\n",
    "    ax2.set_title('Information Density by Model')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, dim_results['Information_Density']):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01,\n",
    "                f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Embedding Variance vs Dimensions\n",
    "    ax3.plot(dim_results['Dimensions'], dim_results['Embedding_Variance'], \n",
    "             'o-', linewidth=2, markersize=8, color='purple')\n",
    "    \n",
    "    for i, row in dim_results.iterrows():\n",
    "        ax3.annotate(row['Model'], \n",
    "                    (row['Dimensions'], row['Embedding_Variance']),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax3.set_xlabel('Embedding Dimensions')\n",
    "    ax3.set_ylabel('Embedding Variance')\n",
    "    ax3.set_title('Embedding Variance vs Dimensions')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Multi-metric comparison\n",
    "    metrics = ['Semantic_Coherence', 'Information_Density', 'Embedding_Variance']\n",
    "    normalized_data = dim_results[metrics].copy()\n",
    "    \n",
    "    # Normalize to 0-1 scale for comparison\n",
    "    for metric in metrics:\n",
    "        min_val = normalized_data[metric].min()\n",
    "        max_val = normalized_data[metric].max()\n",
    "        normalized_data[metric] = (normalized_data[metric] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    x = np.arange(len(dim_results))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax4.bar(x + i*width, normalized_data[metric], width, \n",
    "               label=metric.replace('_', ' '), alpha=0.8)\n",
    "    \n",
    "    ax4.set_xlabel('Models')\n",
    "    ax4.set_ylabel('Normalized Score')\n",
    "    ax4.set_title('Multi-Metric Comparison (Normalized)')\n",
    "    ax4.set_xticks(x + width)\n",
    "    ax4.set_xticklabels(dim_results['Model'])\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dimensionality_impact_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Run dimensionality analysis\n",
    "dim_results = analyze_dimensionality_impact(analyzer)\n",
    "print(\"\\nðŸ“Š Dimensionality Analysis Results:\")\n",
    "print(dim_results.round(4))\n",
    "\n",
    "# Visualize results\n",
    "visualize_dimensionality_analysis(dim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asymmetric vs Symmetric Semantic Search\n",
    "\n",
    "### Paper Insight: \"The discrepancy can be attributed to the nature of the semantic search evaluation, which closely resembles an Asymmetric Semantic Search scenario, where embeddings of extensive text summaries and brief queries, averaging four words, are compared.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_asymmetric_vs_symmetric_search(analyzer: MultilingualEmbeddingAnalyzer):\n",
    "    \"\"\"Analyze performance differences between asymmetric and symmetric search scenarios\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ” Asymmetric vs Symmetric Search Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define test scenarios\n",
    "    asymmetric_scenario = {\n",
    "        'name': 'Asymmetric (Query vs Document)',\n",
    "        'short_queries': [\n",
    "            \"Ù…Ø´ÙƒÙ„Ø© ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„\",  # Login problem\n",
    "            \"Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±\",  # Reset password\n",
    "            \"Ø¯ÙØ¹ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ\",  # Electronic payment\n",
    "            \"Ø¥Ù„ØºØ§Ø¡ Ø§Ø´ØªØ±Ø§Ùƒ\"  # Cancel subscription\n",
    "        ],\n",
    "        'long_documents': [\n",
    "            \"Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠÙˆØ§Ø¬Ù‡ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ù‡ Ø§Ù„Ø´Ø®ØµÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆÙŠØ·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ÙÙˆØ±ÙŠØ© Ù„Ø­Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©\",\n",
    "            \"Ø·Ù„Ø¨ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙ†ÙŠØ© ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø­Ø³Ø§Ø¨Ù‡ Ø¨Ø¹Ø¯ Ù†Ø³ÙŠØ§Ù†Ù‡Ø§ ÙˆØ¹Ø¯Ù… Ù‚Ø¯Ø±ØªÙ‡ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ø­Ø³Ø§Ø¨\",\n",
    "            \"ÙŠØ´ÙƒÙˆ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¹Ø¨Ø± Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù† ÙˆÙ„Ø§ ÙŠØ³ØªØ·ÙŠØ¹ Ø¥ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø´Ø±Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­ Ø±ØºÙ… Ù…Ø­Ø§ÙˆÙ„Ø§ØªÙ‡ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©\",\n",
    "            \"Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ±ÙŠØ¯ Ø¥Ù„ØºØ§Ø¡ Ø§Ø´ØªØ±Ø§ÙƒÙ‡ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø¯ÙÙˆØ¹Ø© Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… Ø±Ø¶Ø§Ù‡ Ø¹Ù† Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆÙŠØ·Ù„Ø¨ Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø¯ÙÙˆØ¹ Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    symmetric_scenario = {\n",
    "        'name': 'Symmetric (Query vs Query)',\n",
    "        'queries_set1': [\n",
    "            \"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ÙŠØŸ\",\n",
    "            \"ÙƒÙŠÙ Ø£Ø¹ÙŠØ¯ ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±ØŸ\", \n",
    "            \"Ù…Ø§ Ù‡ÙŠ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØŸ\",\n",
    "            \"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØŸ\"\n",
    "        ],\n",
    "        'queries_set2': [\n",
    "            \"Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ø­Ø³Ø§Ø¨ÙŠ\",\n",
    "            \"Ù†Ø³ÙŠØª ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø± ÙˆØ£Ø­ØªØ§Ø¬ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ†Ù‡Ø§\",\n",
    "            \"Ù„Ø§ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¯ÙØ¹ Ø¨Ø§Ù„Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠØ©\",\n",
    "            \"Ø£Ø±ÙŠØ¯ Ø¥ÙŠÙ‚Ø§Ù Ø§Ø´ØªØ±Ø§ÙƒÙŠ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Test with multiple models\n",
    "    models_to_test = ['MiniLM', 'MPNet']\n",
    "    results = []\n",
    "    \n",
    "    for model_key in models_to_test:\n",
    "        model = analyzer.load_model(model_key)\n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ” Testing {model_key}...\")\n",
    "        \n",
    "        # Asymmetric scenario\n",
    "        query_embeddings = model.encode(asymmetric_scenario['short_queries'])\n",
    "        doc_embeddings = model.encode(asymmetric_scenario['long_documents'])\n",
    "        asymmetric_similarities = cosine_similarity(query_embeddings, doc_embeddings)\n",
    "        \n",
    "        # Symmetric scenario\n",
    "        set1_embeddings = model.encode(symmetric_scenario['queries_set1'])\n",
    "        set2_embeddings = model.encode(symmetric_scenario['queries_set2'])\n",
    "        symmetric_similarities = cosine_similarity(set1_embeddings, set2_embeddings)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        # For both scenarios, diagonal elements should have highest similarity\n",
    "        asymmetric_diagonal = np.diag(asymmetric_similarities)\n",
    "        symmetric_diagonal = np.diag(symmetric_similarities)\n",
    "        \n",
    "        # Off-diagonal elements (should be lower)\n",
    "        asymmetric_off_diag = asymmetric_similarities[np.triu_indices_from(asymmetric_similarities, k=1)]\n",
    "        symmetric_off_diag = symmetric_similarities[np.triu_indices_from(symmetric_similarities, k=1)]\n",
    "        \n",
    "        # Discrimination ability (how well it separates relevant from irrelevant)\n",
    "        asymmetric_discrimination = np.mean(asymmetric_diagonal) - np.mean(asymmetric_off_diag)\n",
    "        symmetric_discrimination = np.mean(symmetric_diagonal) - np.mean(symmetric_off_diag)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_key,\n",
    "            'Asymmetric_Mean_Similarity': np.mean(asymmetric_diagonal),\n",
    "            'Symmetric_Mean_Similarity': np.mean(symmetric_diagonal),\n",
    "            'Asymmetric_Discrimination': asymmetric_discrimination,\n",
    "            'Symmetric_Discrimination': symmetric_discrimination,\n",
    "            'Asymmetric_Std': np.std(asymmetric_similarities),\n",
    "            'Symmetric_Std': np.std(symmetric_similarities)\n",
    "        })\n",
    "        \n",
    "        print(f\"  ðŸ“Š Asymmetric discrimination: {asymmetric_discrimination:.4f}\")\n",
    "        print(f\"  ðŸ“Š Symmetric discrimination: {symmetric_discrimination:.4f}\")\n",
    "        \n",
    "        # Visualize similarity matrices\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Asymmetric similarity matrix\n",
    "        im1 = ax1.imshow(asymmetric_similarities, cmap='Blues', vmin=0, vmax=1)\n",
    "        ax1.set_title(f'Asymmetric Search\\n{model_key} (Query vs Document)')\n",
    "        ax1.set_xlabel('Document Index')\n",
    "        ax1.set_ylabel('Query Index')\n",
    "        \n",
    "        # Add similarity values\n",
    "        for i in range(asymmetric_similarities.shape[0]):\n",
    "            for j in range(asymmetric_similarities.shape[1]):\n",
    "                ax1.text(j, i, f'{asymmetric_similarities[i,j]:.3f}', \n",
    "                        ha='center', va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        # Symmetric similarity matrix\n",
    "        im2 = ax2.imshow(symmetric_similarities, cmap='Reds', vmin=0, vmax=1)\n",
    "        ax2.set_title(f'Symmetric Search\\n{model_key} (Query vs Query)')\n",
    "        ax2.set_xlabel('Query Set 2 Index')\n",
    "        ax2.set_ylabel('Query Set 1 Index')\n",
    "        \n",
    "        # Add similarity values\n",
    "        for i in range(symmetric_similarities.shape[0]):\n",
    "            for j in range(symmetric_similarities.shape[1]):\n",
    "                ax2.text(j, i, f'{symmetric_similarities[i,j]:.3f}', \n",
    "                        ha='center', va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_key}_asymmetric_vs_symmetric.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return pd.DataFrame(results), asymmetric_scenario, symmetric_scenario\n",
    "\n",
    "# Run asymmetric vs symmetric analysis\n",
    "search_results, asym_scenario, sym_scenario = analyze_asymmetric_vs_symmetric_search(analyzer)\n",
    "\n",
    "print(\"\\nðŸ“Š Search Scenario Comparison Results:\")\n",
    "print(search_results.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Embedding Visualization\n",
    "\n",
    "### Understanding Embedding Spaces through Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_visualization(analyzer: MultilingualEmbeddingAnalyzer, model_key: str = 'MPNet'):\n",
    "    \"\"\"Create comprehensive embedding space visualization\"\"\"\n",
    "    \n",
    "    model = analyzer.load_model(model_key)\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nðŸŽ¨ Creating Embedding Visualization for {model_key}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Combine all test sentences with categories\n",
    "    all_sentences = []\n",
    "    categories = []\n",
    "    colors = []\n",
    "    \n",
    "    # Customer support category\n",
    "    all_sentences.extend(analyzer.arabic_test_sentences['customer_support'])\n",
    "    categories.extend(['Customer Support'] * len(analyzer.arabic_test_sentences['customer_support']))\n",
    "    colors.extend(['red'] * len(analyzer.arabic_test_sentences['customer_support']))\n",
    "    \n",
    "    # Morphological variants\n",
    "    all_sentences.extend(analyzer.arabic_test_sentences['morphological_variants'])\n",
    "    categories.extend(['Morphological'] * len(analyzer.arabic_test_sentences['morphological_variants']))\n",
    "    colors.extend(['blue'] * len(analyzer.arabic_test_sentences['morphological_variants']))\n",
    "    \n",
    "    # Dialectal variations\n",
    "    all_sentences.extend(analyzer.arabic_test_sentences['dialectal_variations'])\n",
    "    categories.extend(['Dialectal'] * len(analyzer.arabic_test_sentences['dialectal_variations']))\n",
    "    colors.extend(['green'] * len(analyzer.arabic_test_sentences['dialectal_variations']))\n",
    "    \n",
    "    # Semantic similarity\n",
    "    all_sentences.extend(analyzer.arabic_test_sentences['semantic_similarity'])\n",
    "    categories.extend(['Semantic'] * len(analyzer.arabic_test_sentences['semantic_similarity']))\n",
    "    colors.extend(['purple'] * len(analyzer.arabic_test_sentences['semantic_similarity']))\n",
    "    \n",
    "    # Generate embeddings\n",
    "    print(f\"ðŸ”„ Encoding {len(all_sentences)} sentences...\")\n",
    "    embeddings = model.encode(all_sentences)\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    print(\"ðŸ”„ Applying PCA...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_pca = pca.fit_transform(embeddings)\n",
    "    \n",
    "    print(\"ðŸ”„ Applying t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_sentences)-1))\n",
    "    embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # PCA plot\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    unique_categories = list(set(categories))\n",
    "    category_colors = {'Customer Support': 'red', 'Morphological': 'blue', \n",
    "                      'Dialectal': 'green', 'Semantic': 'purple'}\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        mask = [cat == category for cat in categories]\n",
    "        ax1.scatter(embeddings_pca[mask, 0], embeddings_pca[mask, 1], \n",
    "                   c=category_colors[category], label=category, alpha=0.7, s=60)\n",
    "    \n",
    "    ax1.set_xlabel(f'PC1 (Var: {pca.explained_variance_ratio_[0]:.2%})')\n",
    "    ax1.set_ylabel(f'PC2 (Var: {pca.explained_variance_ratio_[1]:.2%})')\n",
    "    ax1.set_title(f'PCA Visualization\\n{model_key}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # t-SNE plot\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    for category in unique_categories:\n",
    "        mask = [cat == category for cat in categories]\n",
    "        ax2.scatter(embeddings_tsne[mask, 0], embeddings_tsne[mask, 1], \n",
    "                   c=category_colors[category], label=category, alpha=0.7, s=60)\n",
    "    \n",
    "    ax2.set_xlabel('t-SNE 1')\n",
    "    ax2.set_ylabel('t-SNE 2')\n",
    "    ax2.set_title(f't-SNE Visualization\\n{model_key}')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Similarity matrix heatmap\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    im = ax3.imshow(similarity_matrix, cmap='viridis', vmin=0, vmax=1)\n",
    "    ax3.set_title(f'Cosine Similarity Matrix\\n{model_key}')\n",
    "    ax3.set_xlabel('Sentence Index')\n",
    "    ax3.set_ylabel('Sentence Index')\n",
    "    plt.colorbar(im, ax=ax3)\n",
    "    \n",
    "    # Embedding magnitude distribution\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    embedding_norms = np.linalg.norm(embeddings, axis=1)\n",
    "    ax4.hist(embedding_norms, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax4.set_xlabel('Embedding Magnitude')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax4.set_title(f'Embedding Magnitude Distribution\\n{model_key}')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Principal component variance\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    pca_full = PCA()\n",
    "    pca_full.fit(embeddings)\n",
    "    cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    ax5.plot(range(1, min(51, len(cumsum_var)+1)), cumsum_var[:50], 'o-', linewidth=2)\n",
    "    ax5.set_xlabel('Principal Component')\n",
    "    ax5.set_ylabel('Cumulative Explained Variance')\n",
    "    ax5.set_title(f'PCA Variance Explained\\n{model_key}')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% Variance')\n",
    "    ax5.legend()\n",
    "    \n",
    "    # Embedding statistics summary\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "ðŸ“Š EMBEDDING STATISTICS\n",
    "\n",
    "Model: {model_key}\n",
    "Dimensions: {embeddings.shape[1]}\n",
    "Sentences: {embeddings.shape[0]}\n",
    "\n",
    "ðŸ“ Magnitude Stats:\n",
    "Mean: {np.mean(embedding_norms):.4f}\n",
    "Std: {np.std(embedding_norms):.4f}\n",
    "Min: {np.min(embedding_norms):.4f}\n",
    "Max: {np.max(embedding_norms):.4f}\n",
    "\n",
    "ðŸŽ¯ Similarity Stats:\n",
    "Mean: {np.mean(similarity_matrix):.4f}\n",
    "Std: {np.std(similarity_matrix):.4f}\n",
    "\n",
    "ðŸ“ˆ Variance:\n",
    "Total: {np.var(embeddings.flatten()):.6f}\n",
    "95% in {np.argmax(cumsum_var >= 0.95)+1} PCs\n",
    "\"\"\"\n",
    "    \n",
    "    ax6.text(0.05, 0.95, stats_text, transform=ax6.transAxes, fontsize=11, \n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_key}_embedding_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some sentences for reference\n",
    "    print(\"\\nðŸ“ Sample Sentences by Category:\")\n",
    "    for category in unique_categories:\n",
    "        print(f\"\\n{category}:\")\n",
    "        category_sentences = [sent for sent, cat in zip(all_sentences, categories) if cat == category]\n",
    "        for i, sent in enumerate(category_sentences[:2]):  # Show first 2 from each category\n",
    "            print(f\"  {i+1}. {sent}\")\n",
    "    \n",
    "    return {\n",
    "        'embeddings': embeddings,\n",
    "        'pca_embeddings': embeddings_pca,\n",
    "        'tsne_embeddings': embeddings_tsne,\n",
    "        'sentences': all_sentences,\n",
    "        'categories': categories,\n",
    "        'similarity_matrix': similarity_matrix,\n",
    "        'pca_variance_ratio': pca.explained_variance_ratio_\n",
    "    }\n",
    "\n",
    "# Create embedding visualization\n",
    "viz_results = create_embedding_visualization(analyzer, 'MPNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Performance Analysis\n",
    "\n",
    "### Comprehensive comparison following the paper's methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_model_comparison(analyzer: MultilingualEmbeddingAnalyzer):\n",
    "    \"\"\"Comprehensive comparison of all models following paper methodology\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ† Comprehensive Model Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Models to test (limit to 3 for demo due to loading time)\n",
    "    models_to_test = ['MiniLM', 'MPNet', 'DistilBERT']\n",
    "    \n",
    "    comparison_results = []\n",
    "    test_scenarios = {\n",
    "        'Customer Support': analyzer.arabic_test_sentences['customer_support'],\n",
    "        'Morphological': analyzer.arabic_test_sentences['morphological_variants'],\n",
    "        'Dialectal': analyzer.arabic_test_sentences['dialectal_variations'],\n",
    "        'Semantic': analyzer.arabic_test_sentences['semantic_similarity']\n",
    "    }\n",
    "    \n",
    "    for model_key in models_to_test:\n",
    "        model = analyzer.load_model(model_key)\n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ” Evaluating {model_key}...\")\n",
    "        \n",
    "        model_results = {\n",
    "            'Model': model_key,\n",
    "            'Dimensions': analyzer.models_config[model_key]['dimensions'],\n",
    "            'Architecture': analyzer.models_config[model_key]['architecture']\n",
    "        }\n",
    "        \n",
    "        # Test each scenario\n",
    "        for scenario_name, sentences in test_scenarios.items():\n",
    "            embeddings = model.encode(sentences)\n",
    "            similarity_matrix = cosine_similarity(embeddings)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mean_similarity = np.mean(similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)])\n",
    "            embedding_variance = np.var(embeddings.flatten())\n",
    "            mean_magnitude = np.mean(np.linalg.norm(embeddings, axis=1))\n",
    "            \n",
    "            # Coherence: how well similar sentences cluster\n",
    "            if len(sentences) >= 3:\n",
    "                # Take first 3 sentences as one cluster\n",
    "                intra_cluster_sim = np.mean([\n",
    "                    similarity_matrix[0,1], similarity_matrix[0,2], similarity_matrix[1,2]\n",
    "                ])\n",
    "                # Inter-cluster with remaining sentences\n",
    "                if len(sentences) > 3:\n",
    "                    inter_cluster_sim = np.mean([\n",
    "                        similarity_matrix[i,j] for i in range(3) for j in range(3, len(sentences))\n",
    "                    ])\n",
    "                    coherence = intra_cluster_sim - inter_cluster_sim\n",
    "                else:\n",
    "                    coherence = intra_cluster_sim\n",
    "            else:\n",
    "                coherence = mean_similarity\n",
    "            \n",
    "            model_results[f'{scenario_name}_Similarity'] = mean_similarity\n",
    "            model_results[f'{scenario_name}_Variance'] = embedding_variance\n",
    "            model_results[f'{scenario_name}_Magnitude'] = mean_magnitude\n",
    "            model_results[f'{scenario_name}_Coherence'] = coherence\n",
    "        \n",
    "        # Overall performance metrics\n",
    "        all_sentences = [sent for sentences in test_scenarios.values() for sent in sentences]\n",
    "        all_embeddings = model.encode(all_sentences)\n",
    "        overall_similarity = cosine_similarity(all_embeddings)\n",
    "        \n",
    "        model_results['Overall_Performance'] = np.mean([\n",
    "            model_results[f'{scenario}_Coherence'] for scenario in test_scenarios.keys()\n",
    "        ])\n",
    "        \n",
    "        comparison_results.append(model_results)\n",
    "        \n",
    "        print(f\"  ðŸ“Š Overall Performance: {model_results['Overall_Performance']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(comparison_results)\n",
    "\n",
    "def visualize_model_comparison(comparison_df: pd.DataFrame):\n",
    "    \"\"\"Create comprehensive visualization of model comparison\"\"\"\n",
    "    \n",
    "    # Create performance radar chart\n",
    "    scenarios = ['Customer Support', 'Morphological', 'Dialectal', 'Semantic']\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. Radar chart for coherence across scenarios\n",
    "    ax1 = plt.subplot(2, 3, 1, projection='polar')\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(scenarios), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "    \n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        values = [row[f'{scenario}_Coherence'] for scenario in scenarios]\n",
    "        values += values[:1]  # Complete the circle\n",
    "        \n",
    "        ax1.plot(angles, values, 'o-', linewidth=2, label=row['Model'], color=colors[i])\n",
    "        ax1.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "    \n",
    "    ax1.set_xticks(angles[:-1])\n",
    "    ax1.set_xticklabels(scenarios)\n",
    "    ax1.set_title('Coherence Across Scenarios', size=14, fontweight='bold', pad=20)\n",
    "    ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    # 2. Dimensions vs Performance\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    scatter = ax2.scatter(comparison_df['Dimensions'], comparison_df['Overall_Performance'], \n",
    "                         c=colors[:len(comparison_df)], s=100, alpha=0.7)\n",
    "    \n",
    "    for i, row in comparison_df.iterrows():\n",
    "        ax2.annotate(row['Model'], \n",
    "                    (row['Dimensions'], row['Overall_Performance']),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax2.set_xlabel('Embedding Dimensions')\n",
    "    ax2.set_ylabel('Overall Performance')\n",
    "    ax2.set_title('Dimensions vs Overall Performance')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Architecture comparison\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    architectures = comparison_df['Architecture'].tolist()\n",
    "    performances = comparison_df['Overall_Performance'].tolist()\n",
    "    \n",
    "    bars = ax3.bar(range(len(architectures)), performances, \n",
    "                   color=colors[:len(comparison_df)], alpha=0.7)\n",
    "    ax3.set_xticks(range(len(architectures)))\n",
    "    ax3.set_xticklabels(architectures, rotation=45)\n",
    "    ax3.set_ylabel('Overall Performance')\n",
    "    ax3.set_title('Architecture Performance Comparison')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, performances):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. Scenario-specific performance\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    \n",
    "    x = np.arange(len(scenarios))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        coherence_values = [row[f'{scenario}_Coherence'] for scenario in scenarios]\n",
    "        ax4.bar(x + i*width, coherence_values, width, \n",
    "               label=row['Model'], color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax4.set_xlabel('Scenarios')\n",
    "    ax4.set_ylabel('Coherence Score')\n",
    "    ax4.set_title('Scenario-Specific Performance')\n",
    "    ax4.set_xticks(x + width)\n",
    "    ax4.set_xticklabels(scenarios, rotation=45)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Performance vs Efficiency trade-off\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    \n",
    "    # Use dimensions as proxy for computational cost\n",
    "    efficiency = 1000 / comparison_df['Dimensions']  # Inverse relationship\n",
    "    \n",
    "    for i, row in comparison_df.iterrows():\n",
    "        ax5.scatter(efficiency.iloc[i], row['Overall_Performance'], \n",
    "                   c=colors[i], s=100, alpha=0.7, label=row['Model'])\n",
    "        ax5.annotate(row['Model'], \n",
    "                    (efficiency.iloc[i], row['Overall_Performance']),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax5.set_xlabel('Efficiency (1000/Dimensions)')\n",
    "    ax5.set_ylabel('Overall Performance')\n",
    "    ax5.set_title('Performance vs Efficiency Trade-off')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Summary statistics\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Find best performing model\n",
    "    best_model = comparison_df.loc[comparison_df['Overall_Performance'].idxmax()]\n",
    "    most_efficient = comparison_df.loc[comparison_df['Dimensions'].idxmin()]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "ðŸ† MODEL COMPARISON SUMMARY\n",
    "\n",
    "ðŸ“Š Best Overall Performance:\n",
    "{best_model['Model']} ({best_model['Overall_Performance']:.4f})\n",
    "Architecture: {best_model['Architecture']}\n",
    "Dimensions: {best_model['Dimensions']}\n",
    "\n",
    "âš¡ Most Efficient:\n",
    "{most_efficient['Model']} ({most_efficient['Dimensions']} dims)\n",
    "Performance: {most_efficient['Overall_Performance']:.4f}\n",
    "\n",
    "ðŸ’¡ Key Insights:\n",
    "â€¢ Higher dimensions generally â†— performance\n",
    "â€¢ Architecture matters as much as size\n",
    "â€¢ Arabic benefits from larger embeddings\n",
    "â€¢ Trade-off between efficiency and accuracy\n",
    "\n",
    "ðŸŽ¯ Paper Finding Confirmed:\n",
    "\"Larger vectors can encapsulate more \n",
    "information, potentially enhancing \n",
    "overall performance, particularly \n",
    "for Arabic.\"\n",
    "\"\"\"\n",
    "    \n",
    "    ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes, fontsize=10, \n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comprehensive_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Run comprehensive comparison\n",
    "comparison_results = comprehensive_model_comparison(analyzer)\n",
    "\n",
    "print(\"\\nðŸ“Š Model Comparison Results:\")\n",
    "print(comparison_results[['Model', 'Dimensions', 'Architecture', 'Overall_Performance']].round(4))\n",
    "\n",
    "# Visualize comparison\n",
    "visualize_model_comparison(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Learning Summary\n",
    "\n",
    "### ðŸŽ“ What We've Mastered\n",
    "\n",
    "Through this focused learning session, we've gained deep insights into:\n",
    "\n",
    "#### ðŸ”¬ Multilingual Embedding Models\n",
    "1. **Architecture Impact**: Different transformer architectures (MiniLM, MPNet, DistilBERT, XLM-RoBERTa) handle Arabic differently\n",
    "2. **Dimensionality Trade-offs**: Higher dimensions (768D) vs efficiency (384D)\n",
    "3. **Training Objectives**: Models trained on different tasks (paraphrasing, NLI, universal encoding) show varying Arabic performance\n",
    "\n",
    "#### ðŸŒ Arabic Language Challenges\n",
    "1. **Morphological Complexity**: Root-based word formation creates semantic relationships that models must capture\n",
    "2. **Dialectal Variations**: MSA vs regional dialects require robust embedding spaces\n",
    "3. **Script Characteristics**: Right-to-left text and optional diacritics add complexity\n",
    "\n",
    "#### ðŸ“Š Performance Analysis\n",
    "1. **Asymmetric vs Symmetric Search**: Different scenarios require different model strengths\n",
    "2. **Embedding Space Quality**: Visualization reveals clustering and separation patterns\n",
    "3. **Evaluation Metrics**: Multi-faceted assessment beyond simple similarity scores\n",
    "\n",
    "### ðŸš€ Practical Applications\n",
    "\n",
    "This knowledge directly applies to:\n",
    "- **Model Selection**: Choose appropriate embeddings for Arabic tasks\n",
    "- **System Design**: Balance performance vs computational efficiency\n",
    "- **Quality Assessment**: Understand embedding space characteristics\n",
    "- **Optimization**: Target specific Arabic linguistic phenomena\n",
    "\n",
    "### ðŸ”® Future Directions\n",
    "\n",
    "1. **Fine-tuning**: Adapt models specifically for Arabic domains\n",
    "2. **Hybrid Approaches**: Combine multiple models for better coverage\n",
    "3. **Specialized Architectures**: Develop Arabic-specific embedding models\n",
    "4. **Evaluation Frameworks**: Create more comprehensive Arabic benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ“ MULTILINGUAL EMBEDDINGS MASTERY COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "âœ… What you've mastered:\n",
    "\n",
    "ðŸ”¬ Technical Understanding:\n",
    "â€¢ Architecture differences (MiniLM, MPNet, DistilBERT, XLM-RoBERTa)\n",
    "â€¢ Dimensionality impact on Arabic performance\n",
    "â€¢ Embedding space visualization and analysis\n",
    "â€¢ Asymmetric vs symmetric search scenarios\n",
    "\n",
    "ðŸŒ Arabic Language Insights:\n",
    "â€¢ Morphological variation handling\n",
    "â€¢ Dialectal similarity patterns\n",
    "â€¢ Semantic relationship capture\n",
    "â€¢ Cross-linguistic transfer effectiveness\n",
    "\n",
    "ðŸ“Š Practical Skills:\n",
    "â€¢ Model comparison methodologies\n",
    "â€¢ Performance vs efficiency trade-offs\n",
    "â€¢ Embedding quality assessment\n",
    "â€¢ Visualization and interpretation techniques\n",
    "\n",
    "ðŸŽ¯ Paper Findings Validated:\n",
    "â€¢ \"Higher-quality encoders produce more detailed embedding vectors\"\n",
    "â€¢ \"Larger vectors can encapsulate more information for Arabic\"\n",
    "â€¢ \"Asymmetric search scenarios have different requirements\"\n",
    "\n",
    "ðŸš€ Ready to select and optimize embeddings for real-world Arabic applications!\n",
    "\"\"\")\n",
    "\n",
    "# Save comprehensive results\n",
    "results_summary = {\n",
    "    'model_comparison': comparison_results.to_dict('records'),\n",
    "    'dimensionality_analysis': dim_results.to_dict('records'),\n",
    "    'search_scenario_analysis': search_results.to_dict('records'),\n",
    "    'key_insights': {\n",
    "        'best_overall_model': comparison_results.loc[comparison_results['Overall_Performance'].idxmax(), 'Model'],\n",
    "        'most_efficient_model': comparison_results.loc[comparison_results['Dimensions'].idxmin(), 'Model'],\n",
    "        'dimension_performance_correlation': dim_results[['Dimensions', 'Semantic_Coherence']].corr().iloc[0,1],\n",
    "        'arabic_specific_challenges': [\n",
    "            'Morphological complexity requires larger embedding spaces',\n",
    "            'Dialectal variations need robust cross-dialectal understanding',\n",
    "            'Asymmetric search scenarios benefit from different model architectures'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('multilingual_embeddings_analysis_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nðŸ’¾ Analysis results saved to 'multilingual_embeddings_analysis_results.json'\")\n",
    "print(\"ðŸ“Š All visualizations saved as PNG files\")\n",
    "print(\"\\nðŸŽ‰ Multilingual Embeddings Deep Dive Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Papers (PDF Utils)",\n",
   "language": "python",
   "name": "ai-papers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}