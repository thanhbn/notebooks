{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangFuse Data Processing Prompts Optimization\n",
    "\n",
    "## M·ª•c ti√™u h·ªçc t·∫≠p\n",
    "Hi·ªÉu c√°ch s·ª≠ d·ª•ng LangFuse ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c v√† hi·ªáu qu·∫£ c·ªßa c√°c prompt d√πng cho tr√≠ch xu·∫•t, chu·∫©n h√≥a v√† chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu b·∫±ng LLM.\n",
    "\n",
    "## Gi·ªõi thi·ªáu\n",
    "\n",
    "Vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu phi c·∫•u tr√∫c b·∫±ng LLM g·∫∑p ph·∫£i nhi·ªÅu th√°ch th·ª©c:\n",
    "- **L·ªói ƒë·ªãnh d·∫°ng**: LLM c√≥ th·ªÉ tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng ƒë√∫ng schema mong mu·ªën\n",
    "- **Th√¥ng tin b·ªã b·ªè s√≥t**: M·ªôt s·ªë tr∆∞·ªùng quan tr·ªçng c√≥ th·ªÉ b·ªã b·ªè qua\n",
    "- **Hallucination**: LLM c√≥ th·ªÉ t·∫°o ra th√¥ng tin kh√¥ng c√≥ trong d·ªØ li·ªáu g·ªëc\n",
    "- **T√≠nh nh·∫•t qu√°n**: K·∫øt qu·∫£ c√≥ th·ªÉ kh√°c nhau gi·ªØa c√°c l·∫ßn ch·∫°y\n",
    "\n",
    "LangFuse gi√∫p gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ n√†y b·∫±ng c√°ch:\n",
    "- Theo d√µi v√† ph√¢n t√≠ch hi·ªáu su·∫•t c·ªßa t·ª´ng prompt\n",
    "- Cung c·∫•p d·ªØ li·ªáu ƒë·ªÉ so s√°nh c√°c phi√™n b·∫£n prompt kh√°c nhau\n",
    "- Ph√°t hi·ªán c√°c pattern l·ªói v√† c·∫£i thi·ªán iterative\n",
    "- ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng output m·ªôt c√°ch h·ªá th·ªëng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√†i ƒë·∫∑t & C·∫•u h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import re\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# C·∫•u h√¨nh API keys\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key-here\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"your-langfuse-secret-key\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"your-langfuse-public-key\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"http://localhost:3000\"\n",
    "\n",
    "# Kh·ªüi t·∫°o LangFuse\n",
    "langfuse = Langfuse()\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "print(\"‚úÖ C·∫•u h√¨nh ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 1: Tr√≠ch xu·∫•t th√¥ng tin t·ª´ h√≥a ƒë∆°n\n",
    "\n",
    "Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt h·ªá th·ªëng tr√≠ch xu·∫•t th√¥ng tin t·ª´ vƒÉn b·∫£n h√≥a ƒë∆°n v√† theo d√µi hi·ªáu su·∫•t b·∫±ng LangFuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a schema cho th√¥ng tin h√≥a ƒë∆°n\n",
    "class InvoiceItem(BaseModel):\n",
    "    name: str = Field(description=\"T√™n s·∫£n ph·∫©m/d·ªãch v·ª•\")\n",
    "    quantity: int = Field(description=\"S·ªë l∆∞·ª£ng\")\n",
    "    unit_price: float = Field(description=\"ƒê∆°n gi√°\")\n",
    "    total_price: float = Field(description=\"Th√†nh ti·ªÅn\")\n",
    "\n",
    "class InvoiceData(BaseModel):\n",
    "    invoice_number: str = Field(description=\"S·ªë h√≥a ƒë∆°n\")\n",
    "    date: str = Field(description=\"Ng√†y th√°ng (ƒë·ªãnh d·∫°ng YYYY-MM-DD)\")\n",
    "    vendor_name: str = Field(description=\"T√™n nh√† cung c·∫•p\")\n",
    "    vendor_address: Optional[str] = Field(description=\"ƒê·ªãa ch·ªâ nh√† cung c·∫•p\")\n",
    "    items: List[InvoiceItem] = Field(description=\"Danh s√°ch c√°c m·ª•c h√†ng\")\n",
    "    subtotal: float = Field(description=\"T·ªïng ti·ªÅn tr∆∞·ªõc thu·∫ø\")\n",
    "    tax_amount: float = Field(description=\"S·ªë ti·ªÅn thu·∫ø\")\n",
    "    total_amount: float = Field(description=\"T·ªïng ti·ªÅn sau thu·∫ø\")\n",
    "\n",
    "# T·∫°o parser\n",
    "invoice_parser = PydanticOutputParser(pydantic_object=InvoiceData)\n",
    "\n",
    "print(\"‚úÖ Schema ƒë·ªãnh nghƒ©a ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D·ªØ li·ªáu h√≥a ƒë∆°n m·∫´u\n",
    "sample_invoices = [\n",
    "    \"\"\"\n",
    "    H√ìA ƒê∆†N B√ÅN H√ÄNG\n",
    "    S·ªë: HD-2024-001\n",
    "    Ng√†y: 15/01/2024\n",
    "    \n",
    "    Nh√† cung c·∫•p: C√¥ng ty TNHH ABC\n",
    "    ƒê·ªãa ch·ªâ: 123 ƒê∆∞·ªùng Nguy·ªÖn VƒÉn A, Qu·∫≠n 1, TP.HCM\n",
    "    \n",
    "    STT | T√™n h√†ng h√≥a | S·ªë l∆∞·ª£ng | ƒê∆°n gi√° | Th√†nh ti·ªÅn\n",
    "    1   | Laptop Dell  | 2        | 15000000| 30000000\n",
    "    2   | Chu·ªôt m√°y t√≠nh| 5       | 200000  | 1000000\n",
    "    3   | B√†n ph√≠m     | 3        | 500000  | 1500000\n",
    "    \n",
    "    T·ªïng ti·ªÅn tr∆∞·ªõc thu·∫ø: 32500000\n",
    "    Thu·∫ø VAT (10%): 3250000\n",
    "    T·ªïng ti·ªÅn thanh to√°n: 35750000\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    INVOICE\n",
    "    Invoice #: INV-2024-0045\n",
    "    Date: 2024-02-20\n",
    "    \n",
    "    Vendor: Tech Solutions Ltd\n",
    "    Address: 456 Technology St, District 7, Ho Chi Minh City\n",
    "    \n",
    "    Description        | Qty | Unit Price | Total\n",
    "    Software License   | 10  | $299.99    | $2999.90\n",
    "    Technical Support  | 1   | $500.00    | $500.00\n",
    "    Training Session   | 2   | $750.00    | $1500.00\n",
    "    \n",
    "    Subtotal: $4999.90\n",
    "    Tax (8%): $399.99\n",
    "    Total: $5399.89\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Chu·∫©n b·ªã {len(sample_invoices)} h√≥a ƒë∆°n m·∫´u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o prompt template cho tr√≠ch xu·∫•t h√≥a ƒë∆°n\n",
    "invoice_extraction_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "B·∫°n l√† m·ªôt chuy√™n gia tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√≥a ƒë∆°n. H√£y ph√¢n t√≠ch vƒÉn b·∫£n h√≥a ƒë∆°n sau v√† tr√≠ch xu·∫•t th√¥ng tin theo ƒë·ªãnh d·∫°ng JSON ƒë∆∞·ª£c y√™u c·∫ßu.\n",
    "\n",
    "L∆∞u √Ω quan tr·ªçng:\n",
    "- ƒê·∫£m b·∫£o t·∫•t c·∫£ s·ªë ti·ªÅn ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi v·ªÅ ƒë·ªìng VND (n·∫øu c√≥ ƒë∆°n v·ªã kh√°c)\n",
    "- Ng√†y th√°ng ph·∫£i theo ƒë·ªãnh d·∫°ng YYYY-MM-DD\n",
    "- N·∫øu th√¥ng tin kh√¥ng c√≥, h√£y ƒë·ªÉ tr·ªëng ho·∫∑c ghi \"N/A\"\n",
    "- Ki·ªÉm tra t√≠nh to√°n: subtotal + tax = total\n",
    "\n",
    "VƒÉn b·∫£n h√≥a ƒë∆°n:\n",
    "{invoice_text}\n",
    "\n",
    "ƒê·ªãnh d·∫°ng output:\n",
    "{format_instructions}\n",
    "\n",
    "JSON Output:\n",
    "\"\"\",\n",
    "    input_variables=[\"invoice_text\"],\n",
    "    partial_variables={\"format_instructions\": invoice_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Prompt template t·∫°o th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o LLM\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0.1,\n",
    "    callbacks=[langfuse_handler]\n",
    ")\n",
    "\n",
    "# T·∫°o chain\n",
    "invoice_chain = invoice_extraction_prompt | llm | invoice_parser\n",
    "\n",
    "print(\"‚úÖ Chain t·∫°o th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_invoice_with_tracing(invoice_text: str, invoice_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω h√≥a ƒë∆°n v·ªõi full tracking qua LangFuse\n",
    "    \"\"\"\n",
    "    # T·∫°o trace cho to√†n b·ªô qu√° tr√¨nh\n",
    "    trace = langfuse.trace(\n",
    "        name=\"invoice_extraction\",\n",
    "        input={\"invoice_text\": invoice_text[:200] + \"...\"},\n",
    "        tags=[\"data_processing\", \"invoice\", \"extraction\"],\n",
    "        metadata={\n",
    "            \"invoice_id\": invoice_id,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"text_length\": len(invoice_text)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Th·ª±c hi·ªán tr√≠ch xu·∫•t\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = invoice_chain.invoke({\"invoice_text\": invoice_text})\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # Validation logic\n",
    "        validation_errors = []\n",
    "        \n",
    "        # Ki·ªÉm tra t√≠nh to√°n\n",
    "        calculated_total = result.subtotal + result.tax_amount\n",
    "        if abs(calculated_total - result.total_amount) > 0.01:\n",
    "            validation_errors.append(f\"Math error: {result.subtotal} + {result.tax_amount} ‚â† {result.total_amount}\")\n",
    "        \n",
    "        # Ki·ªÉm tra items\n",
    "        items_total = sum(item.total_price for item in result.items)\n",
    "        if abs(items_total - result.subtotal) > 0.01:\n",
    "            validation_errors.append(f\"Items total mismatch: {items_total} ‚â† {result.subtotal}\")\n",
    "        \n",
    "        # C·∫≠p nh·∫≠t trace v·ªõi k·∫øt qu·∫£\n",
    "        trace.update(\n",
    "            output={\n",
    "                \"extracted_data\": result.dict(),\n",
    "                \"validation_errors\": validation_errors,\n",
    "                \"processing_time_seconds\": processing_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # T·∫°o score cho ch·∫•t l∆∞·ª£ng tr√≠ch xu·∫•t\n",
    "        quality_score = 1.0 - (len(validation_errors) * 0.2)\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"extraction_quality\",\n",
    "            value=max(0, quality_score),\n",
    "            comment=f\"Validation errors: {len(validation_errors)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": result,\n",
    "            \"validation_errors\": validation_errors,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Log l·ªói\n",
    "        trace.update(\n",
    "            output={\"error\": str(e)}\n",
    "        )\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"extraction_quality\",\n",
    "            value=0.0,\n",
    "            comment=f\"Extraction failed: {str(e)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Function x·ª≠ l√Ω h√≥a ƒë∆°n v·ªõi tracing ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th·ª≠ nghi·ªám tr√≠ch xu·∫•t v·ªõi h√≥a ƒë∆°n ƒë·∫ßu ti√™n\n",
    "print(\"üîç ƒêang x·ª≠ l√Ω h√≥a ƒë∆°n ƒë·∫ßu ti√™n...\")\n",
    "\n",
    "result1 = process_invoice_with_tracing(sample_invoices[0], \"invoice_001\")\n",
    "\n",
    "if result1[\"success\"]:\n",
    "    print(\"\\n‚úÖ Tr√≠ch xu·∫•t th√†nh c√¥ng!\")\n",
    "    print(f\"üìä Trace ID: {result1['trace_id']}\")\n",
    "    print(f\"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {result1['processing_time']:.2f}s\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    data = result1[\"data\"]\n",
    "    print(f\"\\nüìã Th√¥ng tin h√≥a ƒë∆°n:\")\n",
    "    print(f\"- S·ªë Hƒê: {data.invoice_number}\")\n",
    "    print(f\"- Ng√†y: {data.date}\")\n",
    "    print(f\"- Nh√† cung c·∫•p: {data.vendor_name}\")\n",
    "    print(f\"- S·ªë m·ª•c h√†ng: {len(data.items)}\")\n",
    "    print(f\"- T·ªïng ti·ªÅn: {data.total_amount:,.0f} VND\")\n",
    "    \n",
    "    if result1[\"validation_errors\"]:\n",
    "        print(f\"\\n‚ö†Ô∏è L·ªói validation: {result1['validation_errors']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Kh√¥ng c√≥ l·ªói validation\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå L·ªói: {result1['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X·ª≠ l√Ω h√≥a ƒë∆°n th·ª© hai\n",
    "print(\"üîç ƒêang x·ª≠ l√Ω h√≥a ƒë∆°n th·ª© hai...\")\n",
    "\n",
    "result2 = process_invoice_with_tracing(sample_invoices[1], \"invoice_002\")\n",
    "\n",
    "if result2[\"success\"]:\n",
    "    print(\"\\n‚úÖ Tr√≠ch xu·∫•t th√†nh c√¥ng!\")\n",
    "    print(f\"üìä Trace ID: {result2['trace_id']}\")\n",
    "    print(f\"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {result2['processing_time']:.2f}s\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    data = result2[\"data\"]\n",
    "    print(f\"\\nüìã Th√¥ng tin h√≥a ƒë∆°n:\")\n",
    "    print(f\"- S·ªë Hƒê: {data.invoice_number}\")\n",
    "    print(f\"- Ng√†y: {data.date}\")\n",
    "    print(f\"- Nh√† cung c·∫•p: {data.vendor_name}\")\n",
    "    print(f\"- S·ªë m·ª•c h√†ng: {len(data.items)}\")\n",
    "    print(f\"- T·ªïng ti·ªÅn: {data.total_amount:,.0f} VND\")\n",
    "    \n",
    "    if result2[\"validation_errors\"]:\n",
    "        print(f\"\\n‚ö†Ô∏è L·ªói validation: {result2['validation_errors']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Kh√¥ng c√≥ l·ªói validation\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå L·ªói: {result2['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2: Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªãa ch·ªâ\n",
    "\n",
    "Ch√∫ng ta s·∫Ω x√¢y d·ª±ng h·ªá th·ªëng chu·∫©n h√≥a ƒë·ªãa ch·ªâ t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng kh√°c nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema cho ƒë·ªãa ch·ªâ chu·∫©n h√≥a\n",
    "class StandardizedAddress(BaseModel):\n",
    "    street_number: Optional[str] = Field(description=\"S·ªë nh√†\")\n",
    "    street_name: str = Field(description=\"T√™n ƒë∆∞·ªùng\")\n",
    "    ward: Optional[str] = Field(description=\"Ph∆∞·ªùng/X√£\")\n",
    "    district: str = Field(description=\"Qu·∫≠n/Huy·ªán\")\n",
    "    city: str = Field(description=\"Th√†nh ph·ªë/T·ªânh\")\n",
    "    postal_code: Optional[str] = Field(description=\"M√£ b∆∞u ƒëi·ªán\")\n",
    "    country: str = Field(description=\"Qu·ªëc gia\", default=\"Vietnam\")\n",
    "    formatted_address: str = Field(description=\"ƒê·ªãa ch·ªâ ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\")\n",
    "    confidence_score: float = Field(description=\"ƒêi·ªÉm tin c·∫≠y (0-1)\", ge=0, le=1)\n",
    "\n",
    "address_parser = PydanticOutputParser(pydantic_object=StandardizedAddress)\n",
    "\n",
    "# D·ªØ li·ªáu ƒë·ªãa ch·ªâ m·∫´u v·ªõi nhi·ªÅu ƒë·ªãnh d·∫°ng\n",
    "sample_addresses = [\n",
    "    \"123 Nguyen Van A, Ward 1, District 1, HCMC\",\n",
    "    \"456 ƒë∆∞·ªùng L√™ L·ª£i, ph∆∞·ªùng B·∫øn Ngh√©, qu·∫≠n 1, th√†nh ph·ªë H·ªì Ch√≠ Minh\",\n",
    "    \"789 Le Duan St, Dist 3, Ho Chi Minh City, Vietnam\",\n",
    "    \"S·ªë 101, Ph·ªë Tr·∫ßn H∆∞ng ƒê·∫°o, P. C·ª≠a ƒê√¥ng, Q. Ho√†n Ki·∫øm, H√† N·ªôi\",\n",
    "    \"999 Hai Ba Trung, Da Kao Ward, D1, HCMC 70000\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Chu·∫©n b·ªã {len(sample_addresses)} ƒë·ªãa ch·ªâ m·∫´u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt cho chu·∫©n h√≥a ƒë·ªãa ch·ªâ\n",
    "address_normalization_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "B·∫°n l√† chuy√™n gia chu·∫©n h√≥a ƒë·ªãa ch·ªâ Vi·ªát Nam. H√£y ph√¢n t√≠ch ƒë·ªãa ch·ªâ sau v√† chu·∫©n h√≥a theo ƒë·ªãnh d·∫°ng th·ªëng nh·∫•t.\n",
    "\n",
    "Quy t·∫Øc chu·∫©n h√≥a:\n",
    "- Chu·∫©n h√≥a t√™n ƒë∆∞·ªùng (VD: \"Nguyen Van A\" ‚Üí \"Nguy·ªÖn VƒÉn A\")\n",
    "- Chu·∫©n h√≥a ƒë∆°n v·ªã h√†nh ch√≠nh (VD: \"District 1\" ‚Üí \"Qu·∫≠n 1\", \"Ward 1\" ‚Üí \"Ph∆∞·ªùng 1\")\n",
    "- T√™n th√†nh ph·ªë: \"Ho Chi Minh City\" ho·∫∑c \"HCMC\" ‚Üí \"Th√†nh ph·ªë H·ªì Ch√≠ Minh\"\n",
    "- T√™n th·ªß ƒë√¥: \"Hanoi\" ‚Üí \"H√† N·ªôi\"\n",
    "- ƒê√°nh gi√° ƒë·ªô tin c·∫≠y d·ª±a tr√™n t√≠nh ƒë·∫ßy ƒë·ªß v√† r√µ r√†ng c·ªßa th√¥ng tin\n",
    "\n",
    "ƒê·ªãa ch·ªâ c·∫ßn chu·∫©n h√≥a:\n",
    "{address_text}\n",
    "\n",
    "ƒê·ªãnh d·∫°ng output:\n",
    "{format_instructions}\n",
    "\n",
    "JSON Output:\n",
    "\"\"\",\n",
    "    input_variables=[\"address_text\"],\n",
    "    partial_variables={\"format_instructions\": address_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# T·∫°o chain cho chu·∫©n h√≥a ƒë·ªãa ch·ªâ\n",
    "address_chain = address_normalization_prompt | llm | address_parser\n",
    "\n",
    "print(\"‚úÖ Chain chu·∫©n h√≥a ƒë·ªãa ch·ªâ ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_address_with_tracing(address_text: str, address_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a ƒë·ªãa ch·ªâ v·ªõi full tracking\n",
    "    \"\"\"\n",
    "    trace = langfuse.trace(\n",
    "        name=\"address_normalization\",\n",
    "        input={\"address_text\": address_text},\n",
    "        tags=[\"data_processing\", \"address\", \"normalization\"],\n",
    "        metadata={\n",
    "            \"address_id\": address_id,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = address_chain.invoke({\"address_text\": address_text})\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # Validation\n",
    "        validation_errors = []\n",
    "        \n",
    "        # Ki·ªÉm tra c√°c tr∆∞·ªùng b·∫Øt bu·ªôc\n",
    "        if not result.street_name:\n",
    "            validation_errors.append(\"Missing street name\")\n",
    "        if not result.district:\n",
    "            validation_errors.append(\"Missing district\")\n",
    "        if not result.city:\n",
    "            validation_errors.append(\"Missing city\")\n",
    "        \n",
    "        # C·∫≠p nh·∫≠t trace\n",
    "        trace.update(\n",
    "            output={\n",
    "                \"normalized_address\": result.dict(),\n",
    "                \"validation_errors\": validation_errors,\n",
    "                \"processing_time_seconds\": processing_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Score d·ª±a tr√™n confidence v√† validation\n",
    "        final_score = result.confidence_score * (1 - len(validation_errors) * 0.1)\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"normalization_quality\",\n",
    "            value=max(0, final_score),\n",
    "            comment=f\"Confidence: {result.confidence_score}, Errors: {len(validation_errors)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": result,\n",
    "            \"validation_errors\": validation_errors,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        trace.update(output={\"error\": str(e)})\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"normalization_quality\",\n",
    "            value=0.0,\n",
    "            comment=f\"Normalization failed: {str(e)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Function chu·∫©n h√≥a ƒë·ªãa ch·ªâ v·ªõi tracing ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th·ª±c hi·ªán chu·∫©n h√≥a cho t·∫•t c·∫£ ƒë·ªãa ch·ªâ m·∫´u\n",
    "print(\"üîç ƒêang chu·∫©n h√≥a t·∫•t c·∫£ ƒë·ªãa ch·ªâ m·∫´u...\\n\")\n",
    "\n",
    "results = []\n",
    "for i, address in enumerate(sample_addresses):\n",
    "    print(f\"üìç ƒê·ªãa ch·ªâ {i+1}: {address}\")\n",
    "    \n",
    "    result = normalize_address_with_tracing(address, f\"addr_{i+1:03d}\")\n",
    "    results.append(result)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        data = result[\"data\"]\n",
    "        print(f\"   ‚úÖ Chu·∫©n h√≥a: {data.formatted_address}\")\n",
    "        print(f\"   üéØ ƒê·ªô tin c·∫≠y: {data.confidence_score:.2f}\")\n",
    "        print(f\"   ‚è±Ô∏è Th·ªùi gian: {result['processing_time']:.2f}s\")\n",
    "        \n",
    "        if result[\"validation_errors\"]:\n",
    "            print(f\"   ‚ö†Ô∏è L·ªói: {result['validation_errors']}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå L·ªói: {result['error']}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# T√≥m t·∫Øt k·∫øt qu·∫£\n",
    "successful_results = [r for r in results if r[\"success\"]]\n",
    "avg_confidence = sum(r[\"data\"].confidence_score for r in successful_results) / len(successful_results) if successful_results else 0\n",
    "avg_processing_time = sum(r[\"processing_time\"] for r in successful_results) / len(successful_results) if successful_results else 0\n",
    "\n",
    "print(f\"üìä T√≥m t·∫Øt k·∫øt qu·∫£:\")\n",
    "print(f\"   - Th√†nh c√¥ng: {len(successful_results)}/{len(results)}\")\n",
    "print(f\"   - ƒê·ªô tin c·∫≠y trung b√¨nh: {avg_confidence:.2f}\")\n",
    "print(f\"   - Th·ªùi gian x·ª≠ l√Ω trung b√¨nh: {avg_processing_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 3: Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng d·ªØ li·ªáu t·ª´ vƒÉn b·∫£n sang JSON\n",
    "\n",
    "Chuy·ªÉn ƒë·ªïi th√¥ng tin s·∫£n ph·∫©m t·ª´ m√¥ t·∫£ vƒÉn b·∫£n sang c·∫•u tr√∫c JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema cho th√¥ng tin s·∫£n ph·∫©m\n",
    "class ProductSpecification(BaseModel):\n",
    "    attribute: str = Field(description=\"T√™n thu·ªôc t√≠nh\")\n",
    "    value: str = Field(description=\"Gi√° tr·ªã thu·ªôc t√≠nh\")\n",
    "    unit: Optional[str] = Field(description=\"ƒê∆°n v·ªã ƒëo\")\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    "    name: str = Field(description=\"T√™n s·∫£n ph·∫©m\")\n",
    "    category: str = Field(description=\"Danh m·ª•c s·∫£n ph·∫©m\")\n",
    "    brand: Optional[str] = Field(description=\"Th∆∞∆°ng hi·ªáu\")\n",
    "    model: Optional[str] = Field(description=\"M√£ model\")\n",
    "    price: Optional[float] = Field(description=\"Gi√° b√°n\")\n",
    "    currency: str = Field(description=\"ƒê∆°n v·ªã ti·ªÅn t·ªá\", default=\"VND\")\n",
    "    specifications: List[ProductSpecification] = Field(description=\"Th√¥ng s·ªë k·ªπ thu·∫≠t\")\n",
    "    description: str = Field(description=\"M√¥ t·∫£ s·∫£n ph·∫©m\")\n",
    "    availability: str = Field(description=\"T√¨nh tr·∫°ng c√≥ h√†ng\")\n",
    "\n",
    "product_parser = PydanticOutputParser(pydantic_object=ProductInfo)\n",
    "\n",
    "# D·ªØ li·ªáu s·∫£n ph·∫©m m·∫´u\n",
    "sample_products = [\n",
    "    \"\"\"\n",
    "    Laptop Gaming ASUS ROG Strix G15 G513QM-HN015W\n",
    "    \n",
    "    Th√¥ng tin c∆° b·∫£n:\n",
    "    - Th∆∞∆°ng hi·ªáu: ASUS\n",
    "    - D√≤ng s·∫£n ph·∫©m: ROG Strix G15\n",
    "    - Model: G513QM-HN015W\n",
    "    - Gi√° b√°n: 25,990,000 VND\n",
    "    - T√¨nh tr·∫°ng: C√≤n h√†ng\n",
    "    \n",
    "    Th√¥ng s·ªë k·ªπ thu·∫≠t:\n",
    "    - CPU: AMD Ryzen 7 5800H (8 nh√¢n, 16 lu·ªìng, 3.2GHz base, 4.4GHz boost)\n",
    "    - RAM: 16GB DDR4-3200MHz\n",
    "    - ·ªî c·ª©ng: 512GB NVMe SSD\n",
    "    - Card ƒë·ªì h·ªça: NVIDIA GeForce RTX 3060 6GB GDDR6\n",
    "    - M√†n h√¨nh: 15.6 inch Full HD IPS 144Hz\n",
    "    - H·ªá ƒëi·ªÅu h√†nh: Windows 11 Home\n",
    "    - Tr·ªçng l∆∞·ª£ng: 2.3kg\n",
    "    - Pin: 56Wh\n",
    "    \n",
    "    M√¥ t·∫£: Laptop gaming m·∫°nh m·∫Ω v·ªõi thi·∫øt k·∫ø RGB ƒë·∫πp m·∫Øt, hi·ªáu nƒÉng cao cho game v√† c√¥ng vi·ªác ƒë·ªì h·ªça.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    iPhone 15 Pro Max 256GB Natural Titanium\n",
    "    \n",
    "    Brand: Apple\n",
    "    Product Line: iPhone 15 Pro Max\n",
    "    Storage: 256GB\n",
    "    Color: Natural Titanium\n",
    "    Price: $1,199 USD\n",
    "    Status: In Stock\n",
    "    \n",
    "    Key Features:\n",
    "    - Display: 6.7-inch Super Retina XDR OLED\n",
    "    - Processor: A17 Pro chip with 6-core CPU\n",
    "    - Camera: 48MP main camera with 5x optical zoom\n",
    "    - Battery: Up to 29 hours video playback\n",
    "    - Material: Titanium body with Ceramic Shield front\n",
    "    - Operating System: iOS 17\n",
    "    - Connectivity: 5G, Wi-Fi 6E, Bluetooth 5.3\n",
    "    - Weight: 221g\n",
    "    \n",
    "    Description: The most advanced iPhone ever with titanium design and professional camera system.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Chu·∫©n b·ªã {len(sample_products)} s·∫£n ph·∫©m m·∫´u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt cho chuy·ªÉn ƒë·ªïi th√¥ng tin s·∫£n ph·∫©m\n",
    "product_conversion_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch th√¥ng tin s·∫£n ph·∫©m. H√£y tr√≠ch xu·∫•t v√† c·∫•u tr√∫c h√≥a th√¥ng tin s·∫£n ph·∫©m t·ª´ vƒÉn b·∫£n sau.\n",
    "\n",
    "L∆∞u √Ω quan tr·ªçng:\n",
    "- Chuy·ªÉn ƒë·ªïi gi√° v·ªÅ VND n·∫øu c·∫ßn (1 USD = 24,000 VND)\n",
    "- Ph√¢n t√≠ch k·ªπ th√¥ng s·ªë k·ªπ thu·∫≠t v√† t√°ch th√†nh c√°c thu·ªôc t√≠nh ri√™ng bi·ªát\n",
    "- X√°c ƒë·ªãnh ƒë√∫ng danh m·ª•c s·∫£n ph·∫©m (Laptop, Smartphone, Tablet, v.v.)\n",
    "- T√¨nh tr·∫°ng h√†ng: \"C√≤n h√†ng\", \"H·∫øt h√†ng\", \"S·∫Øp c√≥ h√†ng\"\n",
    "\n",
    "Th√¥ng tin s·∫£n ph·∫©m:\n",
    "{product_text}\n",
    "\n",
    "ƒê·ªãnh d·∫°ng output:\n",
    "{format_instructions}\n",
    "\n",
    "JSON Output:\n",
    "\"\"\",\n",
    "    input_variables=[\"product_text\"],\n",
    "    partial_variables={\"format_instructions\": product_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# T·∫°o chain\n",
    "product_chain = product_conversion_prompt | llm | product_parser\n",
    "\n",
    "print(\"‚úÖ Chain chuy·ªÉn ƒë·ªïi s·∫£n ph·∫©m ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_product_with_tracing(product_text: str, product_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi th√¥ng tin s·∫£n ph·∫©m v·ªõi full tracking\n",
    "    \"\"\"\n",
    "    trace = langfuse.trace(\n",
    "        name=\"product_conversion\",\n",
    "        input={\"product_text\": product_text[:300] + \"...\"},\n",
    "        tags=[\"data_processing\", \"product\", \"conversion\"],\n",
    "        metadata={\n",
    "            \"product_id\": product_id,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"text_length\": len(product_text)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = product_chain.invoke({\"product_text\": product_text})\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # Validation\n",
    "        validation_errors = []\n",
    "        \n",
    "        # Ki·ªÉm tra c√°c tr∆∞·ªùng b·∫Øt bu·ªôc\n",
    "        if not result.name:\n",
    "            validation_errors.append(\"Missing product name\")\n",
    "        if not result.category:\n",
    "            validation_errors.append(\"Missing category\")\n",
    "        if len(result.specifications) == 0:\n",
    "            validation_errors.append(\"No specifications found\")\n",
    "        \n",
    "        # Ki·ªÉm tra logic gi√°\n",
    "        if result.price and result.price <= 0:\n",
    "            validation_errors.append(\"Invalid price value\")\n",
    "        \n",
    "        # C·∫≠p nh·∫≠t trace\n",
    "        trace.update(\n",
    "            output={\n",
    "                \"converted_product\": result.dict(),\n",
    "                \"validation_errors\": validation_errors,\n",
    "                \"processing_time_seconds\": processing_time,\n",
    "                \"specifications_count\": len(result.specifications)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Score d·ª±a tr√™n completeness\n",
    "        completeness_score = 0\n",
    "        if result.name: completeness_score += 0.2\n",
    "        if result.brand: completeness_score += 0.1\n",
    "        if result.price: completeness_score += 0.2\n",
    "        if result.specifications: completeness_score += 0.3\n",
    "        if result.description: completeness_score += 0.2\n",
    "        \n",
    "        final_score = completeness_score * (1 - len(validation_errors) * 0.1)\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"conversion_quality\",\n",
    "            value=max(0, final_score),\n",
    "            comment=f\"Completeness: {completeness_score:.2f}, Errors: {len(validation_errors)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": result,\n",
    "            \"validation_errors\": validation_errors,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"completeness_score\": completeness_score,\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        trace.update(output={\"error\": str(e)})\n",
    "        \n",
    "        langfuse.score(\n",
    "            trace_id=trace.id,\n",
    "            name=\"conversion_quality\",\n",
    "            value=0.0,\n",
    "            comment=f\"Conversion failed: {str(e)}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"trace_id\": trace.id\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Function chuy·ªÉn ƒë·ªïi s·∫£n ph·∫©m v·ªõi tracing ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi cho t·∫•t c·∫£ s·∫£n ph·∫©m m·∫´u\n",
    "print(\"üîç ƒêang chuy·ªÉn ƒë·ªïi th√¥ng tin s·∫£n ph·∫©m...\\n\")\n",
    "\n",
    "product_results = []\n",
    "for i, product in enumerate(sample_products):\n",
    "    print(f\"üì± S·∫£n ph·∫©m {i+1}:\")\n",
    "    \n",
    "    result = convert_product_with_tracing(product, f\"prod_{i+1:03d}\")\n",
    "    product_results.append(result)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        data = result[\"data\"]\n",
    "        print(f\"   ‚úÖ T√™n: {data.name}\")\n",
    "        print(f\"   üè∑Ô∏è Danh m·ª•c: {data.category}\")\n",
    "        print(f\"   üè¢ Th∆∞∆°ng hi·ªáu: {data.brand or 'N/A'}\")\n",
    "        print(f\"   üí∞ Gi√°: {data.price:,.0f} {data.currency}\" if data.price else \"   üí∞ Gi√°: N/A\")\n",
    "        print(f\"   üìã Th√¥ng s·ªë: {len(data.specifications)} m·ª•c\")\n",
    "        print(f\"   üìä ƒê·ªô ho√†n thi·ªán: {result['completeness_score']:.2f}\")\n",
    "        print(f\"   ‚è±Ô∏è Th·ªùi gian: {result['processing_time']:.2f}s\")\n",
    "        \n",
    "        if result[\"validation_errors\"]:\n",
    "            print(f\"   ‚ö†Ô∏è L·ªói: {result['validation_errors']}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå L·ªói: {result['error']}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# T√≥m t·∫Øt k·∫øt qu·∫£\n",
    "successful_products = [r for r in product_results if r[\"success\"]]\n",
    "avg_completeness = sum(r[\"completeness_score\"] for r in successful_products) / len(successful_products) if successful_products else 0\n",
    "avg_specs_count = sum(len(r[\"data\"].specifications) for r in successful_products) / len(successful_products) if successful_products else 0\n",
    "\n",
    "print(f\"üìä T√≥m t·∫Øt k·∫øt qu·∫£ chuy·ªÉn ƒë·ªïi s·∫£n ph·∫©m:\")\n",
    "print(f\"   - Th√†nh c√¥ng: {len(successful_products)}/{len(product_results)}\")\n",
    "print(f\"   - ƒê·ªô ho√†n thi·ªán trung b√¨nh: {avg_completeness:.2f}\")\n",
    "print(f\"   - S·ªë th√¥ng s·ªë trung b√¨nh: {avg_specs_count:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ph√¢n t√≠ch & C·∫£i thi·ªán Prompt v·ªõi LangFuse\n",
    "\n",
    "B√¢y gi·ªù ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng LangFuse UI ƒë·ªÉ ph√¢n t√≠ch hi·ªáu su·∫•t v√† c·∫£i thi·ªán prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o session ƒë·ªÉ nh√≥m t·∫•t c·∫£ c√°c traces\n",
    "session = langfuse.create_session(\n",
    "    name=\"data_processing_optimization\",\n",
    "    metadata={\n",
    "        \"experiment_type\": \"prompt_optimization\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_operations\": len(sample_invoices) + len(sample_addresses) + len(sample_products)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"üìä Session t·∫°o th√†nh c√¥ng: {session.id}\")\n",
    "print(f\"üîó Xem chi ti·∫øt t·∫°i: http://localhost:3000/sessions/{session.id}\")\n",
    "\n",
    "# Flush ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ d·ªØ li·ªáu ƒë∆∞·ª£c g·ª≠i\n",
    "langfuse.flush()\n",
    "\n",
    "print(\"\\n‚úÖ T·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g·ª≠i l√™n LangFuse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y th·ªëng k√™ t·ª´ LangFuse\n",
    "def get_performance_stats():\n",
    "    \"\"\"\n",
    "    L·∫•y th·ªëng k√™ hi·ªáu su·∫•t t·ª´ LangFuse\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # L·∫•y t·∫•t c·∫£ traces t·ª´ session\n",
    "        traces = langfuse.get_traces(limit=100)\n",
    "        \n",
    "        # Ph√¢n lo·∫°i theo tags\n",
    "        invoice_traces = []\n",
    "        address_traces = []\n",
    "        product_traces = []\n",
    "        \n",
    "        for trace in traces.data:\n",
    "            if 'invoice' in trace.tags:\n",
    "                invoice_traces.append(trace)\n",
    "            elif 'address' in trace.tags:\n",
    "                address_traces.append(trace)\n",
    "            elif 'product' in trace.tags:\n",
    "                product_traces.append(trace)\n",
    "        \n",
    "        stats = {\n",
    "            \"invoice_extraction\": {\n",
    "                \"count\": len(invoice_traces),\n",
    "                \"avg_latency\": sum(t.latency for t in invoice_traces if t.latency) / len(invoice_traces) if invoice_traces else 0\n",
    "            },\n",
    "            \"address_normalization\": {\n",
    "                \"count\": len(address_traces),\n",
    "                \"avg_latency\": sum(t.latency for t in address_traces if t.latency) / len(address_traces) if address_traces else 0\n",
    "            },\n",
    "            \"product_conversion\": {\n",
    "                \"count\": len(product_traces),\n",
    "                \"avg_latency\": sum(t.latency for t in product_traces if t.latency) / len(product_traces) if product_traces else 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi l·∫•y th·ªëng k√™: {e}\")\n",
    "        return None\n",
    "\n",
    "# Hi·ªÉn th·ªã th·ªëng k√™\n",
    "stats = get_performance_stats()\n",
    "if stats:\n",
    "    print(\"üìà Th·ªëng k√™ hi·ªáu su·∫•t:\")\n",
    "    print(f\"\\nüßæ Tr√≠ch xu·∫•t h√≥a ƒë∆°n:\")\n",
    "    print(f\"   - S·ªë traces: {stats['invoice_extraction']['count']}\")\n",
    "    print(f\"   - Latency trung b√¨nh: {stats['invoice_extraction']['avg_latency']:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\nüìç Chu·∫©n h√≥a ƒë·ªãa ch·ªâ:\")\n",
    "    print(f\"   - S·ªë traces: {stats['address_normalization']['count']}\")\n",
    "    print(f\"   - Latency trung b√¨nh: {stats['address_normalization']['avg_latency']:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\nüì± Chuy·ªÉn ƒë·ªïi s·∫£n ph·∫©m:\")\n",
    "    print(f\"   - S·ªë traces: {stats['product_conversion']['count']}\")\n",
    "    print(f\"   - Latency trung b√¨nh: {stats['product_conversion']['avg_latency']:.2f}ms\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y th·ªëng k√™ t·ª´ LangFuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng LangFuse UI ƒë·ªÉ c·∫£i thi·ªán prompt\n",
    "\n",
    "### 1. Truy c·∫≠p LangFuse Dashboard\n",
    "- M·ªü tr√¨nh duy·ªát v√† truy c·∫≠p: `http://localhost:3000`\n",
    "- ƒêƒÉng nh·∫≠p v·ªõi t√†i kho·∫£n c·ªßa b·∫°n\n",
    "\n",
    "### 2. Ph√¢n t√≠ch Traces\n",
    "- Trong tab **Traces**, t√¨m c√°c traces v·ªõi tags `data_processing`\n",
    "- S·∫Øp x·∫øp theo **Score** ƒë·ªÉ xem c√°c k·∫øt qu·∫£ t·ªët nh·∫•t v√† t·ªá nh·∫•t\n",
    "- Click v√†o t·ª´ng trace ƒë·ªÉ xem chi ti·∫øt:\n",
    "  - Input: D·ªØ li·ªáu ƒë·∫ßu v√†o\n",
    "  - Output: K·∫øt qu·∫£ tr√≠ch xu·∫•t\n",
    "  - Metadata: Th√¥ng tin b·ªï sung (th·ªùi gian, l·ªói validation)\n",
    "\n",
    "### 3. X√°c ƒë·ªãnh Pattern l·ªói\n",
    "- **L·ªói th∆∞·ªùng g·∫∑p v·ªõi h√≥a ƒë∆°n:**\n",
    "  - Sai ƒë·ªãnh d·∫°ng ng√†y th√°ng\n",
    "  - Nh·∫ßm l·∫´n ƒë∆°n v·ªã ti·ªÅn t·ªá\n",
    "  - Thi·∫øu th√¥ng tin thu·∫ø\n",
    "- **L·ªói th∆∞·ªùng g·∫∑p v·ªõi ƒë·ªãa ch·ªâ:**\n",
    "  - Kh√¥ng chu·∫©n h√≥a ƒë∆∞·ª£c t√™n ƒë·ªãa danh\n",
    "  - Thi·∫øu th√¥ng tin qu·∫≠n/huy·ªán\n",
    "  - Confidence score th·∫•p\n",
    "- **L·ªói th∆∞·ªùng g·∫∑p v·ªõi s·∫£n ph·∫©m:**\n",
    "  - B·ªè s√≥t th√¥ng s·ªë k·ªπ thu·∫≠t\n",
    "  - Kh√¥ng chuy·ªÉn ƒë·ªïi ƒë∆∞·ª£c ƒë∆°n v·ªã\n",
    "  - Ph√¢n lo·∫°i sai danh m·ª•c\n",
    "\n",
    "### 4. C·∫£i thi·ªán Prompt\n",
    "D·ª±a tr√™n ph√¢n t√≠ch, b·∫°n c√≥ th·ªÉ:\n",
    "- **Th√™m v√≠ d·ª• c·ª• th·ªÉ** trong prompt cho c√°c tr∆∞·ªùng h·ª£p kh√≥\n",
    "- **C·∫£i thi·ªán instruction** ƒë·ªÉ x·ª≠ l√Ω edge cases\n",
    "- **Th√™m validation rules** trong prompt\n",
    "- **S·ª≠ d·ª•ng few-shot learning** v·ªõi c√°c v√≠ d·ª• th√†nh c√¥ng\n",
    "\n",
    "### 5. A/B Testing\n",
    "- T·∫°o phi√™n b·∫£n prompt m·ªõi\n",
    "- Ch·∫°y th·ª≠ nghi·ªám v·ªõi c√πng d·ªØ li·ªáu\n",
    "- So s√°nh scores gi·ªØa c√°c phi√™n b·∫£n\n",
    "- Ch·ªçn phi√™n b·∫£n c√≥ hi·ªáu su·∫•t t·ªët nh·∫•t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√≠ d·ª• v·ªÅ c·∫£i thi·ªán prompt d·ª±a tr√™n feedback\n",
    "improved_invoice_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "B·∫°n l√† m·ªôt chuy√™n gia tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√≥a ƒë∆°n v·ªõi 10 nƒÉm kinh nghi·ªám. H√£y ph√¢n t√≠ch vƒÉn b·∫£n h√≥a ƒë∆°n sau v√† tr√≠ch xu·∫•t th√¥ng tin theo ƒë·ªãnh d·∫°ng JSON ƒë∆∞·ª£c y√™u c·∫ßu.\n",
    "\n",
    "QUAN TR·ªåNG - Quy t·∫Øc x·ª≠ l√Ω:\n",
    "1. NG√ÄY TH√ÅNG: \n",
    "   - Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ v·ªÅ ƒë·ªãnh d·∫°ng YYYY-MM-DD\n",
    "   - VD: \"15/01/2024\" ‚Üí \"2024-01-15\"\n",
    "   - VD: \"Jan 15, 2024\" ‚Üí \"2024-01-15\"\n",
    "\n",
    "2. TI·ªÄN T·ªÜ:\n",
    "   - T·∫•t c·∫£ s·ªë ti·ªÅn ph·∫£i chuy·ªÉn v·ªÅ VND\n",
    "   - 1 USD = 24,000 VND\n",
    "   - 1 EUR = 26,000 VND\n",
    "   - Lo·∫°i b·ªè d·∫•u ph·∫©y v√† k√Ω hi·ªáu ti·ªÅn t·ªá\n",
    "\n",
    "3. VALIDATION:\n",
    "   - Ki·ªÉm tra: T·ªïng c√°c items = Subtotal\n",
    "   - Ki·ªÉm tra: Subtotal + Tax = Total\n",
    "   - N·∫øu kh√¥ng kh·ªõp, ∆∞u ti√™n s·ªë li·ªáu t·ª´ b·∫£ng chi ti·∫øt\n",
    "\n",
    "4. TH√îNG TIN THI·∫æU:\n",
    "   - N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, ghi \"N/A\"\n",
    "   - Kh√¥ng ƒë∆∞·ª£c t·ª± t·∫°o ra th√¥ng tin kh√¥ng c√≥\n",
    "\n",
    "VƒÉn b·∫£n h√≥a ƒë∆°n:\n",
    "{invoice_text}\n",
    "\n",
    "ƒê·ªãnh d·∫°ng output:\n",
    "{format_instructions}\n",
    "\n",
    "H√£y ki·ªÉm tra k·ªπ t·∫•t c·∫£ ph√©p t√≠nh tr∆∞·ªõc khi tr·∫£ v·ªÅ k·∫øt qu·∫£.\n",
    "\n",
    "JSON Output:\n",
    "\"\"\",\n",
    "    input_variables=[\"invoice_text\"],\n",
    "    partial_variables={\"format_instructions\": invoice_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Prompt c·∫£i thi·ªán ƒë√£ s·∫µn s√†ng!\")\n",
    "print(\"\\nüîÑ B·∫°n c√≥ th·ªÉ th·ª≠ nghi·ªám prompt m·ªõi n√†y v·ªõi d·ªØ li·ªáu t∆∞∆°ng t·ª± v√† so s√°nh k·∫øt qu·∫£ trong LangFuse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T√†i li·ªáu Tham kh·∫£o\n",
    "\n",
    "### LangFuse Documentation\n",
    "- **Prompt Management**: https://langfuse.com/docs/prompts\n",
    "- **Evaluation & Scoring**: https://langfuse.com/docs/scores\n",
    "- **Tracing & Observability**: https://langfuse.com/docs/tracing\n",
    "- **LangChain Integration**: https://langfuse.com/docs/integrations/langchain\n",
    "- **Dashboard Analytics**: https://langfuse.com/docs/analytics\n",
    "\n",
    "### Best Practices\n",
    "- **Prompt Engineering**: https://langfuse.com/docs/prompts/best-practices\n",
    "- **Data Quality Monitoring**: https://langfuse.com/docs/data-quality\n",
    "- **Performance Optimization**: https://langfuse.com/docs/performance\n",
    "\n",
    "### API References\n",
    "- **Python SDK**: https://langfuse.com/docs/sdk/python\n",
    "- **REST API**: https://langfuse.com/docs/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n & B∆∞·ªõc ti·∫øp theo\n",
    "\n",
    "### Nh·ªØng g√¨ ƒë√£ h·ªçc ƒë∆∞·ª£c:\n",
    "1. **C√°ch s·ª≠ d·ª•ng LangFuse ƒë·ªÉ theo d√µi hi·ªáu su·∫•t** c·ªßa c√°c prompt x·ª≠ l√Ω d·ªØ li·ªáu\n",
    "2. **Thi·∫øt k·∫ø validation logic** ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu ƒë·∫ßu ra\n",
    "3. **Ph√¢n t√≠ch pattern l·ªói** v√† c·∫£i thi·ªán prompt d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø\n",
    "4. **S·ª≠ d·ª•ng scoring system** ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng t·ª± ƒë·ªông\n",
    "5. **T·∫°o metadata phong ph√∫** ƒë·ªÉ ph√¢n t√≠ch s√¢u h∆°n\n",
    "\n",
    "### B∆∞·ªõc ti·∫øp theo:\n",
    "1. **M·ªü r·ªông validation rules** cho c√°c use case c·ª• th·ªÉ\n",
    "2. **Th·ª±c hi·ªán A/B testing** v·ªõi c√°c phi√™n b·∫£n prompt kh√°c nhau\n",
    "3. **T√≠ch h·ª£p human feedback** ƒë·ªÉ c·∫£i thi·ªán li√™n t·ª•c\n",
    "4. **X√¢y d·ª±ng pipeline t·ª± ƒë·ªông** cho vi·ªác retraining prompt\n",
    "5. **Tri·ªÉn khai monitoring** trong production environment\n",
    "\n",
    "### Key Takeaways:\n",
    "- **LangFuse l√† c√¥ng c·ª• m·∫°nh m·∫Ω** ƒë·ªÉ t·ªëi ∆∞u h√≥a prompt cho data processing\n",
    "- **Validation v√† scoring** l√† ch√¨a kh√≥a ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng\n",
    "- **Iterative improvement** d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø mang l·∫°i k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "- **Structured output parsing** gi√∫p ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n c·ªßa d·ªØ li·ªáu\n",
    "\n",
    "### Th·ª±c h√†nh ti·∫øp theo:\n",
    "H√£y th·ª≠ √°p d·ª•ng nh·ªØng k·ªπ thu·∫≠t n√†y v√†o d·ª± √°n th·ª±c t·∫ø c·ªßa b·∫°n v√† s·ª≠ d·ª•ng LangFuse ƒë·ªÉ li√™n t·ª•c c·∫£i thi·ªán hi·ªáu su·∫•t!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}