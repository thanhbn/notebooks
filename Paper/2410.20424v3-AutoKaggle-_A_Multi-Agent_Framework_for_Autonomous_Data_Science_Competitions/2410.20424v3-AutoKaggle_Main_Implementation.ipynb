{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions\n",
    "\n",
    "## Giới thiệu Paper\n",
    "\n",
    "- **Tên paper:** AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions\n",
    "- **Tác giả:** Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, Wanjun Zhong, Wangchunshu Zhou, Wenhao Huang, Ge Zhang\n",
    "- **Link:** [arXiv:2410.20424v3](https://arxiv.org/abs/2410.20424)\n",
    "- **Tóm tắt:** \n",
    "  > Paper giới thiệu AutoKaggle - một framework đa tác tử giúp tự động hóa quy trình giải quyết các bài toán khoa học dữ liệu trong các cuộc thi Kaggle. AutoKaggle triển khai quy trình phát triển lặp kết hợp thực thi code, gỡ lỗi và kiểm thử đơn vị toàn diện để đảm bảo tính chính xác của code. Framework này cung cấp luồng công việc tùy biến cao, cho phép người dùng can thiệp ở mỗi giai đoạn, tích hợp trí tuệ tự động với chuyên môn của con người. Nền tảng của giải pháp là bộ công cụ khoa học dữ liệu đã được xác thực, bao gồm các hàm dùng cho làm sạch dữ liệu, kỹ thuật đặc trưng và mô hình hóa. Đánh giá trên 8 cuộc thi Kaggle cho thấy AutoKaggle đạt tỷ lệ nộp bài hợp lệ 0.85 và điểm toàn diện 0.82, chứng minh hiệu quả và tính thực tiễn trong xử lý các tác vụ khoa học dữ liệu phức tạp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cài đặt môi trường và thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai langchain-community langchain-core\n",
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip install -q langgraph\n",
    "!pip install -q langchain-anthropic\n",
    "!pip install -q deepeval\n",
    "!pip install -q langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Optional, Tuple, Any, Union\n",
    "from enum import Enum\n",
    "\n",
    "# Import các thư viện LangChain và LangGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Import LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# Để đánh giá\n",
    "from deepeval.metrics import FactualConsistencyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Thiết lập môi trường\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_ANTHROPIC_API_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cấu trúc tổng quát của AutoKaggle\n",
    "\n",
    "AutoKaggle là một framework đa tác tử dựa trên phase, được thiết kế để giải quyết các cuộc thi khoa học dữ liệu trên Kaggle. Framework này bao gồm hai thành phần chính:\n",
    "\n",
    "1. **Luồng công việc dựa trên phase (Phase-based Workflow)**: Chia quy trình khoa học dữ liệu thành 6 giai đoạn chính:\n",
    "   - Hiểu biết nền tảng (Background Understanding)\n",
    "   - Phân tích dữ liệu khám phá sơ bộ (Preliminary EDA)\n",
    "   - Làm sạch dữ liệu (Data Cleaning)\n",
    "   - Phân tích dữ liệu khám phá chuyên sâu (In-depth EDA)\n",
    "   - Kỹ thuật đặc trưng (Feature Engineering)\n",
    "   - Xây dựng, xác thực và dự đoán mô hình (Model Building, Validation and Prediction)\n",
    "\n",
    "2. **Hệ thống đa tác tử (Multi-agent System)**: Bao gồm 5 tác tử chuyên biệt:\n",
    "   - Reader: Đọc và tóm tắt thông tin\n",
    "   - Planner: Lập kế hoạch cho các nhiệm vụ\n",
    "   - Developer: Viết và thực thi code\n",
    "   - Reviewer: Đánh giá kết quả\n",
    "   - Summarizer: Tạo báo cáo tổng hợp\n",
    "\n",
    "Dưới đây, chúng ta sẽ triển khai một phiên bản đơn giản hóa của AutoKaggle sử dụng LangChain và LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Định nghĩa các Phase và State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa các phase trong AutoKaggle\n",
    "class Phase(Enum):\n",
    "    BACKGROUND_UNDERSTANDING = \"Background Understanding\"\n",
    "    PRELIMINARY_EDA = \"Preliminary EDA\"\n",
    "    DATA_CLEANING = \"Data Cleaning\"\n",
    "    INDEPTH_EDA = \"In-depth EDA\"\n",
    "    FEATURE_ENGINEERING = \"Feature Engineering\"\n",
    "    MODEL_BUILDING = \"Model Building, Validation and Prediction\"\n",
    "    COMPLETED = \"Completed\"\n",
    "\n",
    "# State của hệ thống\n",
    "class AutoKaggleState:\n",
    "    def __init__(self):\n",
    "        self.current_phase = Phase.BACKGROUND_UNDERSTANDING\n",
    "        self.competition_info = {}\n",
    "        self.data = {}\n",
    "        self.clean_data = {}\n",
    "        self.feature_data = {}\n",
    "        self.model_results = {}\n",
    "        self.errors = []\n",
    "        self.reports = {}\n",
    "        self.plans = {}\n",
    "        self.code = {}\n",
    "        self.execution_results = {}\n",
    "        self.test_results = {}\n",
    "    \n",
    "    def update_phase(self, phase: Phase):\n",
    "        self.current_phase = phase\n",
    "    \n",
    "    def get_current_phase(self):\n",
    "        return self.current_phase\n",
    "    \n",
    "    def add_report(self, phase: Phase, report: str):\n",
    "        self.reports[phase.value] = report\n",
    "    \n",
    "    def add_plan(self, phase: Phase, plan: str):\n",
    "        self.plans[phase.value] = plan\n",
    "    \n",
    "    def add_code(self, phase: Phase, code: str):\n",
    "        self.code[phase.value] = code\n",
    "    \n",
    "    def add_execution_result(self, phase: Phase, result: str):\n",
    "        self.execution_results[phase.value] = result\n",
    "    \n",
    "    def add_test_result(self, phase: Phase, result: Dict):\n",
    "        self.test_results[phase.value] = result\n",
    "    \n",
    "    def add_error(self, phase: Phase, error: str):\n",
    "        if not phase.value in self.errors:\n",
    "            self.errors.append({\"phase\": phase.value, \"error\": error})\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"current_phase\": self.current_phase.value,\n",
    "            \"competition_info\": self.competition_info,\n",
    "            \"reports\": self.reports,\n",
    "            \"plans\": self.plans,\n",
    "            \"code\": self.code,\n",
    "            \"execution_results\": self.execution_results,\n",
    "            \"test_results\": self.test_results,\n",
    "            \"errors\": self.errors\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Triển khai các tác tử (Agents)\n",
    "\n",
    "Trong triển khai này, chúng ta sẽ tập trung vào 5 tác tử chính của AutoKaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reader Agent - Đọc và tóm tắt thông tin\n",
    "class ReaderAgent:\n",
    "    def __init__(self, model: BaseChatModel):\n",
    "        self.model = model\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are a Reader agent specialized in analyzing competition information.\n",
    "            Your task is to read and summarize the competition overview, understand the data files and structure.\n",
    "            Provide a comprehensive analysis covering:\n",
    "            1. Competition Overview\n",
    "            2. Files and their purpose\n",
    "            3. Problem Definition\n",
    "            4. Data Information including data types and descriptions\n",
    "            5. Target Variable\n",
    "            6. Evaluation Metrics\n",
    "            7. Submission Format\n",
    "            8. Other key aspects\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def execute(self, input_data: Dict) -> str:\n",
    "        result = self.chain.invoke({\"input\": input_data.get(\"content\", \"\"), \"history\": []})\n",
    "        return result\n",
    "\n",
    "# 2. Planner Agent - Tạo kế hoạch cho các nhiệm vụ\n",
    "class PlannerAgent:\n",
    "    def __init__(self, model: BaseChatModel):\n",
    "        self.model = model\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are a Planner agent responsible for creating task plans.\n",
    "            Your job is to analyze the current phase and create a detailed plan with the following structure:\n",
    "            1. Break down the phase into a maximum of 4 key tasks\n",
    "            2. For each task, provide:\n",
    "               - Clear objective\n",
    "               - Required methods and approaches\n",
    "               - Expected outputs\n",
    "               - Constraints and considerations\n",
    "            Focus only on the current phase and be specific about each feature to process.\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def execute(self, input_data: Dict) -> str:\n",
    "        phase = input_data.get(\"phase\", \"\")\n",
    "        state_info = input_data.get(\"state_info\", \"\")\n",
    "        result = self.chain.invoke({\n",
    "            \"input\": f\"Current phase: {phase}\\n\\nState information:\\n{state_info}\\n\\nCreate a detailed plan for this phase.\",\n",
    "            \"history\": []\n",
    "        })\n",
    "        return result\n",
    "\n",
    "# 3. Developer Agent - Viết và thực thi code\n",
    "class DeveloperAgent:\n",
    "    def __init__(self, model: BaseChatModel):\n",
    "        self.model = model\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are a Developer agent specialized in implementing code according to plans.\n",
    "            Your task is to write code for data science tasks based on the provided plan.\n",
    "            You should:\n",
    "            1. Create well-structured, efficient, and correct Python code\n",
    "            2. Follow the plan strictly and implement all specified tasks\n",
    "            3. Include detailed comments to explain complex operations\n",
    "            4. Generate code that can be directly executed\n",
    "            5. Prepare for error handling and validation\n",
    "            \n",
    "            When there are errors in the code, you should debug it by:\n",
    "            1. Analyzing the error message\n",
    "            2. Identifying the root cause\n",
    "            3. Correcting the code\n",
    "            4. Retesting to confirm the fix\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def execute(self, input_data: Dict) -> str:\n",
    "        plan = input_data.get(\"plan\", \"\")\n",
    "        phase = input_data.get(\"phase\", \"\")\n",
    "        error_message = input_data.get(\"error_message\", \"\")\n",
    "        previous_code = input_data.get(\"previous_code\", \"\")\n",
    "        \n",
    "        if error_message:\n",
    "            task_description = f\"Debug the following code for phase '{phase}':\\n\\n{previous_code}\\n\\nError message:\\n{error_message}\"\n",
    "        else:\n",
    "            task_description = f\"Implement the code for phase '{phase}' based on the following plan:\\n\\n{plan}\"\n",
    "        \n",
    "        result = self.chain.invoke({\"input\": task_description, \"history\": []})\n",
    "        return result\n",
    "\n",
    "# 4. Reviewer Agent - Đánh giá kết quả\n",
    "class ReviewerAgent:\n",
    "    def __init__(self, model: BaseChatModel):\n",
    "        self.model = model\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are a Reviewer agent responsible for evaluating the quality and correctness of code and results.\n",
    "            Your task is to review the code and execution results to ensure they meet the requirements and objectives.\n",
    "            Evaluate based on:\n",
    "            1. Code correctness and efficiency\n",
    "            2. Alignment with the original plan\n",
    "            3. Quality of the outputs and results\n",
    "            4. Compliance with best practices\n",
    "            Provide detailed feedback highlighting strengths and areas for improvement.\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def execute(self, input_data: Dict) -> str:\n",
    "        code = input_data.get(\"code\", \"\")\n",
    "        plan = input_data.get(\"plan\", \"\")\n",
    "        execution_result = input_data.get(\"execution_result\", \"\")\n",
    "        phase = input_data.get(\"phase\", \"\")\n",
    "        \n",
    "        review_task = f\"Review the following code for phase '{phase}':\\n\\n{code}\\n\\nOriginal plan:\\n{plan}\\n\\nExecution results:\\n{execution_result}\"\n",
    "        result = self.chain.invoke({\"input\": review_task, \"history\": []})\n",
    "        return result\n",
    "\n",
    "# 5. Summarizer Agent - Tạo báo cáo tổng hợp\n",
    "class SummarizerAgent:\n",
    "    def __init__(self, model: BaseChatModel):\n",
    "        self.model = model\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are a Summarizer agent specialized in creating comprehensive reports.\n",
    "            Your task is to summarize the work completed in a phase, analyzing the following:\n",
    "            1. Key findings and insights\n",
    "            2. Actions taken and their rationale\n",
    "            3. Impact on the overall project\n",
    "            4. Challenges faced and how they were addressed\n",
    "            5. Recommendations for subsequent phases\n",
    "            Create a clear, well-structured report that highlights the most important aspects and lessons learned.\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessage(content=\"{input}\")\n",
    "        ])\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "    \n",
    "    def execute(self, input_data: Dict) -> str:\n",
    "        phase = input_data.get(\"phase\", \"\")\n",
    "        plan = input_data.get(\"plan\", \"\")\n",
    "        code = input_data.get(\"code\", \"\")\n",
    "        execution_result = input_data.get(\"execution_result\", \"\")\n",
    "        review = input_data.get(\"review\", \"\")\n",
    "        \n",
    "        summary_task = f\"Create a comprehensive summary report for phase '{phase}':\\n\\nPlan:\\n{plan}\\n\\nCode implementation:\\n{code}\\n\\nExecution results:\\n{execution_result}\\n\\nReview:\\n{review}\"\n",
    "        result = self.chain.invoke({\"input\": summary_task, \"history\": []})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Triển khai các công cụ Machine Learning\n",
    "\n",
    "Thư viện công cụ máy học trong AutoKaggle được phân loại thành ba bộ công cụ chính: làm sạch dữ liệu (data cleaning), kỹ thuật đặc trưng (feature engineering) và xây dựng mô hình, xác thực và dự đoán (model building, validation, and prediction). Dưới đây là một số công cụ quan trọng được triển khai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Cleaning Tools\n",
    "class DataCleaningTools:\n",
    "    @staticmethod\n",
    "    def fill_missing_values(df: pd.DataFrame, strategy: Dict[str, str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fill missing values in a dataframe based on specified strategies.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - strategy: Dictionary with column names as keys and filling strategies as values\n",
    "                   (e.g., {\"col1\": \"mean\", \"col2\": \"median\", \"col3\": \"mode\", \"col4\": \"0\"})\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with filled missing values\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        for column, method in strategy.items():\n",
    "            if column not in df_copy.columns:\n",
    "                continue\n",
    "                \n",
    "            if pd.api.types.is_numeric_dtype(df_copy[column]):\n",
    "                if method == \"mean\":\n",
    "                    df_copy[column].fillna(df_copy[column].mean(), inplace=True)\n",
    "                elif method == \"median\":\n",
    "                    df_copy[column].fillna(df_copy[column].median(), inplace=True)\n",
    "                elif method == \"mode\":\n",
    "                    df_copy[column].fillna(df_copy[column].mode()[0], inplace=True)\n",
    "                elif method == \"0\":\n",
    "                    df_copy[column].fillna(0, inplace=True)\n",
    "                elif method == \"none\":\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        df_copy[column].fillna(float(method), inplace=True)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            else:\n",
    "                if method == \"mode\":\n",
    "                    df_copy[column].fillna(df_copy[column].mode()[0] if not df_copy[column].mode().empty else \"\", inplace=True)\n",
    "                elif method == \"unknown\":\n",
    "                    df_copy[column].fillna(\"Unknown\", inplace=True)\n",
    "                elif method == \"none\":\n",
    "                    pass\n",
    "                else:\n",
    "                    df_copy[column].fillna(method, inplace=True)\n",
    "                    \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_duplicates(df: pd.DataFrame, subset: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove duplicate rows from a dataframe.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - subset: List of column names to consider for identifying duplicates (optional)\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with duplicates removed\n",
    "        \"\"\"\n",
    "        return df.drop_duplicates(subset=subset, keep='first')\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_and_handle_outliers_zscore(df: pd.DataFrame, columns: List[str], threshold: float = 3.0, \n",
    "                                         strategy: str = \"clip\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Detect and handle outliers using Z-score method.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - columns: List of columns to check for outliers\n",
    "        - threshold: Z-score threshold (default: 3.0)\n",
    "        - strategy: Handling strategy - \"clip\", \"remove\", or \"replace\" (default: \"clip\")\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with outliers handled\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        for column in columns:\n",
    "            if column not in df_copy.columns or not pd.api.types.is_numeric_dtype(df_copy[column]):\n",
    "                continue\n",
    "                \n",
    "            # Compute z-scores\n",
    "            z_scores = np.abs((df_copy[column] - df_copy[column].mean()) / df_copy[column].std())\n",
    "            outliers = z_scores > threshold\n",
    "            \n",
    "            if strategy == \"clip\":\n",
    "                lower_bound = df_copy[column].mean() - threshold * df_copy[column].std()\n",
    "                upper_bound = df_copy[column].mean() + threshold * df_copy[column].std()\n",
    "                df_copy.loc[z_scores > threshold, column] = np.clip(df_copy.loc[z_scores > threshold, column], \n",
    "                                                                  lower_bound, upper_bound)\n",
    "            elif strategy == \"remove\":\n",
    "                df_copy = df_copy[~outliers]\n",
    "            elif strategy == \"replace\":\n",
    "                df_copy.loc[outliers, column] = df_copy[column].mean()\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_data_types(df: pd.DataFrame, type_mappings: Dict[str, str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert data types of specified columns.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - type_mappings: Dictionary with column names as keys and desired data types as values\n",
    "                        (e.g., {\"col1\": \"int\", \"col2\": \"float\", \"col3\": \"category\", \"col4\": \"datetime\"})\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with converted data types\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        for column, dtype in type_mappings.items():\n",
    "            if column not in df_copy.columns:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if dtype == \"int\":\n",
    "                    df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce').fillna(0).astype(int)\n",
    "                elif dtype == \"float\":\n",
    "                    df_copy[column] = pd.to_numeric(df_copy[column], errors='coerce')\n",
    "                elif dtype == \"category\":\n",
    "                    df_copy[column] = df_copy[column].astype('category')\n",
    "                elif dtype == \"datetime\":\n",
    "                    df_copy[column] = pd.to_datetime(df_copy[column], errors='coerce')\n",
    "                elif dtype == \"string\" or dtype == \"str\":\n",
    "                    df_copy[column] = df_copy[column].astype(str)\n",
    "                else:\n",
    "                    df_copy[column] = df_copy[column].astype(dtype)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {column} to {dtype}: {e}\")\n",
    "                \n",
    "        return df_copy\n",
    "\n",
    "# 2. Feature Engineering Tools\n",
    "class FeatureEngineeringTools:\n",
    "    @staticmethod\n",
    "    def one_hot_encode(df: pd.DataFrame, columns: List[str], drop_original: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        One-hot encode categorical columns.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - columns: List of categorical columns to encode\n",
    "        - drop_original: Whether to drop the original columns (default: True)\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with one-hot encoded features\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        for column in columns:\n",
    "            if column not in df_copy.columns:\n",
    "                continue\n",
    "                \n",
    "            dummies = pd.get_dummies(df_copy[column], prefix=column, dummy_na=False)\n",
    "            df_copy = pd.concat([df_copy, dummies], axis=1)\n",
    "            \n",
    "            if drop_original:\n",
    "                df_copy.drop(column, axis=1, inplace=True)\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def frequency_encode(df: pd.DataFrame, columns: List[str], drop_original: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Frequency encode categorical columns.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - columns: List of categorical columns to encode\n",
    "        - drop_original: Whether to drop the original columns (default: True)\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with frequency encoded features\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        for column in columns:\n",
    "            if column not in df_copy.columns:\n",
    "                continue\n",
    "                \n",
    "            frequency = df_copy[column].value_counts(normalize=True).to_dict()\n",
    "            df_copy[f\"{column}_freq\"] = df_copy[column].map(frequency)\n",
    "            \n",
    "            if drop_original:\n",
    "                df_copy.drop(column, axis=1, inplace=True)\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def correlation_feature_selection(df: pd.DataFrame, target_column: str, threshold: float = 0.05) -> List[str]:\n",
    "        \"\"\"\n",
    "        Select features based on correlation with target.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - target_column: The target variable column name\n",
    "        - threshold: Minimum absolute correlation threshold (default: 0.05)\n",
    "        \n",
    "        Returns:\n",
    "        - List of selected feature names\n",
    "        \"\"\"\n",
    "        if target_column not in df.columns:\n",
    "            return []\n",
    "            \n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        \n",
    "        if target_column not in numeric_df.columns:\n",
    "            return []\n",
    "            \n",
    "        correlations = numeric_df.corr()[target_column].abs()\n",
    "        selected_features = correlations[correlations > threshold].index.tolist()\n",
    "        \n",
    "        # Remove target column from the list\n",
    "        if target_column in selected_features:\n",
    "            selected_features.remove(target_column)\n",
    "            \n",
    "        return selected_features\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_features(df: pd.DataFrame, columns: List[str], method: str = \"standard\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scale numeric features.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: The input dataframe\n",
    "        - columns: List of numeric columns to scale\n",
    "        - method: Scaling method - \"standard\" or \"minmax\" (default: \"standard\")\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with scaled features\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "        \n",
    "        df_copy = df.copy()\n",
    "        features_to_scale = [col for col in columns if col in df_copy.columns]\n",
    "        \n",
    "        if not features_to_scale:\n",
    "            return df_copy\n",
    "            \n",
    "        if method == \"standard\":\n",
    "            scaler = StandardScaler()\n",
    "        elif method == \"minmax\":\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'standard' or 'minmax'\")\n",
    "            \n",
    "        df_copy[features_to_scale] = scaler.fit_transform(df_copy[features_to_scale])\n",
    "        return df_copy\n",
    "\n",
    "# 3. Model Building, Validation, and Prediction Tools\n",
    "class ModelTools:\n",
    "    @staticmethod\n",
    "    def train_and_validate_and_select_best_model(X_train, y_train, X_val, y_val, \n",
    "                                                models_config: List[Dict], \n",
    "                                                problem_type: str,\n",
    "                                                evaluation_metric: str) -> Tuple[Any, Dict, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Train multiple models, validate them, and select the best one.\n",
    "        \n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - y_train: Training target\n",
    "        - X_val: Validation features\n",
    "        - y_val: Validation target\n",
    "        - models_config: List of model configurations with 'model_type' and 'params'\n",
    "        - problem_type: 'classification' or 'regression'\n",
    "        - evaluation_metric: Metric to evaluate models (e.g., 'accuracy', 'f1', 'rmse')\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of (best_model, best_model_config, results_df)\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                                  mean_squared_error, mean_absolute_error, r2_score\n",
    "        from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "        from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "        from sklearn.svm import SVC, SVR\n",
    "        from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "        import xgboost as xgb\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        results = []\n",
    "        models = []\n",
    "        \n",
    "        # Define metric function\n",
    "        if problem_type == \"classification\":\n",
    "            if evaluation_metric == \"accuracy\":\n",
    "                metric_func = accuracy_score\n",
    "            elif evaluation_metric == \"f1\":\n",
    "                metric_func = f1_score\n",
    "            elif evaluation_metric == \"precision\":\n",
    "                metric_func = precision_score\n",
    "            elif evaluation_metric == \"recall\":\n",
    "                metric_func = recall_score\n",
    "            else:\n",
    "                metric_func = accuracy_score\n",
    "        else:  # regression\n",
    "            if evaluation_metric == \"rmse\":\n",
    "                metric_func = lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            elif evaluation_metric == \"mae\":\n",
    "                metric_func = mean_absolute_error\n",
    "            elif evaluation_metric == \"r2\":\n",
    "                metric_func = r2_score\n",
    "            else:\n",
    "                metric_func = lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        for config in models_config:\n",
    "            model_type = config['model_type']\n",
    "            params = config.get('params', {})\n",
    "            \n",
    "            try:\n",
    "                # Initialize the model based on problem type\n",
    "                if problem_type == \"classification\":\n",
    "                    if model_type == \"RandomForest\":\n",
    "                        model = RandomForestClassifier(**params)\n",
    "                    elif model_type == \"GradientBoosting\":\n",
    "                        model = GradientBoostingClassifier(**params)\n",
    "                    elif model_type == \"LogisticRegression\":\n",
    "                        model = LogisticRegression(**params)\n",
    "                    elif model_type == \"SVM\":\n",
    "                        model = SVC(**params, probability=True)\n",
    "                    elif model_type == \"KNN\":\n",
    "                        model = KNeighborsClassifier(**params)\n",
    "                    elif model_type == \"XGBoost\":\n",
    "                        model = xgb.XGBClassifier(**params)\n",
    "                    elif model_type == \"LightGBM\":\n",
    "                        model = lgb.LGBMClassifier(**params)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:  # regression\n",
    "                    if model_type == \"RandomForest\":\n",
    "                        model = RandomForestRegressor(**params)\n",
    "                    elif model_type == \"GradientBoosting\":\n",
    "                        model = GradientBoostingRegressor(**params)\n",
    "                    elif model_type == \"LinearRegression\":\n",
    "                        model = LinearRegression(**params)\n",
    "                    elif model_type == \"Ridge\":\n",
    "                        model = Ridge(**params)\n",
    "                    elif model_type == \"Lasso\":\n",
    "                        model = Lasso(**params)\n",
    "                    elif model_type == \"SVM\":\n",
    "                        model = SVR(**params)\n",
    "                    elif model_type == \"KNN\":\n",
    "                        model = KNeighborsRegressor(**params)\n",
    "                    elif model_type == \"XGBoost\":\n",
    "                        model = xgb.XGBRegressor(**params)\n",
    "                    elif model_type == \"LightGBM\":\n",
    "                        model = lgb.LGBMRegressor(**params)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train)\n",
    "                models.append(model)\n",
    "                \n",
    "                # Make predictions\n",
    "                train_preds = model.predict(X_train)\n",
    "                val_preds = model.predict(X_val)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                train_score = metric_func(y_train, train_preds)\n",
    "                val_score = metric_func(y_val, val_preds)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    \"model_type\": model_type,\n",
    "                    \"params\": params,\n",
    "                    \"train_score\": train_score,\n",
    "                    \"val_score\": val_score\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error training {model_type}: {e}\")\n",
    "                \n",
    "        # Create results dataframe\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        if results_df.empty:\n",
    "            return None, {}, pd.DataFrame()\n",
    "        \n",
    "        # Select best model based on validation score\n",
    "        if problem_type == \"regression\" and evaluation_metric in [\"rmse\", \"mae\"]:\n",
    "            # Lower is better for these metrics\n",
    "            best_idx = results_df[\"val_score\"].idxmin()\n",
    "        else:\n",
    "            # Higher is better for other metrics\n",
    "            best_idx = results_df[\"val_score\"].idxmax()\n",
    "            \n",
    "        best_model = models[best_idx]\n",
    "        best_config = results[best_idx]\n",
    "        \n",
    "        return best_model, best_config, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Triển khai gỡ lỗi và kiểm thử lặp lại\n",
    "\n",
    "AutoKaggle sử dụng phương pháp gỡ lỗi và kiểm thử lặp lại để đảm bảo code được tạo ra đáp ứng các yêu cầu và đáng tin cậy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeDebugger:\n",
    "    def __init__(self, developer: DeveloperAgent, max_attempts: int = 5):\n",
    "        self.developer = developer\n",
    "        self.max_attempts = max_attempts\n",
    "        self.error_history = []\n",
    "    \n",
    "    def execute_code(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Execute code and capture errors.\n",
    "        \n",
    "        Parameters:\n",
    "        - code: Python code to execute\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of (success flag, output/error message)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # In a real implementation, we would use tools to execute code safely\n",
    "            # For demonstration, we'll simulate this behavior\n",
    "            result = \"[Simulation] Code executed successfully\"\n",
    "            return True, result\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def run_unit_tests(self, code: str, test_specs: List[Dict]) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Run unit tests on code.\n",
    "        \n",
    "        Parameters:\n",
    "        - code: Python code to test\n",
    "        - test_specs: List of test specifications\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of (all_passed flag, test results)\n",
    "        \"\"\"\n",
    "        # In a real implementation, we would use unit testing frameworks\n",
    "        # For demonstration, we'll simulate this behavior\n",
    "        test_results = {}\n",
    "        all_passed = True\n",
    "        \n",
    "        for test in test_specs:\n",
    "            test_id = test.get(\"id\", \"unknown\")\n",
    "            passed = True  # Simulate all tests passing\n",
    "            result = \"[Simulation] Test passed\"\n",
    "            \n",
    "            test_results[test_id] = {\n",
    "                \"passed\": passed,\n",
    "                \"result\": result\n",
    "            }\n",
    "            \n",
    "            if not passed:\n",
    "                all_passed = False\n",
    "        \n",
    "        return all_passed, test_results\n",
    "    \n",
    "    def debug_code(self, code: str, error_message: str, phase: str) -> str:\n",
    "        \"\"\"\n",
    "        Debug code using the Developer agent.\n",
    "        \n",
    "        Parameters:\n",
    "        - code: Code to debug\n",
    "        - error_message: Error message from execution\n",
    "        - phase: Current phase name\n",
    "        \n",
    "        Returns:\n",
    "        - Debugged code\n",
    "        \"\"\"\n",
    "        input_data = {\n",
    "            \"previous_code\": code,\n",
    "            \"error_message\": error_message,\n",
    "            \"phase\": phase\n",
    "        }\n",
    "        \n",
    "        debugged_code = self.developer.execute(input_data)\n",
    "        # Extract code blocks if the result contains explanations\n",
    "        if \"```python\" in debugged_code and \"```\" in debugged_code:\n",
    "            code_blocks = []\n",
    "            in_code_block = False\n",
    "            for line in debugged_code.split(\"\\n\"):\n",
    "                if line.strip() == \"```python\" or line.strip() == \"```python3\":\n",
    "                    in_code_block = True\n",
    "                    continue\n",
    "                elif line.strip() == \"```\" and in_code_block:\n",
    "                    in_code_block = False\n",
    "                    continue\n",
    "                elif in_code_block:\n",
    "                    code_blocks.append(line)\n",
    "            \n",
    "            if code_blocks:\n",
    "                debugged_code = \"\\n\".join(code_blocks)\n",
    "        \n",
    "        return debugged_code\n",
    "    \n",
    "    def iterative_debug_and_test(self, code: str, test_specs: List[Dict], phase: str) -> Tuple[str, bool, str, Dict]:\n",
    "        \"\"\"\n",
    "        Perform iterative debugging and testing.\n",
    "        \n",
    "        Parameters:\n",
    "        - code: Initial code\n",
    "        - test_specs: Unit test specifications\n",
    "        - phase: Current phase name\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of (final_code, success flag, execution_result, test_results)\n",
    "        \"\"\"\n",
    "        current_code = code\n",
    "        success = False\n",
    "        execution_result = \"\"\n",
    "        test_results = {}\n",
    "        attempts = 0\n",
    "        self.error_history = []\n",
    "        \n",
    "        while attempts < self.max_attempts and not success:\n",
    "            # Execute the code\n",
    "            execution_success, execution_result = self.execute_code(current_code)\n",
    "            \n",
    "            if execution_success:\n",
    "                # Run unit tests\n",
    "                tests_passed, test_results = self.run_unit_tests(current_code, test_specs)\n",
    "                \n",
    "                if tests_passed:\n",
    "                    success = True\n",
    "                    break\n",
    "                else:\n",
    "                    # Debug test failures\n",
    "                    error_msg = \"Unit tests failed: \" + str(test_results)\n",
    "                    self.error_history.append(error_msg)\n",
    "                    current_code = self.debug_code(current_code, error_msg, phase)\n",
    "            else:\n",
    "                # Debug execution errors\n",
    "                self.error_history.append(execution_result)\n",
    "                \n",
    "                # Check if similar errors are recurring\n",
    "                if attempts >= 3 and len(set(self.error_history[-3:])) == 1:\n",
    "                    # If the same error occurs multiple times, regenerate code from scratch\n",
    "                    input_data = {\"phase\": phase, \"plan\": \"Please completely rewrite the code to fix recurring errors.\"}\n",
    "                    current_code = self.developer.execute(input_data)\n",
    "                    self.error_history = []\n",
    "                else:\n",
    "                    current_code = self.debug_code(current_code, execution_result, phase)\n",
    "            \n",
    "            attempts += 1\n",
    "        \n",
    "        return current_code, success, execution_result, test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Xây dựng luồng công việc với LangGraph\n",
    "\n",
    "Sử dụng LangGraph để thiết lập luồng làm việc phase-based của AutoKaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoKaggle:\n",
    "    def __init__(self, model_name: str = \"gpt-4o\"):\n",
    "        # Khởi tạo LLM\n",
    "        if \"anthropic\" in model_name.lower() or \"claude\" in model_name.lower():\n",
    "            self.model = ChatAnthropic(model=model_name)\n",
    "        else:  # Default to OpenAI\n",
    "            self.model = ChatOpenAI(model=model_name)\n",
    "            \n",
    "        # Khởi tạo các agent\n",
    "        self.reader = ReaderAgent(self.model)\n",
    "        self.planner = PlannerAgent(self.model)\n",
    "        self.developer = DeveloperAgent(self.model)\n",
    "        self.reviewer = ReviewerAgent(self.model)\n",
    "        self.summarizer = SummarizerAgent(self.model)\n",
    "        \n",
    "        # Khởi tạo debugger\n",
    "        self.debugger = IterativeDebugger(self.developer)\n",
    "        \n",
    "        # Khởi tạo state\n",
    "        self.state = AutoKaggleState()\n",
    "        \n",
    "        # Xây dựng workflow graph\n",
    "        self._build_graph()\n",
    "    \n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        Xây dựng đồ thị LangGraph cho workflow của AutoKaggle\n",
    "        \"\"\"\n",
    "        self.graph = StateGraph(AutoKaggleState)\n",
    "        \n",
    "        # Định nghĩa các node cho các phase\n",
    "        self.graph.add_node(\"background_understanding\", self._execute_background_understanding)\n",
    "        self.graph.add_node(\"preliminary_eda\", self._execute_preliminary_eda)\n",
    "        self.graph.add_node(\"data_cleaning\", self._execute_data_cleaning)\n",
    "        self.graph.add_node(\"indepth_eda\", self._execute_indepth_eda)\n",
    "        self.graph.add_node(\"feature_engineering\", self._execute_feature_engineering)\n",
    "        self.graph.add_node(\"model_building\", self._execute_model_building)\n",
    "        \n",
    "        # Định nghĩa các cạnh và điều kiện chuyển tiếp\n",
    "        self.graph.add_edge(\"background_understanding\", \"preliminary_eda\")\n",
    "        self.graph.add_edge(\"preliminary_eda\", \"data_cleaning\")\n",
    "        self.graph.add_edge(\"data_cleaning\", \"indepth_eda\")\n",
    "        self.graph.add_edge(\"indepth_eda\", \"feature_engineering\")\n",
    "        self.graph.add_edge(\"feature_engineering\", \"model_building\")\n",
    "        self.graph.add_edge(\"model_building\", END)\n",
    "        \n",
    "        # Compiler đồ thị\n",
    "        self.workflow = self.graph.compile()\n",
    "    \n",
    "    def _execute_background_understanding(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase Background Understanding\n",
    "        \"\"\"\n",
    "        # Giả định input_data chứa nội dung của overview.txt\n",
    "        input_data = {\"content\": \"[Competition overview and data information]\"}\n",
    "        \n",
    "        # Reader đọc và tóm tắt thông tin\n",
    "        report = self.reader.execute(input_data)\n",
    "        state.add_report(Phase.BACKGROUND_UNDERSTANDING, report)\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.PRELIMINARY_EDA)\n",
    "        return state\n",
    "    \n",
    "    def _execute_preliminary_eda(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase Preliminary EDA\n",
    "        \"\"\"\n",
    "        # Lấy thông tin từ phase trước\n",
    "        background_report = state.reports.get(Phase.BACKGROUND_UNDERSTANDING.value, \"\")\n",
    "        \n",
    "        # Planner tạo kế hoạch cho EDA sơ bộ\n",
    "        input_data = {\n",
    "            \"phase\": Phase.PRELIMINARY_EDA.value,\n",
    "            \"state_info\": background_report\n",
    "        }\n",
    "        plan = self.planner.execute(input_data)\n",
    "        state.add_plan(Phase.PRELIMINARY_EDA, plan)\n",
    "        \n",
    "        # Developer viết code cho EDA sơ bộ\n",
    "        input_data = {\n",
    "            \"phase\": Phase.PRELIMINARY_EDA.value,\n",
    "            \"plan\": plan\n",
    "        }\n",
    "        code = self.developer.execute(input_data)\n",
    "        \n",
    "        # Thực hiện debugging và testing\n",
    "        test_specs = [{\"id\": \"test_basic\", \"description\": \"Basic functionality test\"}]\n",
    "        final_code, success, execution_result, test_results = self.debugger.iterative_debug_and_test(\n",
    "            code, test_specs, Phase.PRELIMINARY_EDA.value\n",
    "        )\n",
    "        \n",
    "        # Lưu kết quả\n",
    "        state.add_code(Phase.PRELIMINARY_EDA, final_code)\n",
    "        state.add_execution_result(Phase.PRELIMINARY_EDA, execution_result)\n",
    "        state.add_test_result(Phase.PRELIMINARY_EDA, test_results)\n",
    "        \n",
    "        # Reviewer đánh giá kết quả\n",
    "        input_data = {\n",
    "            \"code\": final_code,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result,\n",
    "            \"phase\": Phase.PRELIMINARY_EDA.value\n",
    "        }\n",
    "        review = self.reviewer.execute(input_data)\n",
    "        \n",
    "        # Summarizer tạo báo cáo tổng hợp\n",
    "        input_data = {\n",
    "            \"phase\": Phase.PRELIMINARY_EDA.value,\n",
    "            \"plan\": plan,\n",
    "            \"code\": final_code,\n",
    "            \"execution_result\": execution_result,\n",
    "            \"review\": review\n",
    "        }\n",
    "        summary = self.summarizer.execute(input_data)\n",
    "        state.add_report(Phase.PRELIMINARY_EDA, summary)\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.DATA_CLEANING)\n",
    "        return state\n",
    "    \n",
    "    def _execute_data_cleaning(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase Data Cleaning\n",
    "        \"\"\"\n",
    "        # Tương tự như _execute_preliminary_eda nhưng cho giai đoạn làm sạch dữ liệu\n",
    "        # Trong giai đoạn này, sẽ sử dụng các công cụ DataCleaningTools\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.INDEPTH_EDA)\n",
    "        return state\n",
    "    \n",
    "    def _execute_indepth_eda(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase In-depth EDA\n",
    "        \"\"\"\n",
    "        # Tương tự như các phase khác\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.FEATURE_ENGINEERING)\n",
    "        return state\n",
    "    \n",
    "    def _execute_feature_engineering(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase Feature Engineering\n",
    "        \"\"\"\n",
    "        # Tương tự như các phase khác, sử dụng FeatureEngineeringTools\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.MODEL_BUILDING)\n",
    "        return state\n",
    "    \n",
    "    def _execute_model_building(self, state: AutoKaggleState):\n",
    "        \"\"\"\n",
    "        Thực hiện phase Model Building, Validation, and Prediction\n",
    "        \"\"\"\n",
    "        # Tương tự như các phase khác, sử dụng ModelTools\n",
    "        \n",
    "        # Cập nhật trạng thái\n",
    "        state.update_phase(Phase.COMPLETED)\n",
    "        return state\n",
    "    \n",
    "    def run(self, competition_info: Dict) -> AutoKaggleState:\n",
    "        \"\"\"\n",
    "        Chạy toàn bộ workflow AutoKaggle\n",
    "        \n",
    "        Parameters:\n",
    "        - competition_info: Dictionary chứa thông tin về cuộc thi và dữ liệu\n",
    "        \n",
    "        Returns:\n",
    "        - Trạng thái cuối cùng của hệ thống\n",
    "        \"\"\"\n",
    "        self.state.competition_info = competition_info\n",
    "        final_state = self.workflow.invoke(self.state)\n",
    "        return final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Đánh giá với DeepEval\n",
    "\n",
    "Sử dụng DeepEval để đánh giá hiệu suất của hệ thống AutoKaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá các kết quả được tạo ra bởi AutoKaggle\n",
    "class AutoKaggleEvaluator:\n",
    "    @staticmethod\n",
    "    def evaluate_phase_report(phase_name: str, report: str, ground_truth: str) -> float:\n",
    "        \"\"\"\n",
    "        Đánh giá báo cáo của một phase dựa trên tính nhất quán thực tế\n",
    "        \n",
    "        Parameters:\n",
    "        - phase_name: Tên của phase\n",
    "        - report: Báo cáo cần đánh giá\n",
    "        - ground_truth: Thông tin đúng để so sánh\n",
    "        \n",
    "        Returns:\n",
    "        - Điểm đánh giá\n",
    "        \"\"\"\n",
    "        test_case = LLMTestCase(\n",
    "            input=f\"Evaluate the {phase_name} phase\",\n",
    "            actual_output=report,\n",
    "            expected_output=ground_truth\n",
    "        )\n",
    "        \n",
    "        metric = FactualConsistencyMetric()\n",
    "        metric.measure(test_case)\n",
    "        return metric.score\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_made_submission(state: AutoKaggleState) -> bool:\n",
    "        \"\"\"\n",
    "        Kiểm tra xem đã tạo file submission.csv chưa\n",
    "        \n",
    "        Parameters:\n",
    "        - state: Trạng thái của hệ thống\n",
    "        \n",
    "        Returns:\n",
    "        - True nếu đã tạo, False nếu chưa\n",
    "        \"\"\"\n",
    "        # Giả định kiểm tra file submission.csv trong kết quả thực thi\n",
    "        return \"submission.csv\" in str(state.execution_results.get(Phase.MODEL_BUILDING.value, \"\"))\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_valid_submission(state: AutoKaggleState, expected_format: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Kiểm tra xem file submission có đúng định dạng không\n",
    "        \n",
    "        Parameters:\n",
    "        - state: Trạng thái của hệ thống\n",
    "        - expected_format: Định dạng mong đợi của file submission\n",
    "        \n",
    "        Returns:\n",
    "        - True nếu đúng định dạng, False nếu không\n",
    "        \"\"\"\n",
    "        # Giả định kiểm tra định dạng file submission.csv\n",
    "        return True  # Giả lập kết quả\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_comprehensive_score(made_submission: bool, valid_submission: bool, phase_scores: Dict[str, float]) -> float:\n",
    "        \"\"\"\n",
    "        Tính điểm toàn diện dựa trên công thức từ paper\n",
    "        \n",
    "        Parameters:\n",
    "        - made_submission: Có tạo file submission không\n",
    "        - valid_submission: File submission có hợp lệ không\n",
    "        - phase_scores: Điểm đánh giá cho từng phase\n",
    "        \n",
    "        Returns:\n",
    "        - Điểm toàn diện\n",
    "        \"\"\"\n",
    "        if not made_submission:\n",
    "            return 0.0\n",
    "            \n",
    "        vs = 1.0 if valid_submission else 0.0\n",
    "        anps = sum(phase_scores.values()) / len(phase_scores) if phase_scores else 0.0\n",
    "        \n",
    "        return 0.5 * vs + 0.5 * anps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ví dụ minh họa\n",
    "\n",
    "Dưới đây là một ví dụ minh họa về cách sử dụng AutoKaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo ví dụ minh họa\n",
    "def run_example():\n",
    "    # Giả định thông tin cuộc thi\n",
    "    competition_info = {\n",
    "        \"name\": \"Titanic: Machine Learning from Disaster\",\n",
    "        \"description\": \"Predict survival on the Titanic\",\n",
    "        \"data_files\": {\n",
    "            \"train.csv\": \"Training data with survival information\",\n",
    "            \"test.csv\": \"Test data without survival information\"\n",
    "        },\n",
    "        \"target\": \"Survived\",\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"submission_format\": {\n",
    "            \"columns\": [\"PassengerId\", \"Survived\"],\n",
    "            \"file_name\": \"submission.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Khởi tạo AutoKaggle\n",
    "    auto_kaggle = AutoKaggle(model_name=\"gpt-4o\")\n",
    "    \n",
    "    # Chạy workflow\n",
    "    final_state = auto_kaggle.run(competition_info)\n",
    "    \n",
    "    # Đánh giá kết quả\n",
    "    made_submission = AutoKaggleEvaluator.calculate_made_submission(final_state)\n",
    "    valid_submission = AutoKaggleEvaluator.calculate_valid_submission(\n",
    "        final_state, competition_info[\"submission_format\"]\n",
    "    )\n",
    "    \n",
    "    # Đánh giá các báo cáo\n",
    "    phase_scores = {}\n",
    "    for phase in [p.value for p in list(Phase) if p != Phase.COMPLETED]:\n",
    "        report = final_state.reports.get(phase, \"\")\n",
    "        ground_truth = f\"Expected report for {phase}\"  # Giả định\n",
    "        score = AutoKaggleEvaluator.evaluate_phase_report(phase, report, ground_truth)\n",
    "        phase_scores[phase] = score\n",
    "    \n",
    "    # Tính điểm toàn diện\n",
    "    comprehensive_score = AutoKaggleEvaluator.calculate_comprehensive_score(\n",
    "        made_submission, valid_submission, phase_scores\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"made_submission\": made_submission,\n",
    "        \"valid_submission\": valid_submission,\n",
    "        \"phase_scores\": phase_scores,\n",
    "        \"comprehensive_score\": comprehensive_score\n",
    "    }\n",
    "\n",
    "# Chạy ví dụ (comment lại để không thực thi thực tế)\n",
    "# results = run_example()\n",
    "# print(f\"Comprehensive Score: {results['comprehensive_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ánh xạ từ bài báo đến triển khai\n",
    "\n",
    "Dưới đây là ánh xạ giữa các khái niệm trong bài báo \"AutoKaggle\" và cách chúng được triển khai trong notebook này:\n",
    "\n",
    "1. **Phase-based Workflow**\n",
    "   - Trong bài báo: Quy trình được chia thành 6 giai đoạn từ hiểu biết nền tảng đến xây dựng mô hình\n",
    "   - Triển khai: Enum `Phase` và các phương thức `_execute_*` trong lớp `AutoKaggle`\n",
    "\n",
    "2. **Multi-agent System**\n",
    "   - Trong bài báo: 5 tác tử chuyên biệt (Reader, Planner, Developer, Reviewer, Summarizer)\n",
    "   - Triển khai: Các lớp agent tương ứng và sự hợp tác thông qua LangGraph\n",
    "\n",
    "3. **Iterative Debugging and Testing**\n",
    "   - Trong bài báo: Quy trình gỡ lỗi lặp và kiểm thử đơn vị\n",
    "   - Triển khai: Lớp `IterativeDebugger` và phương thức `iterative_debug_and_test`\n",
    "\n",
    "4. **Machine Learning Tools Library**\n",
    "   - Trong bài báo: Bộ công cụ toàn diện cho làm sạch dữ liệu, kỹ thuật đặc trưng và mô hình hóa\n",
    "   - Triển khai: Các lớp `DataCleaningTools`, `FeatureEngineeringTools`, và `ModelTools`\n",
    "\n",
    "5. **Comprehensive Reporting**\n",
    "   - Trong bài báo: Báo cáo chi tiết sau mỗi giai đoạn\n",
    "   - Triển khai: Tác tử `SummarizerAgent` và phương thức lưu trữ báo cáo trong `AutoKaggleState`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ứng dụng thực tế và hướng phát triển\n",
    "\n",
    "AutoKaggle là một framework mạnh mẽ có thể được ứng dụng trong nhiều lĩnh vực ngoài các cuộc thi Kaggle:\n",
    "\n",
    "1. **Tự động hóa quy trình khoa học dữ liệu**: Giúp tự động hóa các quy trình lặp đi lặp lại trong khoa học dữ liệu, tiết kiệm thời gian và công sức.\n",
    "\n",
    "2. **Hỗ trợ giáo dục và đào tạo**: Cung cấp công cụ học tập cho người mới bắt đầu trong lĩnh vực khoa học dữ liệu.\n",
    "\n",
    "3. **Nghiên cứu đa tác tử**: Mô hình hợp tác đa tác tử có thể được mở rộng cho nhiều lĩnh vực khác.\n",
    "\n",
    "4. **Kiểm thử mô hình**: Giúp kiểm tra tính mạnh mẽ và đáng tin cậy của các mô hình ML trước khi triển khai.\n",
    "\n",
    "Các hướng phát triển trong tương lai:\n",
    "\n",
    "1. **Tích hợp nhiều công cụ ML hơn**: Mở rộng thư viện công cụ để hỗ trợ nhiều kỹ thuật và thuật toán hơn.\n",
    "\n",
    "2. **Hỗ trợ nhiều loại dữ liệu hơn**: Mở rộng hỗ trợ cho dữ liệu hình ảnh, văn bản và dữ liệu dạng chuỗi thời gian.\n",
    "\n",
    "3. **Cải thiện tính tương tác**: Thêm cơ chế phản hồi của người dùng và điều chỉnh quy trình dựa trên phản hồi.\n",
    "\n",
    "4. **Tối ưu hóa hiệu suất**: Cải thiện tốc độ và hiệu quả của framework để xử lý các tập dữ liệu lớn hơn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}