{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80de7f77",
   "metadata": {},
   "source": [
    "# LangGraph Advanced – Part 1️⃣: Code Ingestion & Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f517a",
   "metadata": {},
   "source": [
    "Notebook này hướng dẫn bạn xây dựng **pipeline LangGraph** để thu thập mã nguồn (.py) và tóm tắt chức năng bằng Claude.  \n",
    "**Yêu cầu**  \n",
    "* `pip install langgraph langchain langchain-anthropic`  \n",
    "* Biến môi trường `ANTHROPIC_API_KEY`  \n",
    "* Thư mục mã nguồn mẫu – chỉnh `CODE_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain langchain-anthropic tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb28002",
   "metadata": {},
   "outputs": [],
   "source": [
    "             from pathlib import Path\n",
    "             from langgraph.graph import StateGraph, MessageState\n",
    "             from langchain_anthropic import ChatAnthropic\n",
    "             from langchain.schema import HumanMessage\n",
    "\n",
    "             CODE_DIR = Path(\"sample_code\")  # ← chỉnh đường dẫn thư mục chứa .py\n",
    "             llm = ChatAnthropic(model_name=\"claude-3-haiku-20240307\", temperature=0.2)\n",
    "\n",
    "             class CodeState(MessageState):\n",
    "                 files: list[str] = []\n",
    "                 summaries: dict[str, str] = {}\n",
    "\n",
    "             def list_files(_: CodeState):\n",
    "                 paths = list(CODE_DIR.glob(\"*.py\"))\n",
    "                 return CodeState(files=[str(p) for p in paths], summaries={})\n",
    "\n",
    "             def summarize(state: CodeState):\n",
    "                 for fp in state.files:\n",
    "                     code = Path(fp).read_text()\n",
    "                     prompt = f\"Tóm tắt chức năng file Python sau:\n",
    "```python\n",
    "{code}\n",
    "```\"\n",
    "                     summary = llm([HumanMessage(content=prompt)]).content\n",
    "                     state.summaries[fp] = summary\n",
    "                 return state\n",
    "\n",
    "             g = StateGraph(CodeState)\n",
    "             g.add_node(\"list\", list_files)\n",
    "             g.add_node(\"summarize\", summarize)\n",
    "             g.set_entry_point(\"list\")\n",
    "             g.add_edge(\"list\", \"summarize\")\n",
    "             pipeline = g.compile()\n",
    "             result = pipeline.invoke(CodeState())\n",
    "             for k, v in result.summaries.items():\n",
    "                 print(k, \"→\", v[:120], \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "langchain_env",
   "language": "python",
   "display_name": "Python (langchain_env)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
