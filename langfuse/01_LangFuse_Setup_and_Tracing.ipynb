{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 01. LangFuse Setup and Tracing\n",
    "\n",
    "## M·ª•c ti√™u h·ªçc t·∫≠p\n",
    "\n",
    "Notebook n√†y s·∫Ω h∆∞·ªõng d·∫´n b·∫°n:\n",
    "- Hi·ªÉu kh√°i ni·ªám v√† t·∫ßm quan tr·ªçng c·ªßa tracing trong c√°c ·ª©ng d·ª•ng LLM\n",
    "- C√†i ƒë·∫∑t v√† c·∫•u h√¨nh LangFuse\n",
    "- Th·ª±c hi·ªán tracing c∆° b·∫£n v·ªõi ChatAnthropic\n",
    "- T√≠ch h·ª£p tracing v√†o LangChain chains\n",
    "- Th√™m metadata t√πy ch·ªânh cho traces\n",
    "- Xem v√† ph√¢n t√≠ch traces tr√™n LangFuse UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## 1. Gi·ªõi thi·ªáu v·ªÅ LangFuse Tracing\n",
    "\n",
    "### Tracing l√† g√¨?\n",
    "\n",
    "**Tracing** trong LangFuse l√† qu√° tr√¨nh ghi l·∫°i v√† theo d√µi to√†n b·ªô flow c·ªßa c√°c l·ªùi g·ªçi LLM trong ·ª©ng d·ª•ng c·ªßa b·∫°n. N√≥ gi√∫p:\n",
    "\n",
    "- **Debugging**: X√°c ƒë·ªãnh nhanh l·ªói v√† v·∫•n ƒë·ªÅ trong pipeline\n",
    "- **Performance Monitoring**: Theo d√µi latency, token usage, v√† chi ph√≠\n",
    "- **Quality Assurance**: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng output v√† c·∫£i thi·ªán prompts\n",
    "- **User Analytics**: Hi·ªÉu c√°ch ng∆∞·ªùi d√πng t∆∞∆°ng t√°c v·ªõi h·ªá th·ªëng\n",
    "\n",
    "### T·∫°i sao c·∫ßn LangFuse?\n",
    "\n",
    "1. **Observability**: Kh·∫£ nƒÉng quan s√°t to√†n di·ªán v√†o h·ªá th·ªëng LLM ph·ª©c t·∫°p\n",
    "2. **Cost Control**: Theo d√µi chi ph√≠ s·ª≠ d·ª•ng API theo th·ªùi gian th·ª±c\n",
    "3. **Iterative Improvement**: D·ªØ li·ªáu ƒë·ªÉ c·∫£i thi·ªán prompts v√† chains\n",
    "4. **Compliance**: L∆∞u tr·ªØ v√† audit c√°c interactions cho m·ª•c ƒë√≠ch tu√¢n th·ªß"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 2. C√†i ƒë·∫∑t v√† C·∫•u h√¨nh\n",
    "\n",
    "### 2.1 C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c packages c·∫ßn thi·∫øt\n",
    "!pip install langfuse langchain langchain-anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "### 2.2 C·∫•u h√¨nh bi·∫øn m√¥i tr∆∞·ªùng\n",
    "\n",
    "#### H∆∞·ªõng d·∫´n l·∫•y API Keys t·ª´ LangFuse:\n",
    "\n",
    "1. Truy c·∫≠p [cloud.langfuse.com](https://cloud.langfuse.com) ho·∫∑c self-hosted instance\n",
    "2. ƒêƒÉng k√Ω/ƒêƒÉng nh·∫≠p v√†o t√†i kho·∫£n\n",
    "3. V√†o **Settings** ‚Üí **API Keys**\n",
    "4. T·∫°o new API key v√† copy:\n",
    "   - **Public Key**: D√πng ƒë·ªÉ identify project\n",
    "   - **Secret Key**: D√πng ƒë·ªÉ authenticate\n",
    "   - **Host**: URL c·ªßa LangFuse instance (m·∫∑c ƒë·ªãnh: https://cloud.langfuse.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables t·ª´ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# C·∫•u h√¨nh LangFuse credentials\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.getenv(\"LANGFUSE_PUBLIC_KEY\", \"your-public-key\")\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.getenv(\"LANGFUSE_SECRET_KEY\", \"your-secret-key\")\n",
    "os.environ[\"LANGFUSE_HOST\"] = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "\n",
    "# C·∫•u h√¨nh Anthropic API key\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\", \"your-anthropic-key\")\n",
    "\n",
    "# Verify configuration\n",
    "print(\"LangFuse configuration:\")\n",
    "print(f\"- Host: {os.environ.get('LANGFUSE_HOST')}\")\n",
    "print(f\"- Public Key: {os.environ.get('LANGFUSE_PUBLIC_KEY')[:10]}...\")\n",
    "print(\"- Secret Key: ***configured***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "### 2.3 Kh·ªüi t·∫°o LangFuse client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# Kh·ªüi t·∫°o LangFuse client\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=os.environ.get(\"LANGFUSE_HOST\")\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    langfuse.auth_check()\n",
    "    print(\"‚úÖ K·∫øt n·ªëi LangFuse th√†nh c√¥ng!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói k·∫øt n·ªëi: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 3. V√≠ d·ª• 1: Tracing l·ªùi g·ªçi ChatAnthropic ƒë∆°n gi·∫£n\n",
    "\n",
    "Trong v√≠ d·ª• ƒë·∫ßu ti√™n, ch√∫ng ta s·∫Ω trace m·ªôt l·ªùi g·ªçi ƒë∆°n gi·∫£n ƒë·∫øn ChatAnthropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Kh·ªüi t·∫°o callback handler cho LangFuse\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=os.environ.get(\"LANGFUSE_HOST\")\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o ChatAnthropic v·ªõi callback\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0.7,\n",
    "    callbacks=[langfuse_handler]\n",
    ")\n",
    "\n",
    "# Th·ª±c hi·ªán m·ªôt l·ªùi g·ªçi ƒë∆°n gi·∫£n\n",
    "response = chat.invoke(\"Xin ch√†o! H√£y gi·ªõi thi·ªáu v·ªÅ b·∫£n th√¢n b·∫°n trong 2-3 c√¢u.\")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.content)\n",
    "print(\"\\n---\")\n",
    "print(f\"Trace URL: {langfuse_handler.get_trace_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "### Gi·∫£i th√≠ch code:\n",
    "\n",
    "1. **CallbackHandler**: ƒê√¢y l√† bridge gi·ªØa LangChain v√† LangFuse, t·ª± ƒë·ªông capture c√°c events\n",
    "2. **callbacks parameter**: Truy·ªÅn handler v√†o model ƒë·ªÉ enable tracing\n",
    "3. **get_trace_url()**: L·∫•y URL ƒë·ªÉ xem trace tr√™n LangFuse UI\n",
    "\n",
    "### Xem trace tr√™n UI:\n",
    "- Click v√†o URL ƒë∆∞·ª£c in ra\n",
    "- B·∫°n s·∫Ω th·∫•y:\n",
    "  - Input/Output c·ªßa l·ªùi g·ªçi\n",
    "  - Latency v√† token usage\n",
    "  - Model parameters\n",
    "  - Timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## 4. V√≠ d·ª• 2: Tracing m·ªôt Chain ƒë∆°n gi·∫£n\n",
    "\n",
    "Trong v√≠ d·ª• n√†y, ch√∫ng ta s·∫Ω t·∫°o m·ªôt chain v·ªõi prompt template v√† trace to√†n b·ªô flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# T·∫°o m·ªôt prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ {topic}. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† ch√≠nh x√°c.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# T·∫°o chain v·ªõi prompt | model | parser\n",
    "chain = prompt | chat | StrOutputParser()\n",
    "\n",
    "# T·∫°o m·ªôt trace m·ªõi cho chain execution\n",
    "langfuse_handler = CallbackHandler(\n",
    "    trace_name=\"Simple Q&A Chain\",\n",
    "    user_id=\"demo-user-123\",\n",
    "    session_id=\"session-456\"\n",
    ")\n",
    "\n",
    "# Th·ª±c thi chain v·ªõi tracing\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"topic\": \"l·∫≠p tr√¨nh Python\",\n",
    "        \"question\": \"List comprehension trong Python ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?\"\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "print(\"Chain Result:\")\n",
    "print(result)\n",
    "print(\"\\n---\")\n",
    "print(f\"Trace URL: {langfuse_handler.get_trace_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "### Gi·∫£i th√≠ch chain tracing:\n",
    "\n",
    "1. **trace_name**: ƒê·∫∑t t√™n cho trace ƒë·ªÉ d·ªÖ t√¨m ki·∫øm\n",
    "2. **user_id & session_id**: Metadata ƒë·ªÉ group v√† filter traces\n",
    "3. **Chain structure**: LangFuse t·ª± ƒë·ªông capture t·ª´ng step trong chain\n",
    "\n",
    "### Trong LangFuse UI b·∫°n s·∫Ω th·∫•y:\n",
    "- **Prompt formatting step**: Input variables ƒë∆∞·ª£c format v√†o template\n",
    "- **LLM call**: Request ƒë·∫øn Anthropic API\n",
    "- **Parser step**: Output ƒë∆∞·ª£c parse th√†nh string\n",
    "- **Nested structure**: M·ªói step ƒë∆∞·ª£c hi·ªÉn th·ªã nh∆∞ m·ªôt span ri√™ng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "## 5. V√≠ d·ª• 3: Tracing v·ªõi Metadata t√πy ch·ªânh\n",
    "\n",
    "LangFuse cho ph√©p th√™m metadata t√πy ch·ªânh ƒë·ªÉ enrich traces v·ªõi context b·ªï sung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# T·∫°o m·ªôt function v·ªõi custom tracing\n",
    "def analyze_text_with_metadata(text: str, analysis_type: str):\n",
    "    \"\"\"Ph√¢n t√≠ch vƒÉn b·∫£n v·ªõi metadata phong ph√∫\"\"\"\n",
    "    \n",
    "    # T·∫°o trace v·ªõi metadata\n",
    "    trace = langfuse.trace(\n",
    "        name=\"Text Analysis Pipeline\",\n",
    "        user_id=\"analyst-001\",\n",
    "        session_id=f\"analysis-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "        metadata={\n",
    "            \"analysis_type\": analysis_type,\n",
    "            \"text_length\": len(text),\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        },\n",
    "        tags=[\"text-analysis\", analysis_type, \"demo\"]\n",
    "    )\n",
    "    \n",
    "    # Step 1: Pre-processing\n",
    "    span_preprocess = trace.span(\n",
    "        name=\"preprocessing\",\n",
    "        metadata={\"step\": \"clean_text\"}\n",
    "    )\n",
    "    \n",
    "    # Simulate preprocessing\n",
    "    cleaned_text = text.strip().lower()\n",
    "    span_preprocess.end()\n",
    "    \n",
    "    # Step 2: LLM Analysis\n",
    "    span_llm = trace.span(\n",
    "        name=\"llm_analysis\",\n",
    "        metadata={\n",
    "            \"model\": \"claude-3-haiku\",\n",
    "            \"prompt_template\": \"analysis_v1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create analysis prompt\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Ph√¢n t√≠ch vƒÉn b·∫£n sau theo ki·ªÉu '{analysis_type}':\n",
    "    \n",
    "    VƒÉn b·∫£n: {text}\n",
    "    \n",
    "    Y√™u c·∫ßu:\n",
    "    1. T√≥m t·∫Øt n·ªôi dung ch√≠nh\n",
    "    2. X√°c ƒë·ªãnh tone/sentiment\n",
    "    3. ƒê∆∞a ra insights ch√≠nh\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call LLM with custom handler\n",
    "    handler = CallbackHandler(\n",
    "        trace_id=trace.id,\n",
    "        parent_observation_id=span_llm.id\n",
    "    )\n",
    "    \n",
    "    result = chat.invoke(analysis_prompt, config={\"callbacks\": [handler]})\n",
    "    \n",
    "    span_llm.end(\n",
    "        output=result.content,\n",
    "        metadata={\n",
    "            \"response_length\": len(result.content),\n",
    "            \"processing_time\": \"fast\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Step 3: Post-processing and scoring\n",
    "    span_scoring = trace.span(\n",
    "        name=\"quality_scoring\",\n",
    "        metadata={\"scorer_version\": \"1.0\"}\n",
    "    )\n",
    "    \n",
    "    # Simulate quality scoring\n",
    "    quality_score = 0.85  # Gi·∫£ ƒë·ªãnh\n",
    "    \n",
    "    trace.score(\n",
    "        name=\"quality\",\n",
    "        value=quality_score,\n",
    "        comment=\"Automated quality assessment\"\n",
    "    )\n",
    "    \n",
    "    span_scoring.end(\n",
    "        metadata={\"score\": quality_score}\n",
    "    )\n",
    "    \n",
    "    # End trace\n",
    "    trace.update(\n",
    "        output=result.content,\n",
    "        metadata={\n",
    "            \"final_quality_score\": quality_score,\n",
    "            \"total_processing_time\": \"completed\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"analysis\": result.content,\n",
    "        \"quality_score\": quality_score,\n",
    "        \"trace_url\": trace.get_trace_url()\n",
    "    }\n",
    "\n",
    "# S·ª≠ d·ª•ng function v·ªõi tracing\n",
    "sample_text = \"\"\"\n",
    "LangFuse l√† m·ªôt platform observability m·∫°nh m·∫Ω cho c√°c ·ª©ng d·ª•ng LLM. \n",
    "N√≥ gi√∫p developers theo d√µi, debug v√† c·∫£i thi·ªán c√°c h·ªá th·ªëng AI c·ªßa h·ªç \n",
    "th√¥ng qua detailed tracing v√† analytics.\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_text_with_metadata(\n",
    "    text=sample_text,\n",
    "    analysis_type=\"technical_summary\"\n",
    ")\n",
    "\n",
    "print(\"Analysis Result:\")\n",
    "print(f\"Quality Score: {result['quality_score']}\")\n",
    "print(f\"\\nAnalysis:\\n{result['analysis']}\")\n",
    "print(f\"\\nTrace URL: {result['trace_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "### Gi·∫£i th√≠ch metadata v√† spans:\n",
    "\n",
    "1. **Custom Metadata**:\n",
    "   - `metadata`: Dictionary ch·ª©a th√¥ng tin b·ªï sung\n",
    "   - `tags`: Array ƒë·ªÉ categorize v√† filter traces\n",
    "   - Gi√∫p search v√† analyze traces hi·ªáu qu·∫£ h∆°n\n",
    "\n",
    "2. **Nested Spans**:\n",
    "   - `trace.span()`: T·∫°o sub-spans cho t·ª´ng step\n",
    "   - M·ªói span c√≥ th·ªÉ c√≥ metadata ri√™ng\n",
    "   - Gi√∫p visualize flow chi ti·∫øt\n",
    "\n",
    "3. **Scoring**:\n",
    "   - `trace.score()`: Th√™m quality metrics\n",
    "   - C√≥ th·ªÉ track nhi·ªÅu scores kh√°c nhau\n",
    "   - Useful cho A/B testing v√† optimization\n",
    "\n",
    "4. **Trace Linking**:\n",
    "   - `trace_id` v√† `parent_observation_id`: Link c√°c observations\n",
    "   - Maintain context qua nhi·ªÅu operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "## 6. Best Practices v√† Tips\n",
    "\n",
    "### 6.1 Batch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√≠ d·ª• batch processing v·ªõi tracing\n",
    "questions = [\n",
    "    \"Python l√† g√¨?\",\n",
    "    \"JavaScript kh√°c Python nh∆∞ th·∫ø n√†o?\",\n",
    "    \"Khi n√†o n√™n d√πng TypeScript?\"\n",
    "]\n",
    "\n",
    "# Process batch v·ªõi session grouping\n",
    "batch_session_id = f\"batch-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    handler = CallbackHandler(\n",
    "        trace_name=f\"Batch Question {i+1}\",\n",
    "        session_id=batch_session_id,\n",
    "        tags=[\"batch\", \"faq\"],\n",
    "        metadata={\n",
    "            \"question_index\": i,\n",
    "            \"batch_size\": len(questions)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    response = chat.invoke(question, config={\"callbacks\": [handler]})\n",
    "    print(f\"Q{i+1}: {question}\")\n",
    "    print(f\"A: {response.content[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3",
   "metadata": {},
   "source": [
    "### 6.2 Error Handling v·ªõi Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_llm_call_with_trace(prompt: str):\n",
    "    \"\"\"LLM call v·ªõi error handling v√† tracing\"\"\"\n",
    "    trace = langfuse.trace(\n",
    "        name=\"Safe LLM Call\",\n",
    "        metadata={\"prompt_preview\": prompt[:50] + \"...\"}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Attempt LLM call\n",
    "        handler = CallbackHandler(trace_id=trace.id)\n",
    "        response = chat.invoke(prompt, config={\"callbacks\": [handler]})\n",
    "        \n",
    "        trace.update(\n",
    "            output=response.content,\n",
    "            metadata={\"status\": \"success\"}\n",
    "        )\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Log error to trace\n",
    "        trace.update(\n",
    "            output=None,\n",
    "            metadata={\n",
    "                \"status\": \"error\",\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error_message\": str(e)\n",
    "            },\n",
    "            tags=[\"error\"]\n",
    "        )\n",
    "        print(f\"Error traced: {trace.get_trace_url()}\")\n",
    "        raise\n",
    "\n",
    "# Test v·ªõi valid prompt\n",
    "try:\n",
    "    result = safe_llm_call_with_trace(\"Gi·∫£i th√≠ch ng·∫Øn g·ªçn v·ªÅ recursion\")\n",
    "    print(\"Success:\", result[:100], \"...\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## 7. Xem v√† Ph√¢n t√≠ch Traces tr√™n LangFuse UI\n",
    "\n",
    "### Navigation c∆° b·∫£n:\n",
    "\n",
    "1. **Traces List View**:\n",
    "   - Filter by: tags, user_id, session_id, date range\n",
    "   - Sort by: timestamp, latency, cost, score\n",
    "   - Search by trace name ho·∫∑c content\n",
    "\n",
    "2. **Trace Detail View**:\n",
    "   - **Timeline**: Visualize span relationships\n",
    "   - **Metadata panel**: Xem t·∫•t c·∫£ custom metadata\n",
    "   - **Input/Output**: Full content c·ªßa m·ªói step\n",
    "   - **Metrics**: Latency, tokens, cost breakdown\n",
    "\n",
    "3. **Analytics Dashboard**:\n",
    "   - **Usage trends**: Token usage over time\n",
    "   - **Performance**: P50/P95 latency\n",
    "   - **Cost analysis**: Breakdown by model/user\n",
    "   - **Score distribution**: Quality metrics\n",
    "\n",
    "### Pro Tips:\n",
    "- S·ª≠ d·ª•ng consistent naming cho traces\n",
    "- Tag traces theo feature/experiment\n",
    "- Set up alerts cho errors ho·∫∑c high latency\n",
    "- Export data cho deeper analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## 8. K·∫øt lu·∫≠n v√† B∆∞·ªõc ti·∫øp theo\n",
    "\n",
    "### T√≥m t·∫Øt nh·ªØng g√¨ ƒë√£ h·ªçc:\n",
    "\n",
    "‚úÖ **C√†i ƒë·∫∑t v√† c·∫•u h√¨nh LangFuse** v·ªõi API keys v√† environment variables\n",
    "\n",
    "‚úÖ **Tracing c∆° b·∫£n** v·ªõi CallbackHandler cho single LLM calls\n",
    "\n",
    "‚úÖ **Chain tracing** ƒë·ªÉ theo d√µi complex pipelines\n",
    "\n",
    "‚úÖ **Custom metadata v√† spans** cho detailed observability\n",
    "\n",
    "‚úÖ **Best practices** cho error handling v√† batch processing\n",
    "\n",
    "### B∆∞·ªõc ti·∫øp theo:\n",
    "\n",
    "1. **Advanced Tracing**:\n",
    "   - Multi-agent systems\n",
    "   - Streaming responses\n",
    "   - Async operations\n",
    "\n",
    "2. **Evaluation & Scoring**:\n",
    "   - Implement custom scorers\n",
    "   - A/B testing v·ªõi traces\n",
    "   - Quality benchmarking\n",
    "\n",
    "3. **Integration**:\n",
    "   - Connect v·ªõi CI/CD\n",
    "   - Alerts v√† monitoring\n",
    "   - Export cho data analysis\n",
    "\n",
    "4. **Production Best Practices**:\n",
    "   - Sampling strategies\n",
    "   - PII handling\n",
    "   - Cost optimization\n",
    "\n",
    "### Resources:\n",
    "- [LangFuse Documentation](https://langfuse.com/docs)\n",
    "- [LangChain Integration Guide](https://langfuse.com/docs/integrations/langchain)\n",
    "- [Example Projects](https://github.com/langfuse/langfuse/tree/main/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup v√† flush traces\n",
    "langfuse.flush()\n",
    "print(\"‚úÖ T·∫•t c·∫£ traces ƒë√£ ƒë∆∞·ª£c g·ª≠i l√™n LangFuse!\")\n",
    "print(\"üîó Truy c·∫≠p LangFuse UI ƒë·ªÉ xem chi ti·∫øt traces c·ªßa b·∫°n.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}