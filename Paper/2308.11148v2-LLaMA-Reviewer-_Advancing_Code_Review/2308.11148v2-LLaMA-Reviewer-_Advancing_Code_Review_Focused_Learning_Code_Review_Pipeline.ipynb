{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focused Learning: Code Review Automation Pipeline\n",
    "## Deep Dive into the Three Core Tasks\n",
    "\n",
    "### Learning Objectives:\n",
    "- Master the three-stage code review automation pipeline\n",
    "- Implement each task with practical examples\n",
    "- Understand the data flow and task dependencies\n",
    "- Build an end-to-end code review system\n",
    "\n",
    "### Paper References:\n",
    "- **Section II.A**: Automation in Code Review (Page 2)\n",
    "- **Section III.E**: Code Review Automation Tasks (Page 4)\n",
    "- **Figure 1**: The cycle of the code review process\n",
    "- **Table I**: Summary of code review automation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Code Review Cycle\n",
    "\n",
    "According to the paper, modern code review follows a cycle with three key steps:\n",
    "\n",
    "1. **Review Necessity Prediction** (Reviewer): Determine if a code change needs review\n",
    "2. **Review Comment Generation** (Reviewer): Generate constructive feedback\n",
    "3. **Code Refinement** (Committer): Improve code based on feedback\n",
    "\n",
    "This cycle repeats until reviewer and committer reach agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Visualize the code review cycle\n",
    "def visualize_code_review_cycle():\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Define positions for cycle elements\n",
    "    positions = {\n",
    "        'PR': (0.5, 0.9),\n",
    "        'RNP': (0.15, 0.5),\n",
    "        'RCG': (0.5, 0.1),\n",
    "        'CR': (0.85, 0.5),\n",
    "        'Merge': (0.5, 0.5)\n",
    "    }\n",
    "    \n",
    "    # Draw nodes\n",
    "    node_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightgray']\n",
    "    labels = ['Pull Request', 'Review\\nNecessity?', 'Generate\\nComment', 'Refine\\nCode', 'Merge/Reject']\n",
    "    \n",
    "    for (key, pos), color, label in zip(positions.items(), node_colors, labels):\n",
    "        circle = plt.Circle(pos, 0.12, color=color, ec='black', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(pos[0], pos[1], label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Draw arrows\n",
    "    arrows = [\n",
    "        ('PR', 'RNP', 'Submit'),\n",
    "        ('RNP', 'RCG', 'Yes'),\n",
    "        ('RNP', 'Merge', 'No'),\n",
    "        ('RCG', 'CR', 'Comment'),\n",
    "        ('CR', 'RNP', 'Updated'),\n",
    "        ('Merge', 'PR', 'Next PR')\n",
    "    ]\n",
    "    \n",
    "    for start, end, label in arrows:\n",
    "        start_pos = positions[start]\n",
    "        end_pos = positions[end]\n",
    "        \n",
    "        # Calculate arrow position\n",
    "        dx = end_pos[0] - start_pos[0]\n",
    "        dy = end_pos[1] - start_pos[1]\n",
    "        \n",
    "        ax.annotate('', xy=end_pos, xytext=start_pos,\n",
    "                    arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'),\n",
    "                    )\n",
    "        \n",
    "        # Add label\n",
    "        mid_x = (start_pos[0] + end_pos[0]) / 2\n",
    "        mid_y = (start_pos[1] + end_pos[1]) / 2\n",
    "        ax.text(mid_x, mid_y, label, fontsize=9, ha='center', \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Code Review Automation Cycle\\n(Based on Figure 1 from the paper)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_code_review_cycle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task 1: Review Necessity Prediction (RNP)\n",
    "\n",
    "**Goal**: Determine if a code diff requires review (binary classification)\n",
    "\n",
    "**Input**: Diff hunk (code changes)\n",
    "\n",
    "**Output**: Yes/No decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DiffHunk:\n",
    "    \"\"\"Represents a code diff hunk\"\"\"\n",
    "    file_path: str\n",
    "    old_lines: List[str]\n",
    "    new_lines: List[str]\n",
    "    line_numbers: Tuple[int, int]  # (start, end)\n",
    "    \n",
    "    def to_unified_diff(self) -> str:\n",
    "        \"\"\"Convert to unified diff format\"\"\"\n",
    "        diff_lines = []\n",
    "        diff_lines.append(f\"--- {self.file_path}\")\n",
    "        diff_lines.append(f\"+++ {self.file_path}\")\n",
    "        diff_lines.append(f\"@@ -{self.line_numbers[0]},{len(self.old_lines)} +{self.line_numbers[0]},{len(self.new_lines)} @@\")\n",
    "        \n",
    "        for line in self.old_lines:\n",
    "            diff_lines.append(f\"- {line}\")\n",
    "        for line in self.new_lines:\n",
    "            diff_lines.append(f\"+ {line}\")\n",
    "        \n",
    "        return \"\\n\".join(diff_lines)\n",
    "\n",
    "class ReviewNecessityPredictor:\n",
    "    \"\"\"Predicts if a code diff needs review\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define patterns that typically need review\n",
    "        self.review_patterns = [\n",
    "            r'TODO|FIXME|XXX|HACK',  # Comments needing attention\n",
    "            r'console\\.log|print\\(|debug',  # Debug statements\n",
    "            r'password|secret|key|token',  # Security concerns\n",
    "            r'\\b(rm|delete|drop)\\b',  # Destructive operations\n",
    "            r'catch\\s*\\(.*\\)\\s*\\{\\s*\\}',  # Empty catch blocks\n",
    "            r'//.*@',  # Commented out code with annotations\n",
    "        ]\n",
    "        \n",
    "        # Patterns that typically don't need review\n",
    "        self.safe_patterns = [\n",
    "            r'^\\s*//.*$',  # Comment-only changes\n",
    "            r'^\\s*$',  # Whitespace only\n",
    "            r'\\.(md|txt|json)$',  # Documentation files\n",
    "        ]\n",
    "    \n",
    "    def predict(self, diff_hunk: DiffHunk) -> Tuple[bool, float, str]:\n",
    "        \"\"\"Predict if review is needed\n",
    "        Returns: (needs_review, confidence, reason)\n",
    "        \"\"\"\n",
    "        diff_text = diff_hunk.to_unified_diff()\n",
    "        \n",
    "        # Check for review patterns\n",
    "        for pattern in self.review_patterns:\n",
    "            if re.search(pattern, diff_text, re.IGNORECASE):\n",
    "                return True, 0.9, f\"Found pattern: {pattern}\"\n",
    "        \n",
    "        # Check if it's a safe change\n",
    "        all_safe = True\n",
    "        for line in diff_hunk.new_lines:\n",
    "            is_safe = any(re.match(pattern, line) for pattern in self.safe_patterns)\n",
    "            if not is_safe and line.strip():\n",
    "                all_safe = False\n",
    "                break\n",
    "        \n",
    "        if all_safe:\n",
    "            return False, 0.8, \"Only safe changes detected\"\n",
    "        \n",
    "        # Check complexity heuristics\n",
    "        lines_changed = len(diff_hunk.old_lines) + len(diff_hunk.new_lines)\n",
    "        if lines_changed > 50:\n",
    "            return True, 0.7, \"Large change size\"\n",
    "        \n",
    "        # Default: small changes might need review\n",
    "        return True, 0.6, \"Standard code change\"\n",
    "\n",
    "# Example usage\n",
    "example_diffs = [\n",
    "    DiffHunk(\n",
    "        file_path=\"src/auth.py\",\n",
    "        old_lines=[\"def login(username, pwd):\", \"    return authenticate(username, pwd)\"],\n",
    "        new_lines=[\"def login(username, password):\", \"    # TODO: add rate limiting\", \"    return authenticate(username, password)\"],\n",
    "        line_numbers=(10, 12)\n",
    "    ),\n",
    "    DiffHunk(\n",
    "        file_path=\"README.md\",\n",
    "        old_lines=[\"## Installation\"],\n",
    "        new_lines=[\"## Installation\", \"\", \"### Prerequisites\"],\n",
    "        line_numbers=(5, 6)\n",
    "    ),\n",
    "    DiffHunk(\n",
    "        file_path=\"src/utils.js\",\n",
    "        old_lines=[\"function process(data) {\", \"    return data;\", \"}\"],\n",
    "        new_lines=[\"function process(data) {\", \"    console.log('Processing:', data);\", \"    return data;\", \"}\"],\n",
    "        line_numbers=(20, 23)\n",
    "    )\n",
    "]\n",
    "\n",
    "predictor = ReviewNecessityPredictor()\n",
    "\n",
    "print(\"Review Necessity Predictions:\\n\")\n",
    "for i, diff in enumerate(example_diffs):\n",
    "    needs_review, confidence, reason = predictor.predict(diff)\n",
    "    print(f\"Diff {i+1} ({diff.file_path}):\")\n",
    "    print(f\"  Needs Review: {'Yes' if needs_review else 'No'}\")\n",
    "    print(f\"  Confidence: {confidence:.2f}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    print(f\"  Diff Preview:\\n{diff.to_unified_diff()[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Task 2: Review Comment Generation (RCG)\n",
    "\n",
    "**Goal**: Generate constructive review comments for code\n",
    "\n",
    "**Input**: Code snippet or diff hunk\n",
    "\n",
    "**Output**: Natural language comment\n",
    "\n",
    "The paper considers two perspectives:\n",
    "- **Line-level**: Comments on specific lines (CRer dataset)\n",
    "- **Method-level**: Holistic view of the code (Tufano dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewCommentGenerator:\n",
    "    \"\"\"Generates code review comments\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Comment templates based on common patterns\n",
    "        self.comment_templates = {\n",
    "            'null_check': \"Consider adding null/undefined check for '{variable}' before {action}\",\n",
    "            'error_handling': \"Missing error handling for {operation}. Consider wrapping in try-catch\",\n",
    "            'naming': \"Variable name '{name}' could be more descriptive. Consider '{suggestion}'\",\n",
    "            'complexity': \"This {construct} has high complexity. Consider breaking it into smaller functions\",\n",
    "            'security': \"Potential security issue: {issue}. Please validate/sanitize {data}\",\n",
    "            'performance': \"This operation might be inefficient for large {data_structure}. Consider {optimization}\",\n",
    "            'documentation': \"Please add documentation explaining {what}\",\n",
    "            'magic_number': \"Magic number {number} should be extracted to a named constant\",\n",
    "            'duplication': \"This code appears to duplicate logic from {location}. Consider extracting to a shared function\"\n",
    "        }\n",
    "    \n",
    "    def analyze_code(self, code: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Analyze code and identify issues\"\"\"\n",
    "        issues = []\n",
    "        lines = code.split('\\n')\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            line_num = i + 1\n",
    "            \n",
    "            # Check for null checks\n",
    "            if re.search(r'\\.(\\w+)\\(', line) and 'if' not in line:\n",
    "                match = re.search(r'(\\w+)\\.(\\w+)\\(', line)\n",
    "                if match:\n",
    "                    issues.append({\n",
    "                        'line': line_num,\n",
    "                        'type': 'null_check',\n",
    "                        'params': {'variable': match.group(1), 'action': f\"calling {match.group(2)}()\"}\n",
    "                    })\n",
    "            \n",
    "            # Check for error handling\n",
    "            if re.search(r'(fetch|request|save|delete|api)', line, re.IGNORECASE) and 'try' not in code:\n",
    "                issues.append({\n",
    "                    'line': line_num,\n",
    "                    'type': 'error_handling',\n",
    "                    'params': {'operation': 'async operation'}\n",
    "                })\n",
    "            \n",
    "            # Check for magic numbers\n",
    "            if re.search(r'[^\\d]+(\\d{2,})[^\\d]+', line) and not re.search(r'(\\d+\\.\\d+|0x|import)', line):\n",
    "                match = re.search(r'[^\\d]+(\\d{2,})[^\\d]+', line)\n",
    "                if match:\n",
    "                    issues.append({\n",
    "                        'line': line_num,\n",
    "                        'type': 'magic_number',\n",
    "                        'params': {'number': match.group(1)}\n",
    "                    })\n",
    "            \n",
    "            # Check for poor naming\n",
    "            if re.search(r'\\b[a-z]\\b\\s*=', line):  # Single letter variables\n",
    "                match = re.search(r'\\b([a-z])\\b\\s*=', line)\n",
    "                if match and match.group(1) not in ['i', 'j', 'k']:  # Allow loop counters\n",
    "                    issues.append({\n",
    "                        'line': line_num,\n",
    "                        'type': 'naming',\n",
    "                        'params': {'name': match.group(1), 'suggestion': 'a more descriptive name'}\n",
    "                    })\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    def generate_comment(self, code: str, perspective: str = 'line') -> List[str]:\n",
    "        \"\"\"Generate review comments\"\"\"\n",
    "        issues = self.analyze_code(code)\n",
    "        comments = []\n",
    "        \n",
    "        if perspective == 'line':\n",
    "            # Generate line-level comments\n",
    "            for issue in issues:\n",
    "                template = self.comment_templates[issue['type']]\n",
    "                comment = template.format(**issue['params'])\n",
    "                comments.append(f\"Line {issue['line']}: {comment}\")\n",
    "        else:\n",
    "            # Generate method-level comment\n",
    "            if issues:\n",
    "                summary = f\"Found {len(issues)} potential improvements:\\n\"\n",
    "                for i, issue in enumerate(issues[:3]):  # Top 3 issues\n",
    "                    template = self.comment_templates[issue['type']]\n",
    "                    comment = template.format(**issue['params'])\n",
    "                    summary += f\"{i+1}. {comment}\\n\"\n",
    "                comments.append(summary.strip())\n",
    "            else:\n",
    "                comments.append(\"Code looks good! Consider adding unit tests if not already present.\")\n",
    "        \n",
    "        return comments\n",
    "\n",
    "# Example code snippets\n",
    "code_examples = [\n",
    "    # Example 1: Missing null check\n",
    "    \"\"\"function processUser(user) {\n",
    "    user.save();\n",
    "    return user.id;\n",
    "}\"\"\",\n",
    "    \n",
    "    # Example 2: Magic numbers and poor naming\n",
    "    \"\"\"def calculate(x, y):\n",
    "    z = x * 1000 + y * 50;\n",
    "    return z;\n",
    "}\"\"\",\n",
    "    \n",
    "    # Example 3: Missing error handling\n",
    "    \"\"\"async function fetchData(url) {\n",
    "    const response = await fetch(url);\n",
    "    const data = await response.json();\n",
    "    return data;\n",
    "}\"\"\"\n",
    "]\n",
    "\n",
    "generator = ReviewCommentGenerator()\n",
    "\n",
    "print(\"Generated Review Comments:\\n\")\n",
    "for i, code in enumerate(code_examples):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Code Example {i+1}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(code)\n",
    "    print(f\"\\n--- Line-level Comments ---\")\n",
    "    line_comments = generator.generate_comment(code, perspective='line')\n",
    "    for comment in line_comments:\n",
    "        print(f\"• {comment}\")\n",
    "    print(f\"\\n--- Method-level Comment ---\")\n",
    "    method_comments = generator.generate_comment(code, perspective='method')\n",
    "    for comment in method_comments:\n",
    "        print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Task 3: Code Refinement (CR)\n",
    "\n",
    "**Goal**: Automatically refine code based on review comments\n",
    "\n",
    "**Input**: Source code + review comment\n",
    "\n",
    "**Output**: Refined code\n",
    "\n",
    "The Tufano dataset uses `<START>` and `<END>` markers to indicate focus areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeRefiner:\n",
    "    \"\"\"Refines code based on review comments\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Refinement strategies based on comment patterns\n",
    "        self.refinement_strategies = {\n",
    "            'null_check': self._add_null_check,\n",
    "            'error_handling': self._add_error_handling,\n",
    "            'naming': self._improve_naming,\n",
    "            'extract_constant': self._extract_constant,\n",
    "            'type_hints': self._add_type_hints\n",
    "        }\n",
    "    \n",
    "    def _identify_refinement_type(self, comment: str) -> str:\n",
    "        \"\"\"Identify what type of refinement is needed\"\"\"\n",
    "        comment_lower = comment.lower()\n",
    "        \n",
    "        if 'null' in comment_lower or 'undefined' in comment_lower:\n",
    "            return 'null_check'\n",
    "        elif 'error' in comment_lower or 'exception' in comment_lower or 'try' in comment_lower:\n",
    "            return 'error_handling'\n",
    "        elif 'name' in comment_lower or 'descriptive' in comment_lower:\n",
    "            return 'naming'\n",
    "        elif 'constant' in comment_lower or 'magic number' in comment_lower:\n",
    "            return 'extract_constant'\n",
    "        elif 'type' in comment_lower or 'hint' in comment_lower:\n",
    "            return 'type_hints'\n",
    "        \n",
    "        return 'unknown'\n",
    "    \n",
    "    def _add_null_check(self, code: str, comment: str) -> str:\n",
    "        \"\"\"Add null/undefined checks\"\"\"\n",
    "        lines = code.split('\\n')\n",
    "        refined_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Check if line contains method call on object\n",
    "            match = re.search(r'(\\s*)(\\w+)\\.(\\w+)\\(', line)\n",
    "            if match and 'if' not in line:\n",
    "                indent = match.group(1)\n",
    "                obj = match.group(2)\n",
    "                # Add null check before the line\n",
    "                if 'function' in code or 'def' in code:\n",
    "                    # JavaScript/Python style\n",
    "                    refined_lines.append(f\"{indent}if ({obj}) {{\")\n",
    "                    refined_lines.append(f\"{indent}    {line.strip()}\")\n",
    "                    refined_lines.append(f\"{indent}}}\")\n",
    "                else:\n",
    "                    refined_lines.append(line)\n",
    "            else:\n",
    "                refined_lines.append(line)\n",
    "        \n",
    "        return '\\n'.join(refined_lines)\n",
    "    \n",
    "    def _add_error_handling(self, code: str, comment: str) -> str:\n",
    "        \"\"\"Add try-catch error handling\"\"\"\n",
    "        if 'async' in code or 'await' in code:\n",
    "            # JavaScript async function\n",
    "            lines = code.split('\\n')\n",
    "            refined_lines = [lines[0]]  # Keep function declaration\n",
    "            refined_lines.append(\"    try {\")\n",
    "            for line in lines[1:-1]:\n",
    "                refined_lines.append(f\"    {line}\")\n",
    "            refined_lines.append(\"    } catch (error) {\")\n",
    "            refined_lines.append(\"        console.error('Error:', error);\")\n",
    "            refined_lines.append(\"        throw error;\")\n",
    "            refined_lines.append(\"    }\")\n",
    "            refined_lines.append(lines[-1])  # Keep closing brace\n",
    "            return '\\n'.join(refined_lines)\n",
    "        \n",
    "        return code  # Return unchanged if pattern doesn't match\n",
    "    \n",
    "    def _improve_naming(self, code: str, comment: str) -> str:\n",
    "        \"\"\"Improve variable naming\"\"\"\n",
    "        # Simple example: replace single-letter variables\n",
    "        replacements = {\n",
    "            r'\\bx\\b': 'value',\n",
    "            r'\\by\\b': 'offset',\n",
    "            r'\\bz\\b': 'result',\n",
    "            r'\\ba\\b': 'first',\n",
    "            r'\\bb\\b': 'second'\n",
    "        }\n",
    "        \n",
    "        refined_code = code\n",
    "        for pattern, replacement in replacements.items():\n",
    "            refined_code = re.sub(pattern, replacement, refined_code)\n",
    "        \n",
    "        return refined_code\n",
    "    \n",
    "    def _extract_constant(self, code: str, comment: str) -> str:\n",
    "        \"\"\"Extract magic numbers to constants\"\"\"\n",
    "        # Find magic numbers\n",
    "        matches = re.findall(r'[^\\d]+(\\d{2,})[^\\d]+', code)\n",
    "        \n",
    "        if matches:\n",
    "            # Add constants at the beginning\n",
    "            constants = []\n",
    "            refined_code = code\n",
    "            \n",
    "            for i, number in enumerate(set(matches)):\n",
    "                const_name = f\"CONSTANT_{number}\"\n",
    "                if 'function' in code:\n",
    "                    constants.append(f\"const {const_name} = {number};\")\n",
    "                else:\n",
    "                    constants.append(f\"{const_name} = {number}\")\n",
    "                \n",
    "                # Replace in code\n",
    "                refined_code = re.sub(f'\\\\b{number}\\\\b', const_name, refined_code)\n",
    "            \n",
    "            # Prepend constants\n",
    "            return '\\n'.join(constants) + '\\n\\n' + refined_code\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def _add_type_hints(self, code: str, comment: str) -> str:\n",
    "        \"\"\"Add type hints (Python example)\"\"\"\n",
    "        if 'def' in code:\n",
    "            # Simple type hint addition for Python\n",
    "            refined_code = re.sub(\n",
    "                r'def (\\w+)\\((\\w+), (\\w+)\\):',\n",
    "                r'def \\1(\\2: int, \\3: int) -> int:',\n",
    "                code\n",
    "            )\n",
    "            return refined_code\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def refine(self, source_code: str, comment: str, use_markers: bool = False) -> str:\n",
    "        \"\"\"Refine code based on comment\"\"\"\n",
    "        refinement_type = self._identify_refinement_type(comment)\n",
    "        \n",
    "        if use_markers and '<START>' in source_code:\n",
    "            # Extract marked section\n",
    "            start_idx = source_code.index('<START>') + 7\n",
    "            end_idx = source_code.index('<END>')\n",
    "            marked_code = source_code[start_idx:end_idx]\n",
    "            \n",
    "            # Refine marked section\n",
    "            if refinement_type in self.refinement_strategies:\n",
    "                refined_marked = self.refinement_strategies[refinement_type](marked_code, comment)\n",
    "                refined_code = source_code[:start_idx-7] + refined_marked + source_code[end_idx+5:]\n",
    "            else:\n",
    "                refined_code = source_code\n",
    "        else:\n",
    "            # Refine entire code\n",
    "            if refinement_type in self.refinement_strategies:\n",
    "                refined_code = self.refinement_strategies[refinement_type](source_code, comment)\n",
    "            else:\n",
    "                refined_code = source_code\n",
    "        \n",
    "        return refined_code\n",
    "\n",
    "# Examples of code refinement\n",
    "refinement_examples = [\n",
    "    {\n",
    "        'code': \"\"\"function processUser(user) {\n",
    "    user.save();\n",
    "    return user.id;\n",
    "}\"\"\",\n",
    "        'comment': \"Consider adding null check for 'user' before calling save()\"\n",
    "    },\n",
    "    {\n",
    "        'code': \"\"\"def calculate(x, y):\n",
    "    z = x * 1000 + y * 50\n",
    "    return z\"\"\",\n",
    "        'comment': \"Magic numbers 1000 and 50 should be extracted to named constants\"\n",
    "    },\n",
    "    {\n",
    "        'code': \"\"\"async function fetchData(url) {\n",
    "    const response = await fetch(url);\n",
    "    const data = await response.json();\n",
    "    return data;\n",
    "}\"\"\",\n",
    "        'comment': \"Missing error handling for fetch operation. Consider wrapping in try-catch\"\n",
    "    }\n",
    "]\n",
    "\n",
    "refiner = CodeRefiner()\n",
    "\n",
    "print(\"Code Refinement Examples:\\n\")\n",
    "for i, example in enumerate(refinement_examples):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nOriginal Code:\")\n",
    "    print(example['code'])\n",
    "    print(f\"\\nReview Comment: {example['comment']}\")\n",
    "    print(\"\\nRefined Code:\")\n",
    "    refined = refiner.refine(example['code'], example['comment'])\n",
    "    print(refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building an End-to-End Pipeline\n",
    "\n",
    "Now let's combine all three tasks into a complete code review automation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeReviewPipeline:\n",
    "    \"\"\"Complete code review automation pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rnp = ReviewNecessityPredictor()\n",
    "        self.rcg = ReviewCommentGenerator()\n",
    "        self.cr = CodeRefiner()\n",
    "        self.review_history = []\n",
    "    \n",
    "    def process_pull_request(self, pr_diffs: List[DiffHunk]) -> Dict:\n",
    "        \"\"\"Process a complete pull request\"\"\"\n",
    "        results = {\n",
    "            'total_diffs': len(pr_diffs),\n",
    "            'needs_review': 0,\n",
    "            'auto_approved': 0,\n",
    "            'reviews': []\n",
    "        }\n",
    "        \n",
    "        for diff in pr_diffs:\n",
    "            # Step 1: Check if review is needed\n",
    "            needs_review, confidence, reason = self.rnp.predict(diff)\n",
    "            \n",
    "            if needs_review:\n",
    "                results['needs_review'] += 1\n",
    "                \n",
    "                # Step 2: Generate review comment\n",
    "                code = '\\n'.join(diff.new_lines)\n",
    "                comments = self.rcg.generate_comment(code, perspective='method')\n",
    "                \n",
    "                # Step 3: Suggest refinement\n",
    "                refined_code = None\n",
    "                if comments and comments[0] != \"Code looks good!\":\n",
    "                    refined_code = self.cr.refine(code, comments[0])\n",
    "                \n",
    "                review = {\n",
    "                    'file': diff.file_path,\n",
    "                    'lines': diff.line_numbers,\n",
    "                    'needs_review': True,\n",
    "                    'confidence': confidence,\n",
    "                    'reason': reason,\n",
    "                    'comments': comments,\n",
    "                    'original_code': code,\n",
    "                    'refined_code': refined_code\n",
    "                }\n",
    "            else:\n",
    "                results['auto_approved'] += 1\n",
    "                review = {\n",
    "                    'file': diff.file_path,\n",
    "                    'lines': diff.line_numbers,\n",
    "                    'needs_review': False,\n",
    "                    'confidence': confidence,\n",
    "                    'reason': reason\n",
    "                }\n",
    "            \n",
    "            results['reviews'].append(review)\n",
    "            self.review_history.append(review)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_review_report(self, results: Dict) -> str:\n",
    "        \"\"\"Generate a human-readable review report\"\"\"\n",
    "        report = []\n",
    "        report.append(\"# Code Review Report\")\n",
    "        report.append(f\"\\nTotal files reviewed: {results['total_diffs']}\")\n",
    "        report.append(f\"Files needing review: {results['needs_review']}\")\n",
    "        report.append(f\"Files auto-approved: {results['auto_approved']}\")\n",
    "        report.append(\"\\n## Detailed Reviews:\\n\")\n",
    "        \n",
    "        for review in results['reviews']:\n",
    "            report.append(f\"### {review['file']} (lines {review['lines'][0]}-{review['lines'][1]})\")\n",
    "            \n",
    "            if review['needs_review']:\n",
    "                report.append(f\"**Status**: Needs Review (confidence: {review['confidence']:.2f})\")\n",
    "                report.append(f\"**Reason**: {review['reason']}\")\n",
    "                \n",
    "                if 'comments' in review and review['comments']:\n",
    "                    report.append(\"\\n**Review Comments:**\")\n",
    "                    for comment in review['comments']:\n",
    "                        report.append(f\"- {comment}\")\n",
    "                \n",
    "                if review.get('refined_code'):\n",
    "                    report.append(\"\\n**Suggested Refinement:**\")\n",
    "                    report.append(\"```\")\n",
    "                    report.append(review['refined_code'])\n",
    "                    report.append(\"```\")\n",
    "            else:\n",
    "                report.append(f\"**Status**: Auto-approved\")\n",
    "                report.append(f\"**Reason**: {review['reason']}\")\n",
    "            \n",
    "            report.append(\"\\n---\\n\")\n",
    "        \n",
    "        return '\\n'.join(report)\n",
    "\n",
    "# Simulate a pull request with multiple diffs\n",
    "pr_diffs = [\n",
    "    DiffHunk(\n",
    "        file_path=\"src/api/user.js\",\n",
    "        old_lines=[\n",
    "            \"async function updateUser(id, data) {\",\n",
    "            \"    const user = await User.findById(id);\",\n",
    "            \"    user.update(data);\",\n",
    "            \"    return user;\",\n",
    "            \"}\"\n",
    "        ],\n",
    "        new_lines=[\n",
    "            \"async function updateUser(id, data) {\",\n",
    "            \"    const user = await User.findById(id);\",\n",
    "            \"    user.update(data);\",\n",
    "            \"    user.save();\",\n",
    "            \"    return user;\",\n",
    "            \"}\"\n",
    "        ],\n",
    "        line_numbers=(10, 15)\n",
    "    ),\n",
    "    DiffHunk(\n",
    "        file_path=\"src/utils/calc.py\",\n",
    "        old_lines=[\n",
    "            \"def process(a, b):\",\n",
    "            \"    return a + b\"\n",
    "        ],\n",
    "        new_lines=[\n",
    "            \"def process(a, b):\",\n",
    "            \"    c = a * 100 + b * 50\",\n",
    "            \"    return c\"\n",
    "        ],\n",
    "        line_numbers=(5, 7)\n",
    "    ),\n",
    "    DiffHunk(\n",
    "        file_path=\"docs/README.md\",\n",
    "        old_lines=[\"# Project Title\"],\n",
    "        new_lines=[\"# Project Title\", \"\", \"## Description\"],\n",
    "        line_numbers=(1, 3)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline = CodeReviewPipeline()\n",
    "results = pipeline.process_pull_request(pr_diffs)\n",
    "\n",
    "# Generate and display report\n",
    "report = pipeline.generate_review_report(results)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics and Evaluation\n",
    "\n",
    "Let's visualize the performance metrics from the paper for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance data from the paper\n",
    "performance_data = {\n",
    "    'Review Necessity Prediction': {\n",
    "        'models': ['Transformer-b', 'Tufano et al.', 'CodeT5', 'CodeReviewer', 'LLaMA-Reviewer'],\n",
    "        'precision': [74.50, 70.82, 70.36, 78.60, 60.99],\n",
    "        'recall': [46.07, 57.20, 58.96, 65.63, 83.50],\n",
    "        'f1': [56.93, 63.29, 64.16, 71.53, 70.49]\n",
    "    },\n",
    "    'Review Comment Generation': {\n",
    "        'models': ['Transformer-b', 'Tufano et al.', 'CodeT5', 'CodeReviewer', 'LLaMA-Reviewer (LoRA)'],\n",
    "        'bleu4_crer': [4.76, 4.39, 4.83, 5.32, 5.70],\n",
    "        'bleu4_tuf': [None, 7.39, None, None, 5.04]\n",
    "    },\n",
    "    'Code Refinement': {\n",
    "        'models': ['Tufano et al.', 'CodeT5', 'CodeReviewer', 'LLaMA-Reviewer (LoRA)'],\n",
    "        'bleu4_crer': [77.03, 80.82, 82.61, 82.27],\n",
    "        'bleu4_tuf': [78.33, None, None, 78.23]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Review Necessity Prediction - Precision/Recall/F1\n",
    "ax1 = axes[0, 0]\n",
    "rnp_data = performance_data['Review Necessity Prediction']\n",
    "x = np.arange(len(rnp_data['models']))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax1.bar(x - width, rnp_data['precision'], width, label='Precision', color='lightblue')\n",
    "bars2 = ax1.bar(x, rnp_data['recall'], width, label='Recall', color='lightgreen')\n",
    "bars3 = ax1.bar(x + width, rnp_data['f1'], width, label='F1', color='lightcoral')\n",
    "\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Score (%)')\n",
    "ax1.set_title('Review Necessity Prediction Performance')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(rnp_data['models'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Highlight LLaMA-Reviewer's high recall\n",
    "ax1.annotate('High Recall!', xy=(4, 83.5), xytext=(3.5, 90),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=12, color='red', fontweight='bold')\n",
    "\n",
    "# 2. Review Comment Generation - BLEU scores\n",
    "ax2 = axes[0, 1]\n",
    "rcg_data = performance_data['Review Comment Generation']\n",
    "models = rcg_data['models']\n",
    "crer_scores = rcg_data['bleu4_crer']\n",
    "\n",
    "bars = ax2.bar(models, crer_scores, color='skyblue')\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('BLEU-4 Score')\n",
    "ax2.set_title('Review Comment Generation (CRer Dataset)')\n",
    "ax2.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, crer_scores):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Code Refinement - BLEU scores\n",
    "ax3 = axes[1, 0]\n",
    "cr_data = performance_data['Code Refinement']\n",
    "models = cr_data['models']\n",
    "crer_scores = cr_data['bleu4_crer']\n",
    "\n",
    "bars = ax3.bar(models, crer_scores, color='lightgreen')\n",
    "ax3.set_xlabel('Models')\n",
    "ax3.set_ylabel('BLEU-4 Score')\n",
    "ax3.set_title('Code Refinement (CRer Dataset)')\n",
    "ax3.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, crer_scores):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Task complexity analysis\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "task_analysis = \"\"\"Task Complexity Analysis (from paper):\n",
    "\n",
    "1. Review Necessity Prediction:\n",
    "   - Type: Binary Classification\n",
    "   - Challenge: Imbalanced dataset\n",
    "   - LLaMA-Reviewer: Optimized for recall\n",
    "   \n",
    "2. Review Comment Generation:\n",
    "   - Type: Natural Language Generation\n",
    "   - Challenge: Most complex task\n",
    "   - LLaMA-Reviewer: Best performance (5.70)\n",
    "   \n",
    "3. Code Refinement:\n",
    "   - Type: Code Generation/Translation\n",
    "   - Challenge: Preserving semantics\n",
    "   - LLaMA-Reviewer: Competitive (82.27)\n",
    "\n",
    "Key Insight: LLaMA-Reviewer excels at\n",
    "NL generation tasks due to its pre-training\n",
    "on large text corpora.\"\"\"\n",
    "\n",
    "ax4.text(0.1, 0.9, task_analysis, transform=ax4.transAxes,\n",
    "         fontsize=12, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Integration with LangChain/LangGraph\n",
    "\n",
    "Here's how to integrate this pipeline with LangChain for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "\n",
    "# Define state for LangGraph\n",
    "class CodeReviewState(TypedDict):\n",
    "    \"\"\"State for code review workflow\"\"\"\n",
    "    diff_hunks: List[DiffHunk]\n",
    "    review_decisions: List[bool]\n",
    "    comments: List[str]\n",
    "    refined_codes: List[str]\n",
    "    current_index: int\n",
    "    iteration_count: int\n",
    "\n",
    "# LangChain components\n",
    "def create_langchain_pipeline():\n",
    "    \"\"\"Create LangChain components for code review\"\"\"\n",
    "    \n",
    "    # Prompt templates for each task\n",
    "    rnp_prompt = PromptTemplate(\n",
    "        input_variables=[\"diff_hunk\"],\n",
    "        template=\"\"\"You are a code reviewer. Analyze the following diff and determine if it needs review.\n",
    "\n",
    "Diff:\n",
    "{diff_hunk}\n",
    "\n",
    "Does this need review? (yes/no):\"\"\"\n",
    "    )\n",
    "    \n",
    "    rcg_prompt = PromptTemplate(\n",
    "        input_variables=[\"code\"],\n",
    "        template=\"\"\"You are an experienced code reviewer. Provide constructive feedback for this code:\n",
    "\n",
    "Code:\n",
    "{code}\n",
    "\n",
    "Review comment:\"\"\"\n",
    "    )\n",
    "    \n",
    "    cr_prompt = PromptTemplate(\n",
    "        input_variables=[\"code\", \"comment\"],\n",
    "        template=\"\"\"Refine the following code based on the review comment:\n",
    "\n",
    "Original code:\n",
    "{code}\n",
    "\n",
    "Review comment:\n",
    "{comment}\n",
    "\n",
    "Refined code:\"\"\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'rnp_prompt': rnp_prompt,\n",
    "        'rcg_prompt': rcg_prompt,\n",
    "        'cr_prompt': cr_prompt\n",
    "    }\n",
    "\n",
    "# Example workflow implementation\n",
    "class LangChainCodeReviewWorkflow:\n",
    "    \"\"\"Code review workflow using LangChain patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prompts = create_langchain_pipeline()\n",
    "        self.pipeline = CodeReviewPipeline()\n",
    "    \n",
    "    def run_review_cycle(self, pr_diffs: List[DiffHunk], max_iterations: int = 3) -> Dict:\n",
    "        \"\"\"Run the review cycle with iteration limit\"\"\"\n",
    "        \n",
    "        state = {\n",
    "            'diff_hunks': pr_diffs,\n",
    "            'review_decisions': [],\n",
    "            'comments': [],\n",
    "            'refined_codes': [],\n",
    "            'current_index': 0,\n",
    "            'iteration_count': 0\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for diff in pr_diffs:\n",
    "            iteration = 0\n",
    "            current_code = '\\n'.join(diff.new_lines)\n",
    "            review_history = []\n",
    "            \n",
    "            while iteration < max_iterations:\n",
    "                # Step 1: Check if review needed\n",
    "                needs_review, confidence, reason = self.pipeline.rnp.predict(diff)\n",
    "                \n",
    "                if not needs_review:\n",
    "                    break\n",
    "                \n",
    "                # Step 2: Generate comment\n",
    "                comments = self.pipeline.rcg.generate_comment(current_code, 'method')\n",
    "                \n",
    "                if not comments or comments[0] == \"Code looks good!\":\n",
    "                    break\n",
    "                \n",
    "                # Step 3: Refine code\n",
    "                refined_code = self.pipeline.cr.refine(current_code, comments[0])\n",
    "                \n",
    "                review_history.append({\n",
    "                    'iteration': iteration + 1,\n",
    "                    'comment': comments[0],\n",
    "                    'original': current_code,\n",
    "                    'refined': refined_code\n",
    "                })\n",
    "                \n",
    "                # Update for next iteration\n",
    "                current_code = refined_code\n",
    "                iteration += 1\n",
    "            \n",
    "            results.append({\n",
    "                'file': diff.file_path,\n",
    "                'iterations': len(review_history),\n",
    "                'history': review_history,\n",
    "                'final_code': current_code\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Demonstrate the workflow\n",
    "workflow = LangChainCodeReviewWorkflow()\n",
    "\n",
    "# Create a problematic diff that needs multiple iterations\n",
    "problematic_diff = DiffHunk(\n",
    "    file_path=\"src/critical.js\",\n",
    "    old_lines=[\"function process(data) { return data; }\"],\n",
    "    new_lines=[\n",
    "        \"function process(x) {\",\n",
    "        \"    y = x * 1000;\",\n",
    "        \"    x.save();\",\n",
    "        \"    return y;\",\n",
    "        \"}\"\n",
    "    ],\n",
    "    line_numbers=(1, 5)\n",
    ")\n",
    "\n",
    "# Run review cycle\n",
    "print(\"Running iterative review cycle...\\n\")\n",
    "cycle_results = workflow.run_review_cycle([problematic_diff], max_iterations=3)\n",
    "\n",
    "# Display results\n",
    "for result in cycle_results:\n",
    "    print(f\"File: {result['file']}\")\n",
    "    print(f\"Total iterations: {result['iterations']}\\n\")\n",
    "    \n",
    "    for review in result['history']:\n",
    "        print(f\"--- Iteration {review['iteration']} ---\")\n",
    "        print(f\"Comment: {review['comment']}\")\n",
    "        print(f\"\\nRefined code:\")\n",
    "        print(review['refined'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Best Practices\n",
    "\n",
    "### From the Paper's Implementation:\n",
    "\n",
    "1. **Task Input/Output Formats** (Table I):\n",
    "   - RNP: PL → L (Programming Language to Label)\n",
    "   - RCG: PL → NL (Programming Language to Natural Language)  \n",
    "   - CR: PL + NL → PL (Code + Comment to Refined Code)\n",
    "\n",
    "2. **Dataset Characteristics**:\n",
    "   - **CRer**: Multi-language, line-level, preserves formatting\n",
    "   - **Tufano**: Java-only, method-level, cleaned formatting\n",
    "\n",
    "3. **Performance Insights**:\n",
    "   - LLaMA-Reviewer optimizes for **high recall** in RNP (83.5%)\n",
    "   - Best at **comment generation** due to NL pre-training\n",
    "   - Competitive in **code refinement** despite no code pre-training\n",
    "\n",
    "### Implementation Best Practices:\n",
    "\n",
    "1. **For Review Necessity Prediction**:\n",
    "   - Balance precision vs recall based on use case\n",
    "   - Consider cost of false positives vs false negatives\n",
    "   - Use confidence scores for prioritization\n",
    "\n",
    "2. **For Comment Generation**:\n",
    "   - Choose perspective (line vs method) based on context\n",
    "   - Provide specific, actionable feedback\n",
    "   - Consider code context beyond the diff\n",
    "\n",
    "3. **For Code Refinement**:\n",
    "   - Preserve code semantics and style\n",
    "   - Handle multiple refinement types\n",
    "   - Support iterative improvement\n",
    "\n",
    "### Future Enhancements:\n",
    "\n",
    "1. **Multi-modal Understanding**: Combine code structure + semantics\n",
    "2. **Context Awareness**: Consider entire file/project context\n",
    "3. **Learning from Feedback**: Adapt based on developer responses\n",
    "4. **IDE Integration**: Real-time review during development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}