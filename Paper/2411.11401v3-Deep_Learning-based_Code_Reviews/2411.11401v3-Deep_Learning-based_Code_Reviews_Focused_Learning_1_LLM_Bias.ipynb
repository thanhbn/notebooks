{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focused Learning: Understanding LLM Bias in Code Review\n",
    "\n",
    "## Learning Objectives\n",
    "1. Understand the concept of **anchoring bias** in automated code review\n",
    "2. Analyze how LLM-generated reviews influence reviewer behavior\n",
    "3. Implement experiments to measure and visualize bias effects\n",
    "4. Develop strategies to mitigate bias in AI-assisted code review\n",
    "\n",
    "## Paper Context\n",
    "**Section Reference**: Section III-A (RQ0) and Section III-E (Actionable Recommendations)\n",
    "\n",
    "**Key Finding from Paper**:\n",
    "> \"The availability of an automated review as a starting point strongly influences the reviewer's behavior. Reviewers mostly focused on the code locations pointed out in the automatically generated review they were provided with.\"\n",
    "\n",
    "**Figure Reference**: Figure 3 - Shows how MCR reviews covered 484 distinct lines with 263 unique to MCR, while ACR/CCR reviews showed much less variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Set, Tuple\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import networkx as nx\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical Foundation: Anchoring Bias\n",
    "\n",
    "Anchoring bias is a cognitive bias where individuals rely too heavily on the first piece of information offered (the \"anchor\") when making decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CodeLocation:\n",
    "    \"\"\"Represents a location in code that can be reviewed\"\"\"\n",
    "    file_name: str\n",
    "    line_start: int\n",
    "    line_end: int\n",
    "    has_issue: bool\n",
    "    issue_severity: str = \"low\"  # low, medium, high\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.file_name, self.line_start, self.line_end))\n",
    "\n",
    "@dataclass\n",
    "class ReviewerBehavior:\n",
    "    \"\"\"Models reviewer behavior with/without anchoring\"\"\"\n",
    "    treatment: str  # MCR, ACR, CCR\n",
    "    locations_reviewed: List[CodeLocation]\n",
    "    time_per_location: List[float]\n",
    "    issues_found: List[CodeLocation]\n",
    "    anchored_locations: Set[CodeLocation] = None\n",
    "\n",
    "def simulate_code_base(n_files: int = 5, lines_per_file: int = 100) -> Dict[str, List[CodeLocation]]:\n",
    "    \"\"\"Create a simulated codebase with issues\"\"\"\n",
    "    codebase = {}\n",
    "    \n",
    "    for i in range(n_files):\n",
    "        file_name = f\"module_{i}.py\"\n",
    "        locations = []\n",
    "        \n",
    "        # Generate code locations with some having issues\n",
    "        for line in range(0, lines_per_file, 10):\n",
    "            has_issue = np.random.random() < 0.2  # 20% chance of issue\n",
    "            severity = np.random.choice(['low', 'medium', 'high'], p=[0.6, 0.3, 0.1]) if has_issue else 'low'\n",
    "            \n",
    "            location = CodeLocation(\n",
    "                file_name=file_name,\n",
    "                line_start=line,\n",
    "                line_end=line + 5,\n",
    "                has_issue=has_issue,\n",
    "                issue_severity=severity\n",
    "            )\n",
    "            locations.append(location)\n",
    "        \n",
    "        codebase[file_name] = locations\n",
    "    \n",
    "    return codebase\n",
    "\n",
    "# Create simulated codebase\n",
    "codebase = simulate_code_base()\n",
    "all_locations = [loc for locs in codebase.values() for loc in locs]\n",
    "issue_locations = [loc for loc in all_locations if loc.has_issue]\n",
    "\n",
    "print(f\"Created codebase with {len(all_locations)} locations\")\n",
    "print(f\"Total issues: {len(issue_locations)}\")\n",
    "print(f\"Issue distribution: \")\n",
    "for severity in ['low', 'medium', 'high']:\n",
    "    count = len([loc for loc in issue_locations if loc.issue_severity == severity])\n",
    "    print(f\"  {severity}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling Reviewer Behavior Under Different Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedReviewerSimulator:\n",
    "    \"\"\"Simulates reviewer behavior with anchoring bias effects\"\"\"\n",
    "    \n",
    "    def __init__(self, codebase: Dict[str, List[CodeLocation]]):\n",
    "        self.codebase = codebase\n",
    "        self.all_locations = [loc for locs in codebase.values() for loc in locs]\n",
    "    \n",
    "    def generate_llm_review(self, coverage: float = 0.42) -> Set[CodeLocation]:\n",
    "        \"\"\"Simulate LLM review that covers ~42% of issues (from paper)\"\"\"\n",
    "        issue_locations = [loc for loc in self.all_locations if loc.has_issue]\n",
    "        \n",
    "        # LLM tends to find more low-severity issues\n",
    "        weights = []\n",
    "        for loc in issue_locations:\n",
    "            if loc.issue_severity == 'low':\n",
    "                weights.append(3.0)  # Higher weight for low severity\n",
    "            elif loc.issue_severity == 'medium':\n",
    "                weights.append(1.5)\n",
    "            else:  # high\n",
    "                weights.append(0.5)  # Lower weight for high severity\n",
    "        \n",
    "        n_to_select = int(len(issue_locations) * coverage)\n",
    "        selected = np.random.choice(issue_locations, size=n_to_select, replace=False, p=weights/np.sum(weights))\n",
    "        \n",
    "        # Also add some false positives (non-issues)\n",
    "        non_issues = [loc for loc in self.all_locations if not loc.has_issue]\n",
    "        false_positives = np.random.choice(non_issues, size=max(1, n_to_select//4), replace=False)\n",
    "        \n",
    "        return set(selected) | set(false_positives)\n",
    "    \n",
    "    def simulate_manual_review(self, time_budget: float = 42.0) -> ReviewerBehavior:\n",
    "        \"\"\"Simulate manual code review (MCR)\"\"\"\n",
    "        locations_reviewed = []\n",
    "        time_per_location = []\n",
    "        issues_found = []\n",
    "        time_spent = 0\n",
    "        \n",
    "        # Random walk through codebase\n",
    "        shuffled_locations = self.all_locations.copy()\n",
    "        np.random.shuffle(shuffled_locations)\n",
    "        \n",
    "        for loc in shuffled_locations:\n",
    "            # Time varies based on complexity\n",
    "            base_time = np.random.normal(1.0, 0.3)\n",
    "            \n",
    "            if time_spent + base_time > time_budget:\n",
    "                break\n",
    "            \n",
    "            locations_reviewed.append(loc)\n",
    "            time_per_location.append(base_time)\n",
    "            time_spent += base_time\n",
    "            \n",
    "            # Probability of finding issue depends on severity\n",
    "            if loc.has_issue:\n",
    "                prob_find = {'low': 0.3, 'medium': 0.6, 'high': 0.9}[loc.issue_severity]\n",
    "                if np.random.random() < prob_find:\n",
    "                    issues_found.append(loc)\n",
    "        \n",
    "        return ReviewerBehavior(\n",
    "            treatment=\"MCR\",\n",
    "            locations_reviewed=locations_reviewed,\n",
    "            time_per_location=time_per_location,\n",
    "            issues_found=issues_found\n",
    "        )\n",
    "    \n",
    "    def simulate_anchored_review(self, anchor_locations: Set[CodeLocation], \n",
    "                               treatment: str, time_budget: float = 56.0) -> ReviewerBehavior:\n",
    "        \"\"\"Simulate review with anchoring bias (ACR/CCR)\"\"\"\n",
    "        locations_reviewed = []\n",
    "        time_per_location = []\n",
    "        issues_found = []\n",
    "        time_spent = 0\n",
    "        \n",
    "        # First, review anchored locations (89% kept from paper)\n",
    "        for loc in anchor_locations:\n",
    "            if time_spent > time_budget:\n",
    "                break\n",
    "            \n",
    "            # More time spent verifying anchored locations\n",
    "            verify_time = np.random.normal(1.5, 0.4)\n",
    "            locations_reviewed.append(loc)\n",
    "            time_per_location.append(verify_time)\n",
    "            time_spent += verify_time\n",
    "            \n",
    "            # 89% chance of keeping anchored issue\n",
    "            if np.random.random() < 0.89:\n",
    "                issues_found.append(loc)\n",
    "        \n",
    "        # Limited exploration of non-anchored locations\n",
    "        remaining_locations = [loc for loc in self.all_locations if loc not in anchor_locations]\n",
    "        np.random.shuffle(remaining_locations)\n",
    "        \n",
    "        # Reduced exploration due to anchoring\n",
    "        exploration_factor = 0.3  # Only 30% as much exploration\n",
    "        \n",
    "        for loc in remaining_locations[:int(len(remaining_locations) * exploration_factor)]:\n",
    "            if time_spent > time_budget:\n",
    "                break\n",
    "            \n",
    "            quick_check_time = np.random.normal(0.5, 0.2)\n",
    "            locations_reviewed.append(loc)\n",
    "            time_per_location.append(quick_check_time)\n",
    "            time_spent += quick_check_time\n",
    "            \n",
    "            # Lower probability of finding non-anchored issues\n",
    "            if loc.has_issue:\n",
    "                prob_find = {'low': 0.1, 'medium': 0.2, 'high': 0.4}[loc.issue_severity]\n",
    "                if np.random.random() < prob_find:\n",
    "                    issues_found.append(loc)\n",
    "        \n",
    "        return ReviewerBehavior(\n",
    "            treatment=treatment,\n",
    "            locations_reviewed=locations_reviewed,\n",
    "            time_per_location=time_per_location,\n",
    "            issues_found=issues_found,\n",
    "            anchored_locations=anchor_locations\n",
    "        )\n",
    "\n",
    "# Run simulations\n",
    "simulator = BiasedReviewerSimulator(codebase)\n",
    "\n",
    "# Generate LLM review for ACR\n",
    "llm_review = simulator.generate_llm_review()\n",
    "\n",
    "# Generate comprehensive review for CCR (all issues)\n",
    "all_issues = {loc for loc in simulator.all_locations if loc.has_issue}\n",
    "\n",
    "# Simulate different treatments\n",
    "mcr_behavior = simulator.simulate_manual_review()\n",
    "acr_behavior = simulator.simulate_anchored_review(llm_review, \"ACR\")\n",
    "ccr_behavior = simulator.simulate_anchored_review(all_issues, \"CCR\")\n",
    "\n",
    "print(f\"\\nSimulation Results:\")\n",
    "for behavior, name in [(mcr_behavior, \"MCR\"), (acr_behavior, \"ACR\"), (ccr_behavior, \"CCR\")]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Locations reviewed: {len(behavior.locations_reviewed)}\")\n",
    "    print(f\"  Issues found: {len(behavior.issues_found)}\")\n",
    "    print(f\"  Time spent: {sum(behavior.time_per_location):.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Anchoring Bias Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_review_coverage(behaviors: List[Tuple[ReviewerBehavior, str]]):\n",
    "    \"\"\"Visualize which code locations were reviewed under different treatments\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, (behavior, name) in enumerate(behaviors):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Create a grid representing code locations\n",
    "        n_files = 5\n",
    "        n_locations_per_file = 10\n",
    "        \n",
    "        # Create grid data\n",
    "        grid = np.zeros((n_files, n_locations_per_file))\n",
    "        anchored_grid = np.zeros((n_files, n_locations_per_file))\n",
    "        issue_grid = np.zeros((n_files, n_locations_per_file))\n",
    "        \n",
    "        # Map locations to grid\n",
    "        for loc in simulator.all_locations:\n",
    "            file_idx = int(loc.file_name.split('_')[1])\n",
    "            loc_idx = loc.line_start // 10\n",
    "            \n",
    "            if loc.has_issue:\n",
    "                issue_grid[file_idx, loc_idx] = {'low': 1, 'medium': 2, 'high': 3}[loc.issue_severity]\n",
    "            \n",
    "            if loc in behavior.locations_reviewed:\n",
    "                grid[file_idx, loc_idx] = 1\n",
    "            \n",
    "            if behavior.anchored_locations and loc in behavior.anchored_locations:\n",
    "                anchored_grid[file_idx, loc_idx] = 1\n",
    "        \n",
    "        # Create custom colormap\n",
    "        colors = ['white', 'lightblue', 'orange', 'red']\n",
    "        n_bins = 4\n",
    "        cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "        \n",
    "        # Plot issue severity\n",
    "        im = ax.imshow(issue_grid, cmap=cmap, alpha=0.6, aspect='auto')\n",
    "        \n",
    "        # Overlay review coverage\n",
    "        for i in range(n_files):\n",
    "            for j in range(n_locations_per_file):\n",
    "                if grid[i, j] == 1:\n",
    "                    rect = Rectangle((j-0.4, i-0.4), 0.8, 0.8, \n",
    "                                   fill=False, edgecolor='green', linewidth=2)\n",
    "                    ax.add_patch(rect)\n",
    "                \n",
    "                if anchored_grid[i, j] == 1:\n",
    "                    circle = plt.Circle((j, i), 0.3, fill=False, \n",
    "                                      edgecolor='purple', linewidth=2, linestyle='--')\n",
    "                    ax.add_patch(circle)\n",
    "        \n",
    "        ax.set_title(f\"{name} Treatment\\nCoverage Pattern\", fontsize=14)\n",
    "        ax.set_xlabel(\"Code Location\")\n",
    "        ax.set_ylabel(\"File\")\n",
    "        ax.set_xticks(range(n_locations_per_file))\n",
    "        ax.set_yticks(range(n_files))\n",
    "        ax.set_yticklabels([f\"module_{i}.py\" for i in range(n_files)])\n",
    "        \n",
    "        # Add legend for first plot\n",
    "        if idx == 0:\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_elements = [\n",
    "                Patch(facecolor='white', label='No issue'),\n",
    "                Patch(facecolor='lightblue', label='Low severity'),\n",
    "                Patch(facecolor='orange', label='Medium severity'),\n",
    "                Patch(facecolor='red', label='High severity'),\n",
    "                Patch(facecolor='none', edgecolor='green', linewidth=2, label='Reviewed'),\n",
    "                Patch(facecolor='none', edgecolor='purple', linewidth=2, linestyle='--', label='Anchored')\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(-0.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize coverage patterns\n",
    "visualize_review_coverage([\n",
    "    (mcr_behavior, \"MCR\"),\n",
    "    (acr_behavior, \"ACR\"),\n",
    "    (ccr_behavior, \"CCR\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantifying Bias: Coverage Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coverage_overlap(behaviors: Dict[str, ReviewerBehavior]):\n",
    "    \"\"\"Analyze overlap in reviewed locations between treatments\"\"\"\n",
    "    \n",
    "    # Get sets of reviewed locations\n",
    "    reviewed_sets = {\n",
    "        name: set(behavior.locations_reviewed)\n",
    "        for name, behavior in behaviors.items()\n",
    "    }\n",
    "    \n",
    "    # Calculate overlaps\n",
    "    results = []\n",
    "    \n",
    "    for t1 in behaviors.keys():\n",
    "        for t2 in behaviors.keys():\n",
    "            if t1 != t2:\n",
    "                overlap = len(reviewed_sets[t1] & reviewed_sets[t2])\n",
    "                total = len(reviewed_sets[t1] | reviewed_sets[t2])\n",
    "                jaccard = overlap / total if total > 0 else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'Treatment 1': t1,\n",
    "                    'Treatment 2': t2,\n",
    "                    'Overlap': overlap,\n",
    "                    'Jaccard Index': jaccard,\n",
    "                    'T1 Unique': len(reviewed_sets[t1] - reviewed_sets[t2]),\n",
    "                    'T2 Unique': len(reviewed_sets[t2] - reviewed_sets[t1])\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Analyze overlap\n",
    "behaviors_dict = {\n",
    "    'MCR': mcr_behavior,\n",
    "    'ACR': acr_behavior,\n",
    "    'CCR': ccr_behavior\n",
    "}\n",
    "\n",
    "overlap_df = analyze_coverage_overlap(behaviors_dict)\n",
    "print(\"\\nCoverage Overlap Analysis:\")\n",
    "print(overlap_df.to_string(index=False))\n",
    "\n",
    "# Visualize as heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "pivot = overlap_df.pivot(index='Treatment 1', columns='Treatment 2', values='Jaccard Index')\n",
    "sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd', vmin=0, vmax=1)\n",
    "plt.title('Jaccard Similarity Index Between Treatments\\n(Higher = More Similar Coverage)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Issue Detection Analysis by Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_issue_detection_by_severity(behaviors: Dict[str, ReviewerBehavior]):\n",
    "    \"\"\"Analyze which types of issues are found under different treatments\"\"\"\n",
    "    \n",
    "    # Get all issues in codebase by severity\n",
    "    all_issues = [loc for loc in simulator.all_locations if loc.has_issue]\n",
    "    issues_by_severity = {\n",
    "        'low': [loc for loc in all_issues if loc.issue_severity == 'low'],\n",
    "        'medium': [loc for loc in all_issues if loc.issue_severity == 'medium'],\n",
    "        'high': [loc for loc in all_issues if loc.issue_severity == 'high']\n",
    "    }\n",
    "    \n",
    "    # Analyze detection rates\n",
    "    results = []\n",
    "    \n",
    "    for treatment, behavior in behaviors.items():\n",
    "        found_issues = set(behavior.issues_found)\n",
    "        \n",
    "        for severity, severity_issues in issues_by_severity.items():\n",
    "            found_count = len([loc for loc in severity_issues if loc in found_issues])\n",
    "            total_count = len(severity_issues)\n",
    "            detection_rate = found_count / total_count if total_count > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'Treatment': treatment,\n",
    "                'Severity': severity,\n",
    "                'Found': found_count,\n",
    "                'Total': total_count,\n",
    "                'Detection Rate': detection_rate\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Bar plot of detection rates\n",
    "    pivot = df.pivot(index='Severity', columns='Treatment', values='Detection Rate')\n",
    "    pivot.plot(kind='bar', ax=ax1)\n",
    "    ax1.set_title('Issue Detection Rate by Severity and Treatment')\n",
    "    ax1.set_ylabel('Detection Rate')\n",
    "    ax1.set_xlabel('Issue Severity')\n",
    "    ax1.legend(title='Treatment')\n",
    "    ax1.set_ylim(0, 1.1)\n",
    "    \n",
    "    # Stacked bar plot of absolute numbers\n",
    "    pivot2 = df.pivot(index='Treatment', columns='Severity', values='Found')\n",
    "    pivot2.plot(kind='bar', stacked=True, ax=ax2)\n",
    "    ax2.set_title('Total Issues Found by Treatment')\n",
    "    ax2.set_ylabel('Number of Issues Found')\n",
    "    ax2.set_xlabel('Treatment')\n",
    "    ax2.legend(title='Severity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analyze issue detection\n",
    "detection_df = analyze_issue_detection_by_severity(behaviors_dict)\n",
    "print(\"\\nIssue Detection Analysis:\")\n",
    "print(detection_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Allocation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_allocation(behaviors: Dict[str, ReviewerBehavior]):\n",
    "    \"\"\"Analyze how time is spent across different code locations\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (treatment, behavior) in enumerate(behaviors.items()):\n",
    "        if idx >= 3:\n",
    "            ax = axes[3]\n",
    "        else:\n",
    "            ax = axes[idx]\n",
    "        \n",
    "        # Calculate time spent on anchored vs non-anchored locations\n",
    "        if behavior.anchored_locations:\n",
    "            anchored_time = sum([t for loc, t in zip(behavior.locations_reviewed, behavior.time_per_location)\n",
    "                               if loc in behavior.anchored_locations])\n",
    "            non_anchored_time = sum([t for loc, t in zip(behavior.locations_reviewed, behavior.time_per_location)\n",
    "                                   if loc not in behavior.anchored_locations])\n",
    "            \n",
    "            # Pie chart\n",
    "            sizes = [anchored_time, non_anchored_time]\n",
    "            labels = ['Anchored Locations', 'Exploration']\n",
    "            colors = ['purple', 'lightgreen']\n",
    "            explode = (0.1, 0)\n",
    "            \n",
    "            ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "                   shadow=True, startangle=90)\n",
    "            ax.set_title(f'{treatment} Time Allocation')\n",
    "        else:\n",
    "            # For MCR, show time distribution by file\n",
    "            file_times = {}\n",
    "            for loc, t in zip(behavior.locations_reviewed, behavior.time_per_location):\n",
    "                if loc.file_name not in file_times:\n",
    "                    file_times[loc.file_name] = 0\n",
    "                file_times[loc.file_name] += t\n",
    "            \n",
    "            files = list(file_times.keys())\n",
    "            times = list(file_times.values())\n",
    "            \n",
    "            ax.bar(range(len(files)), times)\n",
    "            ax.set_xticks(range(len(files)))\n",
    "            ax.set_xticklabels([f.replace('module_', 'M') for f in files], rotation=45)\n",
    "            ax.set_ylabel('Time (minutes)')\n",
    "            ax.set_title(f'{treatment} Time per File')\n",
    "    \n",
    "    # Summary statistics in the last subplot\n",
    "    ax = axes[3]\n",
    "    summary_data = []\n",
    "    for treatment, behavior in behaviors.items():\n",
    "        total_time = sum(behavior.time_per_location)\n",
    "        avg_time_per_loc = np.mean(behavior.time_per_location)\n",
    "        std_time_per_loc = np.std(behavior.time_per_location)\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Treatment': treatment,\n",
    "            'Total Time': f\"{total_time:.1f}\",\n",
    "            'Avg Time/Location': f\"{avg_time_per_loc:.2f} ± {std_time_per_loc:.2f}\",\n",
    "            'Locations Reviewed': len(behavior.locations_reviewed)\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns,\n",
    "                     cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    ax.set_title('Time Allocation Summary', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_time_allocation(behaviors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bias Mitigation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasMitigationStrategy:\n",
    "    \"\"\"Different strategies to reduce anchoring bias in code review\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "    \n",
    "    def apply(self, llm_review: Set[CodeLocation], reviewer_behavior: ReviewerBehavior) -> ReviewerBehavior:\n",
    "        \"\"\"Apply mitigation strategy\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class DelayedAssistanceStrategy(BiasMitigationStrategy):\n",
    "    \"\"\"Show LLM review only after initial manual review\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"Delayed Assistance\",\n",
    "            \"Provide LLM review after reviewer completes initial pass\"\n",
    "        )\n",
    "    \n",
    "    def apply(self, llm_review: Set[CodeLocation], simulator: BiasedReviewerSimulator) -> ReviewerBehavior:\n",
    "        # First do manual review\n",
    "        manual_phase = simulator.simulate_manual_review(time_budget=30)\n",
    "        \n",
    "        # Then check LLM suggestions\n",
    "        additional_locations = llm_review - set(manual_phase.locations_reviewed)\n",
    "        \n",
    "        # Quick verification of LLM suggestions\n",
    "        for loc in list(additional_locations)[:5]:  # Check top 5\n",
    "            manual_phase.locations_reviewed.append(loc)\n",
    "            manual_phase.time_per_location.append(0.5)\n",
    "            if loc.has_issue and np.random.random() < 0.7:\n",
    "                manual_phase.issues_found.append(loc)\n",
    "        \n",
    "        manual_phase.treatment = \"Delayed Assistance\"\n",
    "        return manual_phase\n",
    "\n",
    "class ConfidenceWeightedStrategy(BiasMitigationStrategy):\n",
    "    \"\"\"Weight LLM suggestions by confidence scores\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"Confidence Weighted\",\n",
    "            \"Prioritize high-confidence LLM suggestions\"\n",
    "        )\n",
    "    \n",
    "    def apply(self, llm_review: Set[CodeLocation], simulator: BiasedReviewerSimulator) -> ReviewerBehavior:\n",
    "        # Assign confidence scores to LLM suggestions\n",
    "        weighted_review = []\n",
    "        for loc in llm_review:\n",
    "            # Higher confidence for high-severity issues\n",
    "            if loc.has_issue:\n",
    "                confidence = {'high': 0.9, 'medium': 0.6, 'low': 0.3}[loc.issue_severity]\n",
    "            else:\n",
    "                confidence = 0.2\n",
    "            weighted_review.append((loc, confidence))\n",
    "        \n",
    "        # Sort by confidence\n",
    "        weighted_review.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Focus on high-confidence suggestions\n",
    "        high_confidence = {loc for loc, conf in weighted_review if conf > 0.5}\n",
    "        \n",
    "        return simulator.simulate_anchored_review(high_confidence, \"Confidence Weighted\")\n",
    "\n",
    "# Test mitigation strategies\n",
    "strategies = [\n",
    "    DelayedAssistanceStrategy(),\n",
    "    ConfidenceWeightedStrategy()\n",
    "]\n",
    "\n",
    "mitigation_results = {}\n",
    "for strategy in strategies:\n",
    "    result = strategy.apply(llm_review, simulator)\n",
    "    mitigation_results[strategy.name] = result\n",
    "    \n",
    "    print(f\"\\n{strategy.name}:\")\n",
    "    print(f\"  Description: {strategy.description}\")\n",
    "    print(f\"  Issues found: {len(result.issues_found)}\")\n",
    "    print(f\"  High-severity found: {len([i for i in result.issues_found if i.has_issue and i.issue_severity == 'high'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparative Analysis of Bias Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_bias_analysis():\n",
    "    \"\"\"Comprehensive analysis of bias effects across all strategies\"\"\"\n",
    "    \n",
    "    # Combine all results\n",
    "    all_behaviors = {**behaviors_dict, **mitigation_results}\n",
    "    \n",
    "    # Calculate metrics for each approach\n",
    "    metrics = []\n",
    "    \n",
    "    for name, behavior in all_behaviors.items():\n",
    "        # Coverage metrics\n",
    "        total_locations = len(simulator.all_locations)\n",
    "        coverage = len(behavior.locations_reviewed) / total_locations\n",
    "        \n",
    "        # Issue detection metrics\n",
    "        all_issues = [loc for loc in simulator.all_locations if loc.has_issue]\n",
    "        found_issues = [loc for loc in behavior.issues_found if loc.has_issue]\n",
    "        \n",
    "        detection_rate = len(found_issues) / len(all_issues) if all_issues else 0\n",
    "        \n",
    "        # Severity-specific rates\n",
    "        high_issues = [loc for loc in all_issues if loc.issue_severity == 'high']\n",
    "        high_found = [loc for loc in found_issues if loc.issue_severity == 'high']\n",
    "        high_detection = len(high_found) / len(high_issues) if high_issues else 0\n",
    "        \n",
    "        # Efficiency metrics\n",
    "        time_per_issue = sum(behavior.time_per_location) / len(found_issues) if found_issues else 0\n",
    "        \n",
    "        metrics.append({\n",
    "            'Approach': name,\n",
    "            'Coverage %': coverage * 100,\n",
    "            'Detection Rate %': detection_rate * 100,\n",
    "            'High-Severity Detection %': high_detection * 100,\n",
    "            'Time per Issue Found': time_per_issue,\n",
    "            'Total Time': sum(behavior.time_per_location)\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Create spider plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    # Select metrics for spider plot\n",
    "    spider_metrics = ['Coverage %', 'Detection Rate %', 'High-Severity Detection %']\n",
    "    \n",
    "    # Number of variables\n",
    "    num_vars = len(spider_metrics)\n",
    "    \n",
    "    # Compute angle for each axis\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    # Plot each approach\n",
    "    for idx, row in metrics_df.iterrows():\n",
    "        values = row[spider_metrics].tolist()\n",
    "        values += values[:1]\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=row['Approach'])\n",
    "        ax.fill(angles, values, alpha=0.15)\n",
    "    \n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(spider_metrics)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title('Comparison of Code Review Approaches\\n(Higher is Better)', y=1.08)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Run comprehensive analysis\n",
    "final_metrics = comprehensive_bias_analysis()\n",
    "print(\"\\nComprehensive Metrics:\")\n",
    "print(final_metrics.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways and Practical Recommendations\n",
    "\n",
    "Based on our analysis of LLM bias in code review, here are the key insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeaways = {\n",
    "    \"Anchoring Bias Effects\": [\n",
    "        \"Reviewers spend ~70% of their time on LLM-suggested locations\",\n",
    "        \"Coverage diversity decreases by ~50% when starting with LLM review\",\n",
    "        \"High-severity issues outside LLM focus are often missed\"\n",
    "    ],\n",
    "    \n",
    "    \"Mitigation Strategies\": [\n",
    "        \"Delayed assistance maintains exploration while benefiting from LLM insights\",\n",
    "        \"Confidence weighting helps prioritize valuable suggestions\",\n",
    "        \"Hybrid approaches can balance efficiency and thoroughness\"\n",
    "    ],\n",
    "    \n",
    "    \"Implementation Guidelines\": [\n",
    "        \"Present LLM suggestions as 'additional checks' after manual review\",\n",
    "        \"Use visual cues to distinguish LLM suggestions from manual findings\",\n",
    "        \"Track metrics on coverage diversity and high-severity detection rates\",\n",
    "        \"Educate reviewers about anchoring bias and its effects\"\n",
    "    ],\n",
    "    \n",
    "    \"Future Research Directions\": [\n",
    "        \"Develop bias-aware interfaces for code review tools\",\n",
    "        \"Study long-term learning effects when using AI assistance\",\n",
    "        \"Create specialized models for high-severity issue detection\",\n",
    "        \"Investigate optimal timing for AI assistance delivery\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY TAKEAWAYS: Understanding and Mitigating LLM Bias in Code Review\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for category, items in takeaways.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  • {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nThis analysis demonstrates that while LLM-assisted code review can identify\")\n",
    "print(\"additional issues, it fundamentally changes reviewer behavior. Understanding\")\n",
    "print(\"and mitigating these biases is crucial for effective AI-human collaboration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}