# 2406.11931v1.pdf
# ÄÃ£ chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: D:\llm\notebooks\AI-Papers\2406.11931v1.pdf
# KÃ­ch thÆ°á»›c file: 396316 bytes

===============================================
Ná»˜I DUNG FILE PDF (Dá»ŠCH TIáº¾NG VIá»†T)
===============================================


--- TRANG 1 ---
DeepSeek-Coder-V2: PhÃ¡ Vá»¡ RÃ o Cáº£n cá»§a CÃ¡c MÃ´ HÃ¬nh Closed-Source 
trong TrÃ­ Tuá»‡ MÃ£ Nguá»“n

Qihao Zhu*, Daya Guo*, Zhihong Shao*, Dejian Yang*, Peiyi Wang, Runxin Xu, Y. Wu
Yukun Li, Huazuo Gao, Shirong Ma, Wangding Zeng, Xiao Bi, Zihui Gu, Hanwei Xu, Damai Dai
Kai Dong, Liyue Zhang, Yishi Piao, Zhibin Gou, Zhenda Xie, Zhewen Hao, Bingxuan Wang
Junxiao Song, Deli Chen, Xin Xie, Kang Guan, Yuxiang You, Aixin Liu, Qiushi Du, Wenjun Gao
Xuan Lu, Qinyu Chen, Yaohui Wang, Chengqi Deng, Jiashi Li, Chenggang Zhao
Chong Ruan, Fuli Luo, Wenfeng Liang

DeepSeek-AI
https://github.com/deepseek-ai/DeepSeek-Coder-V2

TÃ³m táº¯t
ChÃºng tÃ´i giá»›i thiá»‡u DeepSeek-Coder-V2, má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ nguá»“n Mixture-of-Experts (MoE) 
open-source Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i GPT4-Turbo trong cÃ¡c nhiá»‡m vá»¥ Ä‘áº·c thÃ¹ vá» mÃ£ nguá»“n. 
Cá»¥ thá»ƒ, DeepSeek-Coder-V2 Ä‘Æ°á»£c tiáº¿p tá»¥c pre-train tá»« má»™t checkpoint trung gian cá»§a DeepSeek-V2 
vá»›i thÃªm 6 nghÃ¬n tá»· token. ThÃ´ng qua quÃ¡ trÃ¬nh tiáº¿p tá»¥c pre-training nÃ y, DeepSeek-Coder-V2 
nÃ¢ng cao Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng láº­p trÃ¬nh vÃ  lÃ½ luáº­n toÃ¡n há»c cá»§a DeepSeek-V2, Ä‘á»“ng thá»i duy trÃ¬ 
hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng trong cÃ¡c nhiá»‡m vá»¥ ngÃ´n ngá»¯ tá»•ng quÃ¡t. So vá»›i DeepSeek-Coder-33B, 
DeepSeek-Coder-V2 thá»ƒ hiá»‡n nhá»¯ng tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong nhiá»u khÃ­a cáº¡nh cá»§a cÃ¡c nhiá»‡m vá»¥ liÃªn quan 
Ä‘áº¿n mÃ£ nguá»“n, cÅ©ng nhÆ° kháº£ nÄƒng lÃ½ luáº­n vÃ  tá»•ng quÃ¡t. NgoÃ i ra, DeepSeek-Coder-V2 má»Ÿ rá»™ng 
há»— trá»£ ngÃ´n ngá»¯ láº­p trÃ¬nh tá»« 86 lÃªn 338, Ä‘á»“ng thá»i má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»« 16K lÃªn 128K. 
Trong cÃ¡c Ä‘Ã¡nh giÃ¡ benchmark tiÃªu chuáº©n, DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i 
cÃ¡c mÃ´ hÃ¬nh closed-source nhÆ° GPT4-Turbo, Claude 3 Opus, vÃ  Gemini 1.5 Pro trong cÃ¡c benchmark 
láº­p trÃ¬nh vÃ  toÃ¡n há»c.

[Biá»ƒu Ä‘á»“ hiá»‡u suáº¥t cá»§a DeepSeek-Coder-V2 trÃªn cÃ¡c benchmark toÃ¡n há»c vÃ  mÃ£ nguá»“n]

*CÃ¡c tÃ¡c giáº£ chÃ­nh
arXiv:2406.11931v1  [cs.SE]  17 Jun 2024

--- TRANG 2 ---
1. Giá»›i thiá»‡u

Cá»™ng Ä‘á»“ng open-source Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c nhá»¯ng bÆ°á»›c tiáº¿n Ä‘Ã¡ng ká»ƒ trong viá»‡c phÃ¡t triá»ƒn trÃ­ tuá»‡ mÃ£ nguá»“n 
thÃ´ng qua viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n open-source nhÆ° StarCoder (Li et al., 2023b; 
Lozhkov et al., 2024), CodeLlama (Roziere et al., 2023), DeepSeek-Coder (Guo et al., 2024), 
vÃ  Codestral (MistralAI, 2024). Nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Ã£ liÃªn tá»¥c tiáº¿n gáº§n Ä‘áº¿n má»©c hiá»‡u suáº¥t cá»§a 
cÃ¡c Ä‘á»‘i tÃ¡c closed-source, gÃ³p pháº§n vÃ o sá»± tiáº¿n bá»™ cá»§a trÃ­ tuá»‡ mÃ£ nguá»“n. Tuy nhiÃªn, váº«n cÃ²n 
má»™t khoáº£ng cÃ¡ch rÃµ rá»‡t khi so sÃ¡nh chÃºng vá»›i cÃ¡c mÃ´ hÃ¬nh closed-source tiÃªn tiáº¿n nhÆ° GPT4-Turbo 
(OpenAI, 2023), Claude 3 Opus (Anthropic, 2024), vÃ  Gemini 1.5 Pro (Reid et al., 2024). 
Äá»ƒ thu háº¹p khoáº£ng cÃ¡ch nÃ y vÃ  tiáº¿p tá»¥c thÃºc Ä‘áº©y sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n open-source, 
chÃºng tÃ´i giá»›i thiá»‡u dÃ²ng mÃ´ hÃ¬nh DeepSeek-Coder-V2. Nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn ná»n táº£ng 
cá»§a DeepSeek-V2 (DeepSeek-AI, 2024) vÃ  Ä‘Æ°á»£c tiáº¿p tá»¥c pre-train vá»›i má»™t kho dá»¯ liá»‡u bá»• sung 
6 nghÃ¬n tá»· token.

Trong giai Ä‘oáº¡n pre-training, bá»™ dá»¯ liá»‡u cá»§a DeepSeek-Coder-V2 Ä‘Æ°á»£c táº¡o ra vá»›i thÃ nh pháº§n 
60% mÃ£ nguá»“n, 10% kho dá»¯ liá»‡u toÃ¡n há»c, vÃ  30% kho dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn. MÃ£ nguá»“n bao gá»“m 
1.170B token liÃªn quan Ä‘áº¿n mÃ£ nguá»“n Ä‘Æ°á»£c láº¥y tá»« GitHub vÃ  CommonCrawl, sá»­ dá»¥ng cÃ¹ng pipeline 
nhÆ° DeepSeekMath (Shao et al., 2024). Kho dá»¯ liá»‡u nÃ y má»Ÿ rá»™ng tá»« 86 lÃªn 338 ngÃ´n ngá»¯ láº­p trÃ¬nh 
so vá»›i kho dá»¯ liá»‡u mÃ£ nguá»“n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train DeepSeek-Coder. Äá»ƒ chá»©ng minh hiá»‡u quáº£ cá»§a 
kho dá»¯ liá»‡u mÃ£ nguá»“n má»›i, chÃºng tÃ´i tiáº¿n hÃ nh cÃ¡c nghiÃªn cá»©u ablation vá»›i mÃ´ hÃ¬nh 1B tham sá»‘ 
vÃ  quan sÃ¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n 6.7% vÃ  9.4% vá» Ä‘á»™ chÃ­nh xÃ¡c trÃªn cáº£ hai benchmark HumanEval 
(tá»« 30.5% lÃªn 37.2%) vÃ  MBPP (tá»« 44.6% lÃªn 54.0%) (Austin et al., 2021a; Chen et al., 2021), 
tÆ°Æ¡ng á»©ng. Äá»‘i vá»›i kho dá»¯ liá»‡u toÃ¡n há»c, chÃºng tÃ´i thu tháº­p 221B token liÃªn quan Ä‘áº¿n toÃ¡n há»c 
tá»« CommonCrawl sá»­ dá»¥ng cÃ¹ng pipeline, gáº¥p Ä‘Ã´i kÃ­ch thÆ°á»›c cá»§a kho dá»¯ liá»‡u DeepSeekMath 120B 
(Shao et al., 2024), trong khi Ä‘á»‘i vá»›i kho dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn, chÃºng tÃ´i láº¥y máº«u trá»±c tiáº¿p 
tá»« kho dá»¯ liá»‡u training trong DeepSeek-V2. Tá»•ng cá»™ng, DeepSeek-Coder-V2 Ä‘Ã£ Ä‘Æ°á»£c tiáº¿p xÃºc vá»›i 
10.2T token training, trong Ä‘Ã³ 4.2 nghÃ¬n tá»· token cÃ³ nguá»“n gá»‘c tá»« bá»™ dá»¯ liá»‡u DeepSeek V2, 
trong khi 6 nghÃ¬n tá»· token cÃ²n láº¡i Ä‘áº¿n tá»« bá»™ dá»¯ liá»‡u DeepSeek-Coder-V2.

Äá»ƒ phÃ¹ há»£p vá»›i cÃ¡c Ä‘áº§u vÃ o mÃ£ nguá»“n dÃ i hÆ¡n vÃ  tÄƒng cÆ°á»ng kháº£ nÄƒng á»©ng dá»¥ng trong nhiá»u 
tÃ¬nh huá»‘ng láº­p trÃ¬nh khÃ¡c nhau, chÃºng tÃ´i má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»« 16K lÃªn 128K token, 
cho phÃ©p cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ láº­p trÃ¬nh phá»©c táº¡p vÃ  rá»™ng lá»›n hÆ¡n. 
Sau khi tiáº¿p tá»¥c pre-training DeepSeek-V2 trÃªn cÃ¡c kho dá»¯ liá»‡u Ä‘a nguá»“n nÃ y, chÃºng tÃ´i tháº¥y 
ráº±ng DeepSeek-Coder-V2 nÃ¢ng cao Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng láº­p trÃ¬nh vÃ  lÃ½ luáº­n toÃ¡n há»c cá»§a mÃ´ hÃ¬nh 
Ä‘á»“ng thá»i duy trÃ¬ hiá»‡u suáº¥t ngÃ´n ngá»¯ tá»•ng quÃ¡t tÆ°Æ¡ng Ä‘Æ°Æ¡ng.

Trong giai Ä‘oáº¡n alignment, trÆ°á»›c tiÃªn chÃºng tÃ´i xÃ¢y dá»±ng má»™t bá»™ dá»¯ liá»‡u instruction tuning 
bao gá»“m dá»¯ liá»‡u mÃ£ nguá»“n vÃ  toÃ¡n há»c tá»« DeepSeek-Coder (Guo et al., 2024) vÃ  DeepSeek-Math 
(Shao et al., 2024), cÅ©ng nhÆ° dá»¯ liá»‡u instruction tá»•ng quÃ¡t tá»« DeepSeek-V2 (DeepSeek-AI, 2024). 
Bá»™ dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ fine-tune mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Sau Ä‘Ã³, trong giai Ä‘oáº¡n reinforcement learning, 
chÃºng tÃ´i sá»­ dá»¥ng thuáº­t toÃ¡n Group Relative Policy Optimization (GRPO) Ä‘á»ƒ align hÃ nh vi cá»§a nÃ³ 
vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. Dá»¯ liá»‡u Æ°u tiÃªn Ä‘Æ°á»£c thu tháº­p trong domain láº­p trÃ¬nh sá»­ dá»¥ng 
pháº£n há»“i tá»« compiler vÃ  test cases, vÃ  má»™t mÃ´ hÃ¬nh reward Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ hÆ°á»›ng dáº«n 
viá»‡c training mÃ´ hÃ¬nh policy. CÃ¡ch tiáº¿p cáº­n nÃ y Ä‘áº£m báº£o ráº±ng cÃ¡c pháº£n há»“i cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c 
tá»‘i Æ°u hÃ³a vá» tÃ­nh chÃ­nh xÃ¡c vÃ  sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i trong cÃ¡c nhiá»‡m vá»¥ láº­p trÃ¬nh. 
Äá»ƒ cho phÃ©p mÃ´ hÃ¬nh há»— trá»£ code completion sau khi alignment, chÃºng tÃ´i cÅ©ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p 
Fill-In-Middle (Guo et al., 2024) trong quÃ¡ trÃ¬nh fine-tuning mÃ´ hÃ¬nh cÆ¡ sá»Ÿ vá»›i 16B tham sá»‘.

1.1. ÄÃ³ng gÃ³p

TÃ³m láº¡i, cÃ¡c Ä‘Ã³ng gÃ³p chÃ­nh cá»§a chÃºng tÃ´i lÃ :

â€¢ ChÃºng tÃ´i giá»›i thiá»‡u DeepSeek-Coder-V2 vá»›i 16B vÃ  236B tham sá»‘ dá»±a trÃªn framework 

--- TRANG 3 ---
DeepSeek-MoE, cÃ³ tham sá»‘ kÃ­ch hoáº¡t chá»‰ 2.4B vÃ  21B, há»— trá»£ hiá»‡u quáº£ cÃ¡c nhu cáº§u tÃ­nh toÃ¡n 
vÃ  á»©ng dá»¥ng Ä‘a dáº¡ng. NgoÃ i ra, DeepSeek-Coder-V2 há»— trá»£ 338 ngÃ´n ngá»¯ láº­p trÃ¬nh vÃ  
Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»‘i Ä‘a 128K token.

â€¢ ChÃºng tÃ´i thá»±c hiá»‡n ná»— lá»±c Ä‘áº§u tiÃªn Ä‘á»ƒ phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh mÃ£ nguá»“n open-source 
hÃ ng trÄƒm tá»· tham sá»‘ nháº±m thÃºc Ä‘áº©y lÄ©nh vá»±c trÃ­ tuá»‡ mÃ£ nguá»“n. Káº¿t quáº£ thÃ­ nghiá»‡m chá»‰ ra 
ráº±ng DeepSeek-Coder-V2 236B vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh closed-source tiÃªn tiáº¿n, nhÆ° GPT4-Turbo, 
Claude 3 Opus, vÃ  Gemini 1.5 Pro, trong cáº£ cÃ¡c nhiá»‡m vá»¥ láº­p trÃ¬nh vÃ  toÃ¡n há»c.

â€¢ CÃ¡c mÃ´ hÃ¬nh DeepSeek-Coder-V2 Ä‘Æ°á»£c phÃ¡t hÃ nh cÃ´ng khai dÆ°á»›i giáº¥y phÃ©p linh hoáº¡t, 
cho phÃ©p cáº£ nghiÃªn cá»©u vÃ  sá»­ dá»¥ng thÆ°Æ¡ng máº¡i khÃ´ng háº¡n cháº¿.

1.2. TÃ³m táº¯t ÄÃ¡nh giÃ¡ vÃ  Metrics

â€¢ MÃ£ nguá»“n: Vá» Ä‘Ã¡nh giÃ¡ benchmark sinh mÃ£ nguá»“n, DeepSeek-Coder-V2 thá»ƒ hiá»‡n sá»± vÆ°á»£t trá»™i 
Ä‘Ã¡ng ká»ƒ so vá»›i táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh open source Ä‘á»“ng thá»i thá»ƒ hiá»‡n hiá»‡u suáº¥t ngang báº±ng vá»›i 
cÃ¡c mÃ´ hÃ¬nh closed-source hÃ ng Ä‘áº§u, nhÆ° GPT4-Turbo, Claude 3 Opus, vÃ  Gemini 1.5 Pro. 
ÄÃ¡ng chÃº Ã½, chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm sá»‘ 90.2% trÃªn HumanEval (Chen et al., 2021), 
76.2% trÃªn MBPP (Austin et al., 2021a) (thiáº¿t láº­p káº¿t quáº£ state-of-the-art má»›i vá»›i 
pipeline Ä‘Ã¡nh giÃ¡ EvalPlus), vÃ  43.4% trÃªn LiveCodeBench (Jain et al., 2024) 
(cÃ¡c cÃ¢u há»i tá»« thÃ¡ng 12/2023 Ä‘áº¿n thÃ¡ng 6/2024). NgoÃ i ra, DeepSeek-Coder-V2 lÃ  
mÃ´ hÃ¬nh open-source Ä‘áº§u tiÃªn vÆ°á»£t qua Ä‘iá»ƒm sá»‘ 10% trÃªn SWEBench (Jimenez et al., 2023).

â€¢ ToÃ¡n há»c: DeepSeek-Coder-V2 thá»ƒ hiá»‡n kháº£ nÄƒng lÃ½ luáº­n toÃ¡n há»c máº¡nh máº½, sÃ¡nh ngang 
vá»›i cÃ¡c mÃ´ hÃ¬nh closed-source hÃ ng Ä‘áº§u nhÆ° GPT-4o, Gemini 1.5 Pro, vÃ  Claude 3 Opus 
trÃªn cáº£ cÃ¡c benchmark sÆ¡ cáº¥p nhÆ° GSM8K (Cobbe et al., 2021) vÃ  cÃ¡c benchmark cáº¥p Ä‘á»™ 
thi Ä‘áº¥u nÃ¢ng cao bao gá»“m MATH (Hendrycks et al., 2021), AIME (MAA, 2024), vÃ  
Math Odyssey (Netmind.AI, 2024). ÄÃ¡ng chÃº Ã½, DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 
75.7% trÃªn benchmark MATH, gáº§n nhÆ° báº±ng vá»›i Ä‘á»™ chÃ­nh xÃ¡c state-of-the-art 76.6% 
do GPT-4o Ä‘áº¡t Ä‘Æ°á»£c. HÆ¡n ná»¯a, nÃ³ vÆ°á»£t trá»™i hÆ¡n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh closed-source 
nÃ y trong cuá»™c thi AIME 2024.

â€¢ NgÃ´n ngá»¯ Tá»± nhiÃªn: DeepSeek-Coder-V2 duy trÃ¬ hiá»‡u suáº¥t ngÃ´n ngá»¯ tá»•ng quÃ¡t tÆ°Æ¡ng Ä‘Æ°Æ¡ng 
vá»›i DeepSeek-V2. VÃ­ dá»¥, DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c 79.2% trÃªn MMLU vá»›i pipeline 
simple-eval cá»§a OpenAI. Vá» Ä‘Ã¡nh giÃ¡ chá»§ quan vá»›i GPT-4 lÃ m tháº©m phÃ¡n, DeepSeek-Coder-V2 
Ä‘áº¡t Ä‘Æ°á»£c 65.0 trÃªn arena-hard (Li et al., 2024), 8.77 trÃªn MT-bench (Zheng et al., 2023) 
vÃ  7.84 trÃªn alignbench (Liu et al., 2023c). Nhá»¯ng Ä‘iá»ƒm sá»‘ nÃ y tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i 
cÃ¡c mÃ´ hÃ¬nh chuyÃªn vá» mÃ£ nguá»“n khÃ¡c, tháº­m chÃ­ cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh open source tá»•ng quÃ¡t.

2. Thu tháº­p Dá»¯ liá»‡u

Dá»¯ liá»‡u pre-training cho DeepSeek-Coder-V2 chá»§ yáº¿u bao gá»“m 60% mÃ£ nguá»“n, 10% kho dá»¯ liá»‡u toÃ¡n há»c, 
vÃ  30% kho dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn. VÃ¬ kho dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘Æ°á»£c láº¥y máº«u trá»±c tiáº¿p 
tá»« bá»™ dá»¯ liá»‡u training cá»§a DeepSeek-V2, pháº§n nÃ y táº­p trung vÃ o cÃ¡c quy trÃ¬nh thu tháº­p, lÃ m sáº¡ch, 
vÃ  lá»c dá»¯ liá»‡u mÃ£ nguá»“n vÃ  toÃ¡n há»c. Äá»“ng thá»i, chÃºng tÃ´i tiáº¿p tá»¥c xÃ¡c thá»±c cháº¥t lÆ°á»£ng cá»§a 
dá»¯ liá»‡u nÃ y thÃ´ng qua cÃ¡c thÃ­ nghiá»‡m phÃ¢n tÃ­ch so sÃ¡nh.

ChÃºng tÃ´i thu tháº­p cÃ¡c repository cÃ´ng khai Ä‘Æ°á»£c táº¡o trÆ°á»›c thÃ¡ng 11/2023 trÃªn GitHub. 
TrÆ°á»›c tiÃªn, chÃºng tÃ´i Ã¡p dá»¥ng cÃ¹ng cÃ¡c quy táº¯c lá»c vÃ  near-deduplication nhÆ° nhá»¯ng quy táº¯c 
Ä‘Æ°á»£c sá»­ dá»¥ng trong DeepSeek-Coder (Guo et al., 2024) Ä‘á»ƒ lá»c ra mÃ£ nguá»“n cháº¥t lÆ°á»£ng tháº¥p 
vÃ  trÃ¹ng láº·p. Äá»ƒ lÃ m cho bÃ i bÃ¡o Ä‘á»™c láº­p, chÃºng tÃ´i mÃ´ táº£ ngáº¯n gá»n cÃ¡c quy táº¯c lá»c. 
Äáº§u tiÃªn, chÃºng tÃ´i lá»c ra cÃ¡c file cÃ³ Ä‘á»™ dÃ i dÃ²ng trung bÃ¬nh vÆ°á»£t quÃ¡ 100 kÃ½ tá»± hoáº·c 
Ä‘á»™ dÃ i dÃ²ng tá»‘i Ä‘a vÆ°á»£t quÃ¡ 1000 kÃ½ tá»±. NgoÃ i ra, chÃºng tÃ´i loáº¡i bá» cÃ¡c file cÃ³ Ã­t hÆ¡n 
25% kÃ½ tá»± chá»¯ cÃ¡i. Ngoáº¡i trá»« ngÃ´n ngá»¯ láº­p trÃ¬nh XSLT, chÃºng tÃ´i tiáº¿p tá»¥c lá»c ra cÃ¡c file 
mÃ  chuá»—i "<?xml version=" xuáº¥t hiá»‡n trong 100

--- TRANG 4 ---
kÃ½ tá»± Ä‘áº§u tiÃªn. Äá»‘i vá»›i cÃ¡c file HTML, chÃºng tÃ´i xem xÃ©t tá»· lá»‡ cá»§a vÄƒn báº£n hiá»ƒn thá»‹ 
so vá»›i mÃ£ HTML. ChÃºng tÃ´i giá»¯ láº¡i cÃ¡c file mÃ  vÄƒn báº£n hiá»ƒn thá»‹ chiáº¿m Ã­t nháº¥t 20% cá»§a 
mÃ£ vÃ  khÃ´ng Ã­t hÆ¡n 100 kÃ½ tá»±. Äá»‘i vá»›i cÃ¡c file JSON vÃ  YAML, thÆ°á»ng chá»©a nhiá»u dá»¯ liá»‡u hÆ¡n, 
chÃºng tÃ´i chá»‰ giá»¯ cÃ¡c file cÃ³ sá»‘ lÆ°á»£ng kÃ½ tá»± tá»« 50 Ä‘áº¿n 5000 kÃ½ tá»±. Äiá»u nÃ y loáº¡i bá» 
hiá»‡u quáº£ háº§u háº¿t cÃ¡c file cÃ³ dá»¯ liá»‡u náº·ng. Báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c quy táº¯c lá»c nÃ y vÃ  
near-deduplication, chÃºng tÃ´i thu Ä‘Æ°á»£c 821B mÃ£ nguá»“n bao gá»“m 338 ngÃ´n ngá»¯ láº­p trÃ¬nh 
vÃ  185B vÄƒn báº£n liÃªn quan Ä‘áº¿n mÃ£ nguá»“n, nhÆ° markdown vÃ  issues. Danh sÃ¡ch cÃ¡c ngÃ´n ngá»¯ 
láº­p trÃ¬nh Ä‘Æ°á»£c há»— trá»£ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c A. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¹ng 
tokenizer nhÆ° DeepSeekV2, Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong (DeepSeek-AI, 2024).

Äá»ƒ thu tháº­p vÄƒn báº£n web liÃªn quan Ä‘áº¿n mÃ£ nguá»“n vÃ  toÃ¡n há»c tá»« Common Crawl, chÃºng tÃ´i 
theo cÃ¹ng pipeline nhÆ° DeepSeekMath (Shao et al., 2024). Cá»¥ thá»ƒ, chÃºng tÃ´i chá»n cÃ¡c 
diá»…n Ä‘Ã n láº­p trÃ¬nh nhÆ° StackOverflowÂ¹, cÃ¡c trang thÆ° viá»‡n nhÆ° tÃ i liá»‡u PyTorchÂ², 
vÃ  cÃ¡c trang web toÃ¡n há»c nhÆ° StackExchangeÂ³ lÃ m kho dá»¯ liá»‡u seed ban Ä‘áº§u. Sá»­ dá»¥ng 
kho dá»¯ liá»‡u seed nÃ y, chÃºng tÃ´i train má»™t mÃ´ hÃ¬nh fastText (Joulin et al., 2016) 
Ä‘á»ƒ thu há»“i thÃªm cÃ¡c trang web liÃªn quan Ä‘áº¿n láº­p trÃ¬nh vÃ  toÃ¡n há»c. VÃ¬ tokenization 
cho cÃ¡c ngÃ´n ngá»¯ nhÆ° tiáº¿ng Trung khÃ´ng thá»ƒ thá»±c hiá»‡n thÃ´ng qua khoáº£ng tráº¯ng, 
chÃºng tÃ´i sá»­ dá»¥ng tokenizer Byte Pair Encoding (BPE) tá»« DeepSeek-V2, Ä‘iá»u nÃ y 
cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ chÃ­nh xÃ¡c thu há»“i cá»§a fastText. Äá»‘i vá»›i má»—i domain, chÃºng tÃ´i 
tÃ­nh toÃ¡n tá»· lá»‡ pháº§n trÄƒm cá»§a cÃ¡c trang web Ä‘Æ°á»£c thu tháº­p trong láº§n láº·p Ä‘áº§u tiÃªn. 
CÃ¡c domain cÃ³ hÆ¡n 10% trang web Ä‘Æ°á»£c thu tháº­p Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ  liÃªn quan Ä‘áº¿n 
mÃ£ nguá»“n hoáº·c toÃ¡n há»c. Sau Ä‘Ã³, chÃºng tÃ´i chÃº thÃ­ch cÃ¡c URL liÃªn káº¿t vá»›i ná»™i dung 
liÃªn quan Ä‘áº¿n mÃ£ nguá»“n hoáº·c toÃ¡n há»c trong cÃ¡c domain Ä‘Ã£ xÃ¡c Ä‘á»‹nh nÃ y. CÃ¡c trang web 
chÆ°a Ä‘Æ°á»£c thu tháº­p liÃªn káº¿t vá»›i cÃ¡c URL nÃ y Ä‘Æ°á»£c thÃªm vÃ o kho dá»¯ liá»‡u seed. 
Sau ba láº§n láº·p thu tháº­p dá»¯ liá»‡u, chÃºng tÃ´i thu tháº­p Ä‘Æ°á»£c 70 tá»· token liÃªn quan Ä‘áº¿n 
mÃ£ nguá»“n vÃ  221B token liÃªn quan Ä‘áº¿n toÃ¡n há»c tá»« cÃ¡c trang web. Äá»ƒ tiáº¿p tá»¥c thu tháº­p 
mÃ£ nguá»“n cháº¥t lÆ°á»£ng cao tá»« GitHub, chÃºng tÃ´i cÅ©ng Ã¡p dá»¥ng cÃ¹ng pipeline trÃªn GitHub 
vá»›i hai láº§n láº·p thu tháº­p dá»¯ liá»‡u vÃ  thu tháº­p Ä‘Æ°á»£c 94B mÃ£ nguá»“n. Kho dá»¯ liá»‡u seed 
ban Ä‘áº§u Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch thu tháº­p thá»§ cÃ´ng mÃ£ nguá»“n cháº¥t lÆ°á»£ng cao, nhÆ° nhá»¯ng 
mÃ£ cÃ³ chá»©a mÃ´ táº£ chi tiáº¿t. Cuá»‘i cÃ¹ng, kho dá»¯ liá»‡u mÃ£ nguá»“n má»›i bao gá»“m 1.170B token 
liÃªn quan Ä‘áº¿n mÃ£ nguá»“n Ä‘Æ°á»£c láº¥y tá»« GitHub vÃ  CommonCrawl.

Äá»ƒ chá»©ng minh hiá»‡u quáº£ cá»§a kho dá»¯ liá»‡u mÃ£ nguá»“n má»›i, chÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh cÃ¡c nghiÃªn cá»©u 
ablation (xem Báº£ng 1) sá»­ dá»¥ng mÃ´ hÃ¬nh 1B tham sá»‘, so sÃ¡nh vá»›i kho dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng 
Ä‘á»ƒ train DeepSeek-Coder. Pre-training mÃ´ hÃ¬nh 1B trÃªn kho dá»¯ liá»‡u mÃ£ nguá»“n má»›i sá»­ dá»¥ng 
1T token dáº«n Ä‘áº¿n cáº£i thiá»‡n 5.5% vÃ  4.4% vá» Ä‘á»™ chÃ­nh xÃ¡c trÃªn cÃ¡c benchmark HumanEval 
(tá»« 30.5% lÃªn 36.0%) vÃ  MBPP (tá»« 44.6% lÃªn 49.0%), tÆ°Æ¡ng á»©ng. Training thÃªm mÃ´ hÃ¬nh 1B 
vá»›i 2T token dáº«n Ä‘áº¿n cáº£i thiá»‡n bá»• sung, vá»›i Ä‘iá»ƒm sá»‘ HumanEval vÃ  MBPP tÄƒng lÃªn 37.2% 
vÃ  54.0%, tÆ°Æ¡ng á»©ng. Do Ä‘Ã³, kho dá»¯ liá»‡u mÃ£ nguá»“n má»›i vÆ°á»£t trá»™i hÆ¡n kho dá»¯ liá»‡u mÃ£ nguá»“n 
Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ train DeepSeek-Coder.

[Báº£ng 1: Hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh base 1B giá»¯a DeepSeek-Coder vÃ  DeepSeek-Coder-V2]

3. ChÃ­nh sÃ¡ch Training

3.1. Chiáº¿n lÆ°á»£c Training

ChÃºng tÃ´i sá»­ dá»¥ng hai má»¥c tiÃªu training cho DeepSeek-Coder-v2 16B: Next-Token-Prediction 
vÃ  Fill-In-Middle (FIM) (Bavarian et al., 2022; Guo et al., 2024; Li et al., 2023b). 
Äá»‘i vá»›i DeepSeek-Coder-v2

Â¹https://stackoverflow.com
Â²https://pytorch.org/docs
Â³https://math.stackexchange.com

--- TRANG 5 ---
236B, chÃºng tÃ´i chá»‰ sá»­ dá»¥ng má»¥c tiÃªu Next-Token-Prediction. á» Ä‘Ã¢y chÃºng tÃ´i Ä‘Æ°a ra 
má»™t giá»›i thiá»‡u ngáº¯n gá»n vá» chÃ­nh sÃ¡ch training FIM. ChÃºng tÃ´i Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p 
training FIM Ä‘á»ƒ phÃ¡t triá»ƒn DeepSeek-Coder-v2-16B, táº­n dá»¥ng cháº¿ Ä‘á»™ PSM (Prefix, Suffix, Middle). 
PhÆ°Æ¡ng phÃ¡p nÃ y cáº¥u trÃºc viá»‡c tÃ¡i táº¡o ná»™i dung theo chuá»—i: Prefix, Suffix, vÃ  Middle, 
nhÆ° Ä‘Æ°á»£c minh há»a dÆ°á»›i Ä‘Ã¢y:

<ï½œfim_beginï½œ>ğ‘“ğ‘ğ‘Ÿğ‘’<ï½œfim_holeï½œ>ğ‘“ğ‘ ğ‘¢ ğ‘“<ï½œfim_endï½œ>ğ‘“ğ‘šğ‘–ğ‘‘ğ‘‘ğ‘™ğ‘’<|eos_token|>

Cáº¥u trÃºc nÃ y Ä‘Æ°á»£c Ã¡p dá»¥ng á»Ÿ cáº¥p Ä‘á»™ tÃ i liá»‡u nhÆ° má»™t pháº§n cá»§a quy trÃ¬nh pre-packing. 
FIM Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i tá»· lá»‡ 0.5, phÃ¹ há»£p vá»›i framework PSM, Ä‘á»ƒ tÄƒng cÆ°á»ng hiá»‡u quáº£ 
training vÃ  hiá»‡u suáº¥t mÃ´ hÃ¬nh.

3.2. Kiáº¿n trÃºc MÃ´ hÃ¬nh

Kiáº¿n trÃºc cá»§a chÃºng tÃ´i phÃ¹ há»£p vá»›i kiáº¿n trÃºc cá»§a DeepSeekV2 (DeepSeek-AI, 2024). 
CÃ¡c cÃ i Ä‘áº·t hyperparameter, 16B vÃ  236B, tÆ°Æ¡ng á»©ng vá»›i nhá»¯ng cÃ i Ä‘áº·t Ä‘Æ°á»£c sá»­ dá»¥ng 
trong DeepSeek-V2-Lite vÃ  DeepSeek-V2, tÆ°Æ¡ng á»©ng. ÄÃ¡ng chÃº Ã½, chÃºng tÃ´i gáº·p pháº£i 
sá»± báº¥t á»•n trong quÃ¡ trÃ¬nh training vÃ  cÃ¡c Ä‘á»™t biáº¿n trong giÃ¡ trá»‹ gradient, Ä‘iá»u mÃ  
chÃºng tÃ´i cho lÃ  do ká»¹ thuáº­t chuáº©n hÃ³a mÅ©. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng tÃ´i 
quay láº¡i phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a thÃ´ng thÆ°á»ng.

3.3. SiÃªu tham sá»‘ Training

PhÃ¹ há»£p vá»›i phÆ°Æ¡ng phÃ¡p DeepSeek V2 (DeepSeek-AI, 2024), chÃºng tÃ´i sá»­ dá»¥ng optimizer 
AdamW (Loshchilov vÃ  Hutter, 2019), Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i ğ›½1=0.9, ğ›½2=0.95, vÃ  weight decay 
lÃ  0.1. KÃ­ch thÆ°á»›c batch vÃ  learning rate Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo Ä‘áº·c táº£ DeepSeek-V2. 
Äá»ƒ láº­p lá»‹ch learning rate, chÃºng tÃ´i sá»­ dá»¥ng chiáº¿n lÆ°á»£c cosine decay, báº¯t Ä‘áº§u vá»›i 
2000 bÆ°á»›c warm-up vÃ  giáº£m dáº§n learning rate xuá»‘ng 10% giÃ¡ trá»‹ ban Ä‘áº§u.

Cáº£ DeepSeek-Coder-V2 vÃ  DeepSeek-Coder-V2-Lite Ä‘á»u Ä‘Æ°á»£c train báº±ng cÃ¹ng má»™t phÆ°Æ¡ng phÃ¡p. 
Äá»ƒ duy trÃ¬ kháº£ nÄƒng hiá»ƒu ngÃ´n ngá»¯ tá»± nhiÃªn máº¡nh máº½ trong DeepSeek-Coder-V2, chÃºng tÃ´i 
tiáº¿p tá»¥c quÃ¡ trÃ¬nh pre-training tá»« má»™t checkpoint trung gian cá»§a DeepSeek-V2. Checkpoint 
trung gian ban Ä‘áº§u Ä‘Æ°á»£c train trÃªn 4.2T token. Do Ä‘Ã³, DeepSeek-Coder-V2 Ä‘Ã£ Ä‘Æ°á»£c tiáº¿p xÃºc 
vá»›i tá»•ng cá»™ng 10.2T token cháº¥t lÆ°á»£ng cao trong giai Ä‘oáº¡n pre-training.

[Báº£ng 2: CÃ i Ä‘áº·t Training cá»§a DeepSeek-Coder-V2]

3.4. Má»Ÿ rá»™ng Ngá»¯ cáº£nh DÃ i

Theo DeepSeek-V2, chÃºng tÃ´i má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh cá»§a DeepSeek-Coder-V2 lÃªn 128K 
báº±ng cÃ¡ch sá»­ dá»¥ng Yarn (Peng et al., 2023). CÃ¡c hyperparameter cá»§a YARN giá»‘ng nhÆ° 
DeepSeek-V2: scale ğ‘  thÃ nh 40, ğ›¼ thÃ nh 1, ğ›½ thÃ nh 32. ChÃºng tÃ´i tiáº¿p tá»¥c training 
mÃ´ hÃ¬nh báº±ng hai giai Ä‘oáº¡n Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng xá»­ lÃ½ ngá»¯ cáº£nh dÃ i. Trong giai Ä‘oáº¡n 
Ä‘áº§u tiÃªn, chÃºng tÃ´i sá»­ dá»¥ng Ä‘á»™ dÃ i sequence 32K vÃ  kÃ­ch thÆ°á»›c batch 1152 trong 1000 bÆ°á»›c. 
Trong giai Ä‘oáº¡n thá»© hai, chÃºng tÃ´i train mÃ´ hÃ¬nh thÃªm 1000 bÆ°á»›c, sá»­ dá»¥ng Ä‘á»™ dÃ i sequence 
128K vÃ  kÃ­ch thÆ°á»›c batch 288 sequence.

--- TRANG 6 ---
[HÃ¬nh 2: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c thá»­ nghiá»‡m "Needle In A Haystack" (NIAH). 
DeepSeek-Coder-V2 hoáº¡t Ä‘á»™ng tá»‘t trÃªn táº¥t cáº£ Ä‘á»™ dÃ i cá»­a sá»• ngá»¯ cáº£nh lÃªn Ä‘áº¿n 128K.]

Cáº§n lÆ°u Ã½ á»Ÿ Ä‘Ã¢y chÃºng tÃ´i tÄƒng tá»· lá»‡ dá»¯ liá»‡u ngá»¯ cáº£nh dÃ i trong quÃ¡ trÃ¬nh má»Ÿ rá»™ng 
ngá»¯ cáº£nh dÃ i. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2, káº¿t quáº£ trÃªn cÃ¡c thá»­ nghiá»‡m "Needle In A Haystack" 
(NIAH) chá»‰ ra ráº±ng DeepSeek-Coder-V2 hoáº¡t Ä‘á»™ng tá»‘t trÃªn táº¥t cáº£ Ä‘á»™ dÃ i cá»­a sá»• ngá»¯ cáº£nh 
lÃªn Ä‘áº¿n 128K.

3.5. Alignment

3.5.1. Supervised Fine-Tuning

Äá»ƒ xÃ¢y dá»±ng DeepSeek-Coder-V2 Chat, chÃºng tÃ´i xÃ¢y dá»±ng bá»™ dá»¯ liá»‡u instruction training 
káº¿t há»£p vá»›i dá»¯ liá»‡u mÃ£ nguá»“n vÃ  toÃ¡n há»c. TrÆ°á»›c tiÃªn chÃºng tÃ´i thu tháº­p 20k dá»¯ liá»‡u 
instruction liÃªn quan Ä‘áº¿n mÃ£ nguá»“n vÃ  30k dá»¯ liá»‡u liÃªn quan Ä‘áº¿n toÃ¡n há»c tá»« DeepSeek-Coder 
vÃ  DeepSeek-Math. Äá»ƒ duy trÃ¬ kháº£ nÄƒng tá»•ng quÃ¡t, chÃºng tÃ´i cÅ©ng láº¥y máº«u má»™t sá»‘ dá»¯ liá»‡u 
tá»« dá»¯ liá»‡u instruction cá»§a DeepSeek-V2. Cuá»‘i cÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng bá»™ dá»¯ liá»‡u instruction 
300M token. Äá»ƒ training, chÃºng tÃ´i sá»­ dá»¥ng lá»‹ch trÃ¬nh cosine vá»›i 100 bÆ°á»›c warm-up vÃ  
learning rate ban Ä‘áº§u 5ğ‘’âˆ’6. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng kÃ­ch thÆ°á»›c batch 1M token vÃ  
tá»•ng cá»™ng 1B token.

3.5.2. Reinforcement Learning

ChÃºng tÃ´i tiáº¿p tá»¥c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Reinforcement Learning (RL) Ä‘á»ƒ mÃ´ phá»ng Ä‘áº§y Ä‘á»§ 
kháº£ nÄƒng cá»§a DeepSeek-Coder-V2, Ä‘iá»u nÃ y Ä‘Æ°á»£c chá»©ng minh lÃ  khÃ¡ hiá»‡u quáº£.

Prompts: ÄÃ£ bá» ra ná»— lá»±c Ä‘Ã¡ng ká»ƒ Ä‘á»ƒ thu tháº­p cÃ¡c prompt liÃªn quan Ä‘áº¿n mÃ£ nguá»“n vÃ  toÃ¡n há»c 
tá»« nhiá»u nguá»“n khÃ¡c nhau, vÃ  má»—i prompt mÃ£ nguá»“n Ä‘i kÃ¨m vá»›i cÃ¡c test case tÆ°Æ¡ng á»©ng. 
Sau khi lá»c cÃ¡c prompt, cÃ³ khoáº£ng 40k dá»¯ liá»‡u tá»•ng cá»™ng.

Reward Modeling: CÃ¡c mÃ´ hÃ¬nh reward Ä‘Ã³ng vai trÃ² quan trá»ng trong training RL. Vá» dá»¯ liá»‡u 
Æ°u tiÃªn toÃ¡n há»c, chÃºng tÃ´i thu Ä‘Æ°á»£c chÃºng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c nhÃ£n ground-truth. 
Vá» dá»¯ liá»‡u Æ°u tiÃªn mÃ£ nguá»“n, máº·c dÃ¹ compiler mÃ£ nguá»“n tá»± nÃ³ Ä‘Ã£ cÃ³ thá»ƒ cung cáº¥p pháº£n há»“i 
0-1 (liá»‡u mÃ£ cÃ³ vÆ°á»£t qua táº¥t cáº£ test case hay khÃ´ng), má»™t sá»‘ prompt mÃ£ nguá»“n cÃ³ thá»ƒ 
cÃ³ sá»‘ lÆ°á»£ng test case háº¡n cháº¿, vÃ  khÃ´ng cung cáº¥p phá»§ sÃ³ng Ä‘áº§y Ä‘á»§, vÃ  do Ä‘Ã³ viá»‡c sá»­ dá»¥ng 
trá»±c tiáº¿p pháº£n há»“i 0-1 tá»« compiler cÃ³ thá»ƒ cÃ³ nhiá»…u vÃ  khÃ´ng tá»‘i Æ°u. Do Ä‘Ã³, chÃºng tÃ´i 
váº«n quyáº¿t Ä‘á»‹nh train má»™t mÃ´ hÃ¬nh reward trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p bá»Ÿi compiler, 
vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh reward Ä‘á»ƒ cung cáº¥p tÃ­n hiá»‡u trong quÃ¡ trÃ¬nh training RL, Ä‘iá»u nÃ y 
máº¡nh máº½ hÆ¡n

--- TRANG 7 ---
vÃ  cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n, so vá»›i tÃ­n hiá»‡u compiler thÃ´. NhÆ° Ä‘Æ°á»£c minh há»a 
trong HÃ¬nh 3, trong cÃ¡c bá»™ test ná»™i bá»™ cá»§a chÃºng tÃ´i (Leetcode vÃ  Leetcode-zh), 
viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh reward Ä‘á»ƒ cung cáº¥p tÃ­n hiá»‡u training RL rÃµ rÃ ng vÆ°á»£t trá»™i hÆ¡n 
viá»‡c sá»­ dá»¥ng tÃ­n hiá»‡u compiler thÃ´. Do Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng tÃ­n hiá»‡u mÃ´ hÃ¬nh reward 
thay vÃ¬ tÃ­n hiá»‡u compiler trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m tiáº¿p theo.

Thuáº­t toÃ¡n Reinforcement Learning: ChÃºng tÃ´i sá»­ dá»¥ng Group Relative Policy Optimization (GRPO) 
Shao et al. (2024) lÃ m thuáº­t toÃ¡n RL cá»§a chÃºng tÃ´i, giá»‘ng nhÆ° nhá»¯ng gÃ¬ DeepSeek-V2 sá»­ dá»¥ng. 
ÄÃ¡ng chÃº Ã½, GRPO Ä‘Æ°á»£c chá»©ng minh lÃ  khÃ¡ hiá»‡u quáº£ vÃ  cÃ³ chi phÃ­ tháº¥p hÆ¡n so vá»›i PPO, 
vÃ¬ khÃ´ng cáº§n duy trÃ¬ má»™t mÃ´ hÃ¬nh critic bá»• sung.

[HÃ¬nh 3: Hiá»‡u suáº¥t cá»§a CÃ¡c PhÆ°Æ¡ng phÃ¡p KhÃ¡c nhau]

4. Káº¿t quáº£ ThÃ­ nghiá»‡m

Trong pháº§n nÃ y, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ DeepSeek-Coder-V2 trÃªn ba loáº¡i nhiá»‡m vá»¥, bao gá»“m 
láº­p trÃ¬nh, toÃ¡n há»c, vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn tá»•ng quÃ¡t. ChÃºng tÃ´i so sÃ¡nh DeepSeek-Coder-V2 
vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n state-of-the-art trÆ°á»›c Ä‘Ã³.

â€¢ CodeLlama (Roziere et al., 2023) bao gá»“m má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ nguá»“n 
dá»±a trÃªn Llama2 (Touvron et al., 2023), vÃ  tiáº¿p tá»¥c pre-training trÃªn cÃ¡c bá»™ dá»¯ liá»‡u 
tá»« 500 Ä‘áº¿n 1000 tá»· token mÃ£ nguá»“n. Nhá»¯ng mÃ´ hÃ¬nh nÃ y cÃ³ sáºµn trong bá»‘n kÃ­ch thÆ°á»›c: 
7B, 13B, 34B, vÃ  70B.

â€¢ StarCoder (Lozhkov et al., 2024) lÃ  má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ truy cáº­p cÃ´ng khai vá»›i 
15 tá»· tham sá»‘. NÃ³ Ä‘Æ°á»£c train Ä‘áº·c biá»‡t trÃªn má»™t táº­p con Ä‘Æ°á»£c tuyá»ƒn chá»n cáº©n tháº­n 
cá»§a bá»™ dá»¯ liá»‡u Stack (Kocetkov et al., 2022), bao phá»§ 86 ngÃ´n ngá»¯ láº­p trÃ¬nh.

â€¢ StarCoder2 (Lozhkov et al., 2024) bao gá»“m cÃ¡c mÃ´ hÃ¬nh 3B, 7B, vÃ  15B tham sá»‘ 
Ä‘Æ°á»£c train trÃªn 3.3 Ä‘áº¿n 4.3 nghÃ¬n tá»· token cá»§a bá»™ dá»¯ liá»‡u Stack2 (Lozhkov et al., 2024), 
tráº£i rá»™ng 619 ngÃ´n ngá»¯ láº­p trÃ¬nh.

â€¢ DeepSeek-Coder (Guo et al., 2024) bao gá»“m má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ nguá»“n, 
tá»« 1 tá»· Ä‘áº¿n 33 tá»· tham sá»‘. Má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c train tá»« Ä‘áº§u trÃªn 2 nghÃ¬n tá»· token, 
vá»›i thÃ nh pháº§n 87% mÃ£ nguá»“n vÃ  13% ngÃ´n ngá»¯ tá»± nhiÃªn báº±ng cáº£ tiáº¿ng Anh vÃ  tiáº¿ng Trung. 
Nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c pre-train trÃªn kho dá»¯ liá»‡u mÃ£ nguá»“n cáº¥p dá»± Ã¡n sá»­ dá»¥ng kÃ­ch thÆ°á»›c 
cá»­a sá»• 16K vÃ  má»™t nhiá»‡m vá»¥ fill-in-the-blank bá»• sung, cho phÃ©p há»— trá»£ code completion 
vÃ  infilling cáº¥p dá»± Ã¡n.

â€¢ Codestral (MistralAI, 2024) lÃ  má»™t mÃ´ hÃ¬nh 22B tham sá»‘ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Mistral. 
NÃ³ Ä‘Æ°á»£c train trÃªn má»™t bá»™ dá»¯ liá»‡u Ä‘a dáº¡ng cá»§a hÆ¡n 80 ngÃ´n ngá»¯ láº­p trÃ¬nh, bao gá»“m 
nhá»¯ng ngÃ´n ngá»¯ phá»• biáº¿n nhÆ° Python, Java, vÃ  JavaScript, cÅ©ng nhÆ° cÃ¡c ngÃ´n ngá»¯ 
chuyÃªn biá»‡t hÆ¡n nhÆ° Swift vÃ  Fortran.

--- TRANG 8 ---
â€¢ CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»•ng quÃ¡t mÃ  chÃºng tÃ´i so sÃ¡nh bao gá»“m Llama3 70B (Meta, 2024), 
GPT-4 (OpenAI, 2023), Claude 3 Opus (Anthropic, 2024), vÃ  Gemini 1.5 Pro (Reid et al., 2024). 
Máº·c dÃ¹ chÃºng khÃ´ng Ä‘Æ°á»£c train Ä‘áº·c biá»‡t trÃªn cÃ¡c kho dá»¯ liá»‡u mÃ£ nguá»“n lá»›n, chÃºng Ä‘áº¡t Ä‘Æ°á»£c 
hiá»‡u suáº¥t state-of-the-art trong láº­p trÃ¬nh.

4.1. Sinh MÃ£ nguá»“n

Benchmarks HumanEval vÃ  MBPP: CÃ¡c benchmark HumanEval (Chen et al., 2021)â´ vÃ  MBPP 
(Austin et al., 2021b) thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ 
Lá»›n (LLM) sinh mÃ£ nguá»“n. HumanEval bao gá»“m 164 nhiá»‡m vá»¥ Python Ä‘Æ°á»£c xÃ¡c minh thÃ´ng qua 
cÃ¡c test case Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a Code LLM trong tÃ¬nh huá»‘ng zero-shot. Äá»‘i vá»›i MBPP, 
chÃºng tÃ´i sá»­ dá»¥ng phiÃªn báº£n MBPP-Plus (Liu et al., 2023a) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh. 
Äá»ƒ kiá»ƒm tra kháº£ nÄƒng Ä‘a ngÃ´n ngá»¯ cá»§a cÃ¡c mÃ´ hÃ¬nh, chÃºng tÃ´i má»Ÿ rá»™ng cÃ¡c bÃ i toÃ¡n benchmark 
HumanEval sang báº£y ngÃ´n ngá»¯ bá»• sung: C++, Java, PHP, TypeScript, C#, Bash, JavaScript, 
Swift, R, Julia, D, Rust vÃ  Racket. Äá»‘i vá»›i cáº£ hai benchmark, chÃºng tÃ´i sá»­ dá»¥ng chiáº¿n lÆ°á»£c 
greedy search vÃ  tÃ¡i táº¡o cÃ¡c káº¿t quáº£ baseline báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c script vÃ  mÃ´i trÆ°á»ng 
giá»‘ng há»‡t nhau Ä‘á»ƒ Ä‘áº£m báº£o so sÃ¡nh cÃ´ng báº±ng.

[Báº£ng 3: Metrics Hiá»‡u suáº¥t cho CÃ¡c MÃ´ hÃ¬nh KhÃ¡c nhau trÃªn Benchmarks HumanEval vÃ  MBPP]

Báº£ng 3 cung cáº¥p má»™t tá»•ng quan toÃ n diá»‡n vá» cÃ¡c metrics hiá»‡u suáº¥t cho cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau 
trÃªn nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh trÃªn Benchmarks HumanEval vÃ  MBPP+. DeepSeek-Coder-V2-Instruct 
thá»ƒ hiá»‡n hiá»‡u suáº¥t Ä‘áº·c biá»‡t, Ä‘áº£m báº£o Ä‘iá»ƒm sá»‘ trung bÃ¬nh cao thá»© hai lÃ  75.3%. Hiá»‡u suáº¥t nÃ y 
Ä‘Ã¡ng chÃº Ã½ vÃ¬ nÃ³ phÃ¡ vá»¡ sá»± thá»‘ng trá»‹ thÆ°á»ng tháº¥y tá»« cÃ¡c mÃ´ hÃ¬nh closed-source, ná»•i báº­t 
nhÆ° má»™t á»©ng cá»­ viÃªn open-source hÃ ng Ä‘áº§u. NÃ³ chá»‰ bá»‹ vÆ°á»£t qua bá»Ÿi GPT-4o, dáº«n Ä‘áº§u vá»›i 
Ä‘iá»ƒm sá»‘ trung bÃ¬nh 76.4%. DeepSeek-Coder-V2-Instruct cho tháº¥y káº¿t quáº£ hÃ ng Ä‘áº§u trÃªn 
nhiá»u ngÃ´n ngá»¯, bao gá»“m Ä‘iá»ƒm sá»‘ cao nháº¥t trong Java vÃ  PHP, vÃ  hiá»‡u suáº¥t máº¡nh máº½ trong 
Python, C++, C#, TypeScript, vÃ  JavaScript, nháº¥n máº¡nh tÃ­nh máº¡nh máº½ vÃ  linh hoáº¡t 
trong viá»‡c xá»­ lÃ½ cÃ¡c thÃ¡ch thá»©c láº­p trÃ¬nh Ä‘a dáº¡ng.

HÆ¡n ná»¯a, DeepSeek-Coder-V2-Lite-Instruct cÅ©ng hoáº¡t Ä‘á»™ng áº¥n tÆ°á»£ng, vÆ°á»£t qua mÃ´ hÃ¬nh 33B 
lá»›n hÆ¡n. Vá»›i má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ trong hiá»‡u suáº¥t trung bÃ¬nh (65.6% so vá»›i 61.9%), 
nÃ³ lÃ m ná»•i báº­t hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh 16B trong viá»‡c cung cáº¥p káº¿t quáº£ cáº¡nh tranh máº·c dÃ¹ 
cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n. Äiá»u nÃ y nháº¥n máº¡nh hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh vÃ  nhá»¯ng tiáº¿n bá»™ trong 
kiáº¿n trÃºc mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p training cho phÃ©p nÃ³ vÆ°á»£t trá»™i hÆ¡n cÃ¡c Ä‘á»‘i tÃ¡c lá»›n hÆ¡n.

Láº­p trÃ¬nh Thi Ä‘áº¥u: Äá»ƒ tiáº¿p tá»¥c xÃ¡c thá»±c kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong cÃ¡c bÃ i toÃ¡n láº­p trÃ¬nh 
thi Ä‘áº¥u thá»±c táº¿, chÃºng tÃ´i sá»­ dá»¥ng LiveCodeBench (Jain et al., 2024) vÃ  benchmark USACO 
(Shi et al., 2024) Ä‘á»ƒ Æ°á»›c tÃ­nh hiá»‡u quáº£ cá»§a DeepSeek-Coder-V2. LiveCodeBench lÃ  má»™t 
Ä‘Ã¡nh giÃ¡ tá»‰ má»‰ vÃ  khÃ´ng bá»‹ nhiá»…m chÃ©o cá»§a cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) Ä‘á»ƒ sinh mÃ£ nguá»“n, 
thu tháº­p cÃ³ há»‡ thá»‘ng cÃ¡c thÃ¡ch thá»©c má»›i theo thá»i gian tá»« ba ná»n táº£ng láº­p trÃ¬nh thi Ä‘áº¥u 
ná»•i tiáº¿ng: LeetCode, AtCoder, vÃ  CodeForces. VÃ¬ ngÃ y cáº¯t cá»§a dá»¯ liá»‡u training lÃ  trÆ°á»›c 
thÃ¡ng 11/2023, chÃºng tÃ´i sá»­ dá»¥ng táº­p con (1201-0601) cá»§a Livecodebench. Benchmark USACO 
chá»©a 307 bÃ i toÃ¡n tá»« USA Computing Olympiad, cÃ¹ng vá»›i cÃ¡c unit test cháº¥t lÆ°á»£ng cao, 
mÃ£ tham chiáº¿u, vÃ  phÃ¢n tÃ­ch chÃ­nh thá»©c cho má»—i bÃ i toÃ¡n.

[Báº£ng 4: Hiá»‡u suáº¥t trÃªn cÃ¡c benchmark LiveCodeBench (LCB) vÃ  USACO]

â´ChÃºng tÃ´i sá»­ dá»¥ng template "Please complete the python function below. The final complete version of your function 
must be returned within a code block. Here is the unfinished function:\n ```python\n{problem_description}\n\n" 
Ä‘á»ƒ xÃ¢y dá»±ng instruction prompt.

--- TRANG 9 ---
Báº£ng 4 trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ khÃ¡c nhau trÃªn hai benchmark. 
ÄÃ¡ng chÃº Ã½, DeepSeek-Coder-V2-Instruct mang láº¡i hiá»‡u suáº¥t ná»•i báº­t, hÃ²a vá»›i Ä‘iá»ƒm sá»‘ 
cao nháº¥t trong cÃ¡c mÃ´ hÃ¬nh lá»›n á»Ÿ má»©c 43.4%, ngang báº±ng vá»›i GPT-4o. Káº¿t quáº£ Ä‘áº·c biá»‡t 
nÃ y Ä‘áº·t nÃ³ á»Ÿ vá»‹ trÃ­ thá»© hai tá»•ng thá»ƒ, chá»‰ sau GPT-4-Turbo-0409, dáº«n Ä‘áº§u vá»›i hiá»‡u suáº¥t 
tá»•ng thá»ƒ 45.7%. Kháº£ nÄƒng áº¥n tÆ°á»£ng cá»§a DeepSeek-Coder-V2-Instruct trong viá»‡c xá»­ lÃ½ 
cÃ¡c thÃ¡ch thá»©c láº­p trÃ¬nh phá»©c táº¡p thiáº¿t láº­p cháº¯c cháº¯n nÃ³ nhÆ° má»™t á»©ng cá»­ viÃªn hÃ ng Ä‘áº§u, 
theo sÃ¡t biáº¿n thá»ƒ GPT-4-Turbo dáº«n Ä‘áº§u.

4.2. Code Completion

4.2.1. ÄÃ¡nh giÃ¡ Code Completion Cáº¥p Repository

ChÃºng tÃ´i sá»­ dá»¥ng RepoBench (Liu et al., 2023b) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh 
mÃ£ nguá»“n open-source hiá»‡n cÃ³ vá»›i kÃ­ch thÆ°á»›c dÆ°á»›i 35B trong cÃ¡c nhiá»‡m vá»¥ code completion 
cáº¥p repository. Bá»™ dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« má»™t táº­p há»£p Ä‘a dáº¡ng cÃ¡c repository 
thá»±c táº¿, open-source, cÃ³ giáº¥y phÃ©p cho phÃ©p trong hai ngÃ´n ngá»¯ láº­p trÃ¬nh phá»• biáº¿n: 
Python vÃ  Java. ÄÃ¡ng chÃº Ã½, phiÃªn báº£n má»›i nháº¥t (v1.1) cá»§a RepoBench láº¥y dá»¯ liá»‡u 
tá»« cÃ¡c repository GitHub Ä‘Æ°á»£c táº¡o giá»¯a ngÃ y 6 thÃ¡ng 10 vÃ  ngÃ y 31 thÃ¡ng 12 nÄƒm 2023, 
trong khi dá»¯ liá»‡u pre-training cá»§a chÃºng tÃ´i bao gá»“m mÃ£ Ä‘Æ°á»£c táº¡o trÆ°á»›c thÃ¡ng 11 nÄƒm 2023. 
Äá»ƒ Ä‘áº£m báº£o bá»™ dá»¯ liá»‡u nÃ y khÃ´ng cÃ³ trong dá»¯ liá»‡u pre-training cá»§a chÃºng tÃ´i vÃ  trÃ¡nh 
rÃ² rá»‰ dá»¯ liá»‡u, chÃºng tÃ´i chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u tá»« thÃ¡ng 12 nÄƒm 2023.

ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i bao gá»“m nÄƒm má»©c Ä‘á»™ dÃ i ngá»¯ cáº£nhâ€”2k, 4k, 8k, 12k, vÃ  16k tokenâ€”
trÃªn ba cÃ i Ä‘áº·t: cross-file-first, cross-file-random, vÃ  in-file. ChÃºng tÃ´i sá»­ dá»¥ng 
greedy search cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh dÆ°á»›i sá»± Ä‘Ã¡nh giÃ¡. CÃ¡c mÃ´ hÃ¬nh bá»‹ rÃ ng buá»™c sinh 
tá»‘i Ä‘a 64 token má»›i cho má»—i prompt, vÃ  dÃ²ng Ä‘áº§u tiÃªn khÃ´ng rá»—ng vÃ  khÃ´ng pháº£i comment 
cá»§a Ä‘áº§u ra Ä‘Æ°á»£c chá»n lÃ m dá»± Ä‘oÃ¡n. Äá»™ dÃ i token tá»‘i Ä‘a cho cÃ¡c prompt Ä‘Æ°á»£c Ä‘áº·t á»Ÿ 15.800 
báº±ng cÃ¡ch cáº¯t bá»›t ngá»¯ cáº£nh cross-file dÆ° thá»«a. ChÃºng tÃ´i bÃ¡o cÃ¡o exact match trung bÃ¬nh 
cho cÃ¡c má»©c Ä‘á»™ dÃ i ngá»¯ cáº£nh khÃ¡c nhau.

[Báº£ng 5: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau trÃªn táº­p con thÃ¡ng 12 cá»§a RepoBench v1.1]

NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 5, káº¿t quáº£ chá»‰ ra ráº±ng mÃ´ hÃ¬nh DeepSeek-Coder-V2-Lite-Base, 
máº·c dÃ¹ chá»‰ cÃ³ 2.4 tá»· tham sá»‘ hoáº¡t Ä‘á»™ng, Ä‘áº¡t Ä‘Æ°á»£c kháº£ nÄƒng code completion trong Python 
tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i mÃ´ hÃ¬nh DeepSeek-Coder-Base 33B vÃ  trong Java tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i mÃ´ hÃ¬nh 
DeepSeek-Coder-Base 7B. So vá»›i CodeStral, mÃ´ hÃ¬nh DeepSeek-Coder-V2-Lite-Base chá»‰ cÃ³ 
má»™t pháº§n mÆ°á»i tham sá»‘ hoáº¡t Ä‘á»™ng cá»§a CodeStral, dáº«n Ä‘áº¿n hiá»‡u suáº¥t tháº¥p hÆ¡n trong cÃ¡c 
nhiá»‡m vá»¥ code completion. Tuy nhiÃªn, chÃºng tÃ´i tin ráº±ng sá»‘ lÆ°á»£ng tham sá»‘ hoáº¡t Ä‘á»™ng nhá» hÆ¡n 
trong DeepSeek-Coder-V2 lÃ m cho nÃ³ nhanh hÆ¡n cho cÃ¡c tÃ¬nh huá»‘ng code completion.

4.2.2. Fill-in-the-Middle Code Completion

DeepSeek-Coder-V2-Lite Ä‘Æ°á»£c train vá»›i má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»™c Ä‘Ã¡o bao gá»“m tá»· lá»‡ Fill-In-the-Middle 
(FIM) 0.5 trong giai Ä‘oáº¡n pre-training cá»§a chÃºng. PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p mÃ´ hÃ¬nh 
hoÃ n thÃ nh mÃ£ má»™t cÃ¡ch thÃ nh tháº¡o báº±ng cÃ¡ch Ä‘iá»n vÃ o cÃ¡c chá»— trá»‘ng sá»­ dá»¥ng ngá»¯ cáº£nh 
xung quanh, bao gá»“m cáº£ cÃ¡c Ä‘oáº¡n mÃ£ trÆ°á»›c vÃ  sau. Kháº£ nÄƒng nÃ y Ä‘áº·c biá»‡t cÃ³ lá»£i cho 
cÃ¡c cÃ´ng cá»¥ code completion. Má»™t sá»‘ mÃ´ hÃ¬nh open-source, nhÆ° SantaCoder (Allal et al., 2023), 
StarCoder (Li et al., 2023b), vÃ  CodeLlama (Roziere et al., 2023), cÅ©ng táº­n dá»¥ng 
cÃ¡c kháº£ nÄƒng tÆ°Æ¡ng tá»± vÃ  Ä‘Ã£ thiáº¿t láº­p cÃ¡c tiÃªu chuáº©n cao trong lÄ©nh vá»±c sinh mÃ£ nguá»“n 
vÃ  completion.

Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh DeepSeek-Coder-V2, chÃºng tÃ´i tiáº¿n hÃ nh phÃ¢n tÃ­ch 
so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh hÃ ng Ä‘áº§u. ÄÃ¡nh giÃ¡ dá»±a trÃªn cÃ¡c benchmark Single-Line Infilling, 
bao phá»§ ba ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau nhÆ° Ä‘Æ°á»£c mÃ´ táº£ bá»Ÿi Allal et al. (2023).

--- TRANG 10 ---
Metric chÃ­nh cho Ä‘Ã¡nh giÃ¡ nÃ y lÃ  Ä‘á»™ chÃ­nh xÃ¡c exact match cá»§a dÃ²ngâµ.

[Báº£ng 6: Hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau trÃªn FIM-Tasks]

Báº£ng trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh láº­p trÃ¬nh khÃ¡c nhau trÃªn cÃ¡c nhiá»‡m vá»¥ FIM 
(Fill-in-the-Middle) trÃªn ba ngÃ´n ngá»¯ láº­p trÃ¬nh: Python, Java, vÃ  JavaScript, vá»›i 
Ä‘iá»ƒm Mean chá»‰ ra hiá»‡u quáº£ tá»•ng thá»ƒ. Trong sá»‘ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c so sÃ¡nh, DeepSeek-Coder-V2-Lite-Base, 
vá»›i cáº¥u hÃ¬nh 2.4B tham sá»‘ hoáº¡t Ä‘á»™ng, Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ xuáº¥t sáº¯c. NÃ³ ghi Ä‘iá»ƒm 80.0% 
trong Python, 89.1% trong Java, vÃ  87.2% trong JavaScript, dáº«n Ä‘áº¿n Ä‘iá»ƒm Mean hÃ ng Ä‘áº§u 
86.4%. Äiá»u nÃ y chá»©ng minh hiá»‡u quáº£ vÆ°á»£t trá»™i cá»§a DeepSeek-Coder-V2-Lite-Base, Ä‘áº·c biá»‡t 
trong viá»‡c xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ FIM trÃªn cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau, Ä‘áº¡t Ä‘Æ°á»£c 
hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n khÃ¡c trong Ä‘Ã¡nh giÃ¡.

4.3. Sá»­a lá»—i MÃ£ nguá»“n

Äá»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng sá»­a lá»—i cá»§a mÃ´ hÃ¬nh, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c bá»™ dá»¯ liá»‡u Defects4Jâ·, 
SWE-bench (Jimenez et al., 2023), vÃ  Aiderâ¸ Ä‘á»ƒ kiá»ƒm tra. Defects4J lÃ  má»™t bá»™ dá»¯ liá»‡u 
Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong lÄ©nh vá»±c ká»¹ thuáº­t pháº§n má»m, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho 
má»¥c Ä‘Ã­ch Ä‘Ã¡nh giÃ¡ vÃ  kiá»ƒm tra cÃ¡c ká»¹ thuáº­t sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh. NÃ³ bao gá»“m má»™t 
táº­p há»£p cÃ¡c lá»—i pháº§n má»m thá»±c táº¿ tá»« nhiá»u dá»± Ã¡n open-source khÃ¡c nhau, bao gá»“m 
nhÆ°ng khÃ´ng giá»›i háº¡n á»Ÿ Apache Commons, JFreeChart, vÃ  Closure Compiler. Má»—i lá»—i 
trong bá»™ dá»¯ liá»‡u Ä‘i kÃ¨m vá»›i cÃ¡c test suite cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c thá»±c hiá»‡u quáº£ 
cá»§a cÃ¡c cÃ´ng cá»¥ sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh. VÃ¬ cÃ¡c lá»—i gá»‘c trong Defec4J cÃ³ thá»ƒ cáº§n sá»­a Ä‘á»•i 
nhiá»u file trong repository dáº«n Ä‘áº¿n ngá»¯ cáº£nh dÃ i, chÃºng tÃ´i thu tháº­p 238 lá»—i chá»‰ cáº§n 
sá»­a Ä‘á»•i má»™t phÆ°Æ¡ng thá»©c tá»« benchmark nÃ y.

SWE-bench lÃ  má»™t benchmark toÃ n diá»‡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh 
ngÃ´n ngá»¯ lá»›n trong viá»‡c giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» pháº§n má»m thá»±c táº¿ Ä‘Æ°á»£c láº¥y tá»« GitHub. 
Benchmark trÃ¬nh bÃ y má»™t codebase cÃ¹ng vá»›i má»™t váº¥n Ä‘á» cá»¥ thá»ƒ, thÃ¡ch thá»©c mÃ´ hÃ¬nh ngÃ´n ngá»¯ 
táº¡o ra má»™t patch hiá»‡u quáº£ giáº£i quyáº¿t váº¥n Ä‘á» Ä‘Æ°á»£c mÃ´ táº£. Framework Ä‘Ã¡nh giÃ¡ nghiÃªm ngáº·t 
nÃ y Ä‘áº£m báº£o ráº±ng kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ trong viá»‡c hiá»ƒu vÃ  sá»­a cÃ¡c váº¥n Ä‘á» pháº§n má»m 
thá»±c táº¿ Ä‘Æ°á»£c kiá»ƒm tra ká»¹ lÆ°á»¡ng, cung cáº¥p má»™t thÆ°á»›c Ä‘o rÃµ rÃ ng vá» tÃ­nh há»¯u Ã­ch thá»±c táº¿ 
vÃ  hiá»‡u quáº£ trong cÃ¡c nhiá»‡m vá»¥ phÃ¡t triá»ƒn pháº§n má»m.

Benchmark chá»‰nh sá»­a mÃ£ cá»§a Aider Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a LLM trong viá»‡c sá»­a Ä‘á»•i cÃ¡c file 
nguá»“n Python, hoÃ n thÃ nh 133 nhiá»‡m vá»¥ láº­p trÃ¬nh riÃªng biá»‡t. Benchmark nÃ y khÃ´ng chá»‰ 
kiá»ƒm tra ká»¹ nÄƒng láº­p trÃ¬nh cá»§a LLM mÃ  cÃ²n kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n trong viá»‡c táº¡o ra 
cÃ¡c chá»‰nh sá»­a mÃ£ theo cÃ¡c Ä‘áº·c táº£ trong prompt.

âµChÃºng tÃ´i sá»­ dá»¥ng dÃ²ng Ä‘Æ°á»£c táº¡o Ä‘áº§u tiÃªn thay vÃ¬ toÃ n bá»™ chunk Ä‘Æ°á»£c táº¡o, do Ä‘Ã³ káº¿t quáº£ hÆ¡i khÃ¡c so vá»›i 
DeepSeek-Coder.
â·https://github.com/rjust/defects4j
â¸https://github.com/paul-gauthier/aider

--- TRANG 11 ---
Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh DeepSeek-Coder-V2, chÃºng tÃ´i sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng whole Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.

[Báº£ng 7: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau trÃªn cÃ¡c benchmark sá»­a chá»¯a. 
ChÃºng tÃ´i khÃ´ng Ä‘Ã¡nh giÃ¡ Llama3-Instruct trÃªn SWE-Bench vÃ¬ nÃ³ chá»‰ há»— trá»£ Ä‘á»™ dÃ i ngá»¯ cáº£nh 8K.]

Báº£ng 7 trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ khÃ¡c nhau trÃªn cÃ¡c benchmark sá»­a chá»¯a 
pháº§n má»m, bao gá»“m Defects4J, SWE-Bench, vÃ  Aider. Trong sá»‘ cÃ¡c mÃ´ hÃ¬nh open-source, 
DeepSeek-Coder-Instruct ná»•i lÃªn nhÆ° má»™t Ä‘iá»ƒm sÃ¡ng, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t nháº¥t trong 
cÃ¡c mÃ´ hÃ¬nh open source. NÃ³ ghi Ä‘iá»ƒm 21% trong Defects4J vÃ  12.7% trong SWE-Bench, 
tiáº¿n gáº§n Ä‘áº¿n káº¿t quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh closed-source hÃ ng Ä‘áº§u vÃ  thá»ƒ hiá»‡n kháº£ nÄƒng Ä‘Ã¡ng ká»ƒ 
trong viá»‡c xá»­ lÃ½ cÃ¡c chuá»—i mÃ£ dÃ i hÆ¡n. ÄÃ¡ng chÃº Ã½, DeepSeek-Coder-V2-Instruct Ä‘áº¡t Ä‘Æ°á»£c 
Ä‘iá»ƒm sá»‘ cao nháº¥t 73.7% trong Aider, vÆ°á»£t qua táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh khÃ¡c Ä‘Æ°á»£c liá»‡t kÃª, 
bao gá»“m cáº£ cÃ¡c Ä‘á»‘i tÃ¡c closed-source. Hiá»‡u suáº¥t vÆ°á»£t trá»™i nÃ y lÃ m ná»•i báº­t hiá»‡u quáº£ 
vÃ  tÃ­nh máº¡nh máº½ trong cÃ¡c nhiá»‡m vá»¥ sá»­a chá»¯a mÃ£ tá»± Ä‘á»™ng, Ä‘á»‹nh vá»‹ DeepSeek-Coder-V2-Instruct 
nhÆ° mÃ´ hÃ¬nh open-source hÃ ng Ä‘áº§u vÃ  má»™t Ä‘á»‘i thá»§ Ä‘Ã¡ng gá»m vá»›i cÃ¡c lá»±a chá»n thay tháº¿ 
closed-source trong lÄ©nh vá»±c nÃ y.

4.4. Hiá»ƒu vÃ  LÃ½ luáº­n MÃ£ nguá»“n

Äá»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng lÃ½ luáº­n mÃ£ nguá»“n cá»§a cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng 
benchmark CRUXEval. Benchmark nÃ y bao gá»“m 800 hÃ m Python Ä‘Æ°á»£c ghÃ©p Ä‘Ã´i vá»›i cÃ¡c vÃ­ dá»¥ 
input-output tÆ°Æ¡ng á»©ng. NÃ³ Ä‘Æ°á»£c chia thÃ nh hai nhiá»‡m vá»¥ riÃªng biá»‡t: CRUXEval-I, yÃªu cáº§u 
mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) dá»± Ä‘oÃ¡n output dá»±a trÃªn input Ä‘Ã£ cho, vÃ  CRUXEval-O, trong Ä‘Ã³ 
mÃ´ hÃ¬nh pháº£i dá»± Ä‘oÃ¡n input tá»« output Ä‘Ã£ biáº¿t. Cáº¥u trÃºc nÃ y thÃ¡ch thá»©c kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh 
trong viá»‡c hiá»ƒu vÃ  lÃ½ luáº­n thÃ´ng qua mÃ£ Python theo cáº£ hÆ°á»›ng thuáº­n vÃ  nghá»‹ch. Báº£ng 8 
trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ khÃ¡c nhau trÃªn benchmark CruxEval, Ä‘Ã¡nh giÃ¡ 
cÃ¡c mÃ´ hÃ¬nh trÃªn hai metrics: CruxEval-I-COT vÃ  CruxEval-O-COT. Trong sá»‘ cÃ¡c mÃ´ hÃ¬nh 
open-source, DeepSeek-Coder-V2-Instruct ná»•i báº­t Ä‘Ã¡ng ká»ƒ. NÃ³ ghi Ä‘iá»ƒm 70.0% trÃªn CruxEval-I-COT 
vÃ  75.1% trÃªn CruxEval-O-COT, thá»ƒ hiá»‡n kháº£ nÄƒng vÆ°á»£t trá»™i trong domain open-source. 
Tuy nhiÃªn, khi so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh closed-source lá»›n hÆ¡n, cÃ³ má»™t khoáº£ng cÃ¡ch hiá»‡u suáº¥t. 
Khoáº£ng cÃ¡ch hiá»‡u suáº¥t nÃ y cÃ³ thá»ƒ pháº§n lá»›n Ä‘Æ°á»£c quy cho viá»‡c DeepSeek-Coder-V2-Instruct 
hoáº¡t Ä‘á»™ng vá»›i chá»‰ 21 tá»· tham sá»‘ kÃ­ch hoáº¡t, Ã­t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i nhá»¯ng tham sá»‘ trong 
cÃ¡c mÃ´ hÃ¬nh closed-source lá»›n hÆ¡n, tiÃªn tiáº¿n hÆ¡n nhÆ° GPT-4o. Háº¡n cháº¿ trong Ä‘á»™ phá»©c táº¡p 
mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ háº¡n cháº¿ kháº£ nÄƒng há»c táº­p vÃ  giáº£i quyáº¿t váº¥n Ä‘á».

[Báº£ng 8: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau trÃªn benchmark CruxEval]

4.5. LÃ½ luáº­n ToÃ¡n há»c

Äá»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng lÃ½ luáº­n toÃ¡n há»c cá»§a DeepSeekCoder-V2, chÃºng tÃ´i sá»­ dá»¥ng benchmark 
cáº¥p tiá»ƒu há»c phá»• biáº¿n GSM8K (Cobbe et al., 2021), cÃ¹ng vá»›i cÃ¡c benchmark cáº¥p Ä‘á»™ thi Ä‘áº¥u 
nÃ¢ng cao bao gá»“m MATH (Hendrycks et al., 2021), Ká»³ thi ToÃ¡n Má»i Gá»i Má»¹ (AIME) 2024 
(MAA, 2024), vÃ  Math Odyssey (Netmind.AI, 2024)â¹.

[Báº£ng 9: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau trong lÃ½ luáº­n toÃ¡n há»c]

DeepSeek-Coder-V2-Instruct cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c 5/30 trÃªn AIME 2024 vá»›i maj@64.

â¹Hiá»‡u suáº¥t cá»§a DeepSeek-Coder-V2 trÃªn bá»‘n benchmark toÃ¡n há»c Ä‘Æ°á»£c thu Ä‘Æ°á»£c vá»›i zero-shot 
chain-of-thought prompting; má»—i cÃ¢u há»i test Ä‘Æ°á»£c ná»‘i vá»›i instruction: " \nPlease reason step by step, 
and put your final answer within \boxed{}."

--- TRANG 12 ---
Káº¿t quáº£, Ä‘Æ°á»£c trÃ¬nh bÃ y trong Báº£ng 9, Ä‘Æ°á»£c thu Ä‘Æ°á»£c báº±ng cÃ¡ch sá»­ dá»¥ng greedy decoding 
mÃ  khÃ´ng cÃ³ sá»± há»— trá»£ cá»§a cÃ¡c cÃ´ng cá»¥ hoáº·c ká»¹ thuáº­t voting, trá»« khi Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh khÃ¡c. 
DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 75.7% trÃªn benchmark MATH vÃ  53.7% trÃªn Math Odyssey, 
tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i GPT-4o state-of-the-art. NgoÃ i ra, DeepSeek-Coder-V2 giáº£i Ä‘Æ°á»£c nhiá»u 
bÃ i toÃ¡n tá»« AIME 2024 hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c, chá»©ng minh kháº£ nÄƒng lÃ½ luáº­n toÃ¡n há»c máº¡nh máº½ cá»§a nÃ³.

4.6. NgÃ´n ngá»¯ Tá»± nhiÃªn Tá»•ng quÃ¡t

VÃ¬ DeepSeek-Coder-V2 Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn DeepSeek-V2, nÃ³ káº¿ thá»«a kháº£ nÄƒng ngÃ´n ngá»¯ 
tá»± nhiÃªn máº¡nh máº½, tháº­m chÃ­ vÆ°á»£t qua DeepSeek-V2 trÃªn cÃ¡c benchmark liÃªn quan Ä‘áº¿n lÃ½ luáº­n. 
ChÃºng tÃ´i so sÃ¡nh DeepSeek-Coder-V2 Instruct vá»›i DeepSeek-V2 Chat trÃªn cÃ¡c benchmark 
tiÃªu chuáº©n, bao phá»§ cáº£ benchmark tiáº¿ng Anh vÃ  tiáº¿ng Trung, bao gá»“m BigBench Hard (BBH) 
(Suzgun et al., 2022), MMLU (Hendrycks et al., 2020), ARC (Clark et al., 2018), TriviaQA 
(Joshi et al., 2017), NaturalQuestions (Kwiatkowski et al., 2019), AGIEval (Zhong et al., 2023), 
CLUEWSC (Xu et al., 2020), C-Eval (Huang et al., 2023), vÃ  CMMLU (Li et al., 2023a). 
BÃªn cáº¡nh Ä‘Ã³, chÃºng tÃ´i cÅ©ng Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng sinh má»Ÿ cá»§a cÃ¡c mÃ´ hÃ¬nh, bao gá»“m Arena-Hard 
(Li et al., 2024), AlpacaEval2.0 (Dubois et al., 2024), MT-Bench (Zheng et al., 2023), 
vÃ  Alignbench (Liu et al., 2023c). Pipeline Ä‘Ã¡nh giÃ¡ vÃ  metrics giá»‘ng nhÆ° trong DeepSeek-V2, 
trong Ä‘Ã³ MMLU Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ sá»­ dá»¥ng gÃ³i simple-eval cá»§a OpenAI https://github.com/openai/simple-evals.

[Báº£ng 10: So sÃ¡nh DeepSeek-Coder-V2 Instruct vá»›i DeepSeek-V2 Chat]

Khi so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh 16B, rÃµ rÃ ng ráº±ng DeepSeek-Coder-V2-Lite-Instruct 
vÆ°á»£t trá»™i hÆ¡n DeepSeek-V2-Lite-Chat trong cÃ¡c benchmark nhÆ° BBH vÃ  Arena-Hard. Nhá»¯ng 
benchmark nÃ y Ä‘áº·t ra yÃªu cáº§u cao vá» kháº£ nÄƒng lÃ½ luáº­n cá»§a mÃ´ hÃ¬nh, Ä‘iá»u mÃ  DeepSeek-Coder-V2-Lite-Instruct 
xuáº¥t sáº¯c. Tuy nhiÃªn, DeepSeek-Coder-V2-Lite Instruct tá»¥t láº¡i trong cÃ¡c benchmark 
Ä‘Ã²i há»i kiáº¿n thá»©c chuyÃªn sÃ¢u nhÆ° TriviaQA, chá»§ yáº¿u do lÆ°á»£ng dá»¯ liá»‡u web tÆ°Æ¡ng Ä‘á»‘i Ã­t 
Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh pre-training.

Chuyá»ƒn sang cÃ¡c mÃ´ hÃ¬nh 236B, DeepSeek-Coder-V2 Instruct thá»ƒ hiá»‡n sá»©c máº¡nh lá»›n hÆ¡n 
trong cÃ¡c benchmark lÃ½ luáº­n, Ä‘áº·c biá»‡t trong Arena-Hard, bao gá»“m tá»· lá»‡ Ä‘Ã¡ng ká»ƒ cÃ¡c 
cÃ¢u há»i vá» mÃ£ nguá»“n, toÃ¡n há»c, vÃ  lÃ½ luáº­n. Máº·t khÃ¡c, DeepSeek-V2 Chat thá»ƒ hiá»‡n káº¿t quáº£ 
hÆ¡i tá»‘t hÆ¡n trong cÃ¡c benchmark nhÆ° MT-bench (Zheng et al., 2023), AlpacaEval 2.0 
(Dubois et al., 2024), vÃ  AlignBench (Liu et al., 2023c). Lá»£i tháº¿ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c 
quy cho giai Ä‘oáº¡n alignment Ä‘a má»¥c Ä‘Ã­ch cá»§a DeepSeek-V2 Chat.

5. Káº¿t luáº­n

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i giá»›i thiá»‡u DeepSeek-Coder-V2 Ä‘á»ƒ tiáº¿p tá»¥c thÃºc Ä‘áº©y lÄ©nh vá»±c 
trÃ­ tuá»‡ mÃ£ nguá»“n, Ä‘Æ°á»£c tiáº¿p tá»¥c pre-train tá»« DeepSeek-V2 vá»›i 6 nghÃ¬n tá»· token Ä‘Æ°á»£c láº¥y 
tá»« má»™t kho dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao vÃ  Ä‘a nguá»“n. ThÃ´ng qua quÃ¡ trÃ¬nh tiáº¿p tá»¥c pre-training nÃ y, 
chÃºng tÃ´i tháº¥y ráº±ng DeepSeek-

--- TRANG 13 ---
Coder-V2 nÃ¢ng cao Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng láº­p trÃ¬nh vÃ  lÃ½ luáº­n toÃ¡n há»c cá»§a mÃ´ hÃ¬nh Ä‘á»“ng thá»i 
duy trÃ¬ hiá»‡u suáº¥t ngÃ´n ngá»¯ tá»•ng quÃ¡t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i DeepSeek-V2. So vá»›i DeepSeek-Coder, 
DeepSeek-Coder-V2 há»— trá»£ sá»‘ lÆ°á»£ng ngÃ´n ngá»¯ láº­p trÃ¬nh lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ, tÄƒng tá»« 86 lÃªn 338, 
vÃ  má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»‘i Ä‘a tá»« 16K lÃªn 128K token. Káº¿t quáº£ thÃ­ nghiá»‡m chá»©ng minh 
ráº±ng DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c mÃ´ hÃ¬nh closed-source 
state-of-the-art nhÆ° GPT-4 Turbo, Claude 3 Opus, vÃ  Gemini 1.5 Pro trong cÃ¡c nhiá»‡m vá»¥ 
Ä‘áº·c thÃ¹ vá» mÃ£ nguá»“n vÃ  toÃ¡n há»c.

Máº·c dÃ¹ DeepSeek-Coder-V2 Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t áº¥n tÆ°á»£ng trÃªn cÃ¡c benchmark tiÃªu chuáº©n, 
chÃºng tÃ´i tháº¥y ráº±ng váº«n cÃ²n má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ trong kháº£ nÄƒng tuÃ¢n theo instruction 
so vá»›i cÃ¡c mÃ´ hÃ¬nh state-of-the-art hiá»‡n táº¡i nhÆ° GPT-4 Turbo. Khoáº£ng cÃ¡ch nÃ y dáº«n Ä‘áº¿n 
hiá»‡u suáº¥t kÃ©m trong cÃ¡c tÃ¬nh huá»‘ng vÃ  nhiá»‡m vá»¥ phá»©c táº¡p nhÆ° nhá»¯ng tÃ¬nh huá»‘ng trong SWEbench. 
Do Ä‘Ã³, chÃºng tÃ´i tin ráº±ng má»™t mÃ´ hÃ¬nh mÃ£ nguá»“n cáº§n khÃ´ng chá»‰ kháº£ nÄƒng láº­p trÃ¬nh máº¡nh máº½ 
mÃ  cÃ²n kháº£ nÄƒng tuÃ¢n theo instruction Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½ cÃ¡c tÃ¬nh huá»‘ng láº­p trÃ¬nh phá»©c táº¡p 
trong tháº¿ giá»›i thá»±c. Trong tÆ°Æ¡ng lai, chÃºng tÃ´i sáº½ táº­p trung nhiá»u hÆ¡n vÃ o viá»‡c cáº£i thiá»‡n 
kháº£ nÄƒng tuÃ¢n theo instruction cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ xá»­ lÃ½ tá»‘t hÆ¡n cÃ¡c tÃ¬nh huá»‘ng láº­p trÃ¬nh 
phá»©c táº¡p trong tháº¿ giá»›i thá»±c vÃ  nÃ¢ng cao nÄƒng suáº¥t cá»§a quy trÃ¬nh phÃ¡t triá»ƒn.

TÃ i liá»‡u tham kháº£o

[Danh sÃ¡ch tÃ i liá»‡u tham kháº£o Ä‘Æ°á»£c giá»¯ nguyÃªn nhÆ° báº£n gá»‘c]

--- TRANG 14-18 ---
[CÃ¡c trang tÃ i liá»‡u tham kháº£o tiáº¿p tá»¥c Ä‘Æ°á»£c giá»¯ nguyÃªn nhÆ° báº£n gá»‘c]

--- TRANG 19 ---
A. CÃ¡c NgÃ´n ngá»¯ Láº­p trÃ¬nh ÄÆ°á»£c Há»— trá»£

ABAP, ActionScript, Ada, Agda, AGS Script, Alloy, AmbientTalk, AMD GPU, AMPL, ANSYS
Parametric Design Language, ANTLR, Apache Configuration, APL, AppleScript, Arc, Arduino,
ASP, AspectJ, Assembly, Asymptote, Augeas, AutoHotkey, AutoIt, AWK, BC, Berry, BitBake,
BlitzBasic, BlitzMax, Bluespec, BNF, Boo, Boogie, Brainfuck, BrightScript, Bro, BST, C, C#,
C2HS Haskell, CADL, CapDL, Ceylon, Chapel, ChucK, Cirru, Click, Clojure, CMake, COBOL,
COBOLFree, CoffeeScript, ColdFusion CFC, Common Lisp, C++, Crystal, Csound, Csound Score,
CSS, CUDA, Cypher, Cython, Darcs Patch, Dart, DASM16, Debian Control File, DeviceTree, Diff,
DM, Docker, Dockerfile, Dylan, EBNF, eC, Eiffel, Elixir, Elm, ELPi, Emacs Lisp, EmberScript,
Erlang, Execline, F#, Factor, Fancy, Fantom, Felix, Fennel, Fish, Flux, Fortran, Fortran Fixed Form,
FoxPro, FreeFem, FreeMarker, F*, Futhark, G-Code, GAP, GAS, GDScript, Genshi, Gentoo Ebuild,
Gentoo Eclass, Gettext Catalog, GLSL, Glyph, Gnuplot, Go, Gosu, Grace, Gradle, Grammatical
Framework, GraphQL, Graphviz DOT, Groff, Groovy, Groovy Server Pages, GSQL, Handlebars,
Haskell, Haxe, HCL, HLSL, HTML, HTML Django, HTML ERB, HTML PHP, HTTP, Hy, Idris,
IGOR Pro, Inform 6 Template, Inno Setup, Io, Isabelle, J, Jade, JAGS, Jasmin, Java, Java Server
Pages, JavaScript, JavaScript MozPreproc, JCL, JFlex, JSON, JSONiq, JSX, Julia, Jupyter Notebook,
K, Kconfig, Koka, Kotlin, KRL, Lean, Less, Lex, LFE, Lighttpd Configuration File, LilyPond,
Limbo, Linker Script, Liquid, Literate Agda, Literate CoffeeScript, LLVM, Logtalk, LSL, Lua, M4,
Makefile, Mako, Mason, MATLAB, Maxima, Meson, Metal, MiniScript, Mirah, Mizar, Modelica,
Modula-2, Monkey, MooCode, MoonScript, Mosel, MQL, MUF, MuPAD, NASM, NCL, NetLinx,
Nginx Configuration File, Nimrod, Ninja, Nit, Nix, NSIS, Nu, NuSMV, Objdump, Objective-C,
Objective-C++, OCaml, Octave, Odin, OMG Interface Definition Language, ooc, Opa, OpenCL,
OpenEdge ABL, OpenSCAD, Ox, Oz, Papyrus, Parrot Internal Representation, Pascal, PAWN,
PEG, Perl, Perl 6, PHP, Pike, PkgConfig, POD, Pony, POV-Ray, PowerShell, Praat, Processing,
Propeller Spin, Protocol Buffer, Pug, Puppet, PureBasic, PureScript, Python, Q, QML, QVTO, R,
Racket, Ragel in Ruby Host, RAML, RConsole, Rd, REALbasic, ReasonML, Red, RenderScript,
Ren'Py, REXX, RHTML, Ride, Robot Framework, Rouge, Ruby, Rust, S, Sage, SARL, SAS, Sass,
Scala, Scheme, Scilab, SCSS, Self, Shell, ShExC, Sieve, Silver, Singularity, Slim, Smali, Smarty,
Smithy, SMT, Solidity, SourcePawn, SPARQL, SQF, SQL, Squirrel, Stan, Standard ML, Stata,
Stylus, SuperCollider, Swift, SWIG, SystemVerilog, Tcl, Tcsh, Tea, Terminfo, TeX, Thrift, Transact-
SQL, Treetop, Turing, Twig, TypeScript, TypoScript, Unity3D Asset, Uno, UnrealScript, UrWeb,
USD, Vala, VBScript, VCL, Velocity, Verilog, VHDL, VimL, Visual Basic, Vue, WebAssembly,
Web IDL, Whiley, X10, XBase, XC, XML, XML Lasso, XQuery, XS, XSLT, Xtend, Xtlang, YANG,
Zeek, Zephir, Zig, Zimpl