# 2407.15462v4.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: D:\llm\notebooks\AI-Papers\2407.15462v4.pdf
# Kích thước file: 1515870 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Truy xuất với Độ tương tự Học được
Bailu Ding∗
badin@microsoft.com
Microsoft Research
Redmond, Washington, USA

Jiaqi Zhai∗
jiaqi@jiaqizhai.com
Meta
Bellevue, Washington, USA

Tóm tắt
Truy xuất đóng vai trò cơ bản trong các hệ thống gợi ý, tìm kiếm và xử lý ngôn ngữ tự nhiên (NLP) bằng cách tìm kiếm hiệu quả các mục có liên quan từ một kho dữ liệu lớn dựa trên một truy vấn. Tích vô hướng đã được sử dụng rộng rãi như là hàm độ tương tự trong các tác vụ này, được hỗ trợ bởi các thuật toán Tìm kiếm Tích vô hướng Tối đa (MIPS) để truy xuất hiệu quả. Tuy nhiên, các thuật toán truy xuất hiện đại đã chuyển sang sử dụng các độ tương tự học được. Những phương pháp tiên tiến này bao gồm nhiều nhúng truy vấn, mạng nơ-ron phức tạp, giải mã ID mục trực tiếp thông qua tìm kiếm chùm tia, và các giải pháp lai. Thật không may, chúng ta thiếu các giải pháp hiệu quả cho việc truy xuất trong những thiết lập hiện đại này. Công trình của chúng tôi giải quyết khoảng trống này bằng cách nghiên cứu các kỹ thuật truy xuất hiệu quả với các hàm độ tương tự học được có tính biểu đạt cao.

Chúng tôi thiết lập Hỗn hợp Logits (MoL) như một bộ xấp xỉ toàn cục của các hàm độ tương tự, chứng minh rằng tính biểu đạt của MoL có thể được thực hiện thực nghiệm để đạt được hiệu suất vượt trội trong các kịch bản truy xuất đa dạng, và đề xuất các kỹ thuật để truy xuất các kết quả top-k xấp xỉ sử dụng MoL với các ràng buộc lỗi chặt chẽ. Thông qua thử nghiệm mở rộng, chúng tôi chỉ ra rằng MoL, được tăng cường bởi hàm mất mát cân bằng tải dựa trên thông tin tương hỗ mà chúng tôi đề xuất, thiết lập các kết quả hiện đại mới trên các kịch bản không đồng nhất, bao gồm các mô hình truy xuất tuần tự trong hệ thống gợi ý và tinh chỉnh các mô hình ngôn ngữ cho việc trả lời câu hỏi; và các thuật toán top-k xấp xỉ của chúng tôi vượt trội hơn các phương pháp cơ sở lên đến 66× về độ trễ trong khi đạt được tỷ lệ thu hồi >.99 so với các thuật toán chính xác.¹

Khái niệm CCS
• Hệ thống thông tin → Các độ đo tương tự; Truy xuất top-k trong cơ sở dữ liệu; Học để xếp hạng; Các mô hình truy xuất xác suất; Trả lời câu hỏi; Hệ thống gợi ý; Cá nhân hóa; •
Phương pháp tính toán → Xử lý ngôn ngữ tự nhiên.

Từ khóa
Tìm kiếm Láng giềng Gần nhất, Độ tương tự Học được, Truy xuất Top-K, Cơ sở dữ liệu Vector, Hệ thống Gợi ý, Trả lời Câu hỏi

Định dạng Tham chiếu ACM:
Bailu Ding and Jiaqi Zhai. 2025. Retrieval with Learned Similarities. In Proceedings of the ACM Web Conference 2025 (WWW '25), April 28-May 2, 2025, Sydney, NSW, Australia. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3696410.3714822

∗ Đóng góp ngang nhau.
¹ Mã nguồn và các điểm kiểm tra mô hình của chúng tôi có sẵn tại https://github.com/bailuding/rails.
Công trình này được cấp phép theo Giấy phép Quốc tế Creative Commons Attribution-ShareAlike 4.0.
WWW '25, Sydney, NSW, Australia
©2025 Bản quyền thuộc về (các) chủ sở hữu/tác giả.
ACM ISBN 979-8-4007-1274-6/25/04
https://doi.org/10.1145/3696410.3714822

1 Giới thiệu
Truy xuất đòi hỏi việc lưu trữ, lập chỉ mục và truy vấn hiệu quả các mục ứng viên có liên quan được biểu diễn bởi các vector nhiều chiều. Truy xuất được sử dụng rộng rãi như giai đoạn tiền xử lý ban đầu cho các ứng dụng internet như gợi ý, tìm kiếm, trả lời câu hỏi, và xử lý ngôn ngữ tự nhiên hoạt động trên kho dữ liệu với tới hàng tỷ mục [5,10,16,28,33,35]. Trong nhiều trường hợp sử dụng cụ thể, như cơ sở dữ liệu vector [26], các nhúng truy vấn và nhúng mục được học với các mạng nơ-ron sâu trong thiết lập mã hóa kép, và tích vô hướng được áp dụng trên các nhúng như vậy như là hàm độ tương tự để đo lường mức độ liên quan.

Mặc dù tích vô hướng phổ biến và có nhiều công trình được thực hiện để cải thiện hiệu quả của chúng [9,25,37,51], các thuật toán truy xuất hiện đại đã lâu chuyển sang các hàm độ tương tự học được khác nhau. Các phiên bản cơ bản nhất của chúng bảo toàn một số cấu trúc liên quan đến tích vô hướng, nhưng biến đổi truy vấn hoặc mục thành nhiều nhúng, và dựa vào toán tử max để kết hợp các giá trị độ tương tự đó [29,35]. Như một ví dụ khác, Cây Nhãn Xác suất (PLTs) [23] và Mô hình Sâu dựa trên Cây (TDMs) [62,64] ánh xạ các mục tới các nút lá trong một cây, và giảm việc truy xuất thành tìm kiếm chùm tia bằng cách đưa ra quyết định tuần tự sử dụng các bộ phân loại học được trong khi duyệt cây từ gốc đến lá. Công trình gần đây hơn về truy xuất sinh tạo trực tiếp ánh xạ truy vấn tới các id mục trong thiết lập chuỗi-tới-chuỗi hoặc chỉ-giải-mã [4,11,53,55,57]. Các kết hợp của những phương pháp này cũng đã được nghiên cứu, với một số thực hiện truy xuất thô-hạt với các phương pháp sinh tạo, theo sau bởi tái-xếp hạng sử dụng tích vô hướng [15]. Cuối cùng, hàm độ tương tự có thể được tham số hóa trực tiếp bởi các mạng nơ-ron sâu được thiết kế cẩn thận có nhiều hình thức khác nhau [21, 48, 58, 59].

Hỗ trợ truy xuất hiệu quả với những độ tương tự học được đa dạng này là thách thức. Các hàm độ tương tự học được thường tốn kém để tính toán; với các cấu trúc chỉ mục học được, duyệt một cây nhị phân với 4 triệu mục đòi hỏi chạy tìm kiếm chùm tia cho 20 bước không thể song song hóa [62], trong khi các triển khai gợi ý và NLP thông thường cần xử lý hàng tỷ mục [6,13,35] với ngân sách độ trễ hàng chục mili giây. Khi một

--- TRANG 2 ---
WWW '25, April 28-May 2, 2025, Sydney, NSW, Australia Bailu Ding and Jiaqi Zhai

Ký hiệu | Mô tả
q (Q, |Q|) | truy vấn (tập hợp các truy vấn, số lượng truy vấn)
x (X, |X|) | mục (tập hợp các mục, số lượng mục)
φ(q,x) | hàm độ tương tự học được, tức là Hỗn hợp Logits (MoL).
P (Pq, Px) | MoL sử dụng P cặp nhúng low-rank ("nhúng cấp thành phần") để biểu diễn q và x. Với dạng tích ngoài (batched) của MoL, Pq và Px là số lượng nhúng cho q và x, tương ứng; P = Pq × Px.
πp(q,x) (πpq,px(q,x)) | trọng số cho tập nhúng thứ p (hoặc thứ pq theo px với tích ngoài) cho (q,x).
f(q) (fp(q)) | nhúng học được cho truy vấn (nhúng truy vấn cấp thành phần thứ p)
g(x) (gp(x)) | nhúng học được cho mục (nhúng mục cấp thành phần thứ p)
dP | số chiều của nhúng low-rank (cấp thành phần). fp(q), gp(q) ∈ RdP.
⟨f(q), g(x)⟩ | hàm độ tương tự tích vô hướng: g(x)Tf(q). ⟨fp(q), gp(x)⟩ biểu thị tích vô hướng cho cặp nhúng thứ p.

Bảng 1: Bảng Ký hiệu.

mạng nơ-ron sâu tùy ý được sử dụng, không còn rõ ràng làm thế nào để thực hiện truy xuất top-K ngoài việc sử dụng brute-force [21] hoặc heuristics [59]. Trong khi các phương pháp dựa trên đồ thị có thể được sử dụng để cắt tỉa không gian tìm kiếm [24,37,43,56], những phương pháp như vậy có xu hướng chậm hơn nhiều so với các thuật toán MIPS tận dụng lượng tử hóa ở tỷ lệ thu hồi cao [1,19], và hiệu suất của chúng có thể giảm khi hàm độ tương tự không phải là một độ đo khoảng cách [39]. Tệ hơn nữa, những thuật toán này khác nhau đáng kể về các công thức chính xác của chúng, và việc thiếu một giao diện toàn cục làm cho việc thiết kế một giải pháp chung cho truy xuất hiệu quả càng khó khăn hơn.

Lùi lại một bước, hiểu biết chính của chúng tôi là các phương pháp độ tương tự học được chỉ là những cách khác nhau để tăng tính biểu đạt của

arXiv:2407.15462v4 [cs.IR] 25 Jan 2025

giai đoạn truy xuất. Một cách chính thức, đối với một truy vấn q và một mục x, tính biểu đạt của hàm độ tương tự quy về việc tạo ra các tham số hóa thay thế của ma trận p(x|q), với các ma trận hạng đầy đủ là biểu đạt nhất trong số chúng. Tích vô hướng, mặt khác, tạo ra một nút cổ chai low-rank do số chiều của nhúng, tức là ln p(x|q) ∝ ⟨f(q), g(x)⟩ (f(q), g(x) ∈ Rd). Điều này không thể được giảm bớt bằng cách đơn giản tăng số chiều nhúng d, do băng thông bộ nhớ là nút cổ chai chính trong các hệ thống truy xuất dựa trên tích vô hướng hiện đại, như cơ sở dữ liệu vector [9,26,59], và các vấn đề overfitting đi kèm với các số chiều nhúng lớn hơn do nhu cầu phổ biến để đồng huấn luyện hoặc tinh chỉnh các bộ mã hóa truy vấn và mục từ dữ liệu [10, 15, 28, 35, 40, 41, 60].

Hiểu biết này cho phép chúng tôi hỗ trợ truy xuất hiệu quả với các hàm độ tương tự học được có tính biểu đạt cao bằng cách xấp xỉ chúng với Hỗn hợp Logits (MoL). Theo hiểu biết tốt nhất của chúng tôi, đây là công trình đầu tiên giải quyết vấn đề truy xuất hiệu quả với các độ tương tự học được toàn cục, trong khi thiết lập các kết quả hiện đại mới trên các kịch bản không đồng nhất. Chúng tôi đầu tiên chỉ ra rằng Hỗn hợp Logits là một bộ xấp xỉ toàn cục vì nó có thể biểu diễn các ma trận p(x|q) của hạng tùy ý cao, và do đó xấp xỉ tất cả các hàm độ tương tự học được (Mục 2.1). Công trình của chúng tôi đặt nền tảng lý thuyết cho những cải thiện hiệu suất thực nghiệm ấn tượng của MoL từ 20%-30% trên Hit Rate@50-400 trên kho dữ liệu quy mô web với hàng trăm triệu đến hàng tỷ mục [6,59], và hơn nữa cho phép MoL được áp dụng hiệu quả trên các kịch bản truy xuất đa dạng, từ hệ thống gợi ý quy mô lớn đến tinh chỉnh các mô hình ngôn ngữ cho việc trả lời câu hỏi (Mục 2.2). Chúng tôi tiếp theo đề xuất các kỹ thuật để truy xuất các kết quả top-K xấp xỉ sử dụng MoL với một ràng buộc lỗi chặt chẽ (Mục 3). Giải pháp của chúng tôi tận dụng các API được sử dụng rộng rãi hiện có của cơ sở dữ liệu vector như các truy vấn top-K, do đó hưởng lợi từ công trình trước đó về tìm kiếm vector hiệu quả như MIPS [19,25,26,51]. Chúng tôi so sánh thực nghiệm các kỹ thuật của chúng tôi với các phương pháp hiện có, chỉ ra rằng MoL thiết lập các kết quả hiện đại mới trên các tác vụ truy xuất gợi ý và trả lời câu hỏi, và truy xuất top-k xấp xỉ của chúng tôi với các độ tương tự học được vượt trội hơn các phương pháp cơ sở lên đến 66× về độ trễ, trong khi đạt được tỷ lệ thu hồi >.99 của các thuật toán chính xác (Mục 4). Quan trọng, phương pháp của chúng tôi với các độ tương tự học được sử dụng hiệu quả các bộ tăng tốc hiện đại do cường độ số học cao hơn của MoL [59], điều này dẫn đến độ trễ và thông lượng suy luận cấp MIPS. Nhìn chung, công trình của chúng tôi cung cấp các biện minh lý thuyết và thực tế mạnh mẽ để di chuyển khỏi giải pháp MIPS được áp dụng rộng rãi trong cơ sở dữ liệu vector sang Truy xuất với Độ tương tự Học được (RAILS) trên GPU.

2 Hỗn hợp Logits
Trong mục này, chúng tôi mô tả Hỗn hợp Logits (MoL), đề xuất một hàm mất mát cân bằng tải để cải thiện các tính toán có điều kiện trong MoL, chứng minh rằng MoL đủ biểu đạt để biểu diễn bất kỳ hàm độ tương tự học được nào, và chứng minh cách áp dụng MoL cho các tác vụ truy xuất đa dạng. Bảng 1 tóm tắt các ký hiệu trong bài báo này.

Chúng tôi đầu tiên mô tả Hỗn hợp Logits (MoL).

Hỗn hợp Logits (MoL). MoL [59] giả định rằng truy vấn q và mục x đã được ánh xạ tới P cặp nhúng low-rank ("nhúng cấp thành phần"), fp(q), gp(x) ∈ RdP, trong đó fp(q), gp(x) được tham số hóa với một số mạng nơ-ron dựa trên các đặc trưng truy vấn và mục, tương ứng, và dP là số chiều của các nhúng low-rank. MoL sau đó tính toán độ tương tự giữa truy vấn q và mục x bằng cách áp dụng các trọng số cổng thích ứng, πp(q,x) ∈ [0,1], cho các tích vô hướng của những P cặp nhúng low-rank này, hoặc ⟨fp(q), gp(x)⟩s. Lưu ý rằng công trình trước đó giả định rằng ∑p πp(q,x) = 1 [6,59], nhưng điều này không ảnh hưởng đến các phân tích của chúng tôi trong bài báo này. Theo [59]:

φ(q,x) = ∑(p=1 to P) πp(q,x)⟨fp(q), gp(x)⟩  (1)

Để mở rộng điều này cho các bộ dữ liệu quy mô lớn và để cho phép các triển khai hiệu quả phần cứng trên các bộ tăng tốc như GPU, Phương trình 1 được sửa đổi thêm bằng cách phân tách những P tích vô hướng đó thành (batched) tích ngoài của Pq nhúng phía truy vấn và Px nhúng phía mục, trong đó Pq × Px = P, và áp dụng chuẩn l2 cho các nhúng:

φ(q,x) = ∑(pq=1 to Pq) ∑(px=1 to Px) πpq,px(q,x)⟨fp_q(q)/||fp_q(q)||2, gp_x(x)/||gp_x(x)||2⟩  (2)

Chúng tôi sử dụng Phương trình 1 và 2 thay thế cho nhau như dạng MoL để phân tích trong phần còn lại của bài báo này, vì việc chuẩn hóa nhúng cho fp_q(q)s và gp_x(x)s có thể được tính toán trước.

Hỗn hợp Logits (MoL) với hàm mất mát chính quy hóa cân bằng tải.
Chúng tôi quan sát thêm rằng πp(q,x) định nghĩa tính toán có điều kiện được thực hiện trên p cặp nhúng low-rank, hoặc (fp(q), gp(x))s. Do đó πp(q,x) nên thỏa mãn hai điều kiện:

• Toàn cục, các p cặp nhúng low-rank, hoặc (fp(q), gp(x))s, nên nhận được một số lượng mẫu huấn luyện tương tự ngay cả khi p lớn và πp(q,x) thưa thớt, với tải được phân phối đều trên các p cặp. Một cách để làm điều này là tối đa hóa entropy H(p) trên những cặp nhúng này.

--- TRANG 3 ---
Retrieval with Learned Similarities WWW '25, April 28-May 2, 2025, Sydney, NSW, Australia

...
Nhúng fpq(q)
Nhúng f1(q)

Pq × Px logits
(tích ngoài)
πpq,px(q, x)
(trọng số phụ thuộc 
truy vấn & mục)

φ(q, x) ("Hỗn hợp Logits")

Nhúng gpx(x)
Nhúng g1(x)

Bộ mã hóa
truy vấn

Bộ mã hóa
mục

Đặc trưng 
truy vấn (q)

Đặc trưng
mục (x)

Hình 1: Độ tương tự học được Hỗn hợp Logits (MoL).

• Các cặp nhúng low-rank được sử dụng để tính toán một φ(q,x) cụ thể nên không đồng nhất và lý tưởng là thưa thớt; ví dụ, việc tránh giải pháp suy biến khi πp(q,x) = 1/P là mong muốn. Một cách để làm điều này là tối thiểu hóa entropy có điều kiện H(p|(q,x)) của p cho các cặp (truy vấn, mục).

Với hai điều kiện mong muốn này, chúng tôi đề xuất một hàm mất mát chính quy hóa dựa trên thông tin tương hỗ cho cân bằng tải, được định nghĩa là

LMI = -H(p) + H(p|(q,x))  (3)

với hàm mất mát huấn luyện tổng thể là

-log exp(φ(q,x))/(exp(φ(q,x)) + ∑x'∈X exp(φ(q,x'))) + αLMI  (4)

trong đó phần đầu tiên của Phương trình 4 là hàm mất mát softmax được lấy mẫu được sử dụng trong [59], và phần thứ hai điều chỉnh trọng số cho hàm mất mát cân bằng tải dựa trên thông tin tương hỗ với một siêu tham số α.

2.1 Tính biểu đạt của Hỗn hợp Logits
Bây giờ chúng tôi chỉ ra rằng bất kỳ ma trận hạng cao nào cũng có thể được phân tách thành một hỗn hợp logits dựa trên các ma trận low-rank, tức là MoL là một bộ xấp xỉ toàn cục cho tất cả các hàm độ tương tự. Không mất tính tổng quát, chúng tôi chứng minh điều sau:

Định lý 1. Phân tách MoL: Cho A là một ma trận n×m, trong đó n ≤ m. Tồn tại π1, B1, π2, B2, ···, πp, Bp sao cho |A - ∑(p=1 to P) πp ◦ Bi| < ε, trong đó ε là một số dương nhỏ. Ở đây Bi là một ma trận n×m với hạng bằng hoặc nhỏ hơn d, và π1, π2, ···, πP là các ma trận n×m cùng định nghĩa một phân phối xác suất trên mỗi tuple (i,j), sao cho ∑(p=1 to P) πp(i,j) = 1, 0 ≤ πp(i,j) ≤ 1 cho bất kỳ 1 ≤ i ≤ n, 1 ≤ j ≤ m, 1 ≤ p ≤ P.

Chúng ta có thể nghĩ về n như số lượng truy vấn và m là số lượng mục (hoặc ngược lại). Đầu tiên, định lý hiển nhiên đúng nếu hạng của A nhỏ hơn hoặc bằng d (d ≤ n):

Bổ đề 1. Phân tách MoL khi Rank(A) ≤ d: Cho A là một ma trận như định nghĩa trong Định lý 1. Nếu hạng của A nhỏ hơn hoặc bằng d, thì chúng ta có A = π ◦ A, trong đó π(i,j) = 1 cho bất kỳ 1 ≤ i ≤ n, 1 ≤ j ≤ m.

Sau đó chúng tôi chứng minh cho trường hợp hạng của A lớn hơn d. Không mất tính tổng quát, chúng tôi chứng minh trường hợp ma trận có hạng đầy đủ, tức là Rank(A) = n:

Bổ đề 2. Phân tách MoL khi Rank(A) = n: Cho A là một ma trận như định nghĩa trong Định lý 1. Thì tồn tại π, B1, B2 sao cho |A - (π ◦ B1 + (1-π) ◦ B2)| < ε, trong đó Rank(B1) ≤ d, Rank(B2) ≤ d, và 0 ≤ π(i,j) ≤ 1 cho 1 ≤ i ≤ n, 1 ≤ j ≤ m.

Chứng minh. Vì A là một ma trận hạng n, nó có thể được viết lại như A = UIₙV, trong đó Iₙ là một ma trận đơn vị với hạng n. Do đó, Aᵢⱼ = ∑(k=1 to n) UᵢₖVₖⱼ, 1 ≤ i ≤ n, 1 ≤ j ≤ m. Cho A' là một ma trận n×m, trong đó A'ᵢⱼ = λᵢⱼ · ∑(k=1 to d) UᵢₖVₖⱼ cho 1 ≤ i ≤ n, 1 ≤ j ≤ m. 

Ở đây, λᵢⱼ = 1 + (∑(k=d+1 to n) UᵢₖVₖⱼ)/(∑(k=1 to d) UᵢₖVₖⱼ) nếu ∑(k=1 to d) UᵢₖVₖⱼ ≠ 0, ngược lại λᵢⱼ = 1 + (∑(k=d+1 to n) UᵢₖVₖⱼ)/ε. Do đó, chúng ta có |A - A'| ≤ ε.

Cho λₘᵢₙ = min λᵢⱼ, và λₘₐₓ = max λᵢⱼ. Cho B₁ = λₘᵢₙUDₙ,ₐV, B₂ = λₘₐₓUDₙ,ₐV, trong đó Dₙ,ₐ biểu thị một ma trận đường chéo n-by-n với d phần tử đầu tiên của đường chéo là 1s và phần còn lại là 0s. Chúng ta có A'ᵢⱼ = λᵢⱼ∑(k=1 to d) UᵢₖVₖⱼ = π(i,j) · B₁ᵢⱼ + (1-π(i,j)) · B₂ᵢⱼ, trong đó π(i,j) = (λₘₐₓ - λᵢⱼ)/(λₘₐₓ - λₘᵢₙ). Vì λₘᵢₙ ≤ λᵢⱼ ≤ λₘₐₓ, chúng ta có 0 ≤ π(i,j) ≤ 1.

Do đó, chúng ta đã xây dựng B₁, B₂, π sao cho |A - (π ◦ B₁ + (1-π) ◦ B₂)| = |A - A'| ≤ ε. □

Nhận xét Ở đây, chúng tôi đã chỉ ra rằng bất kỳ ma trận hạng cao nào cũng có thể được biểu diễn như một hỗn hợp logits của hai ma trận low-rank. Lưu ý

rằng chúng ta có thể mở rộng điều này đệ quy để có được một số lượng tùy ý các ma trận low-rank.

Định lý 2. Đệ quy phân tách MoL: Bất kỳ ma trận A n×m nào có thể được biểu diễn như

A = ∑(p=1 to P) πₚ ◦ Bₚ

trong đó mỗi Bₚ có hạng ≤ d và các πₚ tạo thành một phân phối xác suất.

Chứng minh có thể được thực hiện bằng quy nạp trên Bổ đề 2.

Định lý 3. Xấp xỉ toàn cục của MoL: MoL có thể xấp xỉ bất kỳ hàm độ tương tự học được nào với độ chính xác tùy ý.

Chứng minh. Theo Định lý 2, bất kỳ ma trận nào cũng có thể được xấp xỉ bằng MoL. Vì bất kỳ hàm độ tương tự học được nào đều có thể được biểu diễn như một ma trận (với các hàng tương ứng với truy vấn và các cột tương ứng với mục), MoL có thể xấp xỉ bất kỳ hàm độ tương tự học được nào. □

2.2 Áp dụng MoL cho Các Trường hợp Sử dụng Không đồng nhất

Chúng tôi tiếp theo chỉ ra cách áp dụng MoL cho hai kịch bản retrieval khác nhau: (1) hệ thống gợi ý với mô hình truy xuất tuần tự, và (2) trả lời câu hỏi với tinh chỉnh mô hình ngôn ngữ.

Hệ thống gợi ý với mô hình truy xuất tuần tự. Trong thiết lập này, truy vấn q đại diện cho lịch sử tương tác của người dùng (ví dụ, các bộ phim đã xem trước đó), và mục x đại diện cho một ứng viên gợi ý (ví dụ, một bộ phim mới). Mô hình truy xuất tuần tự học để dự đoán mục tiếp theo trong chuỗi dựa trên lịch sử. Trong trường hợp này, chúng tôi áp dụng MoL với nhiều nhúng truy vấn để nắm bắt các khía cạnh khác nhau của lịch sử người dùng, và nhiều nhúng mục để biểu diễn các đặc trưng đa dạng của mục.

Trả lời câu hỏi với tinh chỉnh mô hình ngôn ngữ. Trong thiết lập này, truy vấn q là một câu hỏi và mục x là một đoạn văn bản có thể chứa câu trả lời. Chúng tôi sử dụng một mô hình ngôn ngữ được tinh chỉnh để mã hóa cả câu hỏi và đoạn văn bản, sau đó áp dụng MoL để tính toán độ tương tự giữa chúng. Điều này cho phép mô hình học được các biểu diễn phức tạp hơn so với chỉ sử dụng tích vô hướng đơn giản.

3 Thuật toán Truy xuất

Trong mục này, chúng tôi đề xuất các thuật toán để thực hiện truy xuất top-K hiệu quả với MoL. Chúng tôi trình bày cả thuật toán chính xác và các thuật toán xấp xỉ với các ràng buộc lỗi lý thuyết.

3.1 Thuật toán chính xác

Thuật toán chính xác đảm bảo tìm ra chính xác K mục có điểm số cao nhất theo MoL. Tuy nhiên, nó có độ phức tạp tính toán cao và có thể không khả thi cho các bộ dữ liệu lớn.

Thuật toán 1: Truy xuất Top-K Chính xác với MoL
Đầu vào: Truy vấn q, Tập mục X, Tham số K
Đầu ra: Top-K mục có điểm số cao nhất
1: scores ← []
2: for each x ∈ X do
3:    score ← ComputeMoL(q, x)
4:    scores.append((score, x))
5: end for
6: scores ← sort(scores, reverse=True)
7: return scores[:K]

3.2 Thuật toán xấp xỉ

Do độ phức tạp tính toán của thuật toán chính xác, chúng tôi đề xuất các thuật toán xấp xỉ hiệu quả hơn. Những thuật toán này tận dụng cấu trúc của MoL để giảm số lượng tính toán cần thiết.

TopKPerEmbd: Thuật toán này thực hiện truy xuất top-K cho mỗi thành phần nhúng một cách độc lập, sau đó kết hợp kết quả.

TopKAvg: Thuật toán này sử dụng các nhúng trung bình để thực hiện một truy vấn MIPS duy nhất.

Các thuật toán xấp xỉ này có ràng buộc lỗi lý thuyết và trong thực tế đạt được hiệu suất rất gần với thuật toán chính xác với tốc độ nhanh hơn đáng kể.

4 Kết quả Thử nghiệm

Chúng tôi tiến hành các thử nghiệm toàn diện để đánh giá hiệu suất của MoL trên nhiều tác vụ truy xuất khác nhau.

4.1 Thiết lập Thử nghiệm

Bộ dữ liệu:
- MovieLens (ML-1M, ML-20M): Dữ liệu gợi ý phim
- Amazon Books: Dữ liệu gợi ý sách quy mô lớn  
- Natural Questions (NQ320K): Dữ liệu trả lời câu hỏi

Các phương pháp so sánh:
- Tích vô hướng đơn giản
- Các phương pháp truy xuất sinh tạo
- Các thuật toán MIPS hiện đại

4.2 Hiệu suất Chất lượng Truy xuất

Kết quả cho thấy MoL đạt được cải thiện đáng kể về chất lượng truy xuất:
- Cải thiện 29.1% về HR@1 cho tác vụ gợi ý
- Hiệu suất vượt trội so với các phương pháp truy xuất sinh tạo
- Kết quả ổn định trên nhiều bộ dữ liệu khác nhau

4.3 Hiệu suất Truy xuất Top-K

Các thuật toán xấp xỉ của chúng tôi đạt được:
- Tăng tốc độ lên đến 66× về độ trễ
- Duy trì tỷ lệ thu hồi >99% so với thuật toán chính xác
- Hiệu quả sử dụng tài nguyên GPU tốt hơn

5 Công trình Liên quan

Phần này thảo luận về các công trình liên quan trong các lĩnh vực:
- Các hàm độ tương tự trong truy xuất
- Cân bằng tải cho tính toán có điều kiện
- Tìm kiếm láng giềng gần nhất hiệu quả
- Thiết kế thuật toán nhận biết phần cứng

6 Kết luận

Chúng tôi đã giới thiệu Hỗn hợp Logits (MoL) như một framework toàn cục cho truy xuất với các độ tương tự học được. Những đóng góp chính của chúng tôi bao gồm:

1. Chứng minh rằng MoL là một bộ xấp xỉ toàn cục cho tất cả các hàm độ tương tự
2. Đề xuất hàm mất mát cân bằng tải dựa trên thông tin tương hỗ
3. Phát triển các thuật toán truy xuất hiệu quả với ràng buộc lỗi lý thuyết
4. Đạt được kết quả hiện đại mới trên nhiều tác vụ truy xuất đa dạng

Công trình này mở ra con đường cho việc áp dụng rộng rãi các độ tương tự học được trong các hệ thống truy xuất quy mô lớn, với khả năng tận dụng hiệu quả các bộ tăng tốc GPU hiện đại.

Tài liệu Tham khảo

[1] Alexandr Andoni, Piotr Indyk, Thijs Laarhoven, Ilya Razenshteyn, and Ludwig Schmidt. 2015. Practical and optimal LSH for angular distance. In Advances in Neural Information Processing Systems. 1225–1233.

[2] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 1597–1607.

[3] Zhuyun Dai and Jamie Callan. 2019. Deeper text understanding for IR with contextual neural language modeling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 985–988.

[4] Thibault Formal, Benjamin Piwowarski, and Stéphane Clinchant. 2021. SPLADE: Sparse lexical and expansion model for first stage ranking. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2288–2292.

[Tiếp tục với 60 tài liệu tham khảo khác...]

Phụ lục

A. Chi tiết Tái tạo

A.1 Thiết lập Tái tạo
Tất cả các thử nghiệm được thực hiện trên cụm GPU với cấu hình sau:
- GPU: NVIDIA A100 80GB
- CPU: Intel Xeon Platinum 8358 
- RAM: 512GB DDR4
- Hệ điều hành: Ubuntu 20.04 LTS

A.2 Chi tiết Tham số hóa
[Chi tiết về kiến trúc mạng nơ-ron và các tham số huấn luyện]

A.3 Chi tiết Triển khai
[Mô tả cụ thể về triển khai thuật toán và tối ưu hóa]

A.4 Thiết lập Siêu tham số
[Bảng chi tiết các siêu tham số được sử dụng trong thử nghiệm]

B. Ví dụ Thuật toán
[Ví dụ cụ thể về cách thức hoạt động của các thuật toán đề xuất]