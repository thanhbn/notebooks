{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation\n",
    "\n",
    "**Paper**: [CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation](https://arxiv.org/abs/2504.10046v1)\n",
    "\n",
    "**Authors**: Jia Li, Xianjie Shi, Kechi Zhang, Lei Li, Ge Li, Zhengwei Tao, Jia Li, Fang Liu, Chongyang Tao, Zhi Jin\n",
    "\n",
    "**Institution**: Peking University\n",
    "\n",
    "**Abstract**: CodeRAG is a retrieval-augmented code generation framework that comprehensively retrieves supportive codes for real-world code generation. It constructs a requirement graph and DS-code graph, then uses bigraph mapping and code-oriented agentic reasoning to retrieve supportive codes including APIs, semantically similar codes, and domain knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Key Contributions\n",
    "\n",
    "1. **Requirement Graph**: Models relationships between requirements (parent-child and similarity relations)\n",
    "2. **DS-Code Graph**: Extends traditional code graphs with semantic relationships\n",
    "3. **Bigraph Mapping**: Maps requirement nodes to corresponding code nodes\n",
    "4. **Code-oriented Agentic Reasoning**: LLM-based reasoning with programming tools\n",
    "\n",
    "## 📊 Performance\n",
    "\n",
    "- **+40.90** Pass@1 improvement on GPT-4o\n",
    "- **+37.79** Pass@1 improvement on Gemini-Pro\n",
    "- Outperforms GitHub Copilot and Cursor on complex coding tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai langchain-anthropic langchain-community\n",
    "!pip install chromadb faiss-cpu\n",
    "!pip install tree-sitter tree-sitter-python\n",
    "!pip install neo4j networkx\n",
    "!pip install duckduckgo-search\n",
    "!pip install black pytest\n",
    "!pip install deepeval\n",
    "!pip install numpy pandas matplotlib seaborn\n",
    "!pip install openai anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import networkx as nx\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Tree-sitter for code parsing\n",
    "import tree_sitter\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "# Neo4j for graph database\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key'\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-api-key'\n",
    "\n",
    "# Configure display\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📖 Data Preparation\n",
    "\n",
    "Let's prepare a sample repository structure for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample repository structure\n",
    "sample_repo = {\n",
    "    'utils.py': '''\n",
    "def _listify_string(target_object):\n",
    "    \"\"\"Helper function that takes a dictionary and returns it wrapped in a list\"\"\"\n",
    "    if isinstance(target_object, list):\n",
    "        return target_object\n",
    "    return [target_object]\n",
    "\n",
    "def _matches_after_expansion(str_to_check, str_to_check_against, condition_keys=None):\n",
    "    \"\"\"Helper function that checks the string_to_check against string_to_check_against\"\"\"\n",
    "    copy_str = str_to_check_against\n",
    "    if condition_keys is not None:\n",
    "        for k, v in condition_keys.items():\n",
    "            copy_str = copy_str.replace(f\"{k}\", str(v))\n",
    "    import re\n",
    "    pattern = re.compile(copy_str)\n",
    "    return pattern.match(str_to_check) is not None\n",
    "''',\n",
    "    \n",
    "    'policy.py': '''\n",
    "from utils import _listify_string, _matches_after_expansion\n",
    "\n",
    "def _statement_matches_action(statement, action, is_resource_policy_check=False):\n",
    "    \"\"\"Helper function, returns True if the given action is in the given policy statement\"\"\"\n",
    "    if 'Action' in statement:\n",
    "        for i in _listify_string(statement['Action']):\n",
    "            if not is_resource_policy_check:\n",
    "                if _matches_after_expansion(action, i):\n",
    "                    return True\n",
    "        return False\n",
    "    elif 'NotAction' in statement:\n",
    "        result = True\n",
    "        for i in _listify_string(statement['NotAction']):\n",
    "            if _matches_after_expansion(action, i):\n",
    "                result = False\n",
    "        return result\n",
    "    return True\n",
    "'''\n",
    "}\n",
    "\n",
    "# Create sample target requirement\n",
    "target_requirement = {\n",
    "    'description': 'Helper function, returns True if the given resource is in the given policy statement.',\n",
    "    'signature': 'def _statement_matches_resource(statement, resource, condition_keys=None):',\n",
    "    'expected_code': '''\n",
    "def _statement_matches_resource(statement, resource, condition_keys=None):\n",
    "    \"\"\"Helper function, returns True if the given resource is in the given policy statement\"\"\"\n",
    "    if 'Resource' in statement:\n",
    "        for res in _listify_string(statement['Resource']):\n",
    "            if _matches_after_expansion(resource, res, condition_keys):\n",
    "                return True\n",
    "        return False\n",
    "    elif 'NotResource' in statement:\n",
    "        for res in _listify_string(statement['NotResource']):\n",
    "            if _matches_after_expansion(resource, res, condition_keys):\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "'''\n",
    "}\n",
    "\n",
    "print(\"Sample repository and target requirement prepared!\")\n",
    "print(f\"Repository files: {list(sample_repo.keys())}\")\n",
    "print(f\"Target requirement: {target_requirement['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 1. Requirement Graph Construction\n",
    "\n",
    "As described in Section 3.1 of the paper, we construct a requirement graph where nodes represent functional descriptions and edges represent parent-child or similarity relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RequirementNode:\n",
    "    \"\"\"Node in the requirement graph\"\"\"\n",
    "    id: str\n",
    "    description: str\n",
    "    file_path: str\n",
    "    code_name: str\n",
    "    signature: str\n",
    "    source_code: str\n",
    "\n",
    "class RequirementGraph:\n",
    "    \"\"\"Requirement Graph as described in Section 3.1\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_model=\"gpt-3.5-turbo\"):\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.llm = ChatOpenAI(model=llm_model, temperature=0)\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.nodes = {}\n",
    "        \n",
    "    def extract_nodes_from_code(self, code_content: str, file_path: str) -> List[RequirementNode]:\n",
    "        \"\"\"Extract function/class nodes from code using AST parsing\"\"\"\n",
    "        nodes = []\n",
    "        try:\n",
    "            tree = ast.parse(code_content)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    # Extract function signature and docstring\n",
    "                    signature = f\"def {node.name}({', '.join([arg.arg for arg in node.args.args])}):\"\n",
    "                    docstring = ast.get_docstring(node) or \"\"\n",
    "                    \n",
    "                    # Get function source code\n",
    "                    source_lines = code_content.split('\\n')\n",
    "                    func_source = '\\n'.join(source_lines[node.lineno-1:node.end_lineno])\n",
    "                    \n",
    "                    # Generate requirement if no docstring\n",
    "                    if not docstring:\n",
    "                        docstring = self._generate_requirement(func_source, node.name)\n",
    "                    \n",
    "                    req_node = RequirementNode(\n",
    "                        id=f\"{file_path}:{node.name}\",\n",
    "                        description=docstring,\n",
    "                        file_path=file_path,\n",
    "                        code_name=node.name,\n",
    "                        signature=signature,\n",
    "                        source_code=func_source\n",
    "                    )\n",
    "                    nodes.append(req_node)\n",
    "                    \n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in {file_path}: {e}\")\n",
    "            \n",
    "        return nodes\n",
    "    \n",
    "    def _generate_requirement(self, source_code: str, function_name: str) -> str:\n",
    "        \"\"\"Generate requirement description using LLM as described in paper\"\"\"\n",
    "        # Using the exact prompt from Appendix A of the paper\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"You're an expert Python programmer. Understand the given Python function {function_name}. \n",
    "            Generate a programming requirement that briefly describes the purpose, input, and output of the given Python function.\n",
    "            Don't generate any explanations.\n",
    "            \n",
    "            Please follow the format:\n",
    "            Purpose: ...\n",
    "            Input: ...\n",
    "            Output: ...\n",
    "            \n",
    "            Function code:\n",
    "            {source_code}\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        try:\n",
    "            result = chain.run(function_name=function_name, source_code=source_code)\n",
    "            return result.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating requirement: {e}\")\n",
    "            return f\"Function {function_name} - purpose to be determined\"\n",
    "    \n",
    "    def add_node(self, node: RequirementNode):\n",
    "        \"\"\"Add a node to the requirement graph\"\"\"\n",
    "        self.graph.add_node(node.id, **node.__dict__)\n",
    "        self.nodes[node.id] = node\n",
    "    \n",
    "    def extract_relationships(self, target_node: RequirementNode, candidate_node: RequirementNode) -> str:\n",
    "        \"\"\"Extract relationship between two requirements using LLM\"\"\"\n",
    "        # Using the exact prompt from Appendix A of the paper\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"You're an expert Python programmer. Understand the target requirement and the candidate requirement. \n",
    "            Determine and select the relation between them from the following three options:\n",
    "            \n",
    "            1. Parent-Child Relation: The candidate requirement is a child requirement of the target requirement. \n",
    "               The corresponding code of the target requirement invokes the corresponding code of the child requirement.\n",
    "            2. Semantic Similarity Relation: The candidate requirement and the target requirement are semantically similar. \n",
    "               The code's implementation of the target requirement may learn from the code's implementation of the candidate requirement.\n",
    "            3. Other Relations: The candidate requirement and the target requirement do not have the above relations.\n",
    "            \n",
    "            Only return: Parent-Child Relation OR Semantic Similarity Relation OR Other Relations\n",
    "            \n",
    "            Target requirement: {target_desc}\n",
    "            Target path: {target_path}\n",
    "            \n",
    "            Candidate requirement: {candidate_desc}\n",
    "            Candidate path: {candidate_path}\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        try:\n",
    "            result = chain.run(\n",
    "                target_desc=target_node.description,\n",
    "                target_path=target_node.file_path,\n",
    "                candidate_desc=candidate_node.description,\n",
    "                candidate_path=candidate_node.file_path\n",
    "            )\n",
    "            return result.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting relationship: {e}\")\n",
    "            return \"Other Relations\"\n",
    "    \n",
    "    def build_requirement_graph(self, repository: Dict[str, str]):\n",
    "        \"\"\"Build the complete requirement graph from repository\"\"\"\n",
    "        print(\"Building requirement graph...\")\n",
    "        \n",
    "        # Extract all nodes from repository\n",
    "        all_nodes = []\n",
    "        for file_path, code_content in repository.items():\n",
    "            nodes = self.extract_nodes_from_code(code_content, file_path)\n",
    "            all_nodes.extend(nodes)\n",
    "            \n",
    "        # Add all nodes to graph\n",
    "        for node in all_nodes:\n",
    "            self.add_node(node)\n",
    "            \n",
    "        # Extract relationships between all pairs\n",
    "        print(f\"Extracted {len(all_nodes)} nodes, now extracting relationships...\")\n",
    "        \n",
    "        for i, target_node in enumerate(all_nodes):\n",
    "            for j, candidate_node in enumerate(all_nodes):\n",
    "                if i != j:  # Don't compare node with itself\n",
    "                    relation = self.extract_relationships(target_node, candidate_node)\n",
    "                    \n",
    "                    if \"Parent-Child\" in relation:\n",
    "                        self.graph.add_edge(target_node.id, candidate_node.id, relation_type=\"parent-child\")\n",
    "                    elif \"Semantic Similarity\" in relation:\n",
    "                        self.graph.add_edge(target_node.id, candidate_node.id, relation_type=\"similarity\")\n",
    "        \n",
    "        print(f\"Requirement graph built with {len(self.nodes)} nodes and {len(self.graph.edges)} edges\")\n",
    "    \n",
    "    def find_relevant_requirements(self, target_requirement: str) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Find sub-requirements and similar requirements for target\"\"\"\n",
    "        sub_requirements = []\n",
    "        similar_requirements = []\n",
    "        \n",
    "        # Find the target node in graph\n",
    "        target_node_id = None\n",
    "        for node_id, node in self.nodes.items():\n",
    "            if target_requirement.lower() in node.description.lower():\n",
    "                target_node_id = node_id\n",
    "                break\n",
    "        \n",
    "        if target_node_id:\n",
    "            # Find child requirements (sub-requirements)\n",
    "            for successor in self.graph.successors(target_node_id):\n",
    "                edge_data = self.graph.get_edge_data(target_node_id, successor)\n",
    "                if edge_data and edge_data.get('relation_type') == 'parent-child':\n",
    "                    sub_requirements.append(successor)\n",
    "            \n",
    "            # Find similar requirements\n",
    "            for successor in self.graph.successors(target_node_id):\n",
    "                edge_data = self.graph.get_edge_data(target_node_id, successor)\n",
    "                if edge_data and edge_data.get('relation_type') == 'similarity':\n",
    "                    similar_requirements.append(successor)\n",
    "        \n",
    "        return sub_requirements, similar_requirements\n",
    "    \n",
    "    def visualize_graph(self, figsize=(12, 8)):\n",
    "        \"\"\"Visualize the requirement graph\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create layout\n",
    "        pos = nx.spring_layout(self.graph, k=2, iterations=50)\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(self.graph, pos, \n",
    "                              node_color='lightblue', \n",
    "                              node_size=1000, \n",
    "                              alpha=0.7)\n",
    "        \n",
    "        # Draw edges with different colors for different relationships\n",
    "        parent_child_edges = [(u, v) for u, v, d in self.graph.edges(data=True) \n",
    "                             if d.get('relation_type') == 'parent-child']\n",
    "        similarity_edges = [(u, v) for u, v, d in self.graph.edges(data=True) \n",
    "                           if d.get('relation_type') == 'similarity']\n",
    "        \n",
    "        nx.draw_networkx_edges(self.graph, pos, \n",
    "                              edgelist=parent_child_edges,\n",
    "                              edge_color='red', \n",
    "                              alpha=0.6, \n",
    "                              width=2,\n",
    "                              label='Parent-Child')\n",
    "        \n",
    "        nx.draw_networkx_edges(self.graph, pos, \n",
    "                              edgelist=similarity_edges,\n",
    "                              edge_color='green', \n",
    "                              alpha=0.6, \n",
    "                              width=2,\n",
    "                              style='dashed',\n",
    "                              label='Similarity')\n",
    "        \n",
    "        # Draw labels\n",
    "        labels = {node_id: self.nodes[node_id].code_name for node_id in self.graph.nodes()}\n",
    "        nx.draw_networkx_labels(self.graph, pos, labels, font_size=8)\n",
    "        \n",
    "        plt.title('Requirement Graph\\n(Red: Parent-Child, Green Dashed: Similarity)', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test the requirement graph\n",
    "req_graph = RequirementGraph()\n",
    "req_graph.build_requirement_graph(sample_repo)\n",
    "req_graph.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🕸️ 2. DS-Code Graph Construction\n",
    "\n",
    "As described in Section 3.2, we construct a DS-code graph that models both dependency and semantic relationships between code elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CodeNode:\n",
    "    \"\"\"Node in the DS-code graph\"\"\"\n",
    "    id: str\n",
    "    node_type: str  # Module, Class, Method, Function\n",
    "    name: str\n",
    "    source_code: str\n",
    "    signature: str\n",
    "    file_path: str\n",
    "    embedding: Optional[np.ndarray] = None\n",
    "\n",
    "class DSCodeGraph:\n",
    "    \"\"\"DS-Code Graph as described in Section 3.2\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.nodes = {}\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "    def extract_code_nodes(self, code_content: str, file_path: str) -> List[CodeNode]:\n",
    "        \"\"\"Extract code nodes from source code\"\"\"\n",
    "        nodes = []\n",
    "        \n",
    "        # Add module node\n",
    "        module_node = CodeNode(\n",
    "            id=f\"module:{file_path}\",\n",
    "            node_type=\"Module\",\n",
    "            name=file_path,\n",
    "            source_code=code_content,\n",
    "            signature=f\"module {file_path}\",\n",
    "            file_path=file_path\n",
    "        )\n",
    "        nodes.append(module_node)\n",
    "        \n",
    "        try:\n",
    "            tree = ast.parse(code_content)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    # Extract function source\n",
    "                    source_lines = code_content.split('\\n')\n",
    "                    func_source = '\\n'.join(source_lines[node.lineno-1:node.end_lineno])\n",
    "                    \n",
    "                    func_node = CodeNode(\n",
    "                        id=f\"function:{file_path}:{node.name}\",\n",
    "                        node_type=\"Function\",\n",
    "                        name=node.name,\n",
    "                        source_code=func_source,\n",
    "                        signature=f\"def {node.name}({', '.join([arg.arg for arg in node.args.args])}):\",\n",
    "                        file_path=file_path\n",
    "                    )\n",
    "                    nodes.append(func_node)\n",
    "                    \n",
    "                elif isinstance(node, ast.ClassDef):\n",
    "                    # Extract class source\n",
    "                    source_lines = code_content.split('\\n')\n",
    "                    class_source = '\\n'.join(source_lines[node.lineno-1:node.end_lineno])\n",
    "                    \n",
    "                    class_node = CodeNode(\n",
    "                        id=f\"class:{file_path}:{node.name}\",\n",
    "                        node_type=\"Class\",\n",
    "                        name=node.name,\n",
    "                        source_code=class_source,\n",
    "                        signature=f\"class {node.name}:\",\n",
    "                        file_path=file_path\n",
    "                    )\n",
    "                    nodes.append(class_node)\n",
    "                    \n",
    "                    # Extract methods\n",
    "                    for method in node.body:\n",
    "                        if isinstance(method, ast.FunctionDef):\n",
    "                            method_source = '\\n'.join(source_lines[method.lineno-1:method.end_lineno])\n",
    "                            \n",
    "                            method_node = CodeNode(\n",
    "                                id=f\"method:{file_path}:{node.name}:{method.name}\",\n",
    "                                node_type=\"Method\",\n",
    "                                name=method.name,\n",
    "                                source_code=method_source,\n",
    "                                signature=f\"def {method.name}({', '.join([arg.arg for arg in method.args.args])}):\",\n",
    "                                file_path=file_path\n",
    "                            )\n",
    "                            nodes.append(method_node)\n",
    "                            \n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in {file_path}: {e}\")\n",
    "            \n",
    "        return nodes\n",
    "    \n",
    "    def extract_dependencies(self, code_content: str, file_path: str) -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"Extract dependency relationships (import, call, etc.)\"\"\"\n",
    "        dependencies = []\n",
    "        \n",
    "        try:\n",
    "            tree = ast.parse(code_content)\n",
    "            \n",
    "            # Extract imports\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        dependencies.append((f\"module:{file_path}\", f\"module:{alias.name}\", \"imports\"))\n",
    "                        \n",
    "                elif isinstance(node, ast.ImportFrom):\n",
    "                    if node.module:\n",
    "                        for alias in node.names:\n",
    "                            dependencies.append((f\"module:{file_path}\", f\"function:{node.module}:{alias.name}\", \"imports\"))\n",
    "            \n",
    "            # Extract function calls\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.Call):\n",
    "                    if isinstance(node.func, ast.Name):\n",
    "                        # Find the containing function\n",
    "                        for parent in ast.walk(tree):\n",
    "                            if isinstance(parent, ast.FunctionDef):\n",
    "                                if (hasattr(parent, 'lineno') and hasattr(node, 'lineno') and \n",
    "                                    parent.lineno <= node.lineno <= (parent.end_lineno or float('inf'))):\n",
    "                                    caller_id = f\"function:{file_path}:{parent.name}\"\n",
    "                                    callee_id = f\"function:{file_path}:{node.func.id}\"  # Simplified\n",
    "                                    dependencies.append((caller_id, callee_id, \"calls\"))\n",
    "                                    break\n",
    "                                    \n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in {file_path}: {e}\")\n",
    "            \n",
    "        return dependencies\n",
    "    \n",
    "    def compute_semantic_similarities(self, threshold: float = 0.7) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"Compute semantic similarities between code nodes\"\"\"\n",
    "        similarities = []\n",
    "        \n",
    "        # Get embeddings for all nodes\n",
    "        node_list = list(self.nodes.values())\n",
    "        if len(node_list) < 2:\n",
    "            return similarities\n",
    "            \n",
    "        # Compute embeddings\n",
    "        texts = [node.source_code for node in node_list]\n",
    "        try:\n",
    "            embeddings = self.embeddings.embed_documents(texts)\n",
    "            \n",
    "            # Store embeddings in nodes\n",
    "            for i, node in enumerate(node_list):\n",
    "                node.embedding = np.array(embeddings[i])\n",
    "                \n",
    "            # Compute pairwise similarities\n",
    "            for i in range(len(node_list)):\n",
    "                for j in range(i + 1, len(node_list)):\n",
    "                    node1, node2 = node_list[i], node_list[j]\n",
    "                    \n",
    "                    # Compute cosine similarity\n",
    "                    similarity = np.dot(node1.embedding, node2.embedding) / (\n",
    "                        np.linalg.norm(node1.embedding) * np.linalg.norm(node2.embedding)\n",
    "                    )\n",
    "                    \n",
    "                    if similarity > threshold:\n",
    "                        similarities.append((node1.id, node2.id, similarity))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error computing embeddings: {e}\")\n",
    "            \n",
    "        return similarities\n",
    "    \n",
    "    def build_ds_code_graph(self, repository: Dict[str, str]):\n",
    "        \"\"\"Build the complete DS-code graph\"\"\"\n",
    "        print(\"Building DS-code graph...\")\n",
    "        \n",
    "        # Extract all nodes\n",
    "        all_nodes = []\n",
    "        for file_path, code_content in repository.items():\n",
    "            nodes = self.extract_code_nodes(code_content, file_path)\n",
    "            all_nodes.extend(nodes)\n",
    "            \n",
    "        # Add nodes to graph\n",
    "        for node in all_nodes:\n",
    "            self.graph.add_node(node.id, **node.__dict__)\n",
    "            self.nodes[node.id] = node\n",
    "            \n",
    "        # Extract dependency edges\n",
    "        for file_path, code_content in repository.items():\n",
    "            dependencies = self.extract_dependencies(code_content, file_path)\n",
    "            for source, target, edge_type in dependencies:\n",
    "                if source in self.nodes and target in self.nodes:\n",
    "                    self.graph.add_edge(source, target, edge_type=edge_type)\n",
    "                    \n",
    "        # Add containment edges\n",
    "        for node in all_nodes:\n",
    "            if node.node_type == \"Function\":\n",
    "                module_id = f\"module:{node.file_path}\"\n",
    "                if module_id in self.nodes:\n",
    "                    self.graph.add_edge(module_id, node.id, edge_type=\"contains\")\n",
    "                    \n",
    "        # Add semantic similarity edges\n",
    "        print(\"Computing semantic similarities...\")\n",
    "        similarities = self.compute_semantic_similarities()\n",
    "        for source, target, similarity in similarities:\n",
    "            self.graph.add_edge(source, target, edge_type=\"similarity\", weight=similarity)\n",
    "            \n",
    "        print(f\"DS-code graph built with {len(self.nodes)} nodes and {len(self.graph.edges)} edges\")\n",
    "    \n",
    "    def get_one_hop_neighbors(self, node_id: str) -> List[Tuple[str, Dict]]:\n",
    "        \"\"\"Get one-hop neighbors of a node\"\"\"\n",
    "        neighbors = []\n",
    "        \n",
    "        # Outgoing edges\n",
    "        for successor in self.graph.successors(node_id):\n",
    "            edge_data = self.graph.get_edge_data(node_id, successor)\n",
    "            neighbors.append((successor, edge_data))\n",
    "            \n",
    "        # Incoming edges\n",
    "        for predecessor in self.graph.predecessors(node_id):\n",
    "            edge_data = self.graph.get_edge_data(predecessor, node_id)\n",
    "            neighbors.append((predecessor, edge_data))\n",
    "            \n",
    "        return neighbors\n",
    "    \n",
    "    def visualize_graph(self, figsize=(14, 10)):\n",
    "        \"\"\"Visualize the DS-code graph\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create layout\n",
    "        pos = nx.spring_layout(self.graph, k=3, iterations=50)\n",
    "        \n",
    "        # Color nodes by type\n",
    "        node_colors = {\n",
    "            'Module': 'lightcoral',\n",
    "            'Class': 'lightblue', \n",
    "            'Method': 'lightgreen',\n",
    "            'Function': 'lightyellow'\n",
    "        }\n",
    "        \n",
    "        colors = [node_colors.get(self.nodes[node].node_type, 'gray') for node in self.graph.nodes()]\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(self.graph, pos, \n",
    "                              node_color=colors, \n",
    "                              node_size=1500, \n",
    "                              alpha=0.7)\n",
    "        \n",
    "        # Draw edges by type\n",
    "        edge_colors = {\n",
    "            'imports': 'blue',\n",
    "            'calls': 'red',\n",
    "            'contains': 'green',\n",
    "            'similarity': 'purple'\n",
    "        }\n",
    "        \n",
    "        for edge_type, color in edge_colors.items():\n",
    "            edges = [(u, v) for u, v, d in self.graph.edges(data=True) \n",
    "                    if d.get('edge_type') == edge_type]\n",
    "            if edges:\n",
    "                nx.draw_networkx_edges(self.graph, pos, \n",
    "                                      edgelist=edges,\n",
    "                                      edge_color=color, \n",
    "                                      alpha=0.6, \n",
    "                                      width=2 if edge_type != 'similarity' else 1,\n",
    "                                      style='solid' if edge_type != 'similarity' else 'dashed')\n",
    "        \n",
    "        # Draw labels\n",
    "        labels = {node_id: self.nodes[node_id].name for node_id in self.graph.nodes()}\n",
    "        nx.draw_networkx_labels(self.graph, pos, labels, font_size=8)\n",
    "        \n",
    "        plt.title('DS-Code Graph\\n(Red: Calls, Blue: Imports, Green: Contains, Purple Dashed: Similarity)', \n",
    "                 fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test the DS-code graph\n",
    "ds_graph = DSCodeGraph()\n",
    "ds_graph.build_ds_code_graph(sample_repo)\n",
    "ds_graph.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 3. Bigraph Mapping\n",
    "\n",
    "As described in Section 3.3, we map requirement nodes to their corresponding code nodes in the DS-code graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigraphMapper:\n",
    "    \"\"\"Bigraph Mapping as described in Section 3.3\"\"\"\n",
    "    \n",
    "    def __init__(self, requirement_graph: RequirementGraph, ds_code_graph: DSCodeGraph):\n",
    "        self.req_graph = requirement_graph\n",
    "        self.code_graph = ds_code_graph\n",
    "        \n",
    "    def map_requirement_to_code(self, req_node_id: str) -> Optional[str]:\n",
    "        \"\"\"Map a requirement node to its corresponding code node\"\"\"\n",
    "        if req_node_id not in self.req_graph.nodes:\n",
    "            return None\n",
    "            \n",
    "        req_node = self.req_graph.nodes[req_node_id]\n",
    "        \n",
    "        # Create corresponding code node ID\n",
    "        code_node_id = f\"function:{req_node.file_path}:{req_node.code_name}\"\n",
    "        \n",
    "        if code_node_id in self.code_graph.nodes:\n",
    "            return code_node_id\n",
    "        else:\n",
    "            # Try to find by name matching\n",
    "            for code_id, code_node in self.code_graph.nodes.items():\n",
    "                if (code_node.name == req_node.code_name and \n",
    "                    code_node.file_path == req_node.file_path):\n",
    "                    return code_id\n",
    "                    \n",
    "        return None\n",
    "    \n",
    "    def get_supportive_codes(self, target_requirement: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Get supportive codes for target requirement\"\"\"\n",
    "        supportive_codes = {\n",
    "            'sub_requirement_codes': [],\n",
    "            'similar_requirement_codes': [],\n",
    "            'local_file_codes': []\n",
    "        }\n",
    "        \n",
    "        # Find relevant requirements\n",
    "        sub_reqs, similar_reqs = self.req_graph.find_relevant_requirements(target_requirement)\n",
    "        \n",
    "        # Map sub-requirements to code nodes\n",
    "        for sub_req_id in sub_reqs:\n",
    "            code_id = self.map_requirement_to_code(sub_req_id)\n",
    "            if code_id:\n",
    "                supportive_codes['sub_requirement_codes'].append(code_id)\n",
    "        \n",
    "        # Map similar requirements to code nodes\n",
    "        for similar_req_id in similar_reqs:\n",
    "            code_id = self.map_requirement_to_code(similar_req_id)\n",
    "            if code_id:\n",
    "                supportive_codes['similar_requirement_codes'].append(code_id)\n",
    "        \n",
    "        # Add local file codes (from same file as target)\n",
    "        # This is a simplified approach - in practice, you'd need to identify the target file\n",
    "        target_file = \"policy.py\"  # Simplified assumption\n",
    "        for code_id, code_node in self.code_graph.nodes.items():\n",
    "            if code_node.file_path == target_file and code_node.node_type == \"Function\":\n",
    "                supportive_codes['local_file_codes'].append(code_id)\n",
    "        \n",
    "        return supportive_codes\n",
    "    \n",
    "    def visualize_mapping(self, target_requirement: str, figsize=(16, 10)):\n",
    "        \"\"\"Visualize the bigraph mapping\"\"\"\n",
    "        supportive_codes = self.get_supportive_codes(target_requirement)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # Visualize requirement graph\n",
    "        pos1 = nx.spring_layout(self.req_graph.graph, k=2)\n",
    "        nx.draw(self.req_graph.graph, pos1, ax=ax1, \n",
    "                with_labels=True, node_color='lightblue', \n",
    "                node_size=1000, font_size=8)\n",
    "        ax1.set_title('Requirement Graph')\n",
    "        \n",
    "        # Visualize DS-code graph\n",
    "        pos2 = nx.spring_layout(self.code_graph.graph, k=2)\n",
    "        \n",
    "        # Highlight supportive codes\n",
    "        node_colors = []\n",
    "        for node_id in self.code_graph.graph.nodes():\n",
    "            if node_id in supportive_codes['sub_requirement_codes']:\n",
    "                node_colors.append('red')\n",
    "            elif node_id in supportive_codes['similar_requirement_codes']:\n",
    "                node_colors.append('orange')\n",
    "            elif node_id in supportive_codes['local_file_codes']:\n",
    "                node_colors.append('yellow')\n",
    "            else:\n",
    "                node_colors.append('lightgray')\n",
    "        \n",
    "        nx.draw(self.code_graph.graph, pos2, ax=ax2,\n",
    "                with_labels=True, node_color=node_colors,\n",
    "                node_size=1000, font_size=8)\n",
    "        ax2.set_title('DS-Code Graph\\n(Red: Sub-req codes, Orange: Similar codes, Yellow: Local codes)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return supportive_codes\n",
    "\n",
    "# Test bigraph mapping\n",
    "mapper = BigraphMapper(req_graph, ds_graph)\n",
    "supportive_codes = mapper.visualize_mapping(\"Helper function, returns True if the given resource is in the given policy statement\")\n",
    "\n",
    "print(\"\\nSupportive Codes Found:\")\n",
    "for category, codes in supportive_codes.items():\n",
    "    print(f\"{category}: {codes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 4. Code-oriented Agentic Reasoning\n",
    "\n",
    "As described in Section 3.4, we implement the agentic reasoning process with programming tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeAgenticReasoning:\n",
    "    \"\"\"Code-oriented Agentic Reasoning as described in Section 3.4\"\"\"\n",
    "    \n",
    "    def __init__(self, ds_code_graph: DSCodeGraph, llm_model=\"gpt-4\"):\n",
    "        self.code_graph = ds_code_graph\n",
    "        self.llm = ChatOpenAI(model=llm_model, temperature=0)\n",
    "        self.code_anchors = set()\n",
    "        self.setup_tools()\n",
    "        \n",
    "    def setup_tools(self):\n",
    "        \"\"\"Setup the three programming tools described in the paper\"\"\"\n",
    "        \n",
    "        # 1. Web Search Tool\n",
    "        self.web_search = DuckDuckGoSearchResults(num_results=3)\n",
    "        \n",
    "        # 2. Graph Reasoning Tool\n",
    "        def graph_reason(code_anchor: str, query: str) -> str:\n",
    "            \"\"\"Reason on DS-code graph from code anchor\"\"\"\n",
    "            if code_anchor not in self.code_graph.nodes:\n",
    "                return f\"Code anchor {code_anchor} not found in graph\"\n",
    "                \n",
    "            # Get one-hop neighbors\n",
    "            neighbors = self.code_graph.get_one_hop_neighbors(code_anchor)\n",
    "            \n",
    "            # Format neighbor information\n",
    "            neighbor_info = []\n",
    "            for neighbor_id, edge_data in neighbors:\n",
    "                neighbor_node = self.code_graph.nodes[neighbor_id]\n",
    "                edge_type = edge_data.get('edge_type', 'unknown')\n",
    "                neighbor_info.append(f\"{neighbor_node.name} ({edge_type})\")\n",
    "            \n",
    "            # Use LLM to select relevant neighbors\n",
    "            prompt = ChatPromptTemplate.from_template(\n",
    "                \"\"\"You are analyzing code dependencies. Given the anchor code and its neighbors, \n",
    "                select which neighbors are relevant for the query.\n",
    "                \n",
    "                Anchor: {anchor}\n",
    "                Query: {query}\n",
    "                Neighbors: {neighbors}\n",
    "                \n",
    "                Return the names of relevant neighbors, one per line.\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "            chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "            result = chain.run(\n",
    "                anchor=self.code_graph.nodes[code_anchor].name,\n",
    "                query=query,\n",
    "                neighbors=\"\\n\".join(neighbor_info)\n",
    "            )\n",
    "            \n",
    "            # Add relevant neighbors to code anchors\n",
    "            selected_neighbors = []\n",
    "            for line in result.strip().split('\\n'):\n",
    "                neighbor_name = line.strip()\n",
    "                for neighbor_id, _ in neighbors:\n",
    "                    if self.code_graph.nodes[neighbor_id].name == neighbor_name:\n",
    "                        self.code_anchors.add(neighbor_id)\n",
    "                        selected_neighbors.append(neighbor_id)\n",
    "                        break\n",
    "            \n",
    "            return f\"Selected neighbors: {selected_neighbors}\"\n",
    "        \n",
    "        # 3. Code Testing Tool\n",
    "        def code_test(code: str) -> str:\n",
    "            \"\"\"Test and format code using Black\"\"\"\n",
    "            try:\n",
    "                import black\n",
    "                formatted_code = black.format_str(code, mode=black.FileMode())\n",
    "                \n",
    "                # Simple syntax check\n",
    "                compile(formatted_code, '<string>', 'exec')\n",
    "                return f\"Code formatted successfully:\\n{formatted_code}\"\n",
    "            except Exception as e:\n",
    "                return f\"Code formatting/testing failed: {str(e)}\"\n",
    "        \n",
    "        # Create tools list\n",
    "        self.tools = [\n",
    "            Tool(\n",
    "                name=\"WebSearch\",\n",
    "                func=self.web_search.run,\n",
    "                description=\"Search the web for programming knowledge and solutions\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"GraphReason\",\n",
    "                func=lambda query: graph_reason(list(self.code_anchors)[-1] if self.code_anchors else \"\", query),\n",
    "                description=\"Reason on the DS-code graph to find related code snippets\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"CodeTest\",\n",
    "                func=code_test,\n",
    "                description=\"Format and test generated code\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Initialize agent with ReAct reasoning\n",
    "        self.agent = initialize_agent(\n",
    "            tools=self.tools,\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            max_iterations=5\n",
    "        )\n",
    "    \n",
    "    def generate_code(self, target_requirement: str, supportive_codes: Dict[str, List[str]]) -> str:\n",
    "        \"\"\"Generate code using agentic reasoning process\"\"\"\n",
    "        \n",
    "        # Initialize code anchors with supportive codes\n",
    "        for code_list in supportive_codes.values():\n",
    "            self.code_anchors.update(code_list)\n",
    "        \n",
    "        # Prepare context with supportive codes\n",
    "        context = \"Target Requirement: \" + target_requirement + \"\\n\\n\"\n",
    "        context += \"Supportive Codes:\\n\"\n",
    "        \n",
    "        for category, code_ids in supportive_codes.items():\n",
    "            if code_ids:\n",
    "                context += f\"\\n{category.replace('_', ' ').title()}:\\n\"\n",
    "                for code_id in code_ids:\n",
    "                    if code_id in self.code_graph.nodes:\n",
    "                        code_node = self.code_graph.nodes[code_id]\n",
    "                        context += f\"```python\\n{code_node.source_code}\\n```\\n\"\n",
    "        \n",
    "        # Create the generation prompt\n",
    "        generation_prompt = f\"\"\"\n",
    "        {context}\n",
    "        \n",
    "        Please generate Python code that satisfies the target requirement. \n",
    "        You have access to tools for web search, graph reasoning, and code testing.\n",
    "        Use the supportive codes as reference and invoke necessary functions.\n",
    "        \n",
    "        Generate the complete function implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Use agent to generate code\n",
    "            result = self.agent.run(generation_prompt)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in agentic reasoning: {e}\")\n",
    "            return self._fallback_generation(target_requirement, supportive_codes)\n",
    "    \n",
    "    def _fallback_generation(self, target_requirement: str, supportive_codes: Dict[str, List[str]]) -> str:\n",
    "        \"\"\"Fallback code generation without agent\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Generate Python code for the following requirement:\n",
    "            \n",
    "            Requirement: {requirement}\n",
    "            \n",
    "            Reference codes:\n",
    "            {references}\n",
    "            \n",
    "            Generate a complete function implementation.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Prepare references\n",
    "        references = \"\"\n",
    "        for category, code_ids in supportive_codes.items():\n",
    "            for code_id in code_ids:\n",
    "                if code_id in self.code_graph.nodes:\n",
    "                    code_node = self.code_graph.nodes[code_id]\n",
    "                    references += f\"\\n{code_node.source_code}\\n\"\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        result = chain.run(requirement=target_requirement, references=references)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Test the agentic reasoning\n",
    "agent_reasoner = CodeAgenticReasoning(ds_graph)\n",
    "\n",
    "# Generate code for the target requirement\n",
    "print(\"Generating code using CodeRAG framework...\")\n",
    "generated_code = agent_reasoner.generate_code(\n",
    "    target_requirement[\"description\"],\n",
    "    supportive_codes\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GENERATED CODE:\")\n",
    "print(\"=\"*50)\n",
    "print(generated_code)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 5. Complete CodeRAG Implementation\n",
    "\n",
    "Now let's integrate all components into a complete CodeRAG framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeRAG:\n",
    "    \"\"\"Complete CodeRAG Framework\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_model=\"gpt-4\"):\n",
    "        self.llm_model = llm_model\n",
    "        self.requirement_graph = None\n",
    "        self.ds_code_graph = None\n",
    "        self.mapper = None\n",
    "        self.agent_reasoner = None\n",
    "        \n",
    "    def build_graphs(self, repository: Dict[str, str]):\n",
    "        \"\"\"Build both requirement and DS-code graphs\"\"\"\n",
    "        print(\"Building CodeRAG graphs...\")\n",
    "        \n",
    "        # Build requirement graph\n",
    "        self.requirement_graph = RequirementGraph(self.llm_model)\n",
    "        self.requirement_graph.build_requirement_graph(repository)\n",
    "        \n",
    "        # Build DS-code graph\n",
    "        self.ds_code_graph = DSCodeGraph()\n",
    "        self.ds_code_graph.build_ds_code_graph(repository)\n",
    "        \n",
    "        # Initialize mapper and agent reasoner\n",
    "        self.mapper = BigraphMapper(self.requirement_graph, self.ds_code_graph)\n",
    "        self.agent_reasoner = CodeAgenticReasoning(self.ds_code_graph, self.llm_model)\n",
    "        \n",
    "        print(\"CodeRAG graphs built successfully!\")\n",
    "    \n",
    "    def generate_code(self, target_requirement: str, signature: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Generate code using the complete CodeRAG pipeline\"\"\"\n",
    "        if not all([self.requirement_graph, self.ds_code_graph, self.mapper, self.agent_reasoner]):\n",
    "            raise ValueError(\"Graphs not built. Call build_graphs() first.\")\n",
    "        \n",
    "        results = {\n",
    "            'target_requirement': target_requirement,\n",
    "            'signature': signature,\n",
    "            'supportive_codes': {},\n",
    "            'generated_code': '',\n",
    "            'reasoning_steps': []\n",
    "        }\n",
    "        \n",
    "        # Step 1: Find supportive codes through bigraph mapping\n",
    "        print(\"Step 1: Finding supportive codes...\")\n",
    "        supportive_codes = self.mapper.get_supportive_codes(target_requirement)\n",
    "        results['supportive_codes'] = supportive_codes\n",
    "        results['reasoning_steps'].append(\"Retrieved supportive codes via bigraph mapping\")\n",
    "        \n",
    "        # Step 2: Generate code using agentic reasoning\n",
    "        print(\"Step 2: Generating code with agentic reasoning...\")\n",
    "        generated_code = self.agent_reasoner.generate_code(target_requirement, supportive_codes)\n",
    "        results['generated_code'] = generated_code\n",
    "        results['reasoning_steps'].append(\"Generated code using agentic reasoning with tools\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_generation(self, results: Dict[str, Any], expected_code: str = \"\") -> Dict[str, float]:\n",
    "        \"\"\"Evaluate the generated code\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Syntax check\n",
    "        try:\n",
    "            compile(results['generated_code'], '<string>', 'exec')\n",
    "            metrics['syntax_correct'] = 1.0\n",
    "        except:\n",
    "            metrics['syntax_correct'] = 0.0\n",
    "        \n",
    "        # Code similarity (if expected code provided)\n",
    "        if expected_code:\n",
    "            from difflib import SequenceMatcher\n",
    "            similarity = SequenceMatcher(None, results['generated_code'], expected_code).ratio()\n",
    "            metrics['code_similarity'] = similarity\n",
    "        \n",
    "        # Count supportive codes used\n",
    "        total_supportive = sum(len(codes) for codes in results['supportive_codes'].values())\n",
    "        metrics['supportive_codes_count'] = total_supportive\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def visualize_pipeline(self, target_requirement: str, figsize=(20, 12)):\n",
    "        \"\"\"Visualize the complete CodeRAG pipeline\"\"\"\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Requirement Graph\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        pos1 = nx.spring_layout(self.requirement_graph.graph, k=1)\n",
    "        nx.draw(self.requirement_graph.graph, pos1, ax=ax1, \n",
    "                with_labels=True, node_color='lightblue', \n",
    "                node_size=800, font_size=6)\n",
    "        ax1.set_title('Requirement Graph', fontsize=12)\n",
    "        \n",
    "        # DS-Code Graph\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        pos2 = nx.spring_layout(self.ds_code_graph.graph, k=1)\n",
    "        nx.draw(self.ds_code_graph.graph, pos2, ax=ax2,\n",
    "                with_labels=True, node_color='lightgreen',\n",
    "                node_size=800, font_size=6)\n",
    "        ax2.set_title('DS-Code Graph', fontsize=12)\n",
    "        \n",
    "        # Bigraph Mapping\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        supportive_codes = self.mapper.get_supportive_codes(target_requirement)\n",
    "        \n",
    "        # Create a simple visualization of mapping\n",
    "        categories = list(supportive_codes.keys())\n",
    "        counts = [len(codes) for codes in supportive_codes.values()]\n",
    "        ax3.bar(categories, counts, color=['red', 'orange', 'yellow'])\n",
    "        ax3.set_title('Supportive Codes\\nFound', fontsize=12)\n",
    "        ax3.set_xlabel('Code Type')\n",
    "        ax3.set_ylabel('Count')\n",
    "        plt.setp(ax3.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "        \n",
    "        # Code Generation Process\n",
    "        ax4 = fig.add_subplot(gs[1, :])\n",
    "        \n",
    "        # Generate code for visualization\n",
    "        results = self.generate_code(target_requirement)\n",
    "        \n",
    "        # Show the reasoning steps and generated code\n",
    "        process_text = \"CodeRAG Pipeline Execution:\\n\\n\"\n",
    "        process_text += f\"Target: {target_requirement}\\n\\n\"\n",
    "        \n",
    "        for i, step in enumerate(results['reasoning_steps'], 1):\n",
    "            process_text += f\"{i}. {step}\\n\"\n",
    "        \n",
    "        process_text += f\"\\nGenerated Code:\\n{results['generated_code'][:200]}...\"\n",
    "        \n",
    "        ax4.text(0.05, 0.95, process_text, transform=ax4.transAxes, \n",
    "                fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "        ax4.set_xlim(0, 1)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.axis('off')\n",
    "        ax4.set_title('Code Generation Process', fontsize=12)\n",
    "        \n",
    "        plt.suptitle('CodeRAG: Complete Pipeline Visualization', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize and test complete CodeRAG\n",
    "coderag = CodeRAG(llm_model=\"gpt-3.5-turbo\")  # Using gpt-3.5-turbo for demo\n",
    "coderag.build_graphs(sample_repo)\n",
    "\n",
    "# Visualize the complete pipeline\n",
    "results = coderag.visualize_pipeline(target_requirement[\"description\"])\n",
    "\n",
    "# Evaluate the generation\n",
    "metrics = coderag.evaluate_generation(results, target_requirement[\"expected_code\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CODERAG EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 6. Evaluation with DeepEval\n",
    "\n",
    "Let's evaluate our CodeRAG implementation using DeepEval metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deepeval if not already installed\n",
    "try:\n",
    "    import deepeval\n",
    "except ImportError:\n",
    "    !pip install deepeval\n",
    "    import deepeval\n",
    "\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric, ContextualRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "class CodeRAGEvaluator:\n",
    "    \"\"\"Comprehensive evaluation of CodeRAG using DeepEval\"\"\"\n",
    "    \n",
    "    def __init__(self, coderag_instance: CodeRAG):\n",
    "        self.coderag = coderag_instance\n",
    "        \n",
    "    def create_test_cases(self, test_requirements: List[Dict]) -> List[LLMTestCase]:\n",
    "        \"\"\"Create test cases for evaluation\"\"\"\n",
    "        test_cases = []\n",
    "        \n",
    "        for req_data in test_requirements:\n",
    "            # Generate code using CodeRAG\n",
    "            results = self.coderag.generate_code(\n",
    "                req_data['requirement'], \n",
    "                req_data.get('signature', '')\n",
    "            )\n",
    "            \n",
    "            # Prepare context from supportive codes\n",
    "            context = []\n",
    "            for category, code_ids in results['supportive_codes'].items():\n",
    "                for code_id in code_ids:\n",
    "                    if code_id in self.coderag.ds_code_graph.nodes:\n",
    "                        code_node = self.coderag.ds_code_graph.nodes[code_id]\n",
    "                        context.append(code_node.source_code)\n",
    "            \n",
    "            # Create test case\n",
    "            test_case = LLMTestCase(\n",
    "                input=req_data['requirement'],\n",
    "                actual_output=results['generated_code'],\n",
    "                expected_output=req_data.get('expected_code', ''),\n",
    "                retrieval_context=context\n",
    "            )\n",
    "            test_cases.append(test_case)\n",
    "            \n",
    "        return test_cases\n",
    "    \n",
    "    def evaluate_coderag(self, test_requirements: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Comprehensive evaluation of CodeRAG\"\"\"\n",
    "        print(\"Creating test cases...\")\n",
    "        test_cases = self.create_test_cases(test_requirements)\n",
    "        \n",
    "        # Define metrics\n",
    "        metrics = [\n",
    "            AnswerRelevancyMetric(threshold=0.7),\n",
    "            FaithfulnessMetric(threshold=0.7),\n",
    "            ContextualRelevancyMetric(threshold=0.7)\n",
    "        ]\n",
    "        \n",
    "        # Evaluate\n",
    "        print(\"Running evaluation...\")\n",
    "        results = evaluate(test_cases, metrics)\n",
    "        \n",
    "        # Compile results\n",
    "        evaluation_results = {}\n",
    "        for metric in metrics:\n",
    "            metric_name = metric.__class__.__name__\n",
    "            scores = [getattr(tc, metric_name.lower().replace('metric', ''), 0) for tc in test_cases]\n",
    "            evaluation_results[metric_name] = np.mean(scores) if scores else 0.0\n",
    "        \n",
    "        return evaluation_results\n",
    "    \n",
    "    def compare_with_baselines(self, test_requirements: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"Compare CodeRAG with baseline approaches\"\"\"\n",
    "        results_data = []\n",
    "        \n",
    "        for req_data in test_requirements:\n",
    "            requirement = req_data['requirement']\n",
    "            expected = req_data.get('expected_code', '')\n",
    "            \n",
    "            # CodeRAG results\n",
    "            coderag_results = self.coderag.generate_code(requirement)\n",
    "            coderag_metrics = self.coderag.evaluate_generation(coderag_results, expected)\n",
    "            \n",
    "            # Simulate baseline results (in practice, you'd implement actual baselines)\n",
    "            baseline_results = {\n",
    "                'BM25-RAG': {'syntax_correct': 0.6, 'code_similarity': 0.4},\n",
    "                'Embedding-RAG': {'syntax_correct': 0.7, 'code_similarity': 0.5},\n",
    "                'No-RAG': {'syntax_correct': 0.5, 'code_similarity': 0.3}\n",
    "            }\n",
    "            \n",
    "            # Compile results\n",
    "            for method, metrics in baseline_results.items():\n",
    "                results_data.append({\n",
    "                    'Method': method,\n",
    "                    'Requirement': requirement[:50] + '...',\n",
    "                    'Syntax_Correct': metrics['syntax_correct'],\n",
    "                    'Code_Similarity': metrics['code_similarity']\n",
    "                })\n",
    "            \n",
    "            # Add CodeRAG results\n",
    "            results_data.append({\n",
    "                'Method': 'CodeRAG',\n",
    "                'Requirement': requirement[:50] + '...',\n",
    "                'Syntax_Correct': coderag_metrics.get('syntax_correct', 0),\n",
    "                'Code_Similarity': coderag_metrics.get('code_similarity', 0)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results_data)\n",
    "    \n",
    "    def visualize_results(self, comparison_df: pd.DataFrame):\n",
    "        \"\"\"Visualize evaluation results\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Syntax correctness comparison\n",
    "        syntax_results = comparison_df.groupby('Method')['Syntax_Correct'].mean()\n",
    "        syntax_results.plot(kind='bar', ax=ax1, color='lightblue')\n",
    "        ax1.set_title('Syntax Correctness by Method')\n",
    "        ax1.set_ylabel('Syntax Correctness Rate')\n",
    "        ax1.set_xlabel('Method')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Code similarity comparison\n",
    "        similarity_results = comparison_df.groupby('Method')['Code_Similarity'].mean()\n",
    "        similarity_results.plot(kind='bar', ax=ax2, color='lightgreen')\n",
    "        ax2.set_title('Code Similarity by Method')\n",
    "        ax2.set_ylabel('Code Similarity Score')\n",
    "        ax2.set_xlabel('Method')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nSUMMARY STATISTICS:\")\n",
    "        print(\"=\"*50)\n",
    "        summary = comparison_df.groupby('Method')[['Syntax_Correct', 'Code_Similarity']].mean()\n",
    "        print(summary)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "# Create test requirements\n",
    "test_requirements = [\n",
    "    {\n",
    "        'requirement': 'Helper function, returns True if the given resource is in the given policy statement',\n",
    "        'signature': 'def _statement_matches_resource(statement, resource, condition_keys=None):',\n",
    "        'expected_code': target_requirement['expected_code']\n",
    "    },\n",
    "    {\n",
    "        'requirement': 'Helper function that converts a single item to a list if it is not already a list',\n",
    "        'signature': 'def _listify_string(target_object):',\n",
    "        'expected_code': '''def _listify_string(target_object):\n",
    "    if isinstance(target_object, list):\n",
    "        return target_object\n",
    "    return [target_object]'''\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run evaluation\n",
    "evaluator = CodeRAGEvaluator(coderag)\n",
    "\n",
    "# Compare with baselines\n",
    "print(\"Comparing CodeRAG with baseline methods...\")\n",
    "comparison_results = evaluator.compare_with_baselines(test_requirements)\n",
    "evaluator.visualize_results(comparison_results)\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nDETAILED COMPARISON:\")\n",
    "print(comparison_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 7. Performance Analysis and Insights\n",
    "\n",
    "Let's analyze the performance characteristics of our CodeRAG implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coderag_performance():\n",
    "    \"\"\"Analyze various aspects of CodeRAG performance\"\"\"\n",
    "    \n",
    "    # Create synthetic performance data based on paper results\n",
    "    performance_data = {\n",
    "        'Method': ['ScratchCG', 'BM25-RAG', 'Embedding-RAG', 'RepoCoder', 'CodeAgent', 'CodeRAG'],\n",
    "        'GPT-4o_Pass@1': [17.24, 27.07, 40.43, 30.95, 28.66, 58.14],\n",
    "        'Gemini-Pro_Pass@1': [14.95, 36.60, 39.34, 30.36, 33.09, 54.74]\n",
    "    }\n",
    "    \n",
    "    dependency_performance = {\n",
    "        'Dependency_Type': ['Standalone', 'Non-standalone', 'Local-file', 'Local&Cross-file', 'Cross-file'],\n",
    "        'CodeRAG': [60.16, 48.24, 69.67, 45.18, 43.31],\n",
    "        'Embedding-RAG': [50.19, 39.79, 46.81, 25.04, 21.66],\n",
    "        'ScratchCG': [29.28, 9.74, 12.08, 7.88, 18.47]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrames\n",
    "    perf_df = pd.DataFrame(performance_data)\n",
    "    dep_df = pd.DataFrame(dependency_performance)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Overall performance comparison\n",
    "    x = np.arange(len(perf_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, perf_df['GPT-4o_Pass@1'], width, label='GPT-4o', alpha=0.8)\n",
    "    ax1.bar(x + width/2, perf_df['Gemini-Pro_Pass@1'], width, label='Gemini-Pro', alpha=0.8)\n",
    "    ax1.set_xlabel('Method')\n",
    "    ax1.set_ylabel('Pass@1 Score')\n",
    "    ax1.set_title('CodeRAG vs Baselines: Overall Performance')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(perf_df['Method'], rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement over baseline\n",
    "    improvements_gpt4o = perf_df['GPT-4o_Pass@1'] - perf_df['GPT-4o_Pass@1'].iloc[0]\n",
    "    improvements_gemini = perf_df['Gemini-Pro_Pass@1'] - perf_df['Gemini-Pro_Pass@1'].iloc[0]\n",
    "    \n",
    "    ax2.bar(x - width/2, improvements_gpt4o, width, label='GPT-4o Improvement', alpha=0.8)\n",
    "    ax2.bar(x + width/2, improvements_gemini, width, label='Gemini-Pro Improvement', alpha=0.8)\n",
    "    ax2.set_xlabel('Method')\n",
    "    ax2.set_ylabel('Improvement over ScratchCG')\n",
    "    ax2.set_title('Performance Improvements')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(perf_df['Method'], rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dependency type performance\n",
    "    x_dep = np.arange(len(dep_df))\n",
    "    width_dep = 0.25\n",
    "    \n",
    "    ax3.bar(x_dep - width_dep, dep_df['CodeRAG'], width_dep, label='CodeRAG', alpha=0.8)\n",
    "    ax3.bar(x_dep, dep_df['Embedding-RAG'], width_dep, label='Embedding-RAG', alpha=0.8)\n",
    "    ax3.bar(x_dep + width_dep, dep_df['ScratchCG'], width_dep, label='ScratchCG', alpha=0.8)\n",
    "    ax3.set_xlabel('Dependency Type')\n",
    "    ax3.set_ylabel('Pass@1 Score')\n",
    "    ax3.set_title('Performance by Dependency Type')\n",
    "    ax3.set_xticks(x_dep)\n",
    "    ax3.set_xticklabels(dep_df['Dependency_Type'], rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Component contribution (from ablation study)\n",
    "    components = ['Full CodeRAG', 'w/o WebSearch', 'w/o CodeTest', 'w/o GraphReason']\n",
    "    performance = [58.14, 57.85, 57.09, 51.83]\n",
    "    colors = ['green', 'orange', 'orange', 'red']\n",
    "    \n",
    "    bars = ax4.bar(components, performance, color=colors, alpha=0.7)\n",
    "    ax4.set_xlabel('Configuration')\n",
    "    ax4.set_ylabel('Pass@1 Score')\n",
    "    ax4.set_title('Component Contribution Analysis')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance annotations\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax4.annotate(f'{height:.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key insights\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CODERAG PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n📊 Key Performance Metrics:\")\n",
    "    print(f\"• GPT-4o improvement: +{improvements_gpt4o.iloc[-1]:.2f} Pass@1\")\n",
    "    print(f\"• Gemini-Pro improvement: +{improvements_gemini.iloc[-1]:.2f} Pass@1\")\n",
    "    print(f\"• Best performance on: {dep_df.loc[dep_df['CodeRAG'].idxmax(), 'Dependency_Type']} dependency\")\n",
    "    print(f\"• Most challenging scenario: {dep_df.loc[dep_df['CodeRAG'].idxmin(), 'Dependency_Type']} dependency\")\n",
    "    \n",
    "    print(\"\\n🔧 Component Impact:\")\n",
    "    print(f\"• Graph Reasoning contributes: {performance[0] - performance[3]:.2f} points\")\n",
    "    print(f\"• Code Testing contributes: {performance[0] - performance[2]:.2f} points\")\n",
    "    print(f\"• Web Search contributes: {performance[0] - performance[1]:.2f} points\")\n",
    "    \n",
    "    print(\"\\n🎯 Key Insights:\")\n",
    "    print(\"• CodeRAG excels in complex dependency scenarios\")\n",
    "    print(\"• Graph reasoning is the most critical component\")\n",
    "    print(\"• Significant improvements over traditional RAG approaches\")\n",
    "    print(\"• Consistent performance across different LLM models\")\n",
    "    \n",
    "    return perf_df, dep_df\n",
    "\n",
    "# Run performance analysis\n",
    "perf_df, dep_df = analyze_coderag_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 8. Research Template and Future Directions\n",
    "\n",
    "This section provides a template for further research and potential improvements to CodeRAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Template for CodeRAG Extensions\n",
    "\n",
    "class CodeRAGResearchTemplate:\n",
    "    \"\"\"Template for extending CodeRAG research\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.research_directions = {\n",
    "            'graph_enhancements': [\n",
    "                'Dynamic graph updating during development',\n",
    "                'Multi-language support for graph construction',\n",
    "                'Weighted edges based on code importance',\n",
    "                'Temporal relationships in code evolution'\n",
    "            ],\n",
    "            'reasoning_improvements': [\n",
    "                'Multi-step reasoning with planning',\n",
    "                'Collaborative multi-agent reasoning',\n",
    "                'Learning from generation feedback',\n",
    "                'Adaptive tool selection strategies'\n",
    "            ],\n",
    "            'evaluation_metrics': [\n",
    "                'Code quality metrics beyond syntax',\n",
    "                'Maintainability and readability scores',\n",
    "                'Integration complexity measures',\n",
    "                'Performance impact assessment'\n",
    "            ],\n",
    "            'domain_extensions': [\n",
    "                'Specialized domain knowledge integration',\n",
    "                'Cross-domain code pattern transfer',\n",
    "                'Domain-specific reasoning strategies',\n",
    "                'Industry-specific code standards'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def propose_experiment(self, direction: str, hypothesis: str, methodology: str):\n",
    "        \"\"\"Template for proposing new experiments\"\"\"\n",
    "        experiment = {\n",
    "            'direction': direction,\n",
    "            'hypothesis': hypothesis,\n",
    "            'methodology': methodology,\n",
    "            'expected_outcomes': [],\n",
    "            'evaluation_plan': [],\n",
    "            'timeline': ''\n",
    "        }\n",
    "        return experiment\n",
    "    \n",
    "    def generate_research_questions(self):\n",
    "        \"\"\"Generate potential research questions\"\"\"\n",
    "        questions = [\n",
    "            \"How can CodeRAG be adapted for real-time collaborative coding?\",\n",
    "            \"What impact does code repository size have on retrieval effectiveness?\",\n",
    "            \"How can we incorporate user feedback to improve code generation?\",\n",
    "            \"What are the optimal graph construction strategies for different programming paradigms?\",\n",
    "            \"How can CodeRAG be extended to support code refactoring tasks?\",\n",
    "            \"What role does code documentation quality play in requirement graph effectiveness?\",\n",
    "            \"How can we measure and improve the explainability of CodeRAG decisions?\",\n",
    "            \"What are the computational trade-offs in different graph reasoning strategies?\"\n",
    "        ]\n",
    "        return questions\n",
    "    \n",
    "    def create_benchmark_suite(self):\n",
    "        \"\"\"Template for creating comprehensive benchmarks\"\"\"\n",
    "        benchmark = {\n",
    "            'name': 'CodeRAG-Benchmark',\n",
    "            'categories': [\n",
    "                'Simple function generation',\n",
    "                'Complex algorithm implementation',\n",
    "                'API integration tasks',\n",
    "                'Refactoring challenges',\n",
    "                'Cross-file dependency resolution'\n",
    "            ],\n",
    "            'metrics': [\n",
    "                'Functional correctness',\n",
    "                'Code quality',\n",
    "                'Performance efficiency',\n",
    "                'Maintainability',\n",
    "                'Security compliance'\n",
    "            ],\n",
    "            'datasets': [\n",
    "                'Open-source repositories',\n",
    "                'Industrial codebases',\n",
    "                'Educational programming exercises',\n",
    "                'Domain-specific applications'\n",
    "            ]\n",
    "        }\n",
    "        return benchmark\n",
    "\n",
    "# Initialize research template\n",
    "research_template = CodeRAGResearchTemplate()\n",
    "\n",
    "# Display research directions\n",
    "print(\"🔬 FUTURE RESEARCH DIRECTIONS FOR CODERAG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for direction, topics in research_template.research_directions.items():\n",
    "    print(f\"\\n📋 {direction.replace('_', ' ').title()}:\")\n",
    "    for i, topic in enumerate(topics, 1):\n",
    "        print(f\"   {i}. {topic}\")\n",
    "\n",
    "print(\"\\n🤔 POTENTIAL RESEARCH QUESTIONS:\")\n",
    "print(\"=\"*60)\n",
    "questions = research_template.generate_research_questions()\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "print(\"\\n📊 BENCHMARK SUITE PROPOSAL:\")\n",
    "print(\"=\"*60)\n",
    "benchmark = research_template.create_benchmark_suite()\n",
    "for key, value in benchmark.items():\n",
    "    print(f\"\\n{key.title()}:\")\n",
    "    if isinstance(value, list):\n",
    "        for item in value:\n",
    "            print(f\"  • {item}\")\n",
    "    else:\n",
    "        print(f\"  {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"This notebook provides a comprehensive implementation of CodeRAG,\")\n",
    "print(\"including all major components and evaluation frameworks.\")\n",
    "print(\"Use this as a foundation for further research and development.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}