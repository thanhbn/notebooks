{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focused Learning: Synthetic Data Generation with GPT Translation\n",
    "\n",
    "## Learning Objective\n",
    "Master the techniques for generating high-quality synthetic programming language datasets through translation, as described in Section III.D (KExercises dataset) of the paper.\n",
    "\n",
    "## Paper Reference\n",
    "- **Section**: III.D - KExercises: Kotlin instructions dataset\n",
    "- **Key Result**: Synthetic dataset (KExercises) achieved best performance (55.28% pass rate)\n",
    "- **Method**: GPT-3.5-turbo translation from Python exercises to Kotlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Challenge: Low-Resource Languages\n",
    "\n",
    "### 1.1 Why Synthetic Data?\n",
    "\n",
    "From the paper: \"Kotlin could be considered a low-resource language due to the scarcity of publicly available data and the limited opportunities for improvement using data collected from open-source projects.\"\n",
    "\n",
    "Key challenges:\n",
    "- Limited public Kotlin repositories\n",
    "- Most Kotlin code is in private/enterprise repositories\n",
    "- Need diverse examples covering various programming concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# LangChain imports for translation pipeline\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Source: Python Exercises Dataset\n",
    "\n",
    "### 2.1 Characteristics of Good Exercise Data\n",
    "\n",
    "According to Gunasekar et al. (referenced in the paper), synthetic data should:\n",
    "- Cover broad spectrum of coding concepts\n",
    "- Vary in difficulty and complexity\n",
    "- Include diverse coding styles\n",
    "- Have clear problem statements and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CodeExercise:\n",
    "    \"\"\"Represents a programming exercise for translation\"\"\"\n",
    "    id: str\n",
    "    description: str\n",
    "    python_code: str\n",
    "    difficulty: str  # easy, medium, hard\n",
    "    concepts: List[str]  # e.g., ['loops', 'arrays', 'sorting']\n",
    "    test_cases: Optional[List[Dict]] = None\n",
    "\n",
    "# Example exercises covering different concepts\n",
    "sample_exercises = [\n",
    "    CodeExercise(\n",
    "        id=\"ex001\",\n",
    "        description=\"\"\"Write a function that finds the maximum difference between any two elements in an array,\n",
    "where the larger element appears after the smaller element.\"\"\",\n",
    "        python_code=\"\"\"def max_profit(prices: List[int]) -> int:\n",
    "    '''Find maximum profit from buying and selling stock.\n",
    "    \n",
    "    Args:\n",
    "        prices: List of daily stock prices\n",
    "        \n",
    "    Returns:\n",
    "        Maximum profit possible (0 if no profit)\n",
    "    '''\n",
    "    if not prices:\n",
    "        return 0\n",
    "    \n",
    "    min_price = prices[0]\n",
    "    max_profit = 0\n",
    "    \n",
    "    for price in prices[1:]:\n",
    "        if price < min_price:\n",
    "            min_price = price\n",
    "        else:\n",
    "            max_profit = max(max_profit, price - min_price)\n",
    "    \n",
    "    return max_profit\"\"\",\n",
    "        difficulty=\"medium\",\n",
    "        concepts=[\"arrays\", \"dynamic_programming\", \"optimization\"]\n",
    "    ),\n",
    "    \n",
    "    CodeExercise(\n",
    "        id=\"ex002\",\n",
    "        description=\"\"\"Implement a function that checks if a string is a valid palindrome,\n",
    "considering only alphanumeric characters and ignoring case.\"\"\",\n",
    "        python_code=\"\"\"def is_palindrome(s: str) -> bool:\n",
    "    '''Check if string is a palindrome (alphanumeric only).\n",
    "    \n",
    "    Args:\n",
    "        s: Input string\n",
    "        \n",
    "    Returns:\n",
    "        True if palindrome, False otherwise\n",
    "    '''\n",
    "    # Filter alphanumeric and convert to lowercase\n",
    "    cleaned = ''.join(c.lower() for c in s if c.isalnum())\n",
    "    \n",
    "    # Check palindrome\n",
    "    return cleaned == cleaned[::-1]\"\"\",\n",
    "        difficulty=\"easy\",\n",
    "        concepts=[\"strings\", \"two_pointers\"]\n",
    "    ),\n",
    "    \n",
    "    CodeExercise(\n",
    "        id=\"ex003\",\n",
    "        description=\"\"\"Design a class that implements a Least Recently Used (LRU) cache\n",
    "with get and put operations in O(1) time complexity.\"\"\",\n",
    "        python_code=\"\"\"from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    '''Least Recently Used cache implementation.\n",
    "    \n",
    "    Supports get and put operations in O(1) time.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.cache = OrderedDict()\n",
    "    \n",
    "    def get(self, key: int) -> int:\n",
    "        '''Get value for key, -1 if not exists.'''\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        # Move to end (most recent)\n",
    "        self.cache.move_to_end(key)\n",
    "        return self.cache[key]\n",
    "    \n",
    "    def put(self, key: int, value: int) -> None:\n",
    "        '''Put key-value pair in cache.'''\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "        self.cache[key] = value\n",
    "        if len(self.cache) > self.capacity:\n",
    "            # Remove least recently used\n",
    "            self.cache.popitem(last=False)\"\"\",\n",
    "        difficulty=\"hard\",\n",
    "        concepts=[\"data_structures\", \"design\", \"optimization\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Analyze exercise distribution\n",
    "def analyze_exercise_distribution(exercises: List[CodeExercise]):\n",
    "    \"\"\"Analyze the distribution of exercises by difficulty and concepts\"\"\"\n",
    "    difficulties = Counter(ex.difficulty for ex in exercises)\n",
    "    all_concepts = []\n",
    "    for ex in exercises:\n",
    "        all_concepts.extend(ex.concepts)\n",
    "    concept_counts = Counter(all_concepts)\n",
    "    \n",
    "    return difficulties, concept_counts\n",
    "\n",
    "difficulties, concepts = analyze_exercise_distribution(sample_exercises)\n",
    "print(\"Exercise Distribution:\")\n",
    "print(f\"Difficulties: {dict(difficulties)}\")\n",
    "print(f\"Top concepts: {dict(list(concepts.most_common(5)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Translation Pipeline\n",
    "\n",
    "### 3.1 Translation Prompt from the Paper\n",
    "\n",
    "The paper provides the exact prompt used (Figure 2):\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "User: Rewrite to Kotlin (do not forget about docstring):\n",
    "\n",
    "PYTHON_CODE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KotlinTranslator:\n",
    "    \"\"\"Translates Python exercises to Kotlin following the paper's approach\"\"\"\n",
    "    \n",
    "    def __init__(self, use_mock=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            use_mock: If True, use mock translations for demonstration\n",
    "        \"\"\"\n",
    "        self.use_mock = use_mock\n",
    "        \n",
    "        if not use_mock:\n",
    "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "        \n",
    "        # Exact prompt from the paper\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "            HumanMessage(content=\"\"\"Rewrite to Kotlin (do not forget about docstring):\n",
    "\n",
    "{python_code}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        if not use_mock:\n",
    "            self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "    \n",
    "    def translate(self, exercise: CodeExercise) -> Dict[str, str]:\n",
    "        \"\"\"Translate a Python exercise to Kotlin\"\"\"\n",
    "        if self.use_mock:\n",
    "            return self._mock_translate(exercise)\n",
    "        else:\n",
    "            kotlin_code = self.chain.run(python_code=exercise.python_code)\n",
    "            return {\n",
    "                'kotlin_code': kotlin_code,\n",
    "                'status': 'success'\n",
    "            }\n",
    "    \n",
    "    def _mock_translate(self, exercise: CodeExercise) -> Dict[str, str]:\n",
    "        \"\"\"Mock translation for demonstration\"\"\"\n",
    "        # Create realistic Kotlin translations\n",
    "        translations = {\n",
    "            \"ex001\": \"\"\"fun maxProfit(prices: IntArray): Int {\n",
    "    /**\n",
    "     * Find maximum profit from buying and selling stock.\n",
    "     * \n",
    "     * @param prices List of daily stock prices\n",
    "     * @return Maximum profit possible (0 if no profit)\n",
    "     */\n",
    "    if (prices.isEmpty()) {\n",
    "        return 0\n",
    "    }\n",
    "    \n",
    "    var minPrice = prices[0]\n",
    "    var maxProfit = 0\n",
    "    \n",
    "    for (i in 1 until prices.size) {\n",
    "        val price = prices[i]\n",
    "        if (price < minPrice) {\n",
    "            minPrice = price\n",
    "        } else {\n",
    "            maxProfit = maxOf(maxProfit, price - minPrice)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return maxProfit\n",
    "}\"\"\",\n",
    "            \n",
    "            \"ex002\": \"\"\"fun isPalindrome(s: String): Boolean {\n",
    "    /**\n",
    "     * Check if string is a palindrome (alphanumeric only).\n",
    "     * \n",
    "     * @param s Input string\n",
    "     * @return True if palindrome, false otherwise\n",
    "     */\n",
    "    // Filter alphanumeric and convert to lowercase\n",
    "    val cleaned = s.filter { it.isLetterOrDigit() }.lowercase()\n",
    "    \n",
    "    // Check palindrome\n",
    "    return cleaned == cleaned.reversed()\n",
    "}\"\"\",\n",
    "            \n",
    "            \"ex003\": \"\"\"class LRUCache(private val capacity: Int) {\n",
    "    /**\n",
    "     * Least Recently Used cache implementation.\n",
    "     * \n",
    "     * Supports get and put operations in O(1) time.\n",
    "     */\n",
    "    \n",
    "    private val cache = LinkedHashMap<Int, Int>(capacity + 1, 0.75f, true)\n",
    "    \n",
    "    fun get(key: Int): Int {\n",
    "        /**\n",
    "         * Get value for key, -1 if not exists.\n",
    "         */\n",
    "        return cache[key] ?: -1\n",
    "    }\n",
    "    \n",
    "    fun put(key: Int, value: Int) {\n",
    "        /**\n",
    "         * Put key-value pair in cache.\n",
    "         */\n",
    "        cache[key] = value\n",
    "        if (cache.size > capacity) {\n",
    "            // Remove least recently used (first entry)\n",
    "            val iterator = cache.keys.iterator()\n",
    "            iterator.next()\n",
    "            iterator.remove()\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'kotlin_code': translations.get(exercise.id, \"// Translation not available\"),\n",
    "            'status': 'success'\n",
    "        }\n",
    "    \n",
    "    def batch_translate(self, exercises: List[CodeExercise], \n",
    "                       monitor_quality: bool = True) -> List[Dict]:\n",
    "        \"\"\"Translate multiple exercises with quality monitoring\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for exercise in exercises:\n",
    "            result = self.translate(exercise)\n",
    "            \n",
    "            if monitor_quality:\n",
    "                # Add quality metrics\n",
    "                result['quality_score'] = self._assess_translation_quality(\n",
    "                    exercise.python_code, \n",
    "                    result['kotlin_code']\n",
    "                )\n",
    "            \n",
    "            result['exercise_id'] = exercise.id\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _assess_translation_quality(self, python_code: str, kotlin_code: str) -> float:\n",
    "        \"\"\"Simple heuristic for translation quality\"\"\"\n",
    "        score = 1.0\n",
    "        \n",
    "        # Check for proper Kotlin documentation\n",
    "        if '/**' not in kotlin_code:\n",
    "            score -= 0.2\n",
    "        \n",
    "        # Check for Kotlin idioms\n",
    "        kotlin_idioms = ['fun ', 'val ', 'var ', 'when ', 'lateinit', 'companion object']\n",
    "        idiom_count = sum(1 for idiom in kotlin_idioms if idiom in kotlin_code)\n",
    "        score = min(score + idiom_count * 0.05, 1.0)\n",
    "        \n",
    "        # Check structure preservation\n",
    "        python_lines = len(python_code.split('\\n'))\n",
    "        kotlin_lines = len(kotlin_code.split('\\n'))\n",
    "        if abs(python_lines - kotlin_lines) / python_lines > 0.5:\n",
    "            score -= 0.1\n",
    "        \n",
    "        return max(score, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Translation in Action\n",
    "\n",
    "Let's demonstrate the translation process and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create translator and translate exercises\n",
    "translator = KotlinTranslator(use_mock=True)\n",
    "translation_results = translator.batch_translate(sample_exercises)\n",
    "\n",
    "# Display translations side by side\n",
    "for i, (exercise, result) in enumerate(zip(sample_exercises, translation_results)):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Exercise {i+1}: {exercise.description[:60]}...\")\n",
    "    print(f\"Difficulty: {exercise.difficulty} | Concepts: {', '.join(exercise.concepts)}\")\n",
    "    print(f\"Quality Score: {result['quality_score']:.2f}\")\n",
    "    print(f\"\\n{'Python':-^40} | {'Kotlin':-^40}\")\n",
    "    print(\"-\" * 81)\n",
    "    \n",
    "    # Split and display code side by side\n",
    "    python_lines = exercise.python_code.split('\\n')\n",
    "    kotlin_lines = result['kotlin_code'].split('\\n')\n",
    "    \n",
    "    max_lines = max(len(python_lines), len(kotlin_lines))\n",
    "    for j in range(min(10, max_lines)):  # Show first 10 lines\n",
    "        py_line = python_lines[j] if j < len(python_lines) else \"\"\n",
    "        kt_line = kotlin_lines[j] if j < len(kotlin_lines) else \"\"\n",
    "        print(f\"{py_line[:40]:<40} | {kt_line[:40]:<40}\")\n",
    "    \n",
    "    if max_lines > 10:\n",
    "        print(f\"{'...':<40} | {'...':<40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Control and Validation\n",
    "\n",
    "### 5.1 Paper's Approach\n",
    "\n",
    "From Section III.D: \"We iteratively translated segments of data and monitored the downstream Kotlin generation quality during validation. Additionally, after the translation, we manually reviewed a sample of the data to ensure the accuracy of the translations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationValidator:\n",
    "    \"\"\"Validates translated Kotlin code quality\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.validation_rules = [\n",
    "            self._check_syntax_markers,\n",
    "            self._check_documentation,\n",
    "            self._check_kotlin_idioms,\n",
    "            self._check_type_safety,\n",
    "            self._check_null_safety\n",
    "        ]\n",
    "    \n",
    "    def validate(self, kotlin_code: str) -> Dict[str, any]:\n",
    "        \"\"\"Run all validation checks on Kotlin code\"\"\"\n",
    "        results = {\n",
    "            'valid': True,\n",
    "            'issues': [],\n",
    "            'warnings': [],\n",
    "            'score': 1.0\n",
    "        }\n",
    "        \n",
    "        for rule in self.validation_rules:\n",
    "            rule_result = rule(kotlin_code)\n",
    "            if not rule_result['passed']:\n",
    "                results['score'] -= rule_result['penalty']\n",
    "                if rule_result['severity'] == 'error':\n",
    "                    results['valid'] = False\n",
    "                    results['issues'].append(rule_result['message'])\n",
    "                else:\n",
    "                    results['warnings'].append(rule_result['message'])\n",
    "        \n",
    "        results['score'] = max(0, results['score'])\n",
    "        return results\n",
    "    \n",
    "    def _check_syntax_markers(self, code: str) -> Dict:\n",
    "        \"\"\"Check for basic Kotlin syntax\"\"\"\n",
    "        if 'def ' in code or '__init__' in code:\n",
    "            return {\n",
    "                'passed': False,\n",
    "                'severity': 'error',\n",
    "                'penalty': 0.5,\n",
    "                'message': 'Python syntax found in Kotlin code'\n",
    "            }\n",
    "        return {'passed': True, 'penalty': 0}\n",
    "    \n",
    "    def _check_documentation(self, code: str) -> Dict:\n",
    "        \"\"\"Check for proper Kotlin documentation\"\"\"\n",
    "        if '/**' not in code and 'fun ' in code:\n",
    "            return {\n",
    "                'passed': False,\n",
    "                'severity': 'warning',\n",
    "                'penalty': 0.1,\n",
    "                'message': 'Missing KDoc documentation'\n",
    "            }\n",
    "        return {'passed': True, 'penalty': 0}\n",
    "    \n",
    "    def _check_kotlin_idioms(self, code: str) -> Dict:\n",
    "        \"\"\"Check for Kotlin-specific idioms\"\"\"\n",
    "        # Check for proper use of val/var\n",
    "        if re.search(r'\\blet\\s+\\w+\\s*=', code):  # JavaScript style\n",
    "            return {\n",
    "                'passed': False,\n",
    "                'severity': 'error',\n",
    "                'penalty': 0.3,\n",
    "                'message': 'Non-Kotlin variable declaration found'\n",
    "            }\n",
    "        return {'passed': True, 'penalty': 0}\n",
    "    \n",
    "    def _check_type_safety(self, code: str) -> Dict:\n",
    "        \"\"\"Check for type annotations\"\"\"\n",
    "        function_matches = re.findall(r'fun\\s+\\w+\\s*\\([^)]*\\)', code)\n",
    "        for match in function_matches:\n",
    "            if ':' not in match and '()' not in match:  # Parameters should have types\n",
    "                return {\n",
    "                    'passed': False,\n",
    "                    'severity': 'warning',\n",
    "                    'penalty': 0.2,\n",
    "                    'message': 'Missing type annotations in function parameters'\n",
    "                }\n",
    "        return {'passed': True, 'penalty': 0}\n",
    "    \n",
    "    def _check_null_safety(self, code: str) -> Dict:\n",
    "        \"\"\"Check for proper null safety handling\"\"\"\n",
    "        # Simple heuristic: check for !! usage\n",
    "        if '!!' in code and 'TODO' not in code:\n",
    "            return {\n",
    "                'passed': False,\n",
    "                'severity': 'warning',\n",
    "                'penalty': 0.05,\n",
    "                'message': 'Using !! operator - consider safer null handling'\n",
    "            }\n",
    "        return {'passed': True, 'penalty': 0}\n",
    "\n",
    "# Validate translations\n",
    "validator = TranslationValidator()\n",
    "\n",
    "print(\"Translation Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for result in translation_results:\n",
    "    validation = validator.validate(result['kotlin_code'])\n",
    "    print(f\"\\nExercise: {result['exercise_id']}\")\n",
    "    print(f\"Valid: {'✅' if validation['valid'] else '❌'}\")\n",
    "    print(f\"Quality Score: {validation['score']:.2f}\")\n",
    "    \n",
    "    if validation['issues']:\n",
    "        print(\"Issues:\")\n",
    "        for issue in validation['issues']:\n",
    "            print(f\"  - {issue}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        print(\"Warnings:\")\n",
    "        for warning in validation['warnings']:\n",
    "            print(f\"  - {warning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Characteristics and Impact\n",
    "\n",
    "### 6.1 Final Dataset Statistics\n",
    "\n",
    "From the paper:\n",
    "- 15,000 Kotlin tasks\n",
    "- ~3.5 million tokens\n",
    "- 335,000 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dataset statistics\n",
    "def analyze_kexercises_dataset():\n",
    "    \"\"\"Analyze the characteristics of the KExercises dataset\"\"\"\n",
    "    \n",
    "    # Statistics from the paper\n",
    "    dataset_stats = {\n",
    "        'total_exercises': 15000,\n",
    "        'total_tokens': 3_500_000,\n",
    "        'total_lines': 335_000,\n",
    "        'avg_tokens_per_exercise': 3_500_000 / 15000,\n",
    "        'avg_lines_per_exercise': 335_000 / 15000\n",
    "    }\n",
    "    \n",
    "    # Simulate distribution of exercise characteristics\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Difficulty distribution (assumed)\n",
    "    difficulties = np.random.choice(\n",
    "        ['easy', 'medium', 'hard'], \n",
    "        size=1000, \n",
    "        p=[0.3, 0.5, 0.2]\n",
    "    )\n",
    "    \n",
    "    # Lines per exercise (log-normal distribution)\n",
    "    lines_per_exercise = np.random.lognormal(\n",
    "        mean=np.log(dataset_stats['avg_lines_per_exercise']), \n",
    "        sigma=0.5, \n",
    "        size=1000\n",
    "    )\n",
    "    \n",
    "    # Concepts coverage (simulated)\n",
    "    all_concepts = [\n",
    "        'functions', 'classes', 'loops', 'conditionals', 'arrays',\n",
    "        'strings', 'data_structures', 'algorithms', 'io', 'error_handling',\n",
    "        'generics', 'coroutines', 'lambdas', 'collections', 'null_safety'\n",
    "    ]\n",
    "    \n",
    "    concept_coverage = {concept: np.random.randint(500, 3000) for concept in all_concepts}\n",
    "    \n",
    "    return dataset_stats, difficulties, lines_per_exercise, concept_coverage\n",
    "\n",
    "stats, difficulties, lines, concepts = analyze_kexercises_dataset()\n",
    "\n",
    "# Visualize dataset characteristics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Dataset size comparison\n",
    "datasets = ['KStack', 'KStack-clean', 'KExercises']\n",
    "tokens = [3.1e9, 22e6, 3.5e6]\n",
    "lines = [293e6, 2e6, 335e3]\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, np.log10(tokens), width, label='Tokens (log10)')\n",
    "ax1.bar(x + width/2, np.log10(lines), width, label='Lines (log10)')\n",
    "ax1.set_xlabel('Dataset')\n",
    "ax1.set_ylabel('Size (log10 scale)')\n",
    "ax1.set_title('Dataset Size Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(datasets)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Difficulty distribution\n",
    "ax2 = axes[0, 1]\n",
    "diff_counts = pd.Series(difficulties).value_counts()\n",
    "ax2.pie(diff_counts.values, labels=diff_counts.index, autopct='%1.1f%%', \n",
    "        colors=['lightgreen', 'gold', 'lightcoral'])\n",
    "ax2.set_title('Exercise Difficulty Distribution')\n",
    "\n",
    "# Plot 3: Lines per exercise distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(lines, bins=50, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "ax3.axvline(stats['avg_lines_per_exercise'], color='red', linestyle='--', \n",
    "            label=f\"Average: {stats['avg_lines_per_exercise']:.1f}\")\n",
    "ax3.set_xlabel('Lines per Exercise')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Exercise Length Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Concept coverage\n",
    "ax4 = axes[1, 1]\n",
    "top_concepts = sorted(concepts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "concept_names = [c[0] for c in top_concepts]\n",
    "concept_counts = [c[1] for c in top_concepts]\n",
    "ax4.barh(concept_names, concept_counts, color='purple', alpha=0.7)\n",
    "ax4.set_xlabel('Number of Exercises')\n",
    "ax4.set_title('Top 10 Programming Concepts Coverage')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key statistics\n",
    "print(\"\\nKExercises Dataset Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key.replace('_', ' ').title():<30}: {value:,.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Impact Analysis\n",
    "\n",
    "### 7.1 Why KExercises Outperformed Other Datasets\n",
    "\n",
    "From Table II in the paper, KExercises achieved the best results across all models tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance results from Table II\n",
    "performance_results = pd.DataFrame({\n",
    "    'Model': ['CodeLlama-7B', 'CodeLlama-7B', 'CodeLlama-7B', 'CodeLlama-7B',\n",
    "              'Deepseek-7B', 'Deepseek-7B', 'Deepseek-1.3B', 'Deepseek-1.3B', 'Deepseek-1.3B'],\n",
    "    'Dataset': ['Base', 'KStack', 'KStack-clean', 'KExercises',\n",
    "                'Base', 'KExercises', 'Base', 'KStack', 'KExercises'],\n",
    "    'Pass_Rate': [26.09, 29.19, 37.89, 42.24, 40.99, 55.28, 26.71, 27.95, 36.65],\n",
    "    'Syntax_Error_Rate': [22.98, 22.98, 18.64, 19.25, 21.12, 15.53, 19.26, 19.88, 18.63],\n",
    "    'Completion_Rate': [0.388, 0.396, 0.403, 0.344, 0.403, 0.411, 0.403, 0.404, 0.388]\n",
    "})\n",
    "\n",
    "# Calculate improvements\n",
    "def calculate_improvements(df):\n",
    "    improvements = []\n",
    "    for model in ['CodeLlama-7B', 'Deepseek-7B', 'Deepseek-1.3B']:\n",
    "        model_data = df[df['Model'] == model]\n",
    "        base_pass = model_data[model_data['Dataset'] == 'Base']['Pass_Rate'].values[0]\n",
    "        kexer_data = model_data[model_data['Dataset'] == 'KExercises']\n",
    "        if len(kexer_data) > 0:\n",
    "            kexer_pass = kexer_data['Pass_Rate'].values[0]\n",
    "            improvement = kexer_pass - base_pass\n",
    "            improvements.append({\n",
    "                'Model': model,\n",
    "                'Base_Pass_Rate': base_pass,\n",
    "                'KExercises_Pass_Rate': kexer_pass,\n",
    "                'Improvement': improvement,\n",
    "                'Improvement_Pct': (improvement / base_pass) * 100\n",
    "            })\n",
    "    return pd.DataFrame(improvements)\n",
    "\n",
    "improvements_df = calculate_improvements(performance_results)\n",
    "\n",
    "# Visualize improvements\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart of absolute improvements\n",
    "x = np.arange(len(improvements_df))\n",
    "bars = ax1.bar(x, improvements_df['Improvement'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_ylabel('Pass Rate Improvement (pp)')\n",
    "ax1.set_title('Absolute Improvement with KExercises')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(improvements_df['Model'])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, imp in zip(bars, improvements_df['Improvement']):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'+{imp:.1f}pp', ha='center', va='bottom')\n",
    "\n",
    "# Comparison across all datasets for one model\n",
    "codellama_data = performance_results[performance_results['Model'] == 'CodeLlama-7B']\n",
    "datasets = codellama_data['Dataset'].values\n",
    "pass_rates = codellama_data['Pass_Rate'].values\n",
    "\n",
    "colors = ['lightcoral', 'lightsalmon', 'lightblue', 'lightgreen']\n",
    "bars = ax2.bar(range(len(datasets)), pass_rates, color=colors)\n",
    "ax2.set_xlabel('Dataset')\n",
    "ax2.set_ylabel('Pass Rate (%)')\n",
    "ax2.set_title('CodeLlama-7B Performance Across Datasets')\n",
    "ax2.set_xticks(range(len(datasets)))\n",
    "ax2.set_xticklabels(datasets)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add improvement annotations\n",
    "for i in range(1, len(pass_rates)):\n",
    "    improvement = pass_rates[i] - pass_rates[0]\n",
    "    ax2.annotate(f'+{improvement:.1f}pp',\n",
    "                xy=(i, pass_rates[i]),\n",
    "                xytext=(i, pass_rates[i] + 2),\n",
    "                ha='center',\n",
    "                fontsize=10,\n",
    "                color='darkgreen' if improvement > 0 else 'darkred')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerformance Impact Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(improvements_df.to_string(index=False))\n",
    "print(f\"\\nAverage improvement: {improvements_df['Improvement'].mean():.1f} percentage points\")\n",
    "print(f\"Average relative improvement: {improvements_df['Improvement_Pct'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Practices for Synthetic Data Generation\n",
    "\n",
    "Based on the paper's success, here are key principles for creating synthetic programming datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataGuidelines:\n",
    "    \"\"\"Best practices for synthetic programming data generation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.guidelines = {\n",
    "            \"Source Quality\": {\n",
    "                \"principle\": \"Start with high-quality source data\",\n",
    "                \"implementation\": \"Use curated exercise datasets like CodeExercises\",\n",
    "                \"impact\": \"Ensures diverse, educational examples\"\n",
    "            },\n",
    "            \"Translation Fidelity\": {\n",
    "                \"principle\": \"Preserve semantic meaning while adapting idioms\",\n",
    "                \"implementation\": \"Explicit prompt about docstrings and idioms\",\n",
    "                \"impact\": \"Natural, idiomatic target language code\"\n",
    "            },\n",
    "            \"Iterative Validation\": {\n",
    "                \"principle\": \"Monitor quality during translation process\",\n",
    "                \"implementation\": \"Batch translation with quality checks\",\n",
    "                \"impact\": \"Catch and fix systematic issues early\"\n",
    "            },\n",
    "            \"Manual Review\": {\n",
    "                \"principle\": \"Human validation of representative samples\",\n",
    "                \"implementation\": \"Expert review of diverse examples\",\n",
    "                \"impact\": \"Ensures correctness and quality\"\n",
    "            },\n",
    "            \"Diversity Coverage\": {\n",
    "                \"principle\": \"Cover broad spectrum of concepts and difficulties\",\n",
    "                \"implementation\": \"Track concept distribution, ensure balance\",\n",
    "                \"impact\": \"Model learns comprehensive language features\"\n",
    "            },\n",
    "            \"Size Optimization\": {\n",
    "                \"principle\": \"Quality over quantity for synthetic data\",\n",
    "                \"implementation\": \"15K high-quality examples > millions of noisy ones\",\n",
    "                \"impact\": \"Efficient training, better performance\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def create_translation_pipeline(self):\n",
    "        \"\"\"Create a complete pipeline following best practices\"\"\"\n",
    "        pipeline_steps = [\n",
    "            \"1. Source Data Selection\",\n",
    "            \"   - Choose educational, diverse exercises\",\n",
    "            \"   - Ensure concept coverage\",\n",
    "            \"\",\n",
    "            \"2. Translation Setup\",\n",
    "            \"   - Use consistent, explicit prompts\",\n",
    "            \"   - Include language-specific requirements\",\n",
    "            \"\",\n",
    "            \"3. Batch Processing\",\n",
    "            \"   - Translate in manageable batches\",\n",
    "            \"   - Monitor quality metrics\",\n",
    "            \"\",\n",
    "            \"4. Quality Control\",\n",
    "            \"   - Automated validation checks\",\n",
    "            \"   - Flag problematic translations\",\n",
    "            \"\",\n",
    "            \"5. Manual Review\",\n",
    "            \"   - Sample diverse examples\",\n",
    "            \"   - Expert validation\",\n",
    "            \"\",\n",
    "            \"6. Dataset Compilation\",\n",
    "            \"   - Filter low-quality translations\",\n",
    "            \"   - Balance concept distribution\",\n",
    "            \"\",\n",
    "            \"7. Testing\",\n",
    "            \"   - Train models on subsets\",\n",
    "            \"   - Validate performance improvements\"\n",
    "        ]\n",
    "        \n",
    "        return pipeline_steps\n",
    "    \n",
    "    def display_guidelines(self):\n",
    "        \"\"\"Display guidelines in structured format\"\"\"\n",
    "        print(\"Synthetic Data Generation Best Practices:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for category, details in self.guidelines.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            print(f\"  Principle: {details['principle']}\")\n",
    "            print(f\"  How: {details['implementation']}\")\n",
    "            print(f\"  Why: {details['impact']}\")\n",
    "\n",
    "guidelines = SyntheticDataGuidelines()\n",
    "guidelines.display_guidelines()\n",
    "\n",
    "print(\"\\n\\nTranslation Pipeline:\")\n",
    "print(\"=\" * 50)\n",
    "for step in guidelines.create_translation_pipeline():\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Future Directions\n",
    "\n",
    "### 9.1 From Section VII of the Paper\n",
    "\n",
    "The paper suggests focusing on \"generating more synthetic and high-quality code to cover not only coding exercises but also more realistic production tasks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize potential extensions\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define future directions\n",
    "future_directions = [\n",
    "    \"Production Code Patterns\",\n",
    "    \"Framework-Specific Examples\",\n",
    "    \"Error Handling Scenarios\",\n",
    "    \"Performance Optimizations\",\n",
    "    \"Design Pattern Implementations\",\n",
    "    \"Real-World API Integrations\",\n",
    "    \"Testing and Debugging Code\",\n",
    "    \"Concurrent Programming Examples\"\n",
    "]\n",
    "\n",
    "current_coverage = [20, 15, 30, 25, 35, 10, 40, 20]  # Simulated current coverage %\n",
    "potential_impact = [90, 85, 70, 80, 75, 95, 60, 88]  # Simulated potential impact\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = ax.scatter(current_coverage, potential_impact, \n",
    "                    s=200, alpha=0.6, c=range(len(future_directions)),\n",
    "                    cmap='viridis')\n",
    "\n",
    "# Add labels\n",
    "for i, direction in enumerate(future_directions):\n",
    "    ax.annotate(direction, (current_coverage[i], potential_impact[i]),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=9, alpha=0.8)\n",
    "\n",
    "# Add quadrant lines\n",
    "ax.axhline(y=75, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=30, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Quadrant labels\n",
    "ax.text(15, 90, 'High Impact\\nLow Coverage', ha='center', va='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "ax.text(45, 90, 'High Impact\\nHigh Coverage', ha='center', va='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "ax.set_xlabel('Current Coverage in KExercises (%)')\n",
    "ax.set_ylabel('Potential Impact on Real-World Code Generation (%)')\n",
    "ax.set_title('Future Directions for Synthetic Kotlin Data Generation')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Opportunities for Expansion:\")\n",
    "print(\"=\" * 50)\n",
    "high_impact_low_coverage = [\n",
    "    (direction, impact, coverage) \n",
    "    for direction, impact, coverage in zip(future_directions, potential_impact, current_coverage)\n",
    "    if impact > 75 and coverage < 30\n",
    "]\n",
    "\n",
    "for direction, impact, coverage in sorted(high_impact_low_coverage, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{direction:<30} Impact: {impact}%, Current: {coverage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Takeaways\n",
    "\n",
    "### What Made KExercises Successful\n",
    "\n",
    "1. **High-Quality Source**: Started with curated Python exercises\n",
    "2. **Simple but Effective Prompt**: Clear, concise translation instruction\n",
    "3. **Focus on Education**: Exercises designed for learning, not just functionality\n",
    "4. **Iterative Validation**: Continuous quality monitoring during translation\n",
    "5. **Right Size**: 15K examples proved more effective than millions of uncurated files\n",
    "\n",
    "### Key Results\n",
    "\n",
    "- **Best Performance**: 55.28% pass rate (Deepseek-7B + KExercises)\n",
    "- **Largest Improvement**: +14.29 percentage points for Deepseek-7B\n",
    "- **Consistent Gains**: All models improved with KExercises\n",
    "\n",
    "### Lessons for Other Languages\n",
    "\n",
    "This approach can be replicated for any low-resource programming language:\n",
    "1. Find high-quality exercises in a well-resourced language\n",
    "2. Use LLMs for translation with explicit instructions\n",
    "3. Validate and curate the results\n",
    "4. Focus on quality over quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Data preparation\n",
    "methods = ['Raw GitHub\\n(KStack)', 'Quality Filtered\\n(KStack-clean)', 'Synthetic Exercises\\n(KExercises)']\n",
    "improvements = [3.1, 11.8, 16.15]  # Average improvements across models\n",
    "dataset_sizes = [4000000, 25000, 15000]\n",
    "\n",
    "# Create bubble chart\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "for i, (method, improvement, size) in enumerate(zip(methods, improvements, dataset_sizes)):\n",
    "    # Bubble size proportional to log of dataset size\n",
    "    bubble_size = np.log10(size) * 100\n",
    "    ax.scatter(i, improvement, s=bubble_size, c=colors[i], alpha=0.7, edgecolors='black')\n",
    "    \n",
    "    # Add size label\n",
    "    if size >= 1000000:\n",
    "        size_label = f\"{size/1000000:.1f}M\"\n",
    "    else:\n",
    "        size_label = f\"{size/1000:.0f}K\"\n",
    "    ax.text(i, improvement + 1, size_label, ha='center', fontsize=10)\n",
    "\n",
    "ax.set_xticks(range(len(methods)))\n",
    "ax.set_xticklabels(methods)\n",
    "ax.set_ylabel('Average Pass Rate Improvement (pp)')\n",
    "ax.set_title('Quality vs Quantity: Dataset Impact on Kotlin Code Generation')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 20)\n",
    "\n",
    "# Add annotation\n",
    "ax.annotate('Synthetic data wins!\\nQuality > Quantity',\n",
    "            xy=(2, improvements[2]), xytext=(1.5, 18),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
    "            fontsize=12, ha='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Synthetic data generation through translation is a powerful technique\")\n",
    "print(\"for improving code generation in low-resource languages.\")\n",
    "print(\"\\nThe key is focusing on quality, diversity, and educational value\")\n",
    "print(\"rather than simply maximizing dataset size.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}